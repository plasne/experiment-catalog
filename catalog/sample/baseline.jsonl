{"name": "baseline", "hypothesis": "start-of-sprint baseline", "created": "2025-12-04T14:00:58.9386276Z", "Sets": []}
{"ref": "TQ105-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 33.424506}, "meta_inference_prompt_tokens": {"value": 59802.0}, "meta_inference_completion_tokens": {"value": 1534.0}, "meta_inference_tool_call_count": {"value": 3.0}, "meta_inference_prompt_cost": {"value": 0.0119604}, "meta_inference_completion_cost": {"value": 0.0024544}, "meta_eval_time": {"value": 0.002}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:32:11.166769Z"}
{"ref": "TQ103", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.904792}, "meta_inference_prompt_tokens": {"value": 11622.0}, "meta_inference_completion_tokens": {"value": 618.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023244}, "meta_inference_completion_cost": {"value": 0.0009888}, "meta_eval_time": {"value": 16.399}, "meta_eval_prompt_tokens": {"value": 6100.0}, "meta_eval_completion_tokens": {"value": 1597.0}, "meta_eval_prompt_cost": {"value": 0.001952}, "meta_eval_completion_cost": {"value": 0.00204416}}, "created": "2025-12-10T21:32:15.0503886Z"}
{"ref": "TQ103", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 13.600519}, "meta_inference_prompt_tokens": {"value": 11617.0}, "meta_inference_completion_tokens": {"value": 522.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023234}, "meta_inference_completion_cost": {"value": 0.0008352}, "meta_eval_time": {"value": 10.008}, "meta_eval_prompt_tokens": {"value": 5622.0}, "meta_eval_completion_tokens": {"value": 713.0}, "meta_eval_prompt_cost": {"value": 0.00179904}, "meta_eval_completion_cost": {"value": 0.00091264}}, "created": "2025-12-10T21:32:13.0857814Z"}
{"ref": "TQ103", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.032243}, "meta_inference_prompt_tokens": {"value": 12210.0}, "meta_inference_completion_tokens": {"value": 699.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002442}, "meta_inference_completion_cost": {"value": 0.0011184}, "meta_eval_time": {"value": 14.653}, "meta_eval_prompt_tokens": {"value": 6503.0}, "meta_eval_completion_tokens": {"value": 1143.0}, "meta_eval_prompt_cost": {"value": 0.00208096}, "meta_eval_completion_cost": {"value": 0.00146304}}, "created": "2025-12-10T21:32:17.0502012Z"}
{"ref": "TQ104", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.25}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.25896}, "meta_inference_prompt_tokens": {"value": 8724.0}, "meta_inference_completion_tokens": {"value": 982.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0017448}, "meta_inference_completion_cost": {"value": 0.0015712}, "meta_eval_time": {"value": 20.176}, "meta_eval_prompt_tokens": {"value": 5237.0}, "meta_eval_completion_tokens": {"value": 2022.0}, "meta_eval_prompt_cost": {"value": 0.00167584}, "meta_eval_completion_cost": {"value": 0.00258816}}, "created": "2025-12-10T21:32:17.9843903Z"}
{"ref": "TQ101", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.155162}, "meta_inference_prompt_tokens": {"value": 12216.0}, "meta_inference_completion_tokens": {"value": 963.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024432}, "meta_inference_completion_cost": {"value": 0.0015408}, "meta_eval_time": {"value": 20.748}, "meta_eval_prompt_tokens": {"value": 7280.0}, "meta_eval_completion_tokens": {"value": 2090.0}, "meta_eval_prompt_cost": {"value": 0.0023296}, "meta_eval_completion_cost": {"value": 0.0026752}}, "created": "2025-12-10T21:32:18.1801593Z"}
{"ref": "TQ103", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.434474}, "meta_inference_prompt_tokens": {"value": 12966.0}, "meta_inference_completion_tokens": {"value": 662.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025932}, "meta_inference_completion_cost": {"value": 0.0010592}, "meta_eval_time": {"value": 12.792}, "meta_eval_prompt_tokens": {"value": 7015.0}, "meta_eval_completion_tokens": {"value": 1042.0}, "meta_eval_prompt_cost": {"value": 0.0022448}, "meta_eval_completion_cost": {"value": 0.00133376}}, "created": "2025-12-10T21:32:19.4921697Z"}
{"ref": "TQ104", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.026935}, "meta_inference_prompt_tokens": {"value": 9204.0}, "meta_inference_completion_tokens": {"value": 822.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018408}, "meta_inference_completion_cost": {"value": 0.0013152}, "meta_eval_time": {"value": 14.166}, "meta_eval_prompt_tokens": {"value": 4889.0}, "meta_eval_completion_tokens": {"value": 1181.0}, "meta_eval_prompt_cost": {"value": 0.00156448}, "meta_eval_completion_cost": {"value": 0.00151168}}, "created": "2025-12-10T21:32:20.3176574Z"}
{"ref": "TQ101", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.629714}, "meta_inference_prompt_tokens": {"value": 12195.0}, "meta_inference_completion_tokens": {"value": 1083.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002439}, "meta_inference_completion_cost": {"value": 0.0017328}, "meta_eval_time": {"value": 23.137}, "meta_eval_prompt_tokens": {"value": 7393.0}, "meta_eval_completion_tokens": {"value": 2041.0}, "meta_eval_prompt_cost": {"value": 0.00236576}, "meta_eval_completion_cost": {"value": 0.00261248}}, "created": "2025-12-10T21:32:20.7485866Z"}
{"ref": "TQ102", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.782693}, "meta_inference_prompt_tokens": {"value": 10610.0}, "meta_inference_completion_tokens": {"value": 1059.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002122}, "meta_inference_completion_cost": {"value": 0.0016944}, "meta_eval_time": {"value": 23.484}, "meta_eval_prompt_tokens": {"value": 5731.0}, "meta_eval_completion_tokens": {"value": 2175.0}, "meta_eval_prompt_cost": {"value": 0.00183392}, "meta_eval_completion_cost": {"value": 0.002784}}, "created": "2025-12-10T21:32:20.9495941Z"}
{"ref": "TQ102", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.954545454545454}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.151208}, "meta_inference_prompt_tokens": {"value": 10046.0}, "meta_inference_completion_tokens": {"value": 1968.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020092}, "meta_inference_completion_cost": {"value": 0.0031488}, "meta_eval_time": {"value": 23.563}, "meta_eval_prompt_tokens": {"value": 5399.0}, "meta_eval_completion_tokens": {"value": 2453.0}, "meta_eval_prompt_cost": {"value": 0.00172768}, "meta_eval_completion_cost": {"value": 0.00313984}}, "created": "2025-12-10T21:32:21.4161818Z"}
{"ref": "TQ104", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.166666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.89133}, "meta_inference_prompt_tokens": {"value": 10328.0}, "meta_inference_completion_tokens": {"value": 787.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020656}, "meta_inference_completion_cost": {"value": 0.0012592}, "meta_eval_time": {"value": 16.926}, "meta_eval_prompt_tokens": {"value": 5919.0}, "meta_eval_completion_tokens": {"value": 1613.0}, "meta_eval_prompt_cost": {"value": 0.00189408}, "meta_eval_completion_cost": {"value": 0.00206464}}, "created": "2025-12-10T21:32:23.1079083Z"}
{"ref": "TQ100", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.764705882352941}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 24.739971}, "meta_inference_prompt_tokens": {"value": 12032.0}, "meta_inference_completion_tokens": {"value": 1505.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024064}, "meta_inference_completion_cost": {"value": 0.002408}, "meta_eval_time": {"value": 25.095}, "meta_eval_prompt_tokens": {"value": 7388.0}, "meta_eval_completion_tokens": {"value": 2248.0}, "meta_eval_prompt_cost": {"value": 0.00236416}, "meta_eval_completion_cost": {"value": 0.00287744}}, "created": "2025-12-10T21:32:23.8861472Z"}
{"ref": "TQ104", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 0.764705882352941}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.250024}, "meta_inference_prompt_tokens": {"value": 10829.0}, "meta_inference_completion_tokens": {"value": 723.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021658}, "meta_inference_completion_cost": {"value": 0.0011568}, "meta_eval_time": {"value": 20.876}, "meta_eval_prompt_tokens": {"value": 6821.0}, "meta_eval_completion_tokens": {"value": 1967.0}, "meta_eval_prompt_cost": {"value": 0.00218272}, "meta_eval_completion_cost": {"value": 0.00251776}}, "created": "2025-12-10T21:32:23.9722018Z"}
{"ref": "TQ106", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.375}, "generation_factuality_precision": {"value": 0.230769230769231}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.125504}, "meta_inference_prompt_tokens": {"value": 14148.0}, "meta_inference_completion_tokens": {"value": 608.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028296}, "meta_inference_completion_cost": {"value": 0.0009728}, "meta_eval_time": {"value": 19.041}, "meta_eval_prompt_tokens": {"value": 8084.0}, "meta_eval_completion_tokens": {"value": 1726.0}, "meta_eval_prompt_cost": {"value": 0.00258688}, "meta_eval_completion_cost": {"value": 0.00220928}}, "created": "2025-12-10T21:32:25.6209193Z"}
{"ref": "TQ100", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.210526315789474}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.845982868370527}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.117647058823529}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 37.470425}, "meta_inference_prompt_tokens": {"value": 29038.0}, "meta_inference_completion_tokens": {"value": 2160.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0058076}, "meta_inference_completion_cost": {"value": 0.003456}, "meta_eval_time": {"value": 27.711}, "meta_eval_prompt_tokens": {"value": 12367.0}, "meta_eval_completion_tokens": {"value": 2544.0}, "meta_eval_prompt_cost": {"value": 0.00395744}, "meta_eval_completion_cost": {"value": 0.00325632}}, "created": "2025-12-10T21:32:26.3137992Z"}
{"ref": "TQ102", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.899826}, "meta_inference_prompt_tokens": {"value": 8977.0}, "meta_inference_completion_tokens": {"value": 1111.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0017954}, "meta_inference_completion_cost": {"value": 0.0017776}, "meta_eval_time": {"value": 19.791}, "meta_eval_prompt_tokens": {"value": 4562.0}, "meta_eval_completion_tokens": {"value": 1775.0}, "meta_eval_prompt_cost": {"value": 0.00145984}, "meta_eval_completion_cost": {"value": 0.002272}}, "created": "2025-12-10T21:32:26.4871341Z"}
{"ref": "TQ101", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.695652173913044}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.966663}, "meta_inference_prompt_tokens": {"value": 12196.0}, "meta_inference_completion_tokens": {"value": 1291.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024392}, "meta_inference_completion_cost": {"value": 0.0020656}, "meta_eval_time": {"value": 28.682}, "meta_eval_prompt_tokens": {"value": 7702.0}, "meta_eval_completion_tokens": {"value": 2705.0}, "meta_eval_prompt_cost": {"value": 0.00246464}, "meta_eval_completion_cost": {"value": 0.0034624}}, "created": "2025-12-10T21:32:26.5189508Z"}
{"ref": "TQ10", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.973684210526316}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.213863}, "meta_inference_prompt_tokens": {"value": 13393.0}, "meta_inference_completion_tokens": {"value": 1502.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026786}, "meta_inference_completion_cost": {"value": 0.0024032}, "meta_eval_time": {"value": 32.251}, "meta_eval_prompt_tokens": {"value": 8745.0}, "meta_eval_completion_tokens": {"value": 3288.0}, "meta_eval_prompt_cost": {"value": 0.0027984}, "meta_eval_completion_cost": {"value": 0.00420864}}, "created": "2025-12-10T21:32:26.5572358Z"}
{"ref": "TQ106", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.717528}, "meta_inference_prompt_tokens": {"value": 13995.0}, "meta_inference_completion_tokens": {"value": 700.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002799}, "meta_inference_completion_cost": {"value": 0.00112}, "meta_eval_time": {"value": 20.691}, "meta_eval_prompt_tokens": {"value": 8271.0}, "meta_eval_completion_tokens": {"value": 1858.0}, "meta_eval_prompt_cost": {"value": 0.00264672}, "meta_eval_completion_cost": {"value": 0.00237824}}, "created": "2025-12-10T21:32:26.9716933Z"}
{"ref": "TQ102", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.261932}, "meta_inference_prompt_tokens": {"value": 9706.0}, "meta_inference_completion_tokens": {"value": 1465.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019412}, "meta_inference_completion_cost": {"value": 0.002344}, "meta_eval_time": {"value": 24.395}, "meta_eval_prompt_tokens": {"value": 5092.0}, "meta_eval_completion_tokens": {"value": 2537.0}, "meta_eval_prompt_cost": {"value": 0.00162944}, "meta_eval_completion_cost": {"value": 0.00324736}}, "created": "2025-12-10T21:32:27.3276082Z"}
{"ref": "TQ106", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.269855}, "meta_inference_prompt_tokens": {"value": 13193.0}, "meta_inference_completion_tokens": {"value": 805.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026386}, "meta_inference_completion_cost": {"value": 0.001288}, "meta_eval_time": {"value": 20.257}, "meta_eval_prompt_tokens": {"value": 7305.0}, "meta_eval_completion_tokens": {"value": 1808.0}, "meta_eval_prompt_cost": {"value": 0.0023376}, "meta_eval_completion_cost": {"value": 0.00231424}}, "created": "2025-12-10T21:32:27.381829Z"}
{"ref": "TQ101", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.826086956521739}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.242715}, "meta_inference_prompt_tokens": {"value": 12195.0}, "meta_inference_completion_tokens": {"value": 1127.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002439}, "meta_inference_completion_cost": {"value": 0.0018032}, "meta_eval_time": {"value": 30.29}, "meta_eval_prompt_tokens": {"value": 7581.0}, "meta_eval_completion_tokens": {"value": 2471.0}, "meta_eval_prompt_cost": {"value": 0.00242592}, "meta_eval_completion_cost": {"value": 0.00316288}}, "created": "2025-12-10T21:32:27.9853017Z"}
{"ref": "TQ107", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.685714285714286}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 23.408621}, "meta_inference_prompt_tokens": {"value": 10860.0}, "meta_inference_completion_tokens": {"value": 1026.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002172}, "meta_inference_completion_cost": {"value": 0.0016416}, "meta_eval_time": {"value": 22.108}, "meta_eval_prompt_tokens": {"value": 5745.0}, "meta_eval_completion_tokens": {"value": 2188.0}, "meta_eval_prompt_cost": {"value": 0.0018384}, "meta_eval_completion_cost": {"value": 0.00280064}}, "created": "2025-12-10T21:32:28.3730176Z"}
{"ref": "TQ103", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.605405}, "meta_inference_prompt_tokens": {"value": 11623.0}, "meta_inference_completion_tokens": {"value": 640.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023246}, "meta_inference_completion_cost": {"value": 0.001024}, "meta_eval_time": {"value": 11.868}, "meta_eval_prompt_tokens": {"value": 5955.0}, "meta_eval_completion_tokens": {"value": 1151.0}, "meta_eval_prompt_cost": {"value": 0.0019056}, "meta_eval_completion_cost": {"value": 0.00147328}}, "created": "2025-12-10T21:32:30.0844949Z"}
{"ref": "TQ100", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.622398159651221}, "generation_faithfulness": {"value": 0.818181818181818}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.665265}, "meta_inference_prompt_tokens": {"value": 11774.0}, "meta_inference_completion_tokens": {"value": 1393.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023548}, "meta_inference_completion_cost": {"value": 0.0022288}, "meta_eval_time": {"value": 33.033}, "meta_eval_prompt_tokens": {"value": 7556.0}, "meta_eval_completion_tokens": {"value": 3187.0}, "meta_eval_prompt_cost": {"value": 0.00241792}, "meta_eval_completion_cost": {"value": 0.00407936}}, "created": "2025-12-10T21:32:31.5848078Z"}
{"ref": "TQ100", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 0.95}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 25.627388}, "meta_inference_prompt_tokens": {"value": 12576.0}, "meta_inference_completion_tokens": {"value": 1456.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025152}, "meta_inference_completion_cost": {"value": 0.0023296}, "meta_eval_time": {"value": 28.64}, "meta_eval_prompt_tokens": {"value": 7935.0}, "meta_eval_completion_tokens": {"value": 2510.0}, "meta_eval_prompt_cost": {"value": 0.0025392}, "meta_eval_completion_cost": {"value": 0.0032128}}, "created": "2025-12-10T21:32:31.5854056Z"}
{"ref": "TQ108", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.06160631164485}, "generation_faithfulness": {"value": 0.807692307692308}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.759208}, "meta_inference_prompt_tokens": {"value": 10385.0}, "meta_inference_completion_tokens": {"value": 1223.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002077}, "meta_inference_completion_cost": {"value": 0.0019568}, "meta_eval_time": {"value": 26.123}, "meta_eval_prompt_tokens": {"value": 5958.0}, "meta_eval_completion_tokens": {"value": 2373.0}, "meta_eval_prompt_cost": {"value": 0.00190656}, "meta_eval_completion_cost": {"value": 0.00303744}}, "created": "2025-12-10T21:32:32.5768337Z"}
{"ref": "TQ105-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.898921}, "meta_inference_prompt_tokens": {"value": 12643.0}, "meta_inference_completion_tokens": {"value": 1246.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025286}, "meta_inference_completion_cost": {"value": 0.0019936}, "meta_eval_time": {"value": 12.695}, "meta_eval_prompt_tokens": {"value": 6845.0}, "meta_eval_completion_tokens": {"value": 1017.0}, "meta_eval_prompt_cost": {"value": 0.0021904}, "meta_eval_completion_cost": {"value": 0.00130176}}, "created": "2025-12-10T21:32:33.0513338Z"}
{"ref": "TQ107", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.708333333333334}, "generation_factuality_f1": {"value": 0.685714285714286}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 27.796051}, "meta_inference_prompt_tokens": {"value": 11724.0}, "meta_inference_completion_tokens": {"value": 1662.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023448}, "meta_inference_completion_cost": {"value": 0.0026592}, "meta_eval_time": {"value": 26.718}, "meta_eval_prompt_tokens": {"value": 7118.0}, "meta_eval_completion_tokens": {"value": 2623.0}, "meta_eval_prompt_cost": {"value": 0.00227776}, "meta_eval_completion_cost": {"value": 0.00335744}}, "created": "2025-12-10T21:32:33.305409Z"}
{"ref": "TQ108", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.522769}, "meta_inference_prompt_tokens": {"value": 10243.0}, "meta_inference_completion_tokens": {"value": 1679.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020486}, "meta_inference_completion_cost": {"value": 0.0026864}, "meta_eval_time": {"value": 35.756}, "meta_eval_prompt_tokens": {"value": 6209.0}, "meta_eval_completion_tokens": {"value": 3322.0}, "meta_eval_prompt_cost": {"value": 0.00198688}, "meta_eval_completion_cost": {"value": 0.00425216}}, "created": "2025-12-10T21:32:34.7085331Z"}
{"ref": "TQ106", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.797368}, "meta_inference_prompt_tokens": {"value": 13378.0}, "meta_inference_completion_tokens": {"value": 662.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026756}, "meta_inference_completion_cost": {"value": 0.0010592}, "meta_eval_time": {"value": 17.015}, "meta_eval_prompt_tokens": {"value": 7500.0}, "meta_eval_completion_tokens": {"value": 1726.0}, "meta_eval_prompt_cost": {"value": 0.0024}, "meta_eval_completion_cost": {"value": 0.00220928}}, "created": "2025-12-10T21:32:36.5492769Z"}
{"ref": "TQ10", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.606062}, "meta_inference_prompt_tokens": {"value": 12926.0}, "meta_inference_completion_tokens": {"value": 1156.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025852}, "meta_inference_completion_cost": {"value": 0.0018496}, "meta_eval_time": {"value": 39.108}, "meta_eval_prompt_tokens": {"value": 8646.0}, "meta_eval_completion_tokens": {"value": 4029.0}, "meta_eval_prompt_cost": {"value": 0.00276672}, "meta_eval_completion_cost": {"value": 0.00515712}}, "created": "2025-12-10T21:32:36.8693789Z"}
{"ref": "TQ106", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.151441}, "meta_inference_prompt_tokens": {"value": 12704.0}, "meta_inference_completion_tokens": {"value": 951.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025408}, "meta_inference_completion_cost": {"value": 0.0015216}, "meta_eval_time": {"value": 20.485}, "meta_eval_prompt_tokens": {"value": 7282.0}, "meta_eval_completion_tokens": {"value": 1870.0}, "meta_eval_prompt_cost": {"value": 0.00233024}, "meta_eval_completion_cost": {"value": 0.0023936}}, "created": "2025-12-10T21:32:37.5683829Z"}
{"ref": "TQ105-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 99.997731}, "meta_inference_prompt_tokens": {"value": 335358.0}, "meta_inference_completion_tokens": {"value": 4792.0}, "meta_inference_tool_call_count": {"value": 9.0}, "meta_inference_prompt_cost": {"value": 0.0670716}, "meta_inference_completion_cost": {"value": 0.0076672}, "meta_eval_time": {"value": 26.821}, "meta_eval_prompt_tokens": {"value": 37235.0}, "meta_eval_completion_tokens": {"value": 2844.0}, "meta_eval_prompt_cost": {"value": 0.0119152}, "meta_eval_completion_cost": {"value": 0.00364032}}, "created": "2025-12-10T21:32:37.7951443Z"}
{"ref": "TQ105-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.017788}, "meta_inference_prompt_tokens": {"value": 12830.0}, "meta_inference_completion_tokens": {"value": 1109.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002566}, "meta_inference_completion_cost": {"value": 0.0017744}, "meta_eval_time": {"value": 20.861}, "meta_eval_prompt_tokens": {"value": 7423.0}, "meta_eval_completion_tokens": {"value": 1694.0}, "meta_eval_prompt_cost": {"value": 0.00237536}, "meta_eval_completion_cost": {"value": 0.00216832}}, "created": "2025-12-10T21:32:37.9479088Z"}
{"ref": "TQ112", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.692307692307692}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.101103}, "meta_inference_prompt_tokens": {"value": 10402.0}, "meta_inference_completion_tokens": {"value": 1002.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020804}, "meta_inference_completion_cost": {"value": 0.0016032}, "meta_eval_time": {"value": 16.057}, "meta_eval_prompt_tokens": {"value": 5111.0}, "meta_eval_completion_tokens": {"value": 1496.0}, "meta_eval_prompt_cost": {"value": 0.00163552}, "meta_eval_completion_cost": {"value": 0.00191488}}, "created": "2025-12-10T21:32:39.1923624Z"}
{"ref": "TQ112", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.838528}, "meta_inference_prompt_tokens": {"value": 11782.0}, "meta_inference_completion_tokens": {"value": 1716.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023564}, "meta_inference_completion_cost": {"value": 0.0027456}, "meta_eval_time": {"value": 13.531}, "meta_eval_prompt_tokens": {"value": 6288.0}, "meta_eval_completion_tokens": {"value": 1168.0}, "meta_eval_prompt_cost": {"value": 0.00201216}, "meta_eval_completion_cost": {"value": 0.00149504}}, "created": "2025-12-10T21:32:39.1944509Z"}
{"ref": "TQ107", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.558139534883721}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 28.174241}, "meta_inference_prompt_tokens": {"value": 12613.0}, "meta_inference_completion_tokens": {"value": 1309.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025226}, "meta_inference_completion_cost": {"value": 0.0020944}, "meta_eval_time": {"value": 34.807}, "meta_eval_prompt_tokens": {"value": 8061.0}, "meta_eval_completion_tokens": {"value": 3096.0}, "meta_eval_prompt_cost": {"value": 0.00257952}, "meta_eval_completion_cost": {"value": 0.00396288}}, "created": "2025-12-10T21:32:41.1640378Z"}
{"ref": "TQ10", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.232224}, "meta_inference_prompt_tokens": {"value": 9983.0}, "meta_inference_completion_tokens": {"value": 1487.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019966}, "meta_inference_completion_cost": {"value": 0.0023792}, "meta_eval_time": {"value": 40.648}, "meta_eval_prompt_tokens": {"value": 6856.0}, "meta_eval_completion_tokens": {"value": 3830.0}, "meta_eval_prompt_cost": {"value": 0.00219392}, "meta_eval_completion_cost": {"value": 0.0049024}}, "created": "2025-12-10T21:32:43.2331265Z"}
{"ref": "TQ107", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 38.275852}, "meta_inference_prompt_tokens": {"value": 11029.0}, "meta_inference_completion_tokens": {"value": 2194.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022058}, "meta_inference_completion_cost": {"value": 0.0035104}, "meta_eval_time": {"value": 39.752}, "meta_eval_prompt_tokens": {"value": 7104.0}, "meta_eval_completion_tokens": {"value": 3688.0}, "meta_eval_prompt_cost": {"value": 0.00227328}, "meta_eval_completion_cost": {"value": 0.00472064}}, "created": "2025-12-10T21:32:46.20244Z"}
{"ref": "TQ100", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.964263086904791}, "generation_faithfulness": {"value": 0.964285714285714}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.253095}, "meta_inference_prompt_tokens": {"value": 11987.0}, "meta_inference_completion_tokens": {"value": 1629.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023974}, "meta_inference_completion_cost": {"value": 0.0026064}, "meta_eval_time": {"value": 28.3}, "meta_eval_prompt_tokens": {"value": 7564.0}, "meta_eval_completion_tokens": {"value": 2600.0}, "meta_eval_prompt_cost": {"value": 0.00242048}, "meta_eval_completion_cost": {"value": 0.003328}}, "created": "2025-12-10T21:32:46.3390398Z"}
{"ref": "TQ112", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.692307692307692}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.015504}, "meta_inference_prompt_tokens": {"value": 11085.0}, "meta_inference_completion_tokens": {"value": 1322.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002217}, "meta_inference_completion_cost": {"value": 0.0021152}, "meta_eval_time": {"value": 16.312}, "meta_eval_prompt_tokens": {"value": 5986.0}, "meta_eval_completion_tokens": {"value": 1624.0}, "meta_eval_prompt_cost": {"value": 0.00191552}, "meta_eval_completion_cost": {"value": 0.00207872}}, "created": "2025-12-10T21:32:47.9351305Z"}
{"ref": "TQ107", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 0.90625}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 35.659954}, "meta_inference_prompt_tokens": {"value": 11532.0}, "meta_inference_completion_tokens": {"value": 1527.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023064}, "meta_inference_completion_cost": {"value": 0.0024432}, "meta_eval_time": {"value": 31.4}, "meta_eval_prompt_tokens": {"value": 7018.0}, "meta_eval_completion_tokens": {"value": 3135.0}, "meta_eval_prompt_cost": {"value": 0.00224576}, "meta_eval_completion_cost": {"value": 0.0040128}}, "created": "2025-12-10T21:32:48.4772364Z"}
{"ref": "TQ10", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.281898}, "meta_inference_prompt_tokens": {"value": 12744.0}, "meta_inference_completion_tokens": {"value": 1718.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025488}, "meta_inference_completion_cost": {"value": 0.0027488}, "meta_eval_time": {"value": 41.238}, "meta_eval_prompt_tokens": {"value": 8530.0}, "meta_eval_completion_tokens": {"value": 3584.0}, "meta_eval_prompt_cost": {"value": 0.0027296}, "meta_eval_completion_cost": {"value": 0.00458752}}, "created": "2025-12-10T21:32:48.4784411Z"}
{"ref": "TQ113", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.350877192982456}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 21.648153}, "meta_inference_prompt_tokens": {"value": 10055.0}, "meta_inference_completion_tokens": {"value": 1231.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002011}, "meta_inference_completion_cost": {"value": 0.0019696}, "meta_eval_time": {"value": 25.645}, "meta_eval_prompt_tokens": {"value": 5527.0}, "meta_eval_completion_tokens": {"value": 2421.0}, "meta_eval_prompt_cost": {"value": 0.00176864}, "meta_eval_completion_cost": {"value": 0.00309888}}, "created": "2025-12-10T21:32:49.212362Z"}
{"ref": "TQ114", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.425413}, "meta_inference_prompt_tokens": {"value": 11464.0}, "meta_inference_completion_tokens": {"value": 1288.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022928}, "meta_inference_completion_cost": {"value": 0.0020608}, "meta_eval_time": {"value": 26.461}, "meta_eval_prompt_tokens": {"value": 6517.0}, "meta_eval_completion_tokens": {"value": 2540.0}, "meta_eval_prompt_cost": {"value": 0.00208544}, "meta_eval_completion_cost": {"value": 0.0032512}}, "created": "2025-12-10T21:32:50.4197959Z"}
{"ref": "TQ110", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.936883}, "meta_inference_prompt_tokens": {"value": 13102.0}, "meta_inference_completion_tokens": {"value": 1358.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026204}, "meta_inference_completion_cost": {"value": 0.0021728}, "meta_eval_time": {"value": 25.635}, "meta_eval_prompt_tokens": {"value": 8710.0}, "meta_eval_completion_tokens": {"value": 2772.0}, "meta_eval_prompt_cost": {"value": 0.0027872}, "meta_eval_completion_cost": {"value": 0.00354816}}, "created": "2025-12-10T21:32:51.9879534Z"}
{"ref": "TQ109-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.2}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.2}, "meta_inference_time": {"value": 27.434924}, "meta_inference_prompt_tokens": {"value": 12711.0}, "meta_inference_completion_tokens": {"value": 1211.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025422}, "meta_inference_completion_cost": {"value": 0.0019376}, "meta_eval_time": {"value": 28.021}, "meta_eval_prompt_tokens": {"value": 7867.0}, "meta_eval_completion_tokens": {"value": 2749.0}, "meta_eval_prompt_cost": {"value": 0.00251744}, "meta_eval_completion_cost": {"value": 0.00351872}}, "created": "2025-12-10T21:32:54.5804978Z"}
{"ref": "TQ105-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 50.859618}, "meta_inference_prompt_tokens": {"value": 49712.0}, "meta_inference_completion_tokens": {"value": 2945.0}, "meta_inference_tool_call_count": {"value": 3.0}, "meta_inference_prompt_cost": {"value": 0.0099424}, "meta_inference_completion_cost": {"value": 0.004712}, "meta_eval_time": {"value": 37.683}, "meta_eval_prompt_tokens": {"value": 13714.0}, "meta_eval_completion_tokens": {"value": 3669.0}, "meta_eval_prompt_cost": {"value": 0.00438848}, "meta_eval_completion_cost": {"value": 0.00469632}}, "created": "2025-12-10T21:32:54.7897489Z"}
{"ref": "TQ115", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.074435}, "meta_inference_prompt_tokens": {"value": 11804.0}, "meta_inference_completion_tokens": {"value": 582.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023608}, "meta_inference_completion_cost": {"value": 0.0009312}, "meta_eval_time": {"value": 8.478}, "meta_eval_prompt_tokens": {"value": 6129.0}, "meta_eval_completion_tokens": {"value": 722.0}, "meta_eval_prompt_cost": {"value": 0.00196128}, "meta_eval_completion_cost": {"value": 0.00092416}}, "created": "2025-12-10T21:32:54.8635071Z"}
{"ref": "TQ111", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.769230769230769}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 27.622025}, "meta_inference_prompt_tokens": {"value": 12697.0}, "meta_inference_completion_tokens": {"value": 1404.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025394}, "meta_inference_completion_cost": {"value": 0.0022464}, "meta_eval_time": {"value": 27.899}, "meta_eval_prompt_tokens": {"value": 8017.0}, "meta_eval_completion_tokens": {"value": 2508.0}, "meta_eval_prompt_cost": {"value": 0.00256544}, "meta_eval_completion_cost": {"value": 0.00321024}}, "created": "2025-12-10T21:32:54.9070176Z"}
{"ref": "TQ108", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.797816}, "meta_inference_prompt_tokens": {"value": 10052.0}, "meta_inference_completion_tokens": {"value": 1449.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020104}, "meta_inference_completion_cost": {"value": 0.0023184}, "meta_eval_time": {"value": 32.31}, "meta_eval_prompt_tokens": {"value": 5993.0}, "meta_eval_completion_tokens": {"value": 3250.0}, "meta_eval_prompt_cost": {"value": 0.00191776}, "meta_eval_completion_cost": {"value": 0.00416}}, "created": "2025-12-10T21:32:55.6526986Z"}
{"ref": "TQ108", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.092078}, "meta_inference_prompt_tokens": {"value": 10016.0}, "meta_inference_completion_tokens": {"value": 1326.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020032}, "meta_inference_completion_cost": {"value": 0.0021216}, "meta_eval_time": {"value": 34.903}, "meta_eval_prompt_tokens": {"value": 5772.0}, "meta_eval_completion_tokens": {"value": 3026.0}, "meta_eval_prompt_cost": {"value": 0.00184704}, "meta_eval_completion_cost": {"value": 0.00387328}}, "created": "2025-12-10T21:32:55.7253455Z"}
{"ref": "TQ115", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.710169}, "meta_inference_prompt_tokens": {"value": 8751.0}, "meta_inference_completion_tokens": {"value": 838.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0017502}, "meta_inference_completion_cost": {"value": 0.0013408}, "meta_eval_time": {"value": 7.59}, "meta_eval_prompt_tokens": {"value": 4519.0}, "meta_eval_completion_tokens": {"value": 648.0}, "meta_eval_prompt_cost": {"value": 0.00144608}, "meta_eval_completion_cost": {"value": 0.00082944}}, "created": "2025-12-10T21:32:56.8508535Z"}
{"ref": "TQ10", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.332014}, "meta_inference_prompt_tokens": {"value": 11229.0}, "meta_inference_completion_tokens": {"value": 1290.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022458}, "meta_inference_completion_cost": {"value": 0.002064}, "meta_eval_time": {"value": 36.164}, "meta_eval_prompt_tokens": {"value": 6969.0}, "meta_eval_completion_tokens": {"value": 3631.0}, "meta_eval_prompt_cost": {"value": 0.00223008}, "meta_eval_completion_cost": {"value": 0.00464768}}, "created": "2025-12-10T21:32:57.1736662Z"}
{"ref": "TQ115", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.306683}, "meta_inference_prompt_tokens": {"value": 6228.0}, "meta_inference_completion_tokens": {"value": 669.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0012456}, "meta_inference_completion_cost": {"value": 0.0010704}, "meta_eval_time": {"value": 5.461}, "meta_eval_prompt_tokens": {"value": 2887.0}, "meta_eval_completion_tokens": {"value": 409.0}, "meta_eval_prompt_cost": {"value": 0.00092384}, "meta_eval_completion_cost": {"value": 0.00052352}}, "created": "2025-12-10T21:32:57.4929664Z"}
{"ref": "TQ109-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.227787}, "meta_inference_prompt_tokens": {"value": 11851.0}, "meta_inference_completion_tokens": {"value": 1077.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023702}, "meta_inference_completion_cost": {"value": 0.0017232}, "meta_eval_time": {"value": 30.984}, "meta_eval_prompt_tokens": {"value": 6909.0}, "meta_eval_completion_tokens": {"value": 3076.0}, "meta_eval_prompt_cost": {"value": 0.00221088}, "meta_eval_completion_cost": {"value": 0.00393728}}, "created": "2025-12-10T21:32:58.4063856Z"}
{"ref": "TQ112", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.428571428571429}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.593577}, "meta_inference_prompt_tokens": {"value": 10199.0}, "meta_inference_completion_tokens": {"value": 878.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020398}, "meta_inference_completion_cost": {"value": 0.0014048}, "meta_eval_time": {"value": 10.53}, "meta_eval_prompt_tokens": {"value": 4704.0}, "meta_eval_completion_tokens": {"value": 963.0}, "meta_eval_prompt_cost": {"value": 0.00150528}, "meta_eval_completion_cost": {"value": 0.00123264}}, "created": "2025-12-10T21:32:58.5146056Z"}
{"ref": "TQ113", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.189514}, "meta_inference_prompt_tokens": {"value": 9862.0}, "meta_inference_completion_tokens": {"value": 1078.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019724}, "meta_inference_completion_cost": {"value": 0.0017248}, "meta_eval_time": {"value": 19.359}, "meta_eval_prompt_tokens": {"value": 4847.0}, "meta_eval_completion_tokens": {"value": 1739.0}, "meta_eval_prompt_cost": {"value": 0.00155104}, "meta_eval_completion_cost": {"value": 0.00222592}}, "created": "2025-12-10T21:32:58.5935744Z"}
{"ref": "TQ114", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.921052631578947}, "generation_factuality_f1": {"value": 0.428571428571429}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 28.899993}, "meta_inference_prompt_tokens": {"value": 12086.0}, "meta_inference_completion_tokens": {"value": 1701.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024172}, "meta_inference_completion_cost": {"value": 0.0027216}, "meta_eval_time": {"value": 35.078}, "meta_eval_prompt_tokens": {"value": 8001.0}, "meta_eval_completion_tokens": {"value": 3610.0}, "meta_eval_prompt_cost": {"value": 0.00256032}, "meta_eval_completion_cost": {"value": 0.0046208}}, "created": "2025-12-10T21:32:59.0902498Z"}
{"ref": "TQ110", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.96551724137931}, "generation_factuality_f1": {"value": 0.428571428571429}, "generation_factuality_precision": {"value": 0.272727272727273}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.32432}, "meta_inference_prompt_tokens": {"value": 13419.0}, "meta_inference_completion_tokens": {"value": 1649.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026838}, "meta_inference_completion_cost": {"value": 0.0026384}, "meta_eval_time": {"value": 38.024}, "meta_eval_prompt_tokens": {"value": 9024.0}, "meta_eval_completion_tokens": {"value": 3364.0}, "meta_eval_prompt_cost": {"value": 0.00288768}, "meta_eval_completion_cost": {"value": 0.00430592}}, "created": "2025-12-10T21:32:59.4855776Z"}
{"ref": "TQ11", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.942857142857143}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.059572}, "meta_inference_prompt_tokens": {"value": 10848.0}, "meta_inference_completion_tokens": {"value": 1469.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021696}, "meta_inference_completion_cost": {"value": 0.0023504}, "meta_eval_time": {"value": 37.591}, "meta_eval_prompt_tokens": {"value": 7170.0}, "meta_eval_completion_tokens": {"value": 3684.0}, "meta_eval_prompt_cost": {"value": 0.0022944}, "meta_eval_completion_cost": {"value": 0.00471552}}, "created": "2025-12-10T21:33:00.7352139Z"}
{"ref": "TQ104", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.27023815442732}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0476190476190476}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.516753}, "meta_inference_prompt_tokens": {"value": 50584.0}, "meta_inference_completion_tokens": {"value": 1308.0}, "meta_inference_tool_call_count": {"value": 3.0}, "meta_inference_prompt_cost": {"value": 0.0101168}, "meta_inference_completion_cost": {"value": 0.0020928}, "meta_eval_time": {"value": 19.695}, "meta_eval_prompt_tokens": {"value": 19051.0}, "meta_eval_completion_tokens": {"value": 1823.0}, "meta_eval_prompt_cost": {"value": 0.00609632}, "meta_eval_completion_cost": {"value": 0.00233344}}, "created": "2025-12-10T21:33:00.912153Z"}
{"ref": "TQ109-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 28.325158}, "meta_inference_prompt_tokens": {"value": 13233.0}, "meta_inference_completion_tokens": {"value": 1377.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026466}, "meta_inference_completion_cost": {"value": 0.0022032}, "meta_eval_time": {"value": 34.692}, "meta_eval_prompt_tokens": {"value": 8387.0}, "meta_eval_completion_tokens": {"value": 3534.0}, "meta_eval_prompt_cost": {"value": 0.00268384}, "meta_eval_completion_cost": {"value": 0.00452352}}, "created": "2025-12-10T21:33:01.2858194Z"}
{"ref": "TQ115", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.5}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.825708}, "meta_inference_prompt_tokens": {"value": 10020.0}, "meta_inference_completion_tokens": {"value": 573.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002004}, "meta_inference_completion_cost": {"value": 0.0009168}, "meta_eval_time": {"value": 7.015}, "meta_eval_prompt_tokens": {"value": 4361.0}, "meta_eval_completion_tokens": {"value": 614.0}, "meta_eval_prompt_cost": {"value": 0.00139552}, "meta_eval_completion_cost": {"value": 0.00078592}}, "created": "2025-12-10T21:33:01.9240538Z"}
{"ref": "TQ109-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 20.204601}, "meta_inference_prompt_tokens": {"value": 12556.0}, "meta_inference_completion_tokens": {"value": 939.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025112}, "meta_inference_completion_cost": {"value": 0.0015024}, "meta_eval_time": {"value": 28.989}, "meta_eval_prompt_tokens": {"value": 7585.0}, "meta_eval_completion_tokens": {"value": 2988.0}, "meta_eval_prompt_cost": {"value": 0.0024272}, "meta_eval_completion_cost": {"value": 0.00382464}}, "created": "2025-12-10T21:33:02.0797737Z"}
{"ref": "TQ111", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.65}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 26.848751}, "meta_inference_prompt_tokens": {"value": 13357.0}, "meta_inference_completion_tokens": {"value": 1444.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026714}, "meta_inference_completion_cost": {"value": 0.0023104}, "meta_eval_time": {"value": 24.996}, "meta_eval_prompt_tokens": {"value": 8012.0}, "meta_eval_completion_tokens": {"value": 2220.0}, "meta_eval_prompt_cost": {"value": 0.00256384}, "meta_eval_completion_cost": {"value": 0.0028416}}, "created": "2025-12-10T21:33:02.6022153Z"}
{"ref": "TQ111", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.84}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 22.33482}, "meta_inference_prompt_tokens": {"value": 14244.0}, "meta_inference_completion_tokens": {"value": 1354.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028488}, "meta_inference_completion_cost": {"value": 0.0021664}, "meta_eval_time": {"value": 23.654}, "meta_eval_prompt_tokens": {"value": 8940.0}, "meta_eval_completion_tokens": {"value": 2492.0}, "meta_eval_prompt_cost": {"value": 0.0028608}, "meta_eval_completion_cost": {"value": 0.00318976}}, "created": "2025-12-10T21:33:02.8978808Z"}
{"ref": "TQ109-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.025222}, "meta_inference_prompt_tokens": {"value": 14306.0}, "meta_inference_completion_tokens": {"value": 1279.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028612}, "meta_inference_completion_cost": {"value": 0.0020464}, "meta_eval_time": {"value": 37.051}, "meta_eval_prompt_tokens": {"value": 9599.0}, "meta_eval_completion_tokens": {"value": 3452.0}, "meta_eval_prompt_cost": {"value": 0.00307168}, "meta_eval_completion_cost": {"value": 0.00441856}}, "created": "2025-12-10T21:33:03.5748196Z"}
{"ref": "TQ110", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.963547}, "meta_inference_prompt_tokens": {"value": 13604.0}, "meta_inference_completion_tokens": {"value": 1698.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027208}, "meta_inference_completion_cost": {"value": 0.0027168}, "meta_eval_time": {"value": 36.232}, "meta_eval_prompt_tokens": {"value": 9734.0}, "meta_eval_completion_tokens": {"value": 3567.0}, "meta_eval_prompt_cost": {"value": 0.00311488}, "meta_eval_completion_cost": {"value": 0.00456576}}, "created": "2025-12-10T21:33:03.5967689Z"}
{"ref": "TQ110", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 36.922132}, "meta_inference_prompt_tokens": {"value": 12069.0}, "meta_inference_completion_tokens": {"value": 1447.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024138}, "meta_inference_completion_cost": {"value": 0.0023152}, "meta_eval_time": {"value": 36.12}, "meta_eval_prompt_tokens": {"value": 8253.0}, "meta_eval_completion_tokens": {"value": 3357.0}, "meta_eval_prompt_cost": {"value": 0.00264096}, "meta_eval_completion_cost": {"value": 0.00429696}}, "created": "2025-12-10T21:33:04.5573507Z"}
{"ref": "TQ115", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.865551}, "meta_inference_prompt_tokens": {"value": 6833.0}, "meta_inference_completion_tokens": {"value": 721.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0013666}, "meta_inference_completion_cost": {"value": 0.0011536}, "meta_eval_time": {"value": 7.489}, "meta_eval_prompt_tokens": {"value": 3332.0}, "meta_eval_completion_tokens": {"value": 697.0}, "meta_eval_prompt_cost": {"value": 0.00106624}, "meta_eval_completion_cost": {"value": 0.00089216}}, "created": "2025-12-10T21:33:04.7262965Z"}
{"ref": "TQ114", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 38.450767}, "meta_inference_prompt_tokens": {"value": 13136.0}, "meta_inference_completion_tokens": {"value": 1643.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026272}, "meta_inference_completion_cost": {"value": 0.0026288}, "meta_eval_time": {"value": 41.192}, "meta_eval_prompt_tokens": {"value": 8985.0}, "meta_eval_completion_tokens": {"value": 3624.0}, "meta_eval_prompt_cost": {"value": 0.0028752}, "meta_eval_completion_cost": {"value": 0.00463872}}, "created": "2025-12-10T21:33:05.1262019Z"}
{"ref": "TQ111", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.962962962962963}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 29.097493}, "meta_inference_prompt_tokens": {"value": 15128.0}, "meta_inference_completion_tokens": {"value": 1628.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030256}, "meta_inference_completion_cost": {"value": 0.0026048}, "meta_eval_time": {"value": 27.788}, "meta_eval_prompt_tokens": {"value": 9980.0}, "meta_eval_completion_tokens": {"value": 2512.0}, "meta_eval_prompt_cost": {"value": 0.0031936}, "meta_eval_completion_cost": {"value": 0.00321536}}, "created": "2025-12-10T21:33:05.7753163Z"}
{"ref": "TQ111", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.964285714285714}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 31.401211}, "meta_inference_prompt_tokens": {"value": 14572.0}, "meta_inference_completion_tokens": {"value": 2004.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029144}, "meta_inference_completion_cost": {"value": 0.0032064}, "meta_eval_time": {"value": 29.176}, "meta_eval_prompt_tokens": {"value": 9607.0}, "meta_eval_completion_tokens": {"value": 2955.0}, "meta_eval_prompt_cost": {"value": 0.00307424}, "meta_eval_completion_cost": {"value": 0.0037824}}, "created": "2025-12-10T21:33:05.7879249Z"}
{"ref": "TQ11", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.411529}, "meta_inference_prompt_tokens": {"value": 10886.0}, "meta_inference_completion_tokens": {"value": 1409.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021772}, "meta_inference_completion_cost": {"value": 0.0022544}, "meta_eval_time": {"value": 36.364}, "meta_eval_prompt_tokens": {"value": 7183.0}, "meta_eval_completion_tokens": {"value": 3440.0}, "meta_eval_prompt_cost": {"value": 0.00229856}, "meta_eval_completion_cost": {"value": 0.0044032}}, "created": "2025-12-10T21:33:07.9940545Z"}
{"ref": "TQ113", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.956521739130435}, "generation_factuality_f1": {"value": 0.566037735849056}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 22.601759}, "meta_inference_prompt_tokens": {"value": 9938.0}, "meta_inference_completion_tokens": {"value": 1115.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019876}, "meta_inference_completion_cost": {"value": 0.001784}, "meta_eval_time": {"value": 27.234}, "meta_eval_prompt_tokens": {"value": 5283.0}, "meta_eval_completion_tokens": {"value": 2433.0}, "meta_eval_prompt_cost": {"value": 0.00169056}, "meta_eval_completion_cost": {"value": 0.00311424}}, "created": "2025-12-10T21:33:10.5098204Z"}
{"ref": "TQ114", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.837837837837838}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.703937}, "meta_inference_prompt_tokens": {"value": 11687.0}, "meta_inference_completion_tokens": {"value": 1453.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023374}, "meta_inference_completion_cost": {"value": 0.0023248}, "meta_eval_time": {"value": 37.983}, "meta_eval_prompt_tokens": {"value": 7270.0}, "meta_eval_completion_tokens": {"value": 3455.0}, "meta_eval_prompt_cost": {"value": 0.0023264}, "meta_eval_completion_cost": {"value": 0.0044224}}, "created": "2025-12-10T21:33:10.6029711Z"}
{"ref": "TQ112", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.6}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.881031}, "meta_inference_prompt_tokens": {"value": 10647.0}, "meta_inference_completion_tokens": {"value": 1255.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021294}, "meta_inference_completion_cost": {"value": 0.002008}, "meta_eval_time": {"value": 20.402}, "meta_eval_prompt_tokens": {"value": 5632.0}, "meta_eval_completion_tokens": {"value": 1764.0}, "meta_eval_prompt_cost": {"value": 0.00180224}, "meta_eval_completion_cost": {"value": 0.00225792}}, "created": "2025-12-10T21:33:10.8800361Z"}
{"ref": "TQ11", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.567269}, "meta_inference_prompt_tokens": {"value": 10948.0}, "meta_inference_completion_tokens": {"value": 1397.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021896}, "meta_inference_completion_cost": {"value": 0.0022352}, "meta_eval_time": {"value": 33.881}, "meta_eval_prompt_tokens": {"value": 7040.0}, "meta_eval_completion_tokens": {"value": 3162.0}, "meta_eval_prompt_cost": {"value": 0.0022528}, "meta_eval_completion_cost": {"value": 0.00404736}}, "created": "2025-12-10T21:33:11.742054Z"}
{"ref": "TQ113", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.384615384615385}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 27.468987}, "meta_inference_prompt_tokens": {"value": 10469.0}, "meta_inference_completion_tokens": {"value": 1302.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020938}, "meta_inference_completion_cost": {"value": 0.0020832}, "meta_eval_time": {"value": 43.538}, "meta_eval_prompt_tokens": {"value": 6782.0}, "meta_eval_completion_tokens": {"value": 3557.0}, "meta_eval_prompt_cost": {"value": 0.00217024}, "meta_eval_completion_cost": {"value": 0.00455296}}, "created": "2025-12-10T21:33:13.6692816Z"}
{"ref": "TQ102", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.95}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.238003}, "meta_inference_prompt_tokens": {"value": 9903.0}, "meta_inference_completion_tokens": {"value": 1642.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019806}, "meta_inference_completion_cost": {"value": 0.0026272}, "meta_eval_time": {"value": 25.756}, "meta_eval_prompt_tokens": {"value": 5025.0}, "meta_eval_completion_tokens": {"value": 2181.0}, "meta_eval_prompt_cost": {"value": 0.001608}, "meta_eval_completion_cost": {"value": 0.00279168}}, "created": "2025-12-10T21:33:14.2868645Z"}
{"ref": "TQ101", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.791666666666666}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.354189}, "meta_inference_prompt_tokens": {"value": 12196.0}, "meta_inference_completion_tokens": {"value": 1280.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024392}, "meta_inference_completion_cost": {"value": 0.002048}, "meta_eval_time": {"value": 28.754}, "meta_eval_prompt_tokens": {"value": 7878.0}, "meta_eval_completion_tokens": {"value": 2899.0}, "meta_eval_prompt_cost": {"value": 0.00252096}, "meta_eval_completion_cost": {"value": 0.00371072}}, "created": "2025-12-10T21:33:14.9957569Z"}
{"ref": "TQ11", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.06160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.974177}, "meta_inference_prompt_tokens": {"value": 11026.0}, "meta_inference_completion_tokens": {"value": 1471.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022052}, "meta_inference_completion_cost": {"value": 0.0023536}, "meta_eval_time": {"value": 38.55}, "meta_eval_prompt_tokens": {"value": 7319.0}, "meta_eval_completion_tokens": {"value": 3988.0}, "meta_eval_prompt_cost": {"value": 0.00234208}, "meta_eval_completion_cost": {"value": 0.00510464}}, "created": "2025-12-10T21:33:15.4566831Z"}
{"ref": "TQ118", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.260719}, "meta_inference_prompt_tokens": {"value": 11258.0}, "meta_inference_completion_tokens": {"value": 879.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022516}, "meta_inference_completion_cost": {"value": 0.0014064}, "meta_eval_time": {"value": 13.293}, "meta_eval_prompt_tokens": {"value": 5224.0}, "meta_eval_completion_tokens": {"value": 1159.0}, "meta_eval_prompt_cost": {"value": 0.00167168}, "meta_eval_completion_cost": {"value": 0.00148352}}, "created": "2025-12-10T21:33:15.9351201Z"}
{"ref": "TQ118", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.825749}, "meta_inference_prompt_tokens": {"value": 11231.0}, "meta_inference_completion_tokens": {"value": 687.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022462}, "meta_inference_completion_cost": {"value": 0.0010992}, "meta_eval_time": {"value": 12.606}, "meta_eval_prompt_tokens": {"value": 5375.0}, "meta_eval_completion_tokens": {"value": 992.0}, "meta_eval_prompt_cost": {"value": 0.00172}, "meta_eval_completion_cost": {"value": 0.00126976}}, "created": "2025-12-10T21:33:16.2220308Z"}
{"ref": "TQ11", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.448}, "meta_inference_prompt_tokens": {"value": 10808.0}, "meta_inference_completion_tokens": {"value": 1715.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021616}, "meta_inference_completion_cost": {"value": 0.002744}, "meta_eval_time": {"value": 48.951}, "meta_eval_prompt_tokens": {"value": 7468.0}, "meta_eval_completion_tokens": {"value": 4190.0}, "meta_eval_prompt_cost": {"value": 0.00238976}, "meta_eval_completion_cost": {"value": 0.0053632}}, "created": "2025-12-10T21:33:17.0077234Z"}
{"ref": "TQ110", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.833889}, "meta_inference_prompt_tokens": {"value": 14023.0}, "meta_inference_completion_tokens": {"value": 1914.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028046}, "meta_inference_completion_cost": {"value": 0.0030624}, "meta_eval_time": {"value": 44.295}, "meta_eval_prompt_tokens": {"value": 10291.0}, "meta_eval_completion_tokens": {"value": 4214.0}, "meta_eval_prompt_cost": {"value": 0.00329312}, "meta_eval_completion_cost": {"value": 0.00539392}}, "created": "2025-12-10T21:33:17.6430756Z"}
{"ref": "TQ108", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.997059}, "meta_inference_prompt_tokens": {"value": 10357.0}, "meta_inference_completion_tokens": {"value": 1134.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020714}, "meta_inference_completion_cost": {"value": 0.0018144}, "meta_eval_time": {"value": 20.354}, "meta_eval_prompt_tokens": {"value": 5587.0}, "meta_eval_completion_tokens": {"value": 1877.0}, "meta_eval_prompt_cost": {"value": 0.00178784}, "meta_eval_completion_cost": {"value": 0.00240256}}, "created": "2025-12-10T21:33:18.8013557Z"}
{"ref": "TQ118", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.135929}, "meta_inference_prompt_tokens": {"value": 12041.0}, "meta_inference_completion_tokens": {"value": 1507.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024082}, "meta_inference_completion_cost": {"value": 0.0024112}, "meta_eval_time": {"value": 17.117}, "meta_eval_prompt_tokens": {"value": 6222.0}, "meta_eval_completion_tokens": {"value": 1616.0}, "meta_eval_prompt_cost": {"value": 0.00199104}, "meta_eval_completion_cost": {"value": 0.00206848}}, "created": "2025-12-10T21:33:19.2423777Z"}
{"ref": "TQ118", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.486986}, "meta_inference_prompt_tokens": {"value": 11492.0}, "meta_inference_completion_tokens": {"value": 971.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022984}, "meta_inference_completion_cost": {"value": 0.0015536}, "meta_eval_time": {"value": 18.441}, "meta_eval_prompt_tokens": {"value": 6041.0}, "meta_eval_completion_tokens": {"value": 1577.0}, "meta_eval_prompt_cost": {"value": 0.00193312}, "meta_eval_completion_cost": {"value": 0.00201856}}, "created": "2025-12-10T21:33:19.7827508Z"}
{"ref": "TQ123", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.90939}, "meta_inference_prompt_tokens": {"value": 9232.0}, "meta_inference_completion_tokens": {"value": 1218.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018464}, "meta_inference_completion_cost": {"value": 0.0019488}, "meta_eval_time": {"value": 14.954}, "meta_eval_prompt_tokens": {"value": 5286.0}, "meta_eval_completion_tokens": {"value": 1159.0}, "meta_eval_prompt_cost": {"value": 0.00169152}, "meta_eval_completion_cost": {"value": 0.00148352}}, "created": "2025-12-10T21:33:20.7652526Z"}
{"ref": "TQ118", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.546819}, "meta_inference_prompt_tokens": {"value": 11908.0}, "meta_inference_completion_tokens": {"value": 1483.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023816}, "meta_inference_completion_cost": {"value": 0.0023728}, "meta_eval_time": {"value": 15.586}, "meta_eval_prompt_tokens": {"value": 5973.0}, "meta_eval_completion_tokens": {"value": 1347.0}, "meta_eval_prompt_cost": {"value": 0.00191136}, "meta_eval_completion_cost": {"value": 0.00172416}}, "created": "2025-12-10T21:33:21.4175997Z"}
{"ref": "TQ113", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.780487804878049}, "generation_factuality_f1": {"value": 0.32}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 25.640794}, "meta_inference_prompt_tokens": {"value": 9850.0}, "meta_inference_completion_tokens": {"value": 1692.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00197}, "meta_inference_completion_cost": {"value": 0.0027072}, "meta_eval_time": {"value": 46.758}, "meta_eval_prompt_tokens": {"value": 6037.0}, "meta_eval_completion_tokens": {"value": 3955.0}, "meta_eval_prompt_cost": {"value": 0.00193184}, "meta_eval_completion_cost": {"value": 0.0050624}}, "created": "2025-12-10T21:33:21.5061881Z"}
{"ref": "TQ123", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.5}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.409864}, "meta_inference_prompt_tokens": {"value": 9800.0}, "meta_inference_completion_tokens": {"value": 1032.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00196}, "meta_inference_completion_cost": {"value": 0.0016512}, "meta_eval_time": {"value": 12.968}, "meta_eval_prompt_tokens": {"value": 5021.0}, "meta_eval_completion_tokens": {"value": 1162.0}, "meta_eval_prompt_cost": {"value": 0.00160672}, "meta_eval_completion_cost": {"value": 0.00148736}}, "created": "2025-12-10T21:33:23.6388405Z"}
{"ref": "TQ123", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.142857142857143}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.042077}, "meta_inference_prompt_tokens": {"value": 9789.0}, "meta_inference_completion_tokens": {"value": 1606.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019578}, "meta_inference_completion_cost": {"value": 0.0025696}, "meta_eval_time": {"value": 13.141}, "meta_eval_prompt_tokens": {"value": 5241.0}, "meta_eval_completion_tokens": {"value": 1094.0}, "meta_eval_prompt_cost": {"value": 0.00167712}, "meta_eval_completion_cost": {"value": 0.00140032}}, "created": "2025-12-10T21:33:24.0574322Z"}
{"ref": "TQ123", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.636363636363636}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.158453}, "meta_inference_prompt_tokens": {"value": 9773.0}, "meta_inference_completion_tokens": {"value": 964.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019546}, "meta_inference_completion_cost": {"value": 0.0015424}, "meta_eval_time": {"value": 13.536}, "meta_eval_prompt_tokens": {"value": 5053.0}, "meta_eval_completion_tokens": {"value": 1263.0}, "meta_eval_prompt_cost": {"value": 0.00161696}, "meta_eval_completion_cost": {"value": 0.00161664}}, "created": "2025-12-10T21:33:24.0839446Z"}
{"ref": "TQ123", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.133333333333333}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.57314579990146}, "generation_faithfulness": {"value": 0.625}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0714285714285714}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.05}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 47.398907}, "meta_inference_prompt_tokens": {"value": 33804.0}, "meta_inference_completion_tokens": {"value": 2599.0}, "meta_inference_tool_call_count": {"value": 3.0}, "meta_inference_prompt_cost": {"value": 0.0067608}, "meta_inference_completion_cost": {"value": 0.0041584}, "meta_eval_time": {"value": 12.593}, "meta_eval_prompt_tokens": {"value": 7612.0}, "meta_eval_completion_tokens": {"value": 1080.0}, "meta_eval_prompt_cost": {"value": 0.00243584}, "meta_eval_completion_cost": {"value": 0.0013824}}, "created": "2025-12-10T21:33:24.3724426Z"}
{"ref": "TQ114", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.045614}, "meta_inference_prompt_tokens": {"value": 10838.0}, "meta_inference_completion_tokens": {"value": 1333.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021676}, "meta_inference_completion_cost": {"value": 0.0021328}, "meta_eval_time": {"value": 37.331}, "meta_eval_prompt_tokens": {"value": 6905.0}, "meta_eval_completion_tokens": {"value": 3851.0}, "meta_eval_prompt_cost": {"value": 0.0022096}, "meta_eval_completion_cost": {"value": 0.00492928}}, "created": "2025-12-10T21:33:25.8496952Z"}
{"ref": "TQ117", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.938496}, "meta_inference_prompt_tokens": {"value": 13159.0}, "meta_inference_completion_tokens": {"value": 1735.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026318}, "meta_inference_completion_cost": {"value": 0.002776}, "meta_eval_time": {"value": 25.503}, "meta_eval_prompt_tokens": {"value": 7930.0}, "meta_eval_completion_tokens": {"value": 2497.0}, "meta_eval_prompt_cost": {"value": 0.0025376}, "meta_eval_completion_cost": {"value": 0.00319616}}, "created": "2025-12-10T21:33:26.3117225Z"}
{"ref": "TQ126", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.746141434859122}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.623985}, "meta_inference_prompt_tokens": {"value": 11186.0}, "meta_inference_completion_tokens": {"value": 683.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022372}, "meta_inference_completion_cost": {"value": 0.0010928}, "meta_eval_time": {"value": 14.581}, "meta_eval_prompt_tokens": {"value": 5872.0}, "meta_eval_completion_tokens": {"value": 1446.0}, "meta_eval_prompt_cost": {"value": 0.00187904}, "meta_eval_completion_cost": {"value": 0.00185088}}, "created": "2025-12-10T21:33:28.3004576Z"}
{"ref": "TQ130", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 20.343087}, "meta_inference_prompt_tokens": {"value": 14580.0}, "meta_inference_completion_tokens": {"value": 1229.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002916}, "meta_inference_completion_cost": {"value": 0.0019664}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:33:28.3385312Z"}
{"ref": "TQ126", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.964263086904791}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.222222222222222}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.081756}, "meta_inference_prompt_tokens": {"value": 10545.0}, "meta_inference_completion_tokens": {"value": 672.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002109}, "meta_inference_completion_cost": {"value": 0.0010752}, "meta_eval_time": {"value": 15.929}, "meta_eval_prompt_tokens": {"value": 5324.0}, "meta_eval_completion_tokens": {"value": 1362.0}, "meta_eval_prompt_cost": {"value": 0.00170368}, "meta_eval_completion_cost": {"value": 0.00174336}}, "created": "2025-12-10T21:33:31.4266477Z"}
{"ref": "TQ126", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.166666666666667}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.45466}, "meta_inference_prompt_tokens": {"value": 8243.0}, "meta_inference_completion_tokens": {"value": 581.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0016486}, "meta_inference_completion_cost": {"value": 0.0009296}, "meta_eval_time": {"value": 16.654}, "meta_eval_prompt_tokens": {"value": 4219.0}, "meta_eval_completion_tokens": {"value": 1501.0}, "meta_eval_prompt_cost": {"value": 0.00135008}, "meta_eval_completion_cost": {"value": 0.00192128}}, "created": "2025-12-10T21:33:32.6261319Z"}
{"ref": "TQ126", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.222222222222222}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.166666666666667}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.161967}, "meta_inference_prompt_tokens": {"value": 8406.0}, "meta_inference_completion_tokens": {"value": 614.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0016812}, "meta_inference_completion_cost": {"value": 0.0009824}, "meta_eval_time": {"value": 18.618}, "meta_eval_prompt_tokens": {"value": 4343.0}, "meta_eval_completion_tokens": {"value": 1576.0}, "meta_eval_prompt_cost": {"value": 0.00138976}, "meta_eval_completion_cost": {"value": 0.00201728}}, "created": "2025-12-10T21:33:35.6656348Z"}
{"ref": "TQ116-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.33324743759173}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.533333333333333}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 28.408236}, "meta_inference_prompt_tokens": {"value": 11755.0}, "meta_inference_completion_tokens": {"value": 1200.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002351}, "meta_inference_completion_cost": {"value": 0.00192}, "meta_eval_time": {"value": 41.283}, "meta_eval_prompt_tokens": {"value": 8770.0}, "meta_eval_completion_tokens": {"value": 3900.0}, "meta_eval_prompt_cost": {"value": 0.0028064}, "meta_eval_completion_cost": {"value": 0.004992}}, "created": "2025-12-10T21:33:35.9112908Z"}
{"ref": "TQ12", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.422046}, "meta_inference_prompt_tokens": {"value": 13126.0}, "meta_inference_completion_tokens": {"value": 1252.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026252}, "meta_inference_completion_cost": {"value": 0.0020032}, "meta_eval_time": {"value": 31.291}, "meta_eval_prompt_tokens": {"value": 8378.0}, "meta_eval_completion_tokens": {"value": 3072.0}, "meta_eval_prompt_cost": {"value": 0.00268096}, "meta_eval_completion_cost": {"value": 0.00393216}}, "created": "2025-12-10T21:33:36.0619936Z"}
{"ref": "TQ126", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.166666666666667}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.36428}, "meta_inference_prompt_tokens": {"value": 7718.0}, "meta_inference_completion_tokens": {"value": 638.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0015436}, "meta_inference_completion_cost": {"value": 0.0010208}, "meta_eval_time": {"value": 17.165}, "meta_eval_prompt_tokens": {"value": 3722.0}, "meta_eval_completion_tokens": {"value": 1583.0}, "meta_eval_prompt_cost": {"value": 0.00119104}, "meta_eval_completion_cost": {"value": 0.00202624}}, "created": "2025-12-10T21:33:36.4537131Z"}
{"ref": "TQ12", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.697674418604651}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 27.798067}, "meta_inference_prompt_tokens": {"value": 13307.0}, "meta_inference_completion_tokens": {"value": 1270.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026614}, "meta_inference_completion_cost": {"value": 0.002032}, "meta_eval_time": {"value": 33.018}, "meta_eval_prompt_tokens": {"value": 8914.0}, "meta_eval_completion_tokens": {"value": 3076.0}, "meta_eval_prompt_cost": {"value": 0.00285248}, "meta_eval_completion_cost": {"value": 0.00393728}}, "created": "2025-12-10T21:33:36.683458Z"}
{"ref": "TQ117", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 32.935971}, "meta_inference_prompt_tokens": {"value": 14530.0}, "meta_inference_completion_tokens": {"value": 1912.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002906}, "meta_inference_completion_cost": {"value": 0.0030592}, "meta_eval_time": {"value": 37.444}, "meta_eval_prompt_tokens": {"value": 10259.0}, "meta_eval_completion_tokens": {"value": 3518.0}, "meta_eval_prompt_cost": {"value": 0.00328288}, "meta_eval_completion_cost": {"value": 0.00450304}}, "created": "2025-12-10T21:33:36.9712787Z"}
{"ref": "TQ130", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 20.265698}, "meta_inference_prompt_tokens": {"value": 16108.0}, "meta_inference_completion_tokens": {"value": 937.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032216}, "meta_inference_completion_cost": {"value": 0.0014992}, "meta_eval_time": {"value": 0.002}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:33:37.0125081Z"}
{"ref": "TQ12", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.853658536585366}, "generation_factuality_precision": {"value": 0.875}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 29.895824}, "meta_inference_prompt_tokens": {"value": 15515.0}, "meta_inference_completion_tokens": {"value": 1286.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003103}, "meta_inference_completion_cost": {"value": 0.0020576}, "meta_eval_time": {"value": 31.978}, "meta_eval_prompt_tokens": {"value": 10602.0}, "meta_eval_completion_tokens": {"value": 3041.0}, "meta_eval_prompt_cost": {"value": 0.00339264}, "meta_eval_completion_cost": {"value": 0.00389248}}, "created": "2025-12-10T21:33:37.1634697Z"}
{"ref": "TQ12", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.715824}, "meta_inference_prompt_tokens": {"value": 15200.0}, "meta_inference_completion_tokens": {"value": 1181.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00304}, "meta_inference_completion_cost": {"value": 0.0018896}, "meta_eval_time": {"value": 35.044}, "meta_eval_prompt_tokens": {"value": 10517.0}, "meta_eval_completion_tokens": {"value": 3424.0}, "meta_eval_prompt_cost": {"value": 0.00336544}, "meta_eval_completion_cost": {"value": 0.00438272}}, "created": "2025-12-10T21:33:38.0164839Z"}
{"ref": "TQ117", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 24.860891}, "meta_inference_prompt_tokens": {"value": 11449.0}, "meta_inference_completion_tokens": {"value": 1462.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022898}, "meta_inference_completion_cost": {"value": 0.0023392}, "meta_eval_time": {"value": 39.265}, "meta_eval_prompt_tokens": {"value": 7359.0}, "meta_eval_completion_tokens": {"value": 3479.0}, "meta_eval_prompt_cost": {"value": 0.00235488}, "meta_eval_completion_cost": {"value": 0.00445312}}, "created": "2025-12-10T21:33:41.2449877Z"}
{"ref": "TQ116-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.979166666666666}, "generation_factuality_f1": {"value": 0.533333333333333}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 37.109844}, "meta_inference_prompt_tokens": {"value": 15335.0}, "meta_inference_completion_tokens": {"value": 2068.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003067}, "meta_inference_completion_cost": {"value": 0.0033088}, "meta_eval_time": {"value": 46.409}, "meta_eval_prompt_tokens": {"value": 11401.0}, "meta_eval_completion_tokens": {"value": 4709.0}, "meta_eval_prompt_cost": {"value": 0.00364832}, "meta_eval_completion_cost": {"value": 0.00602752}}, "created": "2025-12-10T21:33:41.3632579Z"}
{"ref": "TQ12", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.168521}, "meta_inference_prompt_tokens": {"value": 15765.0}, "meta_inference_completion_tokens": {"value": 1250.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003153}, "meta_inference_completion_cost": {"value": 0.002}, "meta_eval_time": {"value": 35.049}, "meta_eval_prompt_tokens": {"value": 10742.0}, "meta_eval_completion_tokens": {"value": 3355.0}, "meta_eval_prompt_cost": {"value": 0.00343744}, "meta_eval_completion_cost": {"value": 0.0042944}}, "created": "2025-12-10T21:33:43.0807698Z"}
{"ref": "TQ117", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.837837837837838}, "generation_factuality_f1": {"value": 0.153846153846154}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 29.764534}, "meta_inference_prompt_tokens": {"value": 12214.0}, "meta_inference_completion_tokens": {"value": 1613.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024428}, "meta_inference_completion_cost": {"value": 0.0025808}, "meta_eval_time": {"value": 40.641}, "meta_eval_prompt_tokens": {"value": 8486.0}, "meta_eval_completion_tokens": {"value": 3936.0}, "meta_eval_prompt_cost": {"value": 0.00271552}, "meta_eval_completion_cost": {"value": 0.00503808}}, "created": "2025-12-10T21:33:45.2354478Z"}
{"ref": "TQ127", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.164426}, "meta_inference_prompt_tokens": {"value": 13105.0}, "meta_inference_completion_tokens": {"value": 1617.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002621}, "meta_inference_completion_cost": {"value": 0.0025872}, "meta_eval_time": {"value": 31.126}, "meta_eval_prompt_tokens": {"value": 8726.0}, "meta_eval_completion_tokens": {"value": 3282.0}, "meta_eval_prompt_cost": {"value": 0.00279232}, "meta_eval_completion_cost": {"value": 0.00420096}}, "created": "2025-12-10T21:33:45.4510813Z"}
{"ref": "TQ127", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 39.969041}, "meta_inference_prompt_tokens": {"value": 13047.0}, "meta_inference_completion_tokens": {"value": 1716.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026094}, "meta_inference_completion_cost": {"value": 0.0027456}, "meta_eval_time": {"value": 24.337}, "meta_eval_prompt_tokens": {"value": 8243.0}, "meta_eval_completion_tokens": {"value": 2294.0}, "meta_eval_prompt_cost": {"value": 0.00263776}, "meta_eval_completion_cost": {"value": 0.00293632}}, "created": "2025-12-10T21:33:45.7926246Z"}
{"ref": "TQ116-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 2.017782560806}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.947222}, "meta_inference_prompt_tokens": {"value": 12873.0}, "meta_inference_completion_tokens": {"value": 1474.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025746}, "meta_inference_completion_cost": {"value": 0.0023584}, "meta_eval_time": {"value": 50.962}, "meta_eval_prompt_tokens": {"value": 10118.0}, "meta_eval_completion_tokens": {"value": 4795.0}, "meta_eval_prompt_cost": {"value": 0.00323776}, "meta_eval_completion_cost": {"value": 0.0061376}}, "created": "2025-12-10T21:33:45.8018703Z"}
{"ref": "TQ116-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.68954052044136}, "generation_faithfulness": {"value": 0.92}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.180895}, "meta_inference_prompt_tokens": {"value": 12138.0}, "meta_inference_completion_tokens": {"value": 1545.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024276}, "meta_inference_completion_cost": {"value": 0.002472}, "meta_eval_time": {"value": 49.083}, "meta_eval_prompt_tokens": {"value": 9320.0}, "meta_eval_completion_tokens": {"value": 4524.0}, "meta_eval_prompt_cost": {"value": 0.0029824}, "meta_eval_completion_cost": {"value": 0.00579072}}, "created": "2025-12-10T21:33:46.6165762Z"}
{"ref": "TQ117", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.413793103448276}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 34.264412}, "meta_inference_prompt_tokens": {"value": 11320.0}, "meta_inference_completion_tokens": {"value": 1953.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002264}, "meta_inference_completion_cost": {"value": 0.0031248}, "meta_eval_time": {"value": 45.955}, "meta_eval_prompt_tokens": {"value": 7979.0}, "meta_eval_completion_tokens": {"value": 4456.0}, "meta_eval_prompt_cost": {"value": 0.00255328}, "meta_eval_completion_cost": {"value": 0.00570368}}, "created": "2025-12-10T21:33:46.958782Z"}
{"ref": "TQ13", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 32.059821}, "meta_inference_prompt_tokens": {"value": 13852.0}, "meta_inference_completion_tokens": {"value": 1552.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027704}, "meta_inference_completion_cost": {"value": 0.0024832}, "meta_eval_time": {"value": 25.717}, "meta_eval_prompt_tokens": {"value": 9047.0}, "meta_eval_completion_tokens": {"value": 2435.0}, "meta_eval_prompt_cost": {"value": 0.00289504}, "meta_eval_completion_cost": {"value": 0.0031168}}, "created": "2025-12-10T21:33:47.2590889Z"}
{"ref": "TQ127", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.925863}, "meta_inference_prompt_tokens": {"value": 13326.0}, "meta_inference_completion_tokens": {"value": 1190.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026652}, "meta_inference_completion_cost": {"value": 0.001904}, "meta_eval_time": {"value": 33.517}, "meta_eval_prompt_tokens": {"value": 8925.0}, "meta_eval_completion_tokens": {"value": 3002.0}, "meta_eval_prompt_cost": {"value": 0.002856}, "meta_eval_completion_cost": {"value": 0.00384256}}, "created": "2025-12-10T21:33:49.7763196Z"}
{"ref": "TQ127", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.894736842105263}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.678512}, "meta_inference_prompt_tokens": {"value": 12834.0}, "meta_inference_completion_tokens": {"value": 1406.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025668}, "meta_inference_completion_cost": {"value": 0.0022496}, "meta_eval_time": {"value": 35.415}, "meta_eval_prompt_tokens": {"value": 8332.0}, "meta_eval_completion_tokens": {"value": 2580.0}, "meta_eval_prompt_cost": {"value": 0.00266624}, "meta_eval_completion_cost": {"value": 0.0033024}}, "created": "2025-12-10T21:33:50.4493505Z"}
{"ref": "TQ116-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.017782560806}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.160558}, "meta_inference_prompt_tokens": {"value": 11008.0}, "meta_inference_completion_tokens": {"value": 1383.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022016}, "meta_inference_completion_cost": {"value": 0.0022128}, "meta_eval_time": {"value": 55.211}, "meta_eval_prompt_tokens": {"value": 8016.0}, "meta_eval_completion_tokens": {"value": 5113.0}, "meta_eval_prompt_cost": {"value": 0.00256512}, "meta_eval_completion_cost": {"value": 0.00654464}}, "created": "2025-12-10T21:33:50.9068583Z"}
{"ref": "TQ116-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.677966101694915}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 28.933385}, "meta_inference_prompt_tokens": {"value": 14103.0}, "meta_inference_completion_tokens": {"value": 1735.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028206}, "meta_inference_completion_cost": {"value": 0.002776}, "meta_eval_time": {"value": 52.453}, "meta_eval_prompt_tokens": {"value": 10399.0}, "meta_eval_completion_tokens": {"value": 4461.0}, "meta_eval_prompt_cost": {"value": 0.00332768}, "meta_eval_completion_cost": {"value": 0.00571008}}, "created": "2025-12-10T21:33:51.0079894Z"}
{"ref": "TQ116-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.533333333333333}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 33.455093}, "meta_inference_prompt_tokens": {"value": 15141.0}, "meta_inference_completion_tokens": {"value": 2134.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030282}, "meta_inference_completion_cost": {"value": 0.0034144}, "meta_eval_time": {"value": 51.916}, "meta_eval_prompt_tokens": {"value": 11653.0}, "meta_eval_completion_tokens": {"value": 5197.0}, "meta_eval_prompt_cost": {"value": 0.00372896}, "meta_eval_completion_cost": {"value": 0.00665216}}, "created": "2025-12-10T21:33:51.0495376Z"}
{"ref": "TQ116-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.967741935483871}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 31.721571}, "meta_inference_prompt_tokens": {"value": 15551.0}, "meta_inference_completion_tokens": {"value": 1841.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031102}, "meta_inference_completion_cost": {"value": 0.0029456}, "meta_eval_time": {"value": 56.64}, "meta_eval_prompt_tokens": {"value": 12334.0}, "meta_eval_completion_tokens": {"value": 5727.0}, "meta_eval_prompt_cost": {"value": 0.00394688}, "meta_eval_completion_cost": {"value": 0.00733056}}, "created": "2025-12-10T21:33:52.4162673Z"}
{"ref": "TQ127", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.380956}, "meta_inference_prompt_tokens": {"value": 12986.0}, "meta_inference_completion_tokens": {"value": 1856.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025972}, "meta_inference_completion_cost": {"value": 0.0029696}, "meta_eval_time": {"value": 32.597}, "meta_eval_prompt_tokens": {"value": 8513.0}, "meta_eval_completion_tokens": {"value": 2900.0}, "meta_eval_prompt_cost": {"value": 0.00272416}, "meta_eval_completion_cost": {"value": 0.003712}}, "created": "2025-12-10T21:33:52.4142954Z"}
{"ref": "TQ116-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.533333333333333}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 37.666758}, "meta_inference_prompt_tokens": {"value": 15529.0}, "meta_inference_completion_tokens": {"value": 2110.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031058}, "meta_inference_completion_cost": {"value": 0.003376}, "meta_eval_time": {"value": 55.541}, "meta_eval_prompt_tokens": {"value": 12664.0}, "meta_eval_completion_tokens": {"value": 5663.0}, "meta_eval_prompt_cost": {"value": 0.00405248}, "meta_eval_completion_cost": {"value": 0.00724864}}, "created": "2025-12-10T21:33:52.4542514Z"}
{"ref": "TQ128", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.44369}, "meta_inference_prompt_tokens": {"value": 12432.0}, "meta_inference_completion_tokens": {"value": 1255.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024864}, "meta_inference_completion_cost": {"value": 0.002008}, "meta_eval_time": {"value": 34.86}, "meta_eval_prompt_tokens": {"value": 8114.0}, "meta_eval_completion_tokens": {"value": 3040.0}, "meta_eval_prompt_cost": {"value": 0.00259648}, "meta_eval_completion_cost": {"value": 0.0038912}}, "created": "2025-12-10T21:33:52.5411374Z"}
{"ref": "TQ128", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.130441}, "meta_inference_prompt_tokens": {"value": 12367.0}, "meta_inference_completion_tokens": {"value": 950.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024734}, "meta_inference_completion_cost": {"value": 0.00152}, "meta_eval_time": {"value": 27.094}, "meta_eval_prompt_tokens": {"value": 7893.0}, "meta_eval_completion_tokens": {"value": 2552.0}, "meta_eval_prompt_cost": {"value": 0.00252576}, "meta_eval_completion_cost": {"value": 0.00326656}}, "created": "2025-12-10T21:33:53.4450316Z"}
{"ref": "TQ128", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.823288}, "meta_inference_prompt_tokens": {"value": 13038.0}, "meta_inference_completion_tokens": {"value": 1733.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026076}, "meta_inference_completion_cost": {"value": 0.0027728}, "meta_eval_time": {"value": 33.537}, "meta_eval_prompt_tokens": {"value": 8970.0}, "meta_eval_completion_tokens": {"value": 3195.0}, "meta_eval_prompt_cost": {"value": 0.0028704}, "meta_eval_completion_cost": {"value": 0.0040896}}, "created": "2025-12-10T21:33:54.3380608Z"}
{"ref": "TQ13", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 34.577302}, "meta_inference_prompt_tokens": {"value": 9721.0}, "meta_inference_completion_tokens": {"value": 1595.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019442}, "meta_inference_completion_cost": {"value": 0.002552}, "meta_eval_time": {"value": 31.397}, "meta_eval_prompt_tokens": {"value": 6937.0}, "meta_eval_completion_tokens": {"value": 2943.0}, "meta_eval_prompt_cost": {"value": 0.00221984}, "meta_eval_completion_cost": {"value": 0.00376704}}, "created": "2025-12-10T21:33:55.5390795Z"}
{"ref": "TQ130", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 23.90696}, "meta_inference_prompt_tokens": {"value": 10903.0}, "meta_inference_completion_tokens": {"value": 1090.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021806}, "meta_inference_completion_cost": {"value": 0.001744}, "meta_eval_time": {"value": 20.101}, "meta_eval_prompt_tokens": {"value": 5841.0}, "meta_eval_completion_tokens": {"value": 2002.0}, "meta_eval_prompt_cost": {"value": 0.00186912}, "meta_eval_completion_cost": {"value": 0.00256256}}, "created": "2025-12-10T21:33:56.8281785Z"}
{"ref": "TQ133", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 18.626559}, "meta_inference_prompt_tokens": {"value": 10385.0}, "meta_inference_completion_tokens": {"value": 678.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002077}, "meta_inference_completion_cost": {"value": 0.0010848}, "meta_eval_time": {"value": 12.508}, "meta_eval_prompt_tokens": {"value": 5042.0}, "meta_eval_completion_tokens": {"value": 1313.0}, "meta_eval_prompt_cost": {"value": 0.00161344}, "meta_eval_completion_cost": {"value": 0.00168064}}, "created": "2025-12-10T21:33:58.0223201Z"}
{"ref": "TQ130", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.289064826317888}, "generation_faithfulness": {"value": 0.80952380952381}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.307955}, "meta_inference_prompt_tokens": {"value": 10163.0}, "meta_inference_completion_tokens": {"value": 1692.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020326}, "meta_inference_completion_cost": {"value": 0.0027072}, "meta_eval_time": {"value": 22.439}, "meta_eval_prompt_tokens": {"value": 5374.0}, "meta_eval_completion_tokens": {"value": 2199.0}, "meta_eval_prompt_cost": {"value": 0.00171968}, "meta_eval_completion_cost": {"value": 0.00281472}}, "created": "2025-12-10T21:33:58.4106873Z"}
{"ref": "TQ133", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 14.816323}, "meta_inference_prompt_tokens": {"value": 10172.0}, "meta_inference_completion_tokens": {"value": 588.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020344}, "meta_inference_completion_cost": {"value": 0.0009408}, "meta_eval_time": {"value": 14.608}, "meta_eval_prompt_tokens": {"value": 4926.0}, "meta_eval_completion_tokens": {"value": 1347.0}, "meta_eval_prompt_cost": {"value": 0.00157632}, "meta_eval_completion_cost": {"value": 0.00172416}}, "created": "2025-12-10T21:34:00.4554148Z"}
{"ref": "TQ128", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.375562}, "meta_inference_prompt_tokens": {"value": 11306.0}, "meta_inference_completion_tokens": {"value": 1612.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022612}, "meta_inference_completion_cost": {"value": 0.0025792}, "meta_eval_time": {"value": 41.676}, "meta_eval_prompt_tokens": {"value": 7959.0}, "meta_eval_completion_tokens": {"value": 3910.0}, "meta_eval_prompt_cost": {"value": 0.00254688}, "meta_eval_completion_cost": {"value": 0.0050048}}, "created": "2025-12-10T21:34:00.5174133Z"}
{"ref": "TQ132", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 19.080973}, "meta_inference_prompt_tokens": {"value": 12685.0}, "meta_inference_completion_tokens": {"value": 879.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002537}, "meta_inference_completion_cost": {"value": 0.0014064}, "meta_eval_time": {"value": 21.202}, "meta_eval_prompt_tokens": {"value": 7235.0}, "meta_eval_completion_tokens": {"value": 2169.0}, "meta_eval_prompt_cost": {"value": 0.0023152}, "meta_eval_completion_cost": {"value": 0.00277632}}, "created": "2025-12-10T21:34:02.488984Z"}
{"ref": "TQ133", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 17.847462}, "meta_inference_prompt_tokens": {"value": 10525.0}, "meta_inference_completion_tokens": {"value": 735.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002105}, "meta_inference_completion_cost": {"value": 0.001176}, "meta_eval_time": {"value": 15.456}, "meta_eval_prompt_tokens": {"value": 5279.0}, "meta_eval_completion_tokens": {"value": 1421.0}, "meta_eval_prompt_cost": {"value": 0.00168928}, "meta_eval_completion_cost": {"value": 0.00181888}}, "created": "2025-12-10T21:34:02.7792452Z"}
{"ref": "TQ132", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.722757}, "meta_inference_prompt_tokens": {"value": 11610.0}, "meta_inference_completion_tokens": {"value": 1067.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002322}, "meta_inference_completion_cost": {"value": 0.0017072}, "meta_eval_time": {"value": 26.934}, "meta_eval_prompt_tokens": {"value": 6522.0}, "meta_eval_completion_tokens": {"value": 2182.0}, "meta_eval_prompt_cost": {"value": 0.00208704}, "meta_eval_completion_cost": {"value": 0.00279296}}, "created": "2025-12-10T21:34:03.9830107Z"}
{"ref": "TQ128", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.967741935483871}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.210352}, "meta_inference_prompt_tokens": {"value": 12523.0}, "meta_inference_completion_tokens": {"value": 1236.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025046}, "meta_inference_completion_cost": {"value": 0.0019776}, "meta_eval_time": {"value": 35.798}, "meta_eval_prompt_tokens": {"value": 8333.0}, "meta_eval_completion_tokens": {"value": 3253.0}, "meta_eval_prompt_cost": {"value": 0.00266656}, "meta_eval_completion_cost": {"value": 0.00416384}}, "created": "2025-12-10T21:34:04.1752348Z"}
{"ref": "TQ132", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 19.265119}, "meta_inference_prompt_tokens": {"value": 13004.0}, "meta_inference_completion_tokens": {"value": 789.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026008}, "meta_inference_completion_cost": {"value": 0.0012624}, "meta_eval_time": {"value": 21.806}, "meta_eval_prompt_tokens": {"value": 7525.0}, "meta_eval_completion_tokens": {"value": 2091.0}, "meta_eval_prompt_cost": {"value": 0.002408}, "meta_eval_completion_cost": {"value": 0.00267648}}, "created": "2025-12-10T21:34:04.9298683Z"}
{"ref": "TQ129", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.51063829787234}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 24.886949}, "meta_inference_prompt_tokens": {"value": 10867.0}, "meta_inference_completion_tokens": {"value": 1550.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021734}, "meta_inference_completion_cost": {"value": 0.00248}, "meta_eval_time": {"value": 41.932}, "meta_eval_prompt_tokens": {"value": 7759.0}, "meta_eval_completion_tokens": {"value": 4127.0}, "meta_eval_prompt_cost": {"value": 0.00248288}, "meta_eval_completion_cost": {"value": 0.00528256}}, "created": "2025-12-10T21:34:05.6076521Z"}
{"ref": "TQ13", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 40.490798}, "meta_inference_prompt_tokens": {"value": 11529.0}, "meta_inference_completion_tokens": {"value": 1616.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023058}, "meta_inference_completion_cost": {"value": 0.0025856}, "meta_eval_time": {"value": 41.332}, "meta_eval_prompt_tokens": {"value": 8421.0}, "meta_eval_completion_tokens": {"value": 3762.0}, "meta_eval_prompt_cost": {"value": 0.00269472}, "meta_eval_completion_cost": {"value": 0.00481536}}, "created": "2025-12-10T21:34:05.7436158Z"}
{"ref": "TQ131", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.287344}, "meta_inference_prompt_tokens": {"value": 13070.0}, "meta_inference_completion_tokens": {"value": 1761.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002614}, "meta_inference_completion_cost": {"value": 0.0028176}, "meta_eval_time": {"value": 28.046}, "meta_eval_prompt_tokens": {"value": 8343.0}, "meta_eval_completion_tokens": {"value": 2887.0}, "meta_eval_prompt_cost": {"value": 0.00266976}, "meta_eval_completion_cost": {"value": 0.00369536}}, "created": "2025-12-10T21:34:06.1005814Z"}
{"ref": "TQ116-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.37398974791402}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.705882352941176}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 27.301846}, "meta_inference_prompt_tokens": {"value": 12931.0}, "meta_inference_completion_tokens": {"value": 1603.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025862}, "meta_inference_completion_cost": {"value": 0.0025648}, "meta_eval_time": {"value": 68.36}, "meta_eval_prompt_tokens": {"value": 11293.0}, "meta_eval_completion_tokens": {"value": 6833.0}, "meta_eval_prompt_cost": {"value": 0.00361376}, "meta_eval_completion_cost": {"value": 0.00874624}}, "created": "2025-12-10T21:34:07.0005852Z"}
{"ref": "TQ133", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 14.607558}, "meta_inference_prompt_tokens": {"value": 10186.0}, "meta_inference_completion_tokens": {"value": 631.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020372}, "meta_inference_completion_cost": {"value": 0.0010096}, "meta_eval_time": {"value": 21.294}, "meta_eval_prompt_tokens": {"value": 5049.0}, "meta_eval_completion_tokens": {"value": 1586.0}, "meta_eval_prompt_cost": {"value": 0.00161568}, "meta_eval_completion_cost": {"value": 0.00203008}}, "created": "2025-12-10T21:34:07.1250564Z"}
{"ref": "TQ130", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.210526315789474}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 0.2}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.2}, "meta_inference_time": {"value": 29.492172}, "meta_inference_prompt_tokens": {"value": 14191.0}, "meta_inference_completion_tokens": {"value": 1461.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028382}, "meta_inference_completion_cost": {"value": 0.0023376}, "meta_eval_time": {"value": 24.149}, "meta_eval_prompt_tokens": {"value": 8679.0}, "meta_eval_completion_tokens": {"value": 2374.0}, "meta_eval_prompt_cost": {"value": 0.00277728}, "meta_eval_completion_cost": {"value": 0.00303872}}, "created": "2025-12-10T21:34:09.4271396Z"}
{"ref": "TQ13", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.870967741935484}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 27.212001}, "meta_inference_prompt_tokens": {"value": 8475.0}, "meta_inference_completion_tokens": {"value": 1485.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001695}, "meta_inference_completion_cost": {"value": 0.002376}, "meta_eval_time": {"value": 35.012}, "meta_eval_prompt_tokens": {"value": 6318.0}, "meta_eval_completion_tokens": {"value": 3286.0}, "meta_eval_prompt_cost": {"value": 0.00202176}, "meta_eval_completion_cost": {"value": 0.00420608}}, "created": "2025-12-10T21:34:10.7149384Z"}
{"ref": "TQ129", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.978260869565217}, "generation_factuality_f1": {"value": 0.685714285714286}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 32.094355}, "meta_inference_prompt_tokens": {"value": 11952.0}, "meta_inference_completion_tokens": {"value": 1918.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023904}, "meta_inference_completion_cost": {"value": 0.0030688}, "meta_eval_time": {"value": 48.202}, "meta_eval_prompt_tokens": {"value": 9490.0}, "meta_eval_completion_tokens": {"value": 4824.0}, "meta_eval_prompt_cost": {"value": 0.0030368}, "meta_eval_completion_cost": {"value": 0.00617472}}, "created": "2025-12-10T21:34:12.2971827Z"}
{"ref": "TQ134-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.261111111111111}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 0.85}, "generation_factuality_f1": {"value": 0.235294117647059}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.2}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 0.2}, "meta_inference_time": {"value": 22.896804}, "meta_inference_prompt_tokens": {"value": 11792.0}, "meta_inference_completion_tokens": {"value": 1504.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023584}, "meta_inference_completion_cost": {"value": 0.0024064}, "meta_eval_time": {"value": 24.971}, "meta_eval_prompt_tokens": {"value": 6898.0}, "meta_eval_completion_tokens": {"value": 2352.0}, "meta_eval_prompt_cost": {"value": 0.00220736}, "meta_eval_completion_cost": {"value": 0.00301056}}, "created": "2025-12-10T21:34:17.5487882Z"}
{"ref": "TQ135", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.98713694067948}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.253767}, "meta_inference_prompt_tokens": {"value": 11183.0}, "meta_inference_completion_tokens": {"value": 1257.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022366}, "meta_inference_completion_cost": {"value": 0.0020112}, "meta_eval_time": {"value": 27.741}, "meta_eval_prompt_tokens": {"value": 6871.0}, "meta_eval_completion_tokens": {"value": 2676.0}, "meta_eval_prompt_cost": {"value": 0.00219872}, "meta_eval_completion_cost": {"value": 0.00342528}}, "created": "2025-12-10T21:34:18.2256826Z"}
{"ref": "TQ134-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.266666666666667}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.521739130434783}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.4}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 34.035697}, "meta_inference_prompt_tokens": {"value": 13435.0}, "meta_inference_completion_tokens": {"value": 1935.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002687}, "meta_inference_completion_cost": {"value": 0.003096}, "meta_eval_time": {"value": 31.182}, "meta_eval_prompt_tokens": {"value": 9222.0}, "meta_eval_completion_tokens": {"value": 3028.0}, "meta_eval_prompt_cost": {"value": 0.00295104}, "meta_eval_completion_cost": {"value": 0.00387584}}, "created": "2025-12-10T21:34:18.2362192Z"}
{"ref": "TQ134-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.316666666666667}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 0.904761904761905}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 31.883489}, "meta_inference_prompt_tokens": {"value": 11661.0}, "meta_inference_completion_tokens": {"value": 1796.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023322}, "meta_inference_completion_cost": {"value": 0.0028736}, "meta_eval_time": {"value": 28.474}, "meta_eval_prompt_tokens": {"value": 7016.0}, "meta_eval_completion_tokens": {"value": 2652.0}, "meta_eval_prompt_cost": {"value": 0.00224512}, "meta_eval_completion_cost": {"value": 0.00339456}}, "created": "2025-12-10T21:34:18.2917249Z"}
{"ref": "TQ131", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.946394630357186}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.744399}, "meta_inference_prompt_tokens": {"value": 14202.0}, "meta_inference_completion_tokens": {"value": 1846.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028404}, "meta_inference_completion_cost": {"value": 0.0029536}, "meta_eval_time": {"value": 37.008}, "meta_eval_prompt_tokens": {"value": 9795.0}, "meta_eval_completion_tokens": {"value": 3441.0}, "meta_eval_prompt_cost": {"value": 0.0031344}, "meta_eval_completion_cost": {"value": 0.00440448}}, "created": "2025-12-10T21:34:18.4101566Z"}
{"ref": "TQ132", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.962018}, "meta_inference_prompt_tokens": {"value": 12414.0}, "meta_inference_completion_tokens": {"value": 1014.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024828}, "meta_inference_completion_cost": {"value": 0.0016224}, "meta_eval_time": {"value": 27.502}, "meta_eval_prompt_tokens": {"value": 7555.0}, "meta_eval_completion_tokens": {"value": 2507.0}, "meta_eval_prompt_cost": {"value": 0.0024176}, "meta_eval_completion_cost": {"value": 0.00320896}}, "created": "2025-12-10T21:34:18.591088Z"}
{"ref": "TQ131", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.977777777777778}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.876245}, "meta_inference_prompt_tokens": {"value": 11433.0}, "meta_inference_completion_tokens": {"value": 1703.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022866}, "meta_inference_completion_cost": {"value": 0.0027248}, "meta_eval_time": {"value": 41.704}, "meta_eval_prompt_tokens": {"value": 7625.0}, "meta_eval_completion_tokens": {"value": 4052.0}, "meta_eval_prompt_cost": {"value": 0.00244}, "meta_eval_completion_cost": {"value": 0.00518656}}, "created": "2025-12-10T21:34:18.9059864Z"}
{"ref": "TQ13", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 27.349359}, "meta_inference_prompt_tokens": {"value": 12379.0}, "meta_inference_completion_tokens": {"value": 1816.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024758}, "meta_inference_completion_cost": {"value": 0.0029056}, "meta_eval_time": {"value": 53.29}, "meta_eval_prompt_tokens": {"value": 9933.0}, "meta_eval_completion_tokens": {"value": 4868.0}, "meta_eval_prompt_cost": {"value": 0.00317856}, "meta_eval_completion_cost": {"value": 0.00623104}}, "created": "2025-12-10T21:34:19.1929144Z"}
{"ref": "TQ135", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.966666666666667}, "generation_factuality_f1": {"value": 0.631578947368421}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 28.466497}, "meta_inference_prompt_tokens": {"value": 12355.0}, "meta_inference_completion_tokens": {"value": 1242.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002471}, "meta_inference_completion_cost": {"value": 0.0019872}, "meta_eval_time": {"value": 28.722}, "meta_eval_prompt_tokens": {"value": 8093.0}, "meta_eval_completion_tokens": {"value": 2994.0}, "meta_eval_prompt_cost": {"value": 0.00258976}, "meta_eval_completion_cost": {"value": 0.00383232}}, "created": "2025-12-10T21:34:19.7927287Z"}
{"ref": "TQ131", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.964263086904791}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.095704}, "meta_inference_prompt_tokens": {"value": 14241.0}, "meta_inference_completion_tokens": {"value": 1439.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028482}, "meta_inference_completion_cost": {"value": 0.0023024}, "meta_eval_time": {"value": 44.522}, "meta_eval_prompt_tokens": {"value": 10348.0}, "meta_eval_completion_tokens": {"value": 4385.0}, "meta_eval_prompt_cost": {"value": 0.00331136}, "meta_eval_completion_cost": {"value": 0.0056128}}, "created": "2025-12-10T21:34:21.015261Z"}
{"ref": "TQ137", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.743059994342564}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.648648648648649}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 23.71578}, "meta_inference_prompt_tokens": {"value": 13468.0}, "meta_inference_completion_tokens": {"value": 1551.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026936}, "meta_inference_completion_cost": {"value": 0.0024816}, "meta_eval_time": {"value": 24.608}, "meta_eval_prompt_tokens": {"value": 8665.0}, "meta_eval_completion_tokens": {"value": 2452.0}, "meta_eval_prompt_cost": {"value": 0.0027728}, "meta_eval_completion_cost": {"value": 0.00313856}}, "created": "2025-12-10T21:34:22.6680395Z"}
{"ref": "TQ137", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.67591763355243}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 27.670478}, "meta_inference_prompt_tokens": {"value": 11714.0}, "meta_inference_completion_tokens": {"value": 1612.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023428}, "meta_inference_completion_cost": {"value": 0.0025792}, "meta_eval_time": {"value": 24.539}, "meta_eval_prompt_tokens": {"value": 6980.0}, "meta_eval_completion_tokens": {"value": 2285.0}, "meta_eval_prompt_cost": {"value": 0.0022336}, "meta_eval_completion_cost": {"value": 0.0029248}}, "created": "2025-12-10T21:34:22.9846814Z"}
{"ref": "TQ135", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.315789473684211}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 0.2}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.2}, "meta_inference_time": {"value": 19.966141}, "meta_inference_prompt_tokens": {"value": 11087.0}, "meta_inference_completion_tokens": {"value": 992.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022174}, "meta_inference_completion_cost": {"value": 0.0015872}, "meta_eval_time": {"value": 29.763}, "meta_eval_prompt_tokens": {"value": 7005.0}, "meta_eval_completion_tokens": {"value": 3193.0}, "meta_eval_prompt_cost": {"value": 0.0022416}, "meta_eval_completion_cost": {"value": 0.00408704}}, "created": "2025-12-10T21:34:23.2490584Z"}
{"ref": "TQ131", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.398263}, "meta_inference_prompt_tokens": {"value": 14336.0}, "meta_inference_completion_tokens": {"value": 1321.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028672}, "meta_inference_completion_cost": {"value": 0.0021136}, "meta_eval_time": {"value": 32.283}, "meta_eval_prompt_tokens": {"value": 9806.0}, "meta_eval_completion_tokens": {"value": 3018.0}, "meta_eval_prompt_cost": {"value": 0.00313792}, "meta_eval_completion_cost": {"value": 0.00386304}}, "created": "2025-12-10T21:34:23.2622084Z"}
{"ref": "TQ132", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 15.142542}, "meta_inference_prompt_tokens": {"value": 12913.0}, "meta_inference_completion_tokens": {"value": 742.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025826}, "meta_inference_completion_cost": {"value": 0.0011872}, "meta_eval_time": {"value": 19.623}, "meta_eval_prompt_tokens": {"value": 7289.0}, "meta_eval_completion_tokens": {"value": 2045.0}, "meta_eval_prompt_cost": {"value": 0.00233248}, "meta_eval_completion_cost": {"value": 0.0026176}}, "created": "2025-12-10T21:34:23.833727Z"}
{"ref": "TQ135", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 25.68447}, "meta_inference_prompt_tokens": {"value": 10588.0}, "meta_inference_completion_tokens": {"value": 1085.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021176}, "meta_inference_completion_cost": {"value": 0.001736}, "meta_eval_time": {"value": 32.13}, "meta_eval_prompt_tokens": {"value": 6514.0}, "meta_eval_completion_tokens": {"value": 2645.0}, "meta_eval_prompt_cost": {"value": 0.00208448}, "meta_eval_completion_cost": {"value": 0.0033856}}, "created": "2025-12-10T21:34:24.58931Z"}
{"ref": "TQ134-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.320833333333333}, "retrieval_dcg": {"value": 2.56160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 24.488843}, "meta_inference_prompt_tokens": {"value": 12604.0}, "meta_inference_completion_tokens": {"value": 1497.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025208}, "meta_inference_completion_cost": {"value": 0.0023952}, "meta_eval_time": {"value": 38.361}, "meta_eval_prompt_tokens": {"value": 8347.0}, "meta_eval_completion_tokens": {"value": 3379.0}, "meta_eval_prompt_cost": {"value": 0.00267104}, "meta_eval_completion_cost": {"value": 0.00432512}}, "created": "2025-12-10T21:34:25.0271388Z"}
{"ref": "TQ137", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.886852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.933333333333333}, "generation_factuality_precision": {"value": 0.875}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.091824}, "meta_inference_prompt_tokens": {"value": 13413.0}, "meta_inference_completion_tokens": {"value": 1545.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026826}, "meta_inference_completion_cost": {"value": 0.002472}, "meta_eval_time": {"value": 25.249}, "meta_eval_prompt_tokens": {"value": 8224.0}, "meta_eval_completion_tokens": {"value": 2660.0}, "meta_eval_prompt_cost": {"value": 0.00263168}, "meta_eval_completion_cost": {"value": 0.0034048}}, "created": "2025-12-10T21:34:27.7754015Z"}
{"ref": "TQ129", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.849056603773585}, "generation_factuality_f1": {"value": 0.746666666666666}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 35.029495}, "meta_inference_prompt_tokens": {"value": 11281.0}, "meta_inference_completion_tokens": {"value": 1556.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022562}, "meta_inference_completion_cost": {"value": 0.0024896}, "meta_eval_time": {"value": 56.251}, "meta_eval_prompt_tokens": {"value": 8556.0}, "meta_eval_completion_tokens": {"value": 5328.0}, "meta_eval_prompt_cost": {"value": 0.00273792}, "meta_eval_completion_cost": {"value": 0.00681984}}, "created": "2025-12-10T21:34:28.9163305Z"}
{"ref": "TQ139", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 34.377854}, "meta_inference_prompt_tokens": {"value": 13753.0}, "meta_inference_completion_tokens": {"value": 1664.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027506}, "meta_inference_completion_cost": {"value": 0.0026624}, "meta_eval_time": {"value": 23.348}, "meta_eval_prompt_tokens": {"value": 8345.0}, "meta_eval_completion_tokens": {"value": 2111.0}, "meta_eval_prompt_cost": {"value": 0.0026704}, "meta_eval_completion_cost": {"value": 0.00270208}}, "created": "2025-12-10T21:34:28.9942895Z"}
{"ref": "TQ137", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.833333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.458701}, "meta_inference_prompt_tokens": {"value": 12802.0}, "meta_inference_completion_tokens": {"value": 1154.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025604}, "meta_inference_completion_cost": {"value": 0.0018464}, "meta_eval_time": {"value": 29.338}, "meta_eval_prompt_tokens": {"value": 8036.0}, "meta_eval_completion_tokens": {"value": 2901.0}, "meta_eval_prompt_cost": {"value": 0.00257152}, "meta_eval_completion_cost": {"value": 0.00371328}}, "created": "2025-12-10T21:34:29.898098Z"}
{"ref": "TQ136", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.23170655373737}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.754716981132076}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 25.61}, "meta_inference_prompt_tokens": {"value": 15404.0}, "meta_inference_completion_tokens": {"value": 1488.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030808}, "meta_inference_completion_cost": {"value": 0.0023808}, "meta_eval_time": {"value": 35.717}, "meta_eval_prompt_tokens": {"value": 11665.0}, "meta_eval_completion_tokens": {"value": 3548.0}, "meta_eval_prompt_cost": {"value": 0.0037328}, "meta_eval_completion_cost": {"value": 0.00454144}}, "created": "2025-12-10T21:34:31.2953778Z"}
{"ref": "TQ129", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 27.281506}, "meta_inference_prompt_tokens": {"value": 11583.0}, "meta_inference_completion_tokens": {"value": 1398.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023166}, "meta_inference_completion_cost": {"value": 0.0022368}, "meta_eval_time": {"value": 59.853}, "meta_eval_prompt_tokens": {"value": 8969.0}, "meta_eval_completion_tokens": {"value": 5854.0}, "meta_eval_prompt_cost": {"value": 0.00287008}, "meta_eval_completion_cost": {"value": 0.00749312}}, "created": "2025-12-10T21:34:31.3210109Z"}
{"ref": "TQ133", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.631578947368421}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 12.615759}, "meta_inference_prompt_tokens": {"value": 10728.0}, "meta_inference_completion_tokens": {"value": 620.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021456}, "meta_inference_completion_cost": {"value": 0.000992}, "meta_eval_time": {"value": 13.264}, "meta_eval_prompt_tokens": {"value": 5291.0}, "meta_eval_completion_tokens": {"value": 1150.0}, "meta_eval_prompt_cost": {"value": 0.00169312}, "meta_eval_completion_cost": {"value": 0.001472}}, "created": "2025-12-10T21:34:31.5946185Z"}
{"ref": "TQ136", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.17810118409456}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.541676}, "meta_inference_prompt_tokens": {"value": 16711.0}, "meta_inference_completion_tokens": {"value": 1529.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0033422}, "meta_inference_completion_cost": {"value": 0.0024464}, "meta_eval_time": {"value": 35.092}, "meta_eval_prompt_tokens": {"value": 12701.0}, "meta_eval_completion_tokens": {"value": 3710.0}, "meta_eval_prompt_cost": {"value": 0.00406432}, "meta_eval_completion_cost": {"value": 0.0047488}}, "created": "2025-12-10T21:34:31.9590904Z"}
{"ref": "TQ129", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.980769230769231}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 34.75547}, "meta_inference_prompt_tokens": {"value": 11821.0}, "meta_inference_completion_tokens": {"value": 1975.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023642}, "meta_inference_completion_cost": {"value": 0.00316}, "meta_eval_time": {"value": 55.976}, "meta_eval_prompt_tokens": {"value": 9615.0}, "meta_eval_completion_tokens": {"value": 5469.0}, "meta_eval_prompt_cost": {"value": 0.0030768}, "meta_eval_completion_cost": {"value": 0.00700032}}, "created": "2025-12-10T21:34:32.0783754Z"}
{"ref": "TQ138", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.449433}, "meta_inference_prompt_tokens": {"value": 10991.0}, "meta_inference_completion_tokens": {"value": 1162.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021982}, "meta_inference_completion_cost": {"value": 0.0018592}, "meta_eval_time": {"value": 27.191}, "meta_eval_prompt_tokens": {"value": 6380.0}, "meta_eval_completion_tokens": {"value": 2427.0}, "meta_eval_prompt_cost": {"value": 0.0020416}, "meta_eval_completion_cost": {"value": 0.00310656}}, "created": "2025-12-10T21:34:32.9798001Z"}
{"ref": "TQ14-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.5}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.166666666666667}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.166666666666667}, "meta_inference_time": {"value": 21.733315}, "meta_inference_prompt_tokens": {"value": 5474.0}, "meta_inference_completion_tokens": {"value": 1354.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0010948}, "meta_inference_completion_cost": {"value": 0.0021664}, "meta_eval_time": {"value": 14.933}, "meta_eval_prompt_tokens": {"value": 3123.0}, "meta_eval_completion_tokens": {"value": 1401.0}, "meta_eval_prompt_cost": {"value": 0.00099936}, "meta_eval_completion_cost": {"value": 0.00179328}}, "created": "2025-12-10T21:34:33.1959504Z"}
{"ref": "TQ139", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.962962962962963}, "generation_factuality_f1": {"value": 0.558139534883721}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 24.36042}, "meta_inference_prompt_tokens": {"value": 12053.0}, "meta_inference_completion_tokens": {"value": 1291.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024106}, "meta_inference_completion_cost": {"value": 0.0020656}, "meta_eval_time": {"value": 26.428}, "meta_eval_prompt_tokens": {"value": 7532.0}, "meta_eval_completion_tokens": {"value": 2639.0}, "meta_eval_prompt_cost": {"value": 0.00241024}, "meta_eval_completion_cost": {"value": 0.00337792}}, "created": "2025-12-10T21:34:33.4913279Z"}
{"ref": "TQ139", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428571}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 18.458986}, "meta_inference_prompt_tokens": {"value": 13431.0}, "meta_inference_completion_tokens": {"value": 1123.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026862}, "meta_inference_completion_cost": {"value": 0.0017968}, "meta_eval_time": {"value": 24.569}, "meta_eval_prompt_tokens": {"value": 8337.0}, "meta_eval_completion_tokens": {"value": 2485.0}, "meta_eval_prompt_cost": {"value": 0.00266784}, "meta_eval_completion_cost": {"value": 0.0031808}}, "created": "2025-12-10T21:34:34.0585213Z"}
{"ref": "TQ137", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666666}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 21.937838}, "meta_inference_prompt_tokens": {"value": 12010.0}, "meta_inference_completion_tokens": {"value": 1067.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002402}, "meta_inference_completion_cost": {"value": 0.0017072}, "meta_eval_time": {"value": 29.929}, "meta_eval_prompt_tokens": {"value": 7408.0}, "meta_eval_completion_tokens": {"value": 2840.0}, "meta_eval_prompt_cost": {"value": 0.00237056}, "meta_eval_completion_cost": {"value": 0.0036352}}, "created": "2025-12-10T21:34:34.9042028Z"}
{"ref": "TQ134-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.316666666666667}, "retrieval_dcg": {"value": 1.93067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.342857142857143}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 42.837745}, "meta_inference_prompt_tokens": {"value": 11814.0}, "meta_inference_completion_tokens": {"value": 2188.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023628}, "meta_inference_completion_cost": {"value": 0.0035008}, "meta_eval_time": {"value": 42.521}, "meta_eval_prompt_tokens": {"value": 8272.0}, "meta_eval_completion_tokens": {"value": 4035.0}, "meta_eval_prompt_cost": {"value": 0.00264704}, "meta_eval_completion_cost": {"value": 0.0051648}}, "created": "2025-12-10T21:34:35.0158404Z"}
{"ref": "TQ139", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.754716981132076}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 21.397034}, "meta_inference_prompt_tokens": {"value": 13329.0}, "meta_inference_completion_tokens": {"value": 1334.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026658}, "meta_inference_completion_cost": {"value": 0.0021344}, "meta_eval_time": {"value": 23.028}, "meta_eval_prompt_tokens": {"value": 8140.0}, "meta_eval_completion_tokens": {"value": 2145.0}, "meta_eval_prompt_cost": {"value": 0.0026048}, "meta_eval_completion_cost": {"value": 0.0027456}}, "created": "2025-12-10T21:34:35.389391Z"}
{"ref": "TQ138", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.823529411764706}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.057127}, "meta_inference_prompt_tokens": {"value": 11699.0}, "meta_inference_completion_tokens": {"value": 1599.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023398}, "meta_inference_completion_cost": {"value": 0.0025584}, "meta_eval_time": {"value": 32.64}, "meta_eval_prompt_tokens": {"value": 7568.0}, "meta_eval_completion_tokens": {"value": 3369.0}, "meta_eval_prompt_cost": {"value": 0.00242176}, "meta_eval_completion_cost": {"value": 0.00431232}}, "created": "2025-12-10T21:34:36.6616527Z"}
{"ref": "TQ135", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.646153846153846}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 30.687269}, "meta_inference_prompt_tokens": {"value": 12484.0}, "meta_inference_completion_tokens": {"value": 1491.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024968}, "meta_inference_completion_cost": {"value": 0.0023856}, "meta_eval_time": {"value": 42.54}, "meta_eval_prompt_tokens": {"value": 8674.0}, "meta_eval_completion_tokens": {"value": 3605.0}, "meta_eval_prompt_cost": {"value": 0.00277568}, "meta_eval_completion_cost": {"value": 0.0046144}}, "created": "2025-12-10T21:34:36.9174879Z"}
{"ref": "TQ14-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.764705882352941}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 22.517625}, "meta_inference_prompt_tokens": {"value": 6140.0}, "meta_inference_completion_tokens": {"value": 912.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001228}, "meta_inference_completion_cost": {"value": 0.0014592}, "meta_eval_time": {"value": 19.181}, "meta_eval_prompt_tokens": {"value": 3669.0}, "meta_eval_completion_tokens": {"value": 1775.0}, "meta_eval_prompt_cost": {"value": 0.00117408}, "meta_eval_completion_cost": {"value": 0.002272}}, "created": "2025-12-10T21:34:37.6347387Z"}
{"ref": "TQ136", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.566666666666667}, "retrieval_dcg": {"value": 2.017782560806}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 26.659113}, "meta_inference_prompt_tokens": {"value": 15096.0}, "meta_inference_completion_tokens": {"value": 1474.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030192}, "meta_inference_completion_cost": {"value": 0.0023584}, "meta_eval_time": {"value": 37.259}, "meta_eval_prompt_tokens": {"value": 11078.0}, "meta_eval_completion_tokens": {"value": 3678.0}, "meta_eval_prompt_cost": {"value": 0.00354496}, "meta_eval_completion_cost": {"value": 0.00470784}}, "created": "2025-12-10T21:34:37.753677Z"}
{"ref": "TQ136", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.508333333333333}, "retrieval_dcg": {"value": 2.31881255646998}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.701754385964912}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 27.697743}, "meta_inference_prompt_tokens": {"value": 15477.0}, "meta_inference_completion_tokens": {"value": 1703.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030954}, "meta_inference_completion_cost": {"value": 0.0027248}, "meta_eval_time": {"value": 46.624}, "meta_eval_prompt_tokens": {"value": 11499.0}, "meta_eval_completion_tokens": {"value": 3921.0}, "meta_eval_prompt_cost": {"value": 0.00367968}, "meta_eval_completion_cost": {"value": 0.00501888}}, "created": "2025-12-10T21:34:39.0880119Z"}
{"ref": "TQ14-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.631578947368421}, "generation_factuality_f1": {"value": 0.210526315789474}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 0.2}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.2}, "meta_inference_time": {"value": 34.08955}, "meta_inference_prompt_tokens": {"value": 5741.0}, "meta_inference_completion_tokens": {"value": 1497.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0011482}, "meta_inference_completion_cost": {"value": 0.0023952}, "meta_eval_time": {"value": 21.935}, "meta_eval_prompt_tokens": {"value": 4136.0}, "meta_eval_completion_tokens": {"value": 2194.0}, "meta_eval_prompt_cost": {"value": 0.00132352}, "meta_eval_completion_cost": {"value": 0.00280832}}, "created": "2025-12-10T21:34:40.5750085Z"}
{"ref": "TQ14-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.111111111111111}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.958333333333334}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0588235294117647}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.125}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.762643}, "meta_inference_prompt_tokens": {"value": 12620.0}, "meta_inference_completion_tokens": {"value": 1612.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002524}, "meta_inference_completion_cost": {"value": 0.0025792}, "meta_eval_time": {"value": 22.886}, "meta_eval_prompt_tokens": {"value": 8591.0}, "meta_eval_completion_tokens": {"value": 2585.0}, "meta_eval_prompt_cost": {"value": 0.00274912}, "meta_eval_completion_cost": {"value": 0.0033088}}, "created": "2025-12-10T21:34:40.6088258Z"}
{"ref": "TQ138", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.962962962962963}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.972924}, "meta_inference_prompt_tokens": {"value": 11770.0}, "meta_inference_completion_tokens": {"value": 1223.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002354}, "meta_inference_completion_cost": {"value": 0.0019568}, "meta_eval_time": {"value": 29.971}, "meta_eval_prompt_tokens": {"value": 7451.0}, "meta_eval_completion_tokens": {"value": 2859.0}, "meta_eval_prompt_cost": {"value": 0.00238432}, "meta_eval_completion_cost": {"value": 0.00365952}}, "created": "2025-12-10T21:34:40.7220649Z"}
{"ref": "TQ138", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.86046511627907}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.360397}, "meta_inference_prompt_tokens": {"value": 11289.0}, "meta_inference_completion_tokens": {"value": 1921.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022578}, "meta_inference_completion_cost": {"value": 0.0030736}, "meta_eval_time": {"value": 35.873}, "meta_eval_prompt_tokens": {"value": 7765.0}, "meta_eval_completion_tokens": {"value": 4017.0}, "meta_eval_prompt_cost": {"value": 0.0024848}, "meta_eval_completion_cost": {"value": 0.00514176}}, "created": "2025-12-10T21:34:43.0399967Z"}
{"ref": "TQ141", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.002554}, "meta_inference_prompt_tokens": {"value": 13267.0}, "meta_inference_completion_tokens": {"value": 799.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026534}, "meta_inference_completion_cost": {"value": 0.0012784}, "meta_eval_time": {"value": 18.45}, "meta_eval_prompt_tokens": {"value": 7942.0}, "meta_eval_completion_tokens": {"value": 1839.0}, "meta_eval_prompt_cost": {"value": 0.00254144}, "meta_eval_completion_cost": {"value": 0.00235392}}, "created": "2025-12-10T21:34:43.0805801Z"}
{"ref": "TQ140", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 23.175432}, "meta_inference_prompt_tokens": {"value": 11800.0}, "meta_inference_completion_tokens": {"value": 1016.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00236}, "meta_inference_completion_cost": {"value": 0.0016256}, "meta_eval_time": {"value": 20.865}, "meta_eval_prompt_tokens": {"value": 6981.0}, "meta_eval_completion_tokens": {"value": 1981.0}, "meta_eval_prompt_cost": {"value": 0.00223392}, "meta_eval_completion_cost": {"value": 0.00253568}}, "created": "2025-12-10T21:34:43.9229288Z"}
{"ref": "TQ141", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.85913}, "meta_inference_prompt_tokens": {"value": 12873.0}, "meta_inference_completion_tokens": {"value": 803.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025746}, "meta_inference_completion_cost": {"value": 0.0012848}, "meta_eval_time": {"value": 21.125}, "meta_eval_prompt_tokens": {"value": 7779.0}, "meta_eval_completion_tokens": {"value": 1740.0}, "meta_eval_prompt_cost": {"value": 0.00248928}, "meta_eval_completion_cost": {"value": 0.0022272}}, "created": "2025-12-10T21:34:44.4273199Z"}
{"ref": "TQ141", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.167777}, "meta_inference_prompt_tokens": {"value": 12964.0}, "meta_inference_completion_tokens": {"value": 704.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025928}, "meta_inference_completion_cost": {"value": 0.0011264}, "meta_eval_time": {"value": 19.515}, "meta_eval_prompt_tokens": {"value": 7736.0}, "meta_eval_completion_tokens": {"value": 1619.0}, "meta_eval_prompt_cost": {"value": 0.00247552}, "meta_eval_completion_cost": {"value": 0.00207232}}, "created": "2025-12-10T21:34:44.5858952Z"}
{"ref": "TQ138", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.704545454545454}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.097411}, "meta_inference_prompt_tokens": {"value": 10964.0}, "meta_inference_completion_tokens": {"value": 2091.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021928}, "meta_inference_completion_cost": {"value": 0.0033456}, "meta_eval_time": {"value": 38.986}, "meta_eval_prompt_tokens": {"value": 7215.0}, "meta_eval_completion_tokens": {"value": 3937.0}, "meta_eval_prompt_cost": {"value": 0.0023088}, "meta_eval_completion_cost": {"value": 0.00503936}}, "created": "2025-12-10T21:34:45.1543401Z"}
{"ref": "TQ140", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 25.335666}, "meta_inference_prompt_tokens": {"value": 10709.0}, "meta_inference_completion_tokens": {"value": 1329.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021418}, "meta_inference_completion_cost": {"value": 0.0021264}, "meta_eval_time": {"value": 24.342}, "meta_eval_prompt_tokens": {"value": 6126.0}, "meta_eval_completion_tokens": {"value": 2557.0}, "meta_eval_prompt_cost": {"value": 0.00196032}, "meta_eval_completion_cost": {"value": 0.00327296}}, "created": "2025-12-10T21:34:48.2124166Z"}
{"ref": "TQ147", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.93195974923544}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 19.427414}, "meta_inference_prompt_tokens": {"value": 13810.0}, "meta_inference_completion_tokens": {"value": 885.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002762}, "meta_inference_completion_cost": {"value": 0.001416}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:34:48.2518075Z"}
{"ref": "TQ141", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.944444444444444}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.867535}, "meta_inference_prompt_tokens": {"value": 13159.0}, "meta_inference_completion_tokens": {"value": 754.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026318}, "meta_inference_completion_cost": {"value": 0.0012064}, "meta_eval_time": {"value": 22.202}, "meta_eval_prompt_tokens": {"value": 8023.0}, "meta_eval_completion_tokens": {"value": 2013.0}, "meta_eval_prompt_cost": {"value": 0.00256736}, "meta_eval_completion_cost": {"value": 0.00257664}}, "created": "2025-12-10T21:34:50.0204397Z"}
{"ref": "TQ141", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.496726}, "meta_inference_prompt_tokens": {"value": 12949.0}, "meta_inference_completion_tokens": {"value": 946.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025898}, "meta_inference_completion_cost": {"value": 0.0015136}, "meta_eval_time": {"value": 21.385}, "meta_eval_prompt_tokens": {"value": 7908.0}, "meta_eval_completion_tokens": {"value": 2064.0}, "meta_eval_prompt_cost": {"value": 0.00253056}, "meta_eval_completion_cost": {"value": 0.00264192}}, "created": "2025-12-10T21:34:50.3481285Z"}
{"ref": "TQ139", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.51063829787234}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 22.438068}, "meta_inference_prompt_tokens": {"value": 13278.0}, "meta_inference_completion_tokens": {"value": 1180.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026556}, "meta_inference_completion_cost": {"value": 0.001888}, "meta_eval_time": {"value": 32.395}, "meta_eval_prompt_tokens": {"value": 8334.0}, "meta_eval_completion_tokens": {"value": 2857.0}, "meta_eval_prompt_cost": {"value": 0.00266688}, "meta_eval_completion_cost": {"value": 0.00365696}}, "created": "2025-12-10T21:34:51.3475114Z"}
{"ref": "TQ147", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.13092975357146}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 25.480353}, "meta_inference_prompt_tokens": {"value": 10755.0}, "meta_inference_completion_tokens": {"value": 1263.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002151}, "meta_inference_completion_cost": {"value": 0.0020208}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:34:51.3879284Z"}
{"ref": "TQ140", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 25.730872}, "meta_inference_prompt_tokens": {"value": 11861.0}, "meta_inference_completion_tokens": {"value": 1162.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023722}, "meta_inference_completion_cost": {"value": 0.0018592}, "meta_eval_time": {"value": 21.268}, "meta_eval_prompt_tokens": {"value": 6887.0}, "meta_eval_completion_tokens": {"value": 2143.0}, "meta_eval_prompt_cost": {"value": 0.00220384}, "meta_eval_completion_cost": {"value": 0.00274304}}, "created": "2025-12-10T21:34:52.6267472Z"}
{"ref": "TQ147", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 25.82845}, "meta_inference_prompt_tokens": {"value": 14975.0}, "meta_inference_completion_tokens": {"value": 723.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002995}, "meta_inference_completion_cost": {"value": 0.0011568}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:34:52.6753514Z"}
{"ref": "TQ142", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.111111111111111}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 0.6875}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0588235294117647}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.05}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 37.401693}, "meta_inference_prompt_tokens": {"value": 26520.0}, "meta_inference_completion_tokens": {"value": 2177.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.005304}, "meta_inference_completion_cost": {"value": 0.0034832}, "meta_eval_time": {"value": 21.5}, "meta_eval_prompt_tokens": {"value": 9140.0}, "meta_eval_completion_tokens": {"value": 1973.0}, "meta_eval_prompt_cost": {"value": 0.0029248}, "meta_eval_completion_cost": {"value": 0.00252544}}, "created": "2025-12-10T21:34:53.1560706Z"}
{"ref": "TQ14-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.117647058823529}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.96551724137931}, "generation_factuality_f1": {"value": 0.39344262295082}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.571428571428571}, "retrieval_accuracy": {"value": 0.0625}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.111111111111111}, "retrieval_recall": {"value": 0.125}, "generation_correctness": {"value": 0.571428571428571}, "meta_inference_time": {"value": 27.556811}, "meta_inference_prompt_tokens": {"value": 12621.0}, "meta_inference_completion_tokens": {"value": 1453.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025242}, "meta_inference_completion_cost": {"value": 0.0023248}, "meta_eval_time": {"value": 35.496}, "meta_eval_prompt_tokens": {"value": 8769.0}, "meta_eval_completion_tokens": {"value": 3189.0}, "meta_eval_prompt_cost": {"value": 0.00280608}, "meta_eval_completion_cost": {"value": 0.00408192}}, "created": "2025-12-10T21:34:53.7751781Z"}
{"ref": "TQ140", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.791666666666666}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 39.178844}, "meta_inference_prompt_tokens": {"value": 12129.0}, "meta_inference_completion_tokens": {"value": 1631.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024258}, "meta_inference_completion_cost": {"value": 0.0026096}, "meta_eval_time": {"value": 26.02}, "meta_eval_prompt_tokens": {"value": 7355.0}, "meta_eval_completion_tokens": {"value": 2334.0}, "meta_eval_prompt_cost": {"value": 0.0023536}, "meta_eval_completion_cost": {"value": 0.00298752}}, "created": "2025-12-10T21:34:55.0521784Z"}
{"ref": "TQ136", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.76392399566512}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 28.543312}, "meta_inference_prompt_tokens": {"value": 16472.0}, "meta_inference_completion_tokens": {"value": 1847.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032944}, "meta_inference_completion_cost": {"value": 0.0029552}, "meta_eval_time": {"value": 53.777}, "meta_eval_prompt_tokens": {"value": 13168.0}, "meta_eval_completion_tokens": {"value": 4942.0}, "meta_eval_prompt_cost": {"value": 0.00421376}, "meta_eval_completion_cost": {"value": 0.00632576}}, "created": "2025-12-10T21:34:56.5950513Z"}
{"ref": "TQ144", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.34045}, "meta_inference_prompt_tokens": {"value": 10737.0}, "meta_inference_completion_tokens": {"value": 1496.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021474}, "meta_inference_completion_cost": {"value": 0.0023936}, "meta_eval_time": {"value": 21.443}, "meta_eval_prompt_tokens": {"value": 5954.0}, "meta_eval_completion_tokens": {"value": 2033.0}, "meta_eval_prompt_cost": {"value": 0.00190528}, "meta_eval_completion_cost": {"value": 0.00260224}}, "created": "2025-12-10T21:34:58.3972133Z"}
{"ref": "TQ144", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.621437}, "meta_inference_prompt_tokens": {"value": 11146.0}, "meta_inference_completion_tokens": {"value": 1262.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022292}, "meta_inference_completion_cost": {"value": 0.0020192}, "meta_eval_time": {"value": 21.643}, "meta_eval_prompt_tokens": {"value": 6376.0}, "meta_eval_completion_tokens": {"value": 2304.0}, "meta_eval_prompt_cost": {"value": 0.00204032}, "meta_eval_completion_cost": {"value": 0.00294912}}, "created": "2025-12-10T21:34:59.4359528Z"}
{"ref": "TQ145-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.266666666666667}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 25.322808}, "meta_inference_prompt_tokens": {"value": 13144.0}, "meta_inference_completion_tokens": {"value": 1145.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026288}, "meta_inference_completion_cost": {"value": 0.001832}, "meta_eval_time": {"value": 19.559}, "meta_eval_prompt_tokens": {"value": 7643.0}, "meta_eval_completion_tokens": {"value": 1830.0}, "meta_eval_prompt_cost": {"value": 0.00244576}, "meta_eval_completion_cost": {"value": 0.0023424}}, "created": "2025-12-10T21:35:00.2043267Z"}
{"ref": "TQ144", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 26.481856}, "meta_inference_prompt_tokens": {"value": 11188.0}, "meta_inference_completion_tokens": {"value": 1329.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022376}, "meta_inference_completion_cost": {"value": 0.0021264}, "meta_eval_time": {"value": 28.075}, "meta_eval_prompt_tokens": {"value": 6654.0}, "meta_eval_completion_tokens": {"value": 2743.0}, "meta_eval_prompt_cost": {"value": 0.00212928}, "meta_eval_completion_cost": {"value": 0.00351104}}, "created": "2025-12-10T21:35:04.8133732Z"}
{"ref": "TQ142", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.133333333333333}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.551714361355082}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0714285714285714}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.05}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 50.158694}, "meta_inference_prompt_tokens": {"value": 25611.0}, "meta_inference_completion_tokens": {"value": 2951.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0051222}, "meta_inference_completion_cost": {"value": 0.0047216}, "meta_eval_time": {"value": 38.077}, "meta_eval_prompt_tokens": {"value": 10383.0}, "meta_eval_completion_tokens": {"value": 3658.0}, "meta_eval_prompt_cost": {"value": 0.00332256}, "meta_eval_completion_cost": {"value": 0.00468224}}, "created": "2025-12-10T21:35:08.0264827Z"}
{"ref": "TQ14-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.833333333333333}, "generation_faithfulness": {"value": 0.958333333333334}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.92535}, "meta_inference_prompt_tokens": {"value": 15320.0}, "meta_inference_completion_tokens": {"value": 1640.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003064}, "meta_inference_completion_cost": {"value": 0.002624}, "meta_eval_time": {"value": 48.263}, "meta_eval_prompt_tokens": {"value": 10940.0}, "meta_eval_completion_tokens": {"value": 4557.0}, "meta_eval_prompt_cost": {"value": 0.0035008}, "meta_eval_completion_cost": {"value": 0.00583296}}, "created": "2025-12-10T21:35:08.0924854Z"}
{"ref": "TQ144", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.824393}, "meta_inference_prompt_tokens": {"value": 11316.0}, "meta_inference_completion_tokens": {"value": 1179.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022632}, "meta_inference_completion_cost": {"value": 0.0018864}, "meta_eval_time": {"value": 33.087}, "meta_eval_prompt_tokens": {"value": 6982.0}, "meta_eval_completion_tokens": {"value": 3033.0}, "meta_eval_prompt_cost": {"value": 0.00223424}, "meta_eval_completion_cost": {"value": 0.00388224}}, "created": "2025-12-10T21:35:08.146848Z"}
{"ref": "TQ145-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.30997}, "meta_inference_prompt_tokens": {"value": 14219.0}, "meta_inference_completion_tokens": {"value": 957.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028438}, "meta_inference_completion_cost": {"value": 0.0015312}, "meta_eval_time": {"value": 25.881}, "meta_eval_prompt_tokens": {"value": 8947.0}, "meta_eval_completion_tokens": {"value": 2235.0}, "meta_eval_prompt_cost": {"value": 0.00286304}, "meta_eval_completion_cost": {"value": 0.0028608}}, "created": "2025-12-10T21:35:08.9966135Z"}
{"ref": "TQ144", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.360795}, "meta_inference_prompt_tokens": {"value": 11076.0}, "meta_inference_completion_tokens": {"value": 1344.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022152}, "meta_inference_completion_cost": {"value": 0.0021504}, "meta_eval_time": {"value": 34.07}, "meta_eval_prompt_tokens": {"value": 6308.0}, "meta_eval_completion_tokens": {"value": 2339.0}, "meta_eval_prompt_cost": {"value": 0.00201856}, "meta_eval_completion_cost": {"value": 0.00299392}}, "created": "2025-12-10T21:35:09.0103758Z"}
{"ref": "TQ145-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.98713694067948}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.994202}, "meta_inference_prompt_tokens": {"value": 13074.0}, "meta_inference_completion_tokens": {"value": 1027.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026148}, "meta_inference_completion_cost": {"value": 0.0016432}, "meta_eval_time": {"value": 25.297}, "meta_eval_prompt_tokens": {"value": 7946.0}, "meta_eval_completion_tokens": {"value": 2207.0}, "meta_eval_prompt_cost": {"value": 0.00254272}, "meta_eval_completion_cost": {"value": 0.00282496}}, "created": "2025-12-10T21:35:09.7631342Z"}
{"ref": "TQ14-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.886852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.410639}, "meta_inference_prompt_tokens": {"value": 15317.0}, "meta_inference_completion_tokens": {"value": 1540.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030634}, "meta_inference_completion_cost": {"value": 0.002464}, "meta_eval_time": {"value": 50.528}, "meta_eval_prompt_tokens": {"value": 11278.0}, "meta_eval_completion_tokens": {"value": 5062.0}, "meta_eval_prompt_cost": {"value": 0.00360896}, "meta_eval_completion_cost": {"value": 0.00647936}}, "created": "2025-12-10T21:35:09.7650145Z"}
{"ref": "TQ145-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 0.944444444444444}, "generation_factuality_f1": {"value": 0.533333333333333}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 19.76178}, "meta_inference_prompt_tokens": {"value": 13311.0}, "meta_inference_completion_tokens": {"value": 1033.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026622}, "meta_inference_completion_cost": {"value": 0.0016528}, "meta_eval_time": {"value": 24.905}, "meta_eval_prompt_tokens": {"value": 7898.0}, "meta_eval_completion_tokens": {"value": 2138.0}, "meta_eval_prompt_cost": {"value": 0.00252736}, "meta_eval_completion_cost": {"value": 0.00273664}}, "created": "2025-12-10T21:35:10.0992626Z"}
{"ref": "TQ14-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.930676558073393}, "generation_faithfulness": {"value": 0.978723404255319}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 26.662213}, "meta_inference_prompt_tokens": {"value": 15551.0}, "meta_inference_completion_tokens": {"value": 1376.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031102}, "meta_inference_completion_cost": {"value": 0.0022016}, "meta_eval_time": {"value": 48.432}, "meta_eval_prompt_tokens": {"value": 10817.0}, "meta_eval_completion_tokens": {"value": 4268.0}, "meta_eval_prompt_cost": {"value": 0.00346144}, "meta_eval_completion_cost": {"value": 0.00546304}}, "created": "2025-12-10T21:35:11.7263689Z"}
{"ref": "TQ142", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 0.975}, "generation_factuality_f1": {"value": 0.754716981132076}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 26.914006}, "meta_inference_prompt_tokens": {"value": 10929.0}, "meta_inference_completion_tokens": {"value": 1840.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021858}, "meta_inference_completion_cost": {"value": 0.002944}, "meta_eval_time": {"value": 42.343}, "meta_eval_prompt_tokens": {"value": 7801.0}, "meta_eval_completion_tokens": {"value": 4058.0}, "meta_eval_prompt_cost": {"value": 0.00249632}, "meta_eval_completion_cost": {"value": 0.00519424}}, "created": "2025-12-10T21:35:13.7091316Z"}
{"ref": "TQ142", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.333333333333333}, "generation_faithfulness": {"value": 0.951219512195122}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 33.505109}, "meta_inference_prompt_tokens": {"value": 11439.0}, "meta_inference_completion_tokens": {"value": 2079.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022878}, "meta_inference_completion_cost": {"value": 0.0033264}, "meta_eval_time": {"value": 42.336}, "meta_eval_prompt_tokens": {"value": 7847.0}, "meta_eval_completion_tokens": {"value": 3949.0}, "meta_eval_prompt_cost": {"value": 0.00251104}, "meta_eval_completion_cost": {"value": 0.00505472}}, "created": "2025-12-10T21:35:14.3411105Z"}
{"ref": "TQ14-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.930676558073393}, "generation_faithfulness": {"value": 0.980392156862745}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.24614}, "meta_inference_prompt_tokens": {"value": 15300.0}, "meta_inference_completion_tokens": {"value": 2038.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00306}, "meta_inference_completion_cost": {"value": 0.0032608}, "meta_eval_time": {"value": 51.955}, "meta_eval_prompt_tokens": {"value": 11204.0}, "meta_eval_completion_tokens": {"value": 4793.0}, "meta_eval_prompt_cost": {"value": 0.00358528}, "meta_eval_completion_cost": {"value": 0.00613504}}, "created": "2025-12-10T21:35:14.6620772Z"}
{"ref": "TQ142", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 36.029526}, "meta_inference_prompt_tokens": {"value": 11835.0}, "meta_inference_completion_tokens": {"value": 2398.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002367}, "meta_inference_completion_cost": {"value": 0.0038368}, "meta_eval_time": {"value": 42.543}, "meta_eval_prompt_tokens": {"value": 8593.0}, "meta_eval_completion_tokens": {"value": 4389.0}, "meta_eval_prompt_cost": {"value": 0.00274976}, "meta_eval_completion_cost": {"value": 0.00561792}}, "created": "2025-12-10T21:35:14.6690624Z"}
{"ref": "TQ143", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 37.986862}, "meta_inference_prompt_tokens": {"value": 13961.0}, "meta_inference_completion_tokens": {"value": 2439.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027922}, "meta_inference_completion_cost": {"value": 0.0039024}, "meta_eval_time": {"value": 45.069}, "meta_eval_prompt_tokens": {"value": 11059.0}, "meta_eval_completion_tokens": {"value": 4678.0}, "meta_eval_prompt_cost": {"value": 0.00353888}, "meta_eval_completion_cost": {"value": 0.00598784}}, "created": "2025-12-10T21:35:18.1108002Z"}
{"ref": "TQ152", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 23.529267}, "meta_inference_prompt_tokens": {"value": 12983.0}, "meta_inference_completion_tokens": {"value": 977.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025966}, "meta_inference_completion_cost": {"value": 0.0015632}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:35:18.1487679Z"}
{"ref": "TQ14-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.856207187108022}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.428798}, "meta_inference_prompt_tokens": {"value": 15736.0}, "meta_inference_completion_tokens": {"value": 1860.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031472}, "meta_inference_completion_cost": {"value": 0.002976}, "meta_eval_time": {"value": 57.782}, "meta_eval_prompt_tokens": {"value": 12335.0}, "meta_eval_completion_tokens": {"value": 5749.0}, "meta_eval_prompt_cost": {"value": 0.0039472}, "meta_eval_completion_cost": {"value": 0.00735872}}, "created": "2025-12-10T21:35:18.8640393Z"}
{"ref": "TQ145-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.566666666666667}, "retrieval_dcg": {"value": 1.517782560806}, "generation_faithfulness": {"value": 0.975}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 38.965096}, "meta_inference_prompt_tokens": {"value": 12730.0}, "meta_inference_completion_tokens": {"value": 2257.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002546}, "meta_inference_completion_cost": {"value": 0.0036112}, "meta_eval_time": {"value": 44.05}, "meta_eval_prompt_tokens": {"value": 9380.0}, "meta_eval_completion_tokens": {"value": 3925.0}, "meta_eval_prompt_cost": {"value": 0.0030016}, "meta_eval_completion_cost": {"value": 0.005024}}, "created": "2025-12-10T21:35:21.7328582Z"}
{"ref": "TQ147", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 0.973684210526316}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 41.11404}, "meta_inference_prompt_tokens": {"value": 13983.0}, "meta_inference_completion_tokens": {"value": 2608.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027966}, "meta_inference_completion_cost": {"value": 0.0041728}, "meta_eval_time": {"value": 37.548}, "meta_eval_prompt_tokens": {"value": 9842.0}, "meta_eval_completion_tokens": {"value": 3841.0}, "meta_eval_prompt_cost": {"value": 0.00314944}, "meta_eval_completion_cost": {"value": 0.00491648}}, "created": "2025-12-10T21:35:22.1726262Z"}
{"ref": "TQ148", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 21.783222}, "meta_inference_prompt_tokens": {"value": 12772.0}, "meta_inference_completion_tokens": {"value": 1079.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025544}, "meta_inference_completion_cost": {"value": 0.0017264}, "meta_eval_time": {"value": 32.825}, "meta_eval_prompt_tokens": {"value": 8559.0}, "meta_eval_completion_tokens": {"value": 3485.0}, "meta_eval_prompt_cost": {"value": 0.00273888}, "meta_eval_completion_cost": {"value": 0.0044608}}, "created": "2025-12-10T21:35:22.8838655Z"}
{"ref": "TQ145-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.566666666666667}, "retrieval_dcg": {"value": 1.20231768402027}, "generation_faithfulness": {"value": 0.973684210526316}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.547674}, "meta_inference_prompt_tokens": {"value": 12590.0}, "meta_inference_completion_tokens": {"value": 1467.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002518}, "meta_inference_completion_cost": {"value": 0.0023472}, "meta_eval_time": {"value": 40.807}, "meta_eval_prompt_tokens": {"value": 9205.0}, "meta_eval_completion_tokens": {"value": 3867.0}, "meta_eval_prompt_cost": {"value": 0.0029456}, "meta_eval_completion_cost": {"value": 0.00494976}}, "created": "2025-12-10T21:35:24.771108Z"}
{"ref": "TQ145-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.566666666666667}, "retrieval_dcg": {"value": 1.517782560806}, "generation_faithfulness": {"value": 0.975}, "generation_factuality_f1": {"value": 0.875}, "generation_factuality_precision": {"value": 0.777777777777778}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.462575}, "meta_inference_prompt_tokens": {"value": 12086.0}, "meta_inference_completion_tokens": {"value": 1592.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024172}, "meta_inference_completion_cost": {"value": 0.0025472}, "meta_eval_time": {"value": 44.28}, "meta_eval_prompt_tokens": {"value": 8949.0}, "meta_eval_completion_tokens": {"value": 4016.0}, "meta_eval_prompt_cost": {"value": 0.00286368}, "meta_eval_completion_cost": {"value": 0.00514048}}, "created": "2025-12-10T21:35:24.8930702Z"}
{"ref": "TQ143", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.72}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 31.466824}, "meta_inference_prompt_tokens": {"value": 14764.0}, "meta_inference_completion_tokens": {"value": 2206.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029528}, "meta_inference_completion_cost": {"value": 0.0035296}, "meta_eval_time": {"value": 51.546}, "meta_eval_prompt_tokens": {"value": 11928.0}, "meta_eval_completion_tokens": {"value": 5063.0}, "meta_eval_prompt_cost": {"value": 0.00381696}, "meta_eval_completion_cost": {"value": 0.00648064}}, "created": "2025-12-10T21:35:25.6531021Z"}
{"ref": "TQ145-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.789064826317888}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 23.085223}, "meta_inference_prompt_tokens": {"value": 11307.0}, "meta_inference_completion_tokens": {"value": 912.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022614}, "meta_inference_completion_cost": {"value": 0.0014592}, "meta_eval_time": {"value": 18.396}, "meta_eval_prompt_tokens": {"value": 5616.0}, "meta_eval_completion_tokens": {"value": 1716.0}, "meta_eval_prompt_cost": {"value": 0.00179712}, "meta_eval_completion_cost": {"value": 0.00219648}}, "created": "2025-12-10T21:35:26.4615019Z"}
{"ref": "TQ145-C", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.91781349875287}, "generation_faithfulness": {"value": 0.972972972972973}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.796275}, "meta_inference_prompt_tokens": {"value": 15034.0}, "meta_inference_completion_tokens": {"value": 1739.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030068}, "meta_inference_completion_cost": {"value": 0.0027824}, "meta_eval_time": {"value": 40.297}, "meta_eval_prompt_tokens": {"value": 10151.0}, "meta_eval_completion_tokens": {"value": 3989.0}, "meta_eval_prompt_cost": {"value": 0.00324832}, "meta_eval_completion_cost": {"value": 0.00510592}}, "created": "2025-12-10T21:35:28.5903687Z"}
{"ref": "TQ145-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.566666666666667}, "retrieval_dcg": {"value": 1.31752936530793}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.143446}, "meta_inference_prompt_tokens": {"value": 13572.0}, "meta_inference_completion_tokens": {"value": 1439.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027144}, "meta_inference_completion_cost": {"value": 0.0023024}, "meta_eval_time": {"value": 49.787}, "meta_eval_prompt_tokens": {"value": 10629.0}, "meta_eval_completion_tokens": {"value": 4429.0}, "meta_eval_prompt_cost": {"value": 0.00340128}, "meta_eval_completion_cost": {"value": 0.00566912}}, "created": "2025-12-10T21:35:28.9296818Z"}
{"ref": "TQ143", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.646153846153846}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 48.51319}, "meta_inference_prompt_tokens": {"value": 15803.0}, "meta_inference_completion_tokens": {"value": 2990.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031606}, "meta_inference_completion_cost": {"value": 0.004784}, "meta_eval_time": {"value": 55.795}, "meta_eval_prompt_tokens": {"value": 13059.0}, "meta_eval_completion_tokens": {"value": 5433.0}, "meta_eval_prompt_cost": {"value": 0.00417888}, "meta_eval_completion_cost": {"value": 0.00695424}}, "created": "2025-12-10T21:35:29.0551105Z"}
{"ref": "TQ140", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.958333333333334}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 33.090918}, "meta_inference_prompt_tokens": {"value": 12017.0}, "meta_inference_completion_tokens": {"value": 1506.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024034}, "meta_inference_completion_cost": {"value": 0.0024096}, "meta_eval_time": {"value": 21.496}, "meta_eval_prompt_tokens": {"value": 7332.0}, "meta_eval_completion_tokens": {"value": 2294.0}, "meta_eval_prompt_cost": {"value": 0.00234624}, "meta_eval_completion_cost": {"value": 0.00293632}}, "created": "2025-12-10T21:35:29.6247042Z"}
{"ref": "TQ147", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.96426308690479}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.13622}, "meta_inference_prompt_tokens": {"value": 12435.0}, "meta_inference_completion_tokens": {"value": 1470.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002487}, "meta_inference_completion_cost": {"value": 0.002352}, "meta_eval_time": {"value": 38.938}, "meta_eval_prompt_tokens": {"value": 8442.0}, "meta_eval_completion_tokens": {"value": 3583.0}, "meta_eval_prompt_cost": {"value": 0.00270144}, "meta_eval_completion_cost": {"value": 0.00458624}}, "created": "2025-12-10T21:35:30.3611707Z"}
{"ref": "TQ148", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.612244897959184}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 33.040557}, "meta_inference_prompt_tokens": {"value": 12728.0}, "meta_inference_completion_tokens": {"value": 1844.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025456}, "meta_inference_completion_cost": {"value": 0.0029504}, "meta_eval_time": {"value": 35.597}, "meta_eval_prompt_tokens": {"value": 8797.0}, "meta_eval_completion_tokens": {"value": 3889.0}, "meta_eval_prompt_cost": {"value": 0.00281504}, "meta_eval_completion_cost": {"value": 0.00497792}}, "created": "2025-12-10T21:35:30.6866521Z"}
{"ref": "TQ153", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.775047}, "meta_inference_prompt_tokens": {"value": 11391.0}, "meta_inference_completion_tokens": {"value": 987.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022782}, "meta_inference_completion_cost": {"value": 0.0015792}, "meta_eval_time": {"value": 17.189}, "meta_eval_prompt_tokens": {"value": 6361.0}, "meta_eval_completion_tokens": {"value": 1646.0}, "meta_eval_prompt_cost": {"value": 0.00203552}, "meta_eval_completion_cost": {"value": 0.00210688}}, "created": "2025-12-10T21:35:31.8937251Z"}
{"ref": "TQ150-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 1.06160631164485}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.842105263157895}, "generation_factuality_precision": {"value": 0.888888888888889}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 21.907281}, "meta_inference_prompt_tokens": {"value": 11110.0}, "meta_inference_completion_tokens": {"value": 1055.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002222}, "meta_inference_completion_cost": {"value": 0.001688}, "meta_eval_time": {"value": 23.027}, "meta_eval_prompt_tokens": {"value": 6440.0}, "meta_eval_completion_tokens": {"value": 2308.0}, "meta_eval_prompt_cost": {"value": 0.0020608}, "meta_eval_completion_cost": {"value": 0.00295424}}, "created": "2025-12-10T21:35:32.0807182Z"}
{"ref": "TQ153", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.821739}, "meta_inference_prompt_tokens": {"value": 11353.0}, "meta_inference_completion_tokens": {"value": 1228.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022706}, "meta_inference_completion_cost": {"value": 0.0019648}, "meta_eval_time": {"value": 13.506}, "meta_eval_prompt_tokens": {"value": 5905.0}, "meta_eval_completion_tokens": {"value": 1246.0}, "meta_eval_prompt_cost": {"value": 0.0018896}, "meta_eval_completion_cost": {"value": 0.00159488}}, "created": "2025-12-10T21:35:32.4091346Z"}
{"ref": "TQ148", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 23.541087}, "meta_inference_prompt_tokens": {"value": 12520.0}, "meta_inference_completion_tokens": {"value": 1684.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002504}, "meta_inference_completion_cost": {"value": 0.0026944}, "meta_eval_time": {"value": 40.193}, "meta_eval_prompt_tokens": {"value": 8716.0}, "meta_eval_completion_tokens": {"value": 3861.0}, "meta_eval_prompt_cost": {"value": 0.00278912}, "meta_eval_completion_cost": {"value": 0.00494208}}, "created": "2025-12-10T21:35:32.9046488Z"}
{"ref": "TQ15", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.413793103448276}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 22.083307}, "meta_inference_prompt_tokens": {"value": 16770.0}, "meta_inference_completion_tokens": {"value": 1345.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003354}, "meta_inference_completion_cost": {"value": 0.002152}, "meta_eval_time": {"value": 39.329}, "meta_eval_prompt_tokens": {"value": 12078.0}, "meta_eval_completion_tokens": {"value": 3698.0}, "meta_eval_prompt_cost": {"value": 0.00386496}, "meta_eval_completion_cost": {"value": 0.00473344}}, "created": "2025-12-10T21:35:33.1455998Z"}
{"ref": "TQ152", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.818181818181818}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 30.998831}, "meta_inference_prompt_tokens": {"value": 10404.0}, "meta_inference_completion_tokens": {"value": 1336.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020808}, "meta_inference_completion_cost": {"value": 0.0021376}, "meta_eval_time": {"value": 19.069}, "meta_eval_prompt_tokens": {"value": 5540.0}, "meta_eval_completion_tokens": {"value": 2079.0}, "meta_eval_prompt_cost": {"value": 0.0017728}, "meta_eval_completion_cost": {"value": 0.00266112}}, "created": "2025-12-10T21:35:33.7784822Z"}
{"ref": "TQ148", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.914285714285714}, "generation_factuality_f1": {"value": 0.72}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 34.1923}, "meta_inference_prompt_tokens": {"value": 13171.0}, "meta_inference_completion_tokens": {"value": 1819.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026342}, "meta_inference_completion_cost": {"value": 0.0029104}, "meta_eval_time": {"value": 41.358}, "meta_eval_prompt_tokens": {"value": 9312.0}, "meta_eval_completion_tokens": {"value": 4000.0}, "meta_eval_prompt_cost": {"value": 0.00297984}, "meta_eval_completion_cost": {"value": 0.00512}}, "created": "2025-12-10T21:35:34.5579522Z"}
{"ref": "TQ145-C", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.94845911887939}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.584614}, "meta_inference_prompt_tokens": {"value": 15926.0}, "meta_inference_completion_tokens": {"value": 1732.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031852}, "meta_inference_completion_cost": {"value": 0.0027712}, "meta_eval_time": {"value": 52.259}, "meta_eval_prompt_tokens": {"value": 11732.0}, "meta_eval_completion_tokens": {"value": 4962.0}, "meta_eval_prompt_cost": {"value": 0.00375424}, "meta_eval_completion_cost": {"value": 0.00635136}}, "created": "2025-12-10T21:35:35.4005376Z"}
{"ref": "TQ143", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.685714285714286}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 32.316665}, "meta_inference_prompt_tokens": {"value": 13838.0}, "meta_inference_completion_tokens": {"value": 2433.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027676}, "meta_inference_completion_cost": {"value": 0.0038928}, "meta_eval_time": {"value": 62.955}, "meta_eval_prompt_tokens": {"value": 11213.0}, "meta_eval_completion_tokens": {"value": 5492.0}, "meta_eval_prompt_cost": {"value": 0.00358816}, "meta_eval_completion_cost": {"value": 0.00702976}}, "created": "2025-12-10T21:35:36.5372424Z"}
{"ref": "TQ151", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.67167206389375}, "generation_faithfulness": {"value": 0.956521739130435}, "generation_factuality_f1": {"value": 0.666666666666666}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 25.428772}, "meta_inference_prompt_tokens": {"value": 11288.0}, "meta_inference_completion_tokens": {"value": 1583.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022576}, "meta_inference_completion_cost": {"value": 0.0025328}, "meta_eval_time": {"value": 24.888}, "meta_eval_prompt_tokens": {"value": 6647.0}, "meta_eval_completion_tokens": {"value": 2423.0}, "meta_eval_prompt_cost": {"value": 0.00212704}, "meta_eval_completion_cost": {"value": 0.00310144}}, "created": "2025-12-10T21:35:36.6541489Z"}
{"ref": "TQ153", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.950148}, "meta_inference_prompt_tokens": {"value": 10563.0}, "meta_inference_completion_tokens": {"value": 975.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021126}, "meta_inference_completion_cost": {"value": 0.00156}, "meta_eval_time": {"value": 15.531}, "meta_eval_prompt_tokens": {"value": 5251.0}, "meta_eval_completion_tokens": {"value": 1379.0}, "meta_eval_prompt_cost": {"value": 0.00168032}, "meta_eval_completion_cost": {"value": 0.00176512}}, "created": "2025-12-10T21:35:37.3025701Z"}
{"ref": "TQ150-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.886852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.768515}, "meta_inference_prompt_tokens": {"value": 11473.0}, "meta_inference_completion_tokens": {"value": 1308.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022946}, "meta_inference_completion_cost": {"value": 0.0020928}, "meta_eval_time": {"value": 27.921}, "meta_eval_prompt_tokens": {"value": 6895.0}, "meta_eval_completion_tokens": {"value": 2633.0}, "meta_eval_prompt_cost": {"value": 0.0022064}, "meta_eval_completion_cost": {"value": 0.00337024}}, "created": "2025-12-10T21:35:38.0708664Z"}
{"ref": "TQ145-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.566666666666667}, "retrieval_dcg": {"value": 1.31752936530793}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.933333333333333}, "generation_factuality_precision": {"value": 0.875}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.883405}, "meta_inference_prompt_tokens": {"value": 12608.0}, "meta_inference_completion_tokens": {"value": 1271.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025216}, "meta_inference_completion_cost": {"value": 0.0020336}, "meta_eval_time": {"value": 33.716}, "meta_eval_prompt_tokens": {"value": 8955.0}, "meta_eval_completion_tokens": {"value": 3410.0}, "meta_eval_prompt_cost": {"value": 0.0028656}, "meta_eval_completion_cost": {"value": 0.0043648}}, "created": "2025-12-10T21:35:38.5698855Z"}
{"ref": "TQ145-C", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.94845911887939}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.947368421052632}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 41.727946}, "meta_inference_prompt_tokens": {"value": 15104.0}, "meta_inference_completion_tokens": {"value": 1971.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030208}, "meta_inference_completion_cost": {"value": 0.0031536}, "meta_eval_time": {"value": 48.188}, "meta_eval_prompt_tokens": {"value": 10379.0}, "meta_eval_completion_tokens": {"value": 4527.0}, "meta_eval_prompt_cost": {"value": 0.00332128}, "meta_eval_completion_cost": {"value": 0.00579456}}, "created": "2025-12-10T21:35:38.5721961Z"}
{"ref": "TQ151", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.81752936530793}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666666}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 29.055371}, "meta_inference_prompt_tokens": {"value": 10913.0}, "meta_inference_completion_tokens": {"value": 1526.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021826}, "meta_inference_completion_cost": {"value": 0.0024416}, "meta_eval_time": {"value": 24.841}, "meta_eval_prompt_tokens": {"value": 6318.0}, "meta_eval_completion_tokens": {"value": 2419.0}, "meta_eval_prompt_cost": {"value": 0.00202176}, "meta_eval_completion_cost": {"value": 0.00309632}}, "created": "2025-12-10T21:35:38.5854505Z"}
{"ref": "TQ150-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 0.975}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.529602}, "meta_inference_prompt_tokens": {"value": 11483.0}, "meta_inference_completion_tokens": {"value": 1204.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022966}, "meta_inference_completion_cost": {"value": 0.0019264}, "meta_eval_time": {"value": 31.091}, "meta_eval_prompt_tokens": {"value": 7328.0}, "meta_eval_completion_tokens": {"value": 3323.0}, "meta_eval_prompt_cost": {"value": 0.00234496}, "meta_eval_completion_cost": {"value": 0.00425344}}, "created": "2025-12-10T21:35:39.2751671Z"}
{"ref": "TQ152", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 35.363053}, "meta_inference_prompt_tokens": {"value": 24871.0}, "meta_inference_completion_tokens": {"value": 1728.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0049742}, "meta_inference_completion_cost": {"value": 0.0027648}, "meta_eval_time": {"value": 21.52}, "meta_eval_prompt_tokens": {"value": 8245.0}, "meta_eval_completion_tokens": {"value": 2217.0}, "meta_eval_prompt_cost": {"value": 0.0026384}, "meta_eval_completion_cost": {"value": 0.00283776}}, "created": "2025-12-10T21:35:39.707386Z"}
{"ref": "TQ143", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.711864406779661}, "generation_factuality_precision": {"value": 0.875}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 46.551604}, "meta_inference_prompt_tokens": {"value": 15212.0}, "meta_inference_completion_tokens": {"value": 2794.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030424}, "meta_inference_completion_cost": {"value": 0.0044704}, "meta_eval_time": {"value": 64.295}, "meta_eval_prompt_tokens": {"value": 13205.0}, "meta_eval_completion_tokens": {"value": 6526.0}, "meta_eval_prompt_cost": {"value": 0.0042256}, "meta_eval_completion_cost": {"value": 0.00835328}}, "created": "2025-12-10T21:35:39.7216924Z"}
{"ref": "TQ15", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.674157303370786}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 24.763273}, "meta_inference_prompt_tokens": {"value": 17589.0}, "meta_inference_completion_tokens": {"value": 1465.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0035178}, "meta_inference_completion_cost": {"value": 0.002344}, "meta_eval_time": {"value": 40.577}, "meta_eval_prompt_tokens": {"value": 13132.0}, "meta_eval_completion_tokens": {"value": 3903.0}, "meta_eval_prompt_cost": {"value": 0.00420224}, "meta_eval_completion_cost": {"value": 0.00499584}}, "created": "2025-12-10T21:35:40.052385Z"}
{"ref": "TQ151", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 22.36546}, "meta_inference_prompt_tokens": {"value": 10975.0}, "meta_inference_completion_tokens": {"value": 1409.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002195}, "meta_inference_completion_cost": {"value": 0.0022544}, "meta_eval_time": {"value": 30.312}, "meta_eval_prompt_tokens": {"value": 6589.0}, "meta_eval_completion_tokens": {"value": 2861.0}, "meta_eval_prompt_cost": {"value": 0.00210848}, "meta_eval_completion_cost": {"value": 0.00366208}}, "created": "2025-12-10T21:35:40.1169083Z"}
{"ref": "TQ152", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 32.396089}, "meta_inference_prompt_tokens": {"value": 26810.0}, "meta_inference_completion_tokens": {"value": 1457.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.005362}, "meta_inference_completion_cost": {"value": 0.0023312}, "meta_eval_time": {"value": 16.81}, "meta_eval_prompt_tokens": {"value": 9256.0}, "meta_eval_completion_tokens": {"value": 1489.0}, "meta_eval_prompt_cost": {"value": 0.00296192}, "meta_eval_completion_cost": {"value": 0.00190592}}, "created": "2025-12-10T21:35:41.7386956Z"}
{"ref": "TQ148", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.685714285714286}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 35.911147}, "meta_inference_prompt_tokens": {"value": 12645.0}, "meta_inference_completion_tokens": {"value": 1719.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002529}, "meta_inference_completion_cost": {"value": 0.0027504}, "meta_eval_time": {"value": 45.897}, "meta_eval_prompt_tokens": {"value": 8543.0}, "meta_eval_completion_tokens": {"value": 3272.0}, "meta_eval_prompt_cost": {"value": 0.00273376}, "meta_eval_completion_cost": {"value": 0.00418816}}, "created": "2025-12-10T21:35:42.5324188Z"}
{"ref": "TQ150-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 29.506202}, "meta_inference_prompt_tokens": {"value": 10765.0}, "meta_inference_completion_tokens": {"value": 1317.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002153}, "meta_inference_completion_cost": {"value": 0.0021072}, "meta_eval_time": {"value": 32.857}, "meta_eval_prompt_tokens": {"value": 6477.0}, "meta_eval_completion_tokens": {"value": 2642.0}, "meta_eval_prompt_cost": {"value": 0.00207264}, "meta_eval_completion_cost": {"value": 0.00338176}}, "created": "2025-12-10T21:35:42.6604028Z"}
{"ref": "TQ151", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.56160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.428571428571428}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 24.979657}, "meta_inference_prompt_tokens": {"value": 11252.0}, "meta_inference_completion_tokens": {"value": 1592.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022504}, "meta_inference_completion_cost": {"value": 0.0025472}, "meta_eval_time": {"value": 34.211}, "meta_eval_prompt_tokens": {"value": 6732.0}, "meta_eval_completion_tokens": {"value": 2867.0}, "meta_eval_prompt_cost": {"value": 0.00215424}, "meta_eval_completion_cost": {"value": 0.00366976}}, "created": "2025-12-10T21:35:43.2618765Z"}
{"ref": "TQ145-C", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.94845911887939}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.53068}, "meta_inference_prompt_tokens": {"value": 16035.0}, "meta_inference_completion_tokens": {"value": 2190.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003207}, "meta_inference_completion_cost": {"value": 0.003504}, "meta_eval_time": {"value": 62.558}, "meta_eval_prompt_tokens": {"value": 12258.0}, "meta_eval_completion_tokens": {"value": 5407.0}, "meta_eval_prompt_cost": {"value": 0.00392256}, "meta_eval_completion_cost": {"value": 0.00692096}}, "created": "2025-12-10T21:35:43.3248578Z"}
{"ref": "TQ155", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 17.100323}, "meta_inference_prompt_tokens": {"value": 10749.0}, "meta_inference_completion_tokens": {"value": 761.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021498}, "meta_inference_completion_cost": {"value": 0.0012176}, "meta_eval_time": {"value": 12.967}, "meta_eval_prompt_tokens": {"value": 5252.0}, "meta_eval_completion_tokens": {"value": 1098.0}, "meta_eval_prompt_cost": {"value": 0.00168064}, "meta_eval_completion_cost": {"value": 0.00140544}}, "created": "2025-12-10T21:35:43.3703392Z"}
{"ref": "TQ153", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.785714285714286}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.818771}, "meta_inference_prompt_tokens": {"value": 10810.0}, "meta_inference_completion_tokens": {"value": 1141.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002162}, "meta_inference_completion_cost": {"value": 0.0018256}, "meta_eval_time": {"value": 21.355}, "meta_eval_prompt_tokens": {"value": 5667.0}, "meta_eval_completion_tokens": {"value": 1619.0}, "meta_eval_prompt_cost": {"value": 0.00181344}, "meta_eval_completion_cost": {"value": 0.00207232}}, "created": "2025-12-10T21:35:43.5740016Z"}
{"ref": "TQ15", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.777777777777778}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 0.875}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.875}, "meta_inference_time": {"value": 25.132979}, "meta_inference_prompt_tokens": {"value": 15508.0}, "meta_inference_completion_tokens": {"value": 1351.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031016}, "meta_inference_completion_cost": {"value": 0.0021616}, "meta_eval_time": {"value": 45.508}, "meta_eval_prompt_tokens": {"value": 11011.0}, "meta_eval_completion_tokens": {"value": 3465.0}, "meta_eval_prompt_cost": {"value": 0.00352352}, "meta_eval_completion_cost": {"value": 0.0044352}}, "created": "2025-12-10T21:35:43.9497405Z"}
{"ref": "TQ155", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.56160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.285997}, "meta_inference_prompt_tokens": {"value": 10796.0}, "meta_inference_completion_tokens": {"value": 839.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021592}, "meta_inference_completion_cost": {"value": 0.0013424}, "meta_eval_time": {"value": 19.284}, "meta_eval_prompt_tokens": {"value": 5788.0}, "meta_eval_completion_tokens": {"value": 1781.0}, "meta_eval_prompt_cost": {"value": 0.00185216}, "meta_eval_completion_cost": {"value": 0.00227968}}, "created": "2025-12-10T21:35:44.9762919Z"}
{"ref": "TQ155", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 20.17618}, "meta_inference_prompt_tokens": {"value": 12051.0}, "meta_inference_completion_tokens": {"value": 799.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024102}, "meta_inference_completion_cost": {"value": 0.0012784}, "meta_eval_time": {"value": 14.572}, "meta_eval_prompt_tokens": {"value": 6575.0}, "meta_eval_completion_tokens": {"value": 1235.0}, "meta_eval_prompt_cost": {"value": 0.002104}, "meta_eval_completion_cost": {"value": 0.0015808}}, "created": "2025-12-10T21:35:45.2996095Z"}
{"ref": "TQ155", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.88685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.944572}, "meta_inference_prompt_tokens": {"value": 10333.0}, "meta_inference_completion_tokens": {"value": 660.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020666}, "meta_inference_completion_cost": {"value": 0.001056}, "meta_eval_time": {"value": 17.498}, "meta_eval_prompt_tokens": {"value": 5098.0}, "meta_eval_completion_tokens": {"value": 1628.0}, "meta_eval_prompt_cost": {"value": 0.00163136}, "meta_eval_completion_cost": {"value": 0.00208384}}, "created": "2025-12-10T21:35:46.1231969Z"}
{"ref": "TQ155", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 23.879608}, "meta_inference_prompt_tokens": {"value": 10928.0}, "meta_inference_completion_tokens": {"value": 1021.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021856}, "meta_inference_completion_cost": {"value": 0.0016336}, "meta_eval_time": {"value": 17.946}, "meta_eval_prompt_tokens": {"value": 6030.0}, "meta_eval_completion_tokens": {"value": 1771.0}, "meta_eval_prompt_cost": {"value": 0.0019296}, "meta_eval_completion_cost": {"value": 0.00226688}}, "created": "2025-12-10T21:35:46.9136801Z"}
{"ref": "TQ152", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.705882352941176}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 26.331273}, "meta_inference_prompt_tokens": {"value": 11385.0}, "meta_inference_completion_tokens": {"value": 1501.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002277}, "meta_inference_completion_cost": {"value": 0.0024016}, "meta_eval_time": {"value": 23.597}, "meta_eval_prompt_tokens": {"value": 6868.0}, "meta_eval_completion_tokens": {"value": 2241.0}, "meta_eval_prompt_cost": {"value": 0.00219776}, "meta_eval_completion_cost": {"value": 0.00286848}}, "created": "2025-12-10T21:35:48.4039814Z"}
{"ref": "TQ156", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.958333333333334}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.033912}, "meta_inference_prompt_tokens": {"value": 10777.0}, "meta_inference_completion_tokens": {"value": 1359.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021554}, "meta_inference_completion_cost": {"value": 0.0021744}, "meta_eval_time": {"value": 25.677}, "meta_eval_prompt_tokens": {"value": 6132.0}, "meta_eval_completion_tokens": {"value": 2468.0}, "meta_eval_prompt_cost": {"value": 0.00196224}, "meta_eval_completion_cost": {"value": 0.00315904}}, "created": "2025-12-10T21:35:52.1777721Z"}
{"ref": "TQ156", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.565217391304348}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.670269}, "meta_inference_prompt_tokens": {"value": 10104.0}, "meta_inference_completion_tokens": {"value": 1398.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020208}, "meta_inference_completion_cost": {"value": 0.0022368}, "meta_eval_time": {"value": 25.039}, "meta_eval_prompt_tokens": {"value": 5367.0}, "meta_eval_completion_tokens": {"value": 2336.0}, "meta_eval_prompt_cost": {"value": 0.00171744}, "meta_eval_completion_cost": {"value": 0.00299008}}, "created": "2025-12-10T21:35:54.1348288Z"}
{"ref": "TQ156", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.954545454545454}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.645252}, "meta_inference_prompt_tokens": {"value": 11225.0}, "meta_inference_completion_tokens": {"value": 1353.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002245}, "meta_inference_completion_cost": {"value": 0.0021648}, "meta_eval_time": {"value": 22.28}, "meta_eval_prompt_tokens": {"value": 6368.0}, "meta_eval_completion_tokens": {"value": 2167.0}, "meta_eval_prompt_cost": {"value": 0.00203776}, "meta_eval_completion_cost": {"value": 0.00277376}}, "created": "2025-12-10T21:35:54.4217865Z"}
{"ref": "TQ15", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 38.242264}, "meta_inference_prompt_tokens": {"value": 15117.0}, "meta_inference_completion_tokens": {"value": 1503.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030234}, "meta_inference_completion_cost": {"value": 0.0024048}, "meta_eval_time": {"value": 40.313}, "meta_eval_prompt_tokens": {"value": 10984.0}, "meta_eval_completion_tokens": {"value": 3997.0}, "meta_eval_prompt_cost": {"value": 0.00351488}, "meta_eval_completion_cost": {"value": 0.00511616}}, "created": "2025-12-10T21:35:54.7063453Z"}
{"ref": "TQ156", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.235925}, "meta_inference_prompt_tokens": {"value": 11021.0}, "meta_inference_completion_tokens": {"value": 1371.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022042}, "meta_inference_completion_cost": {"value": 0.0021936}, "meta_eval_time": {"value": 26.137}, "meta_eval_prompt_tokens": {"value": 6322.0}, "meta_eval_completion_tokens": {"value": 2829.0}, "meta_eval_prompt_cost": {"value": 0.00202304}, "meta_eval_completion_cost": {"value": 0.00362112}}, "created": "2025-12-10T21:35:55.7986379Z"}
{"ref": "TQ157", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.842105263157895}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 26.831123}, "meta_inference_prompt_tokens": {"value": 12480.0}, "meta_inference_completion_tokens": {"value": 1619.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002496}, "meta_inference_completion_cost": {"value": 0.0025904}, "meta_eval_time": {"value": 23.344}, "meta_eval_prompt_tokens": {"value": 7044.0}, "meta_eval_completion_tokens": {"value": 2048.0}, "meta_eval_prompt_cost": {"value": 0.00225408}, "meta_eval_completion_cost": {"value": 0.00262144}}, "created": "2025-12-10T21:35:56.2875324Z"}
{"ref": "TQ157", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.647058823529412}, "generation_factuality_f1": {"value": 0.31578947368421}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 38.946522}, "meta_inference_prompt_tokens": {"value": 11834.0}, "meta_inference_completion_tokens": {"value": 2122.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023668}, "meta_inference_completion_cost": {"value": 0.0033952}, "meta_eval_time": {"value": 23.341}, "meta_eval_prompt_tokens": {"value": 6812.0}, "meta_eval_completion_tokens": {"value": 2154.0}, "meta_eval_prompt_cost": {"value": 0.00217984}, "meta_eval_completion_cost": {"value": 0.00275712}}, "created": "2025-12-10T21:35:57.1574321Z"}
{"ref": "TQ156", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.781746}, "meta_inference_prompt_tokens": {"value": 10520.0}, "meta_inference_completion_tokens": {"value": 1186.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002104}, "meta_inference_completion_cost": {"value": 0.0018976}, "meta_eval_time": {"value": 21.766}, "meta_eval_prompt_tokens": {"value": 5598.0}, "meta_eval_completion_tokens": {"value": 2192.0}, "meta_eval_prompt_cost": {"value": 0.00179136}, "meta_eval_completion_cost": {"value": 0.00280576}}, "created": "2025-12-10T21:35:57.2461635Z"}
{"ref": "TQ145-C", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.94845911887939}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 38.864516}, "meta_inference_prompt_tokens": {"value": 15041.0}, "meta_inference_completion_tokens": {"value": 2549.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030082}, "meta_inference_completion_cost": {"value": 0.0040784}, "meta_eval_time": {"value": 57.503}, "meta_eval_prompt_tokens": {"value": 11064.0}, "meta_eval_completion_tokens": {"value": 5137.0}, "meta_eval_prompt_cost": {"value": 0.00354048}, "meta_eval_completion_cost": {"value": 0.00657536}}, "created": "2025-12-10T21:35:57.7502866Z"}
{"ref": "TQ153", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.65504}, "meta_inference_prompt_tokens": {"value": 11196.0}, "meta_inference_completion_tokens": {"value": 1108.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022392}, "meta_inference_completion_cost": {"value": 0.0017728}, "meta_eval_time": {"value": 20.088}, "meta_eval_prompt_tokens": {"value": 6162.0}, "meta_eval_completion_tokens": {"value": 1863.0}, "meta_eval_prompt_cost": {"value": 0.00197184}, "meta_eval_completion_cost": {"value": 0.00238464}}, "created": "2025-12-10T21:35:58.6958959Z"}
{"ref": "TQ18", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.774193548387097}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 25.863489}, "meta_inference_prompt_tokens": {"value": 11075.0}, "meta_inference_completion_tokens": {"value": 1156.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002215}, "meta_inference_completion_cost": {"value": 0.0018496}, "meta_eval_time": {"value": 16.311}, "meta_eval_prompt_tokens": {"value": 6017.0}, "meta_eval_completion_tokens": {"value": 1744.0}, "meta_eval_prompt_cost": {"value": 0.00192544}, "meta_eval_completion_cost": {"value": 0.00223232}}, "created": "2025-12-10T21:35:58.8952952Z"}
{"ref": "TQ18", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 0.818181818181818}, "generation_factuality_f1": {"value": 0.754716981132076}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 17.746347}, "meta_inference_prompt_tokens": {"value": 11990.0}, "meta_inference_completion_tokens": {"value": 730.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002398}, "meta_inference_completion_cost": {"value": 0.001168}, "meta_eval_time": {"value": 14.082}, "meta_eval_prompt_tokens": {"value": 6723.0}, "meta_eval_completion_tokens": {"value": 1470.0}, "meta_eval_prompt_cost": {"value": 0.00215136}, "meta_eval_completion_cost": {"value": 0.0018816}}, "created": "2025-12-10T21:35:59.1054327Z"}
{"ref": "TQ159", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.821428571428571}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 45.257441}, "meta_inference_prompt_tokens": {"value": 11986.0}, "meta_inference_completion_tokens": {"value": 2275.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023972}, "meta_inference_completion_cost": {"value": 0.00364}, "meta_eval_time": {"value": 26.899}, "meta_eval_prompt_tokens": {"value": 7227.0}, "meta_eval_completion_tokens": {"value": 2767.0}, "meta_eval_prompt_cost": {"value": 0.00231264}, "meta_eval_completion_cost": {"value": 0.00354176}}, "created": "2025-12-10T21:35:59.3469763Z"}
{"ref": "TQ18", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.754716981132076}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 22.046114}, "meta_inference_prompt_tokens": {"value": 12063.0}, "meta_inference_completion_tokens": {"value": 1022.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024126}, "meta_inference_completion_cost": {"value": 0.0016352}, "meta_eval_time": {"value": 17.228}, "meta_eval_prompt_tokens": {"value": 6786.0}, "meta_eval_completion_tokens": {"value": 1602.0}, "meta_eval_prompt_cost": {"value": 0.00217152}, "meta_eval_completion_cost": {"value": 0.00205056}}, "created": "2025-12-10T21:35:59.9300085Z"}
{"ref": "TQ16", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.755824}, "meta_inference_prompt_tokens": {"value": 10215.0}, "meta_inference_completion_tokens": {"value": 1004.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002043}, "meta_inference_completion_cost": {"value": 0.0016064}, "meta_eval_time": {"value": 21.69}, "meta_eval_prompt_tokens": {"value": 5472.0}, "meta_eval_completion_tokens": {"value": 2126.0}, "meta_eval_prompt_cost": {"value": 0.00175104}, "meta_eval_completion_cost": {"value": 0.00272128}}, "created": "2025-12-10T21:36:01.0320479Z"}
{"ref": "TQ157", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.222222222222222}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.2}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.2}, "meta_inference_time": {"value": 36.224382}, "meta_inference_prompt_tokens": {"value": 12276.0}, "meta_inference_completion_tokens": {"value": 1903.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024552}, "meta_inference_completion_cost": {"value": 0.0030448}, "meta_eval_time": {"value": 29.672}, "meta_eval_prompt_tokens": {"value": 7589.0}, "meta_eval_completion_tokens": {"value": 2971.0}, "meta_eval_prompt_cost": {"value": 0.00242848}, "meta_eval_completion_cost": {"value": 0.00380288}}, "created": "2025-12-10T21:36:01.6283714Z"}
{"ref": "TQ157", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.958333333333334}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 26.386738}, "meta_inference_prompt_tokens": {"value": 12543.0}, "meta_inference_completion_tokens": {"value": 1683.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025086}, "meta_inference_completion_cost": {"value": 0.0026928}, "meta_eval_time": {"value": 27.749}, "meta_eval_prompt_tokens": {"value": 7754.0}, "meta_eval_completion_tokens": {"value": 2544.0}, "meta_eval_prompt_cost": {"value": 0.00248128}, "meta_eval_completion_cost": {"value": 0.00325632}}, "created": "2025-12-10T21:36:02.3438958Z"}
{"ref": "TQ159", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 25.727773}, "meta_inference_prompt_tokens": {"value": 14473.0}, "meta_inference_completion_tokens": {"value": 1678.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028946}, "meta_inference_completion_cost": {"value": 0.0026848}, "meta_eval_time": {"value": 25.955}, "meta_eval_prompt_tokens": {"value": 9230.0}, "meta_eval_completion_tokens": {"value": 2406.0}, "meta_eval_prompt_cost": {"value": 0.0029536}, "meta_eval_completion_cost": {"value": 0.00307968}}, "created": "2025-12-10T21:36:03.2939141Z"}
{"ref": "TQ157", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 34.880912}, "meta_inference_prompt_tokens": {"value": 11567.0}, "meta_inference_completion_tokens": {"value": 1670.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023134}, "meta_inference_completion_cost": {"value": 0.002672}, "meta_eval_time": {"value": 26.953}, "meta_eval_prompt_tokens": {"value": 7020.0}, "meta_eval_completion_tokens": {"value": 2470.0}, "meta_eval_prompt_cost": {"value": 0.0022464}, "meta_eval_completion_cost": {"value": 0.0031616}}, "created": "2025-12-10T21:36:03.5286044Z"}
{"ref": "TQ150-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.774193548387097}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 25.528355}, "meta_inference_prompt_tokens": {"value": 12430.0}, "meta_inference_completion_tokens": {"value": 1342.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002486}, "meta_inference_completion_cost": {"value": 0.0021472}, "meta_eval_time": {"value": 25.018}, "meta_eval_prompt_tokens": {"value": 7549.0}, "meta_eval_completion_tokens": {"value": 2145.0}, "meta_eval_prompt_cost": {"value": 0.00241568}, "meta_eval_completion_cost": {"value": 0.0027456}}, "created": "2025-12-10T21:36:03.6343403Z"}
{"ref": "TQ15", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.413793103448276}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 25.565198}, "meta_inference_prompt_tokens": {"value": 19260.0}, "meta_inference_completion_tokens": {"value": 1481.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003852}, "meta_inference_completion_cost": {"value": 0.0023696}, "meta_eval_time": {"value": 40.824}, "meta_eval_prompt_tokens": {"value": 14977.0}, "meta_eval_completion_tokens": {"value": 4004.0}, "meta_eval_prompt_cost": {"value": 0.00479264}, "meta_eval_completion_cost": {"value": 0.00512512}}, "created": "2025-12-10T21:36:03.746468Z"}
{"ref": "TQ18", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.284453}, "meta_inference_prompt_tokens": {"value": 12211.0}, "meta_inference_completion_tokens": {"value": 921.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024422}, "meta_inference_completion_cost": {"value": 0.0014736}, "meta_eval_time": {"value": 20.443}, "meta_eval_prompt_tokens": {"value": 7185.0}, "meta_eval_completion_tokens": {"value": 1939.0}, "meta_eval_prompt_cost": {"value": 0.0022992}, "meta_eval_completion_cost": {"value": 0.00248192}}, "created": "2025-12-10T21:36:03.874846Z"}
{"ref": "TQ16", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.297858}, "meta_inference_prompt_tokens": {"value": 10769.0}, "meta_inference_completion_tokens": {"value": 1239.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021538}, "meta_inference_completion_cost": {"value": 0.0019824}, "meta_eval_time": {"value": 24.394}, "meta_eval_prompt_tokens": {"value": 6004.0}, "meta_eval_completion_tokens": {"value": 2090.0}, "meta_eval_prompt_cost": {"value": 0.00192128}, "meta_eval_completion_cost": {"value": 0.0026752}}, "created": "2025-12-10T21:36:04.1941119Z"}
{"ref": "TQ18", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 0.733333333333333}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 18.585665}, "meta_inference_prompt_tokens": {"value": 12209.0}, "meta_inference_completion_tokens": {"value": 981.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024418}, "meta_inference_completion_cost": {"value": 0.0015696}, "meta_eval_time": {"value": 22.616}, "meta_eval_prompt_tokens": {"value": 7337.0}, "meta_eval_completion_tokens": {"value": 1968.0}, "meta_eval_prompt_cost": {"value": 0.00234784}, "meta_eval_completion_cost": {"value": 0.00251904}}, "created": "2025-12-10T21:36:06.2321297Z"}
{"ref": "TQ17", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.470588235294118}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 21.753863}, "meta_inference_prompt_tokens": {"value": 12249.0}, "meta_inference_completion_tokens": {"value": 1230.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024498}, "meta_inference_completion_cost": {"value": 0.001968}, "meta_eval_time": {"value": 26.134}, "meta_eval_prompt_tokens": {"value": 7855.0}, "meta_eval_completion_tokens": {"value": 2407.0}, "meta_eval_prompt_cost": {"value": 0.0025136}, "meta_eval_completion_cost": {"value": 0.00308096}}, "created": "2025-12-10T21:36:06.2897955Z"}
{"ref": "TQ22", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 16.007035}, "meta_inference_prompt_tokens": {"value": 14093.0}, "meta_inference_completion_tokens": {"value": 779.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028186}, "meta_inference_completion_cost": {"value": 0.0012464}, "meta_eval_time": {"value": 11.572}, "meta_eval_prompt_tokens": {"value": 8410.0}, "meta_eval_completion_tokens": {"value": 1060.0}, "meta_eval_prompt_cost": {"value": 0.0026912}, "meta_eval_completion_cost": {"value": 0.0013568}}, "created": "2025-12-10T21:36:06.3183629Z"}
{"ref": "TQ17", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.894736842105263}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.069918}, "meta_inference_prompt_tokens": {"value": 11401.0}, "meta_inference_completion_tokens": {"value": 1193.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022802}, "meta_inference_completion_cost": {"value": 0.0019088}, "meta_eval_time": {"value": 23.621}, "meta_eval_prompt_tokens": {"value": 6949.0}, "meta_eval_completion_tokens": {"value": 2230.0}, "meta_eval_prompt_cost": {"value": 0.00222368}, "meta_eval_completion_cost": {"value": 0.0028544}}, "created": "2025-12-10T21:36:07.0274303Z"}
{"ref": "TQ159", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.730769230769231}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 32.489635}, "meta_inference_prompt_tokens": {"value": 15461.0}, "meta_inference_completion_tokens": {"value": 2341.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030922}, "meta_inference_completion_cost": {"value": 0.0037456}, "meta_eval_time": {"value": 29.213}, "meta_eval_prompt_tokens": {"value": 10094.0}, "meta_eval_completion_tokens": {"value": 2779.0}, "meta_eval_prompt_cost": {"value": 0.00323008}, "meta_eval_completion_cost": {"value": 0.00355712}}, "created": "2025-12-10T21:36:07.3215214Z"}
{"ref": "TQ159", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 30.826547}, "meta_inference_prompt_tokens": {"value": 15053.0}, "meta_inference_completion_tokens": {"value": 1804.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030106}, "meta_inference_completion_cost": {"value": 0.0028864}, "meta_eval_time": {"value": 30.687}, "meta_eval_prompt_tokens": {"value": 9720.0}, "meta_eval_completion_tokens": {"value": 2576.0}, "meta_eval_prompt_cost": {"value": 0.0031104}, "meta_eval_completion_cost": {"value": 0.00329728}}, "created": "2025-12-10T21:36:07.3851718Z"}
{"ref": "TQ159", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.1}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0526315789473684}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.05}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 33.754616}, "meta_inference_prompt_tokens": {"value": 33592.0}, "meta_inference_completion_tokens": {"value": 1941.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0067184}, "meta_inference_completion_cost": {"value": 0.0031056}, "meta_eval_time": {"value": 34.278}, "meta_eval_prompt_tokens": {"value": 13646.0}, "meta_eval_completion_tokens": {"value": 3187.0}, "meta_eval_prompt_cost": {"value": 0.00436672}, "meta_eval_completion_cost": {"value": 0.00407936}}, "created": "2025-12-10T21:36:07.4627813Z"}
{"ref": "TQ16", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.492676}, "meta_inference_prompt_tokens": {"value": 9750.0}, "meta_inference_completion_tokens": {"value": 1084.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00195}, "meta_inference_completion_cost": {"value": 0.0017344}, "meta_eval_time": {"value": 28.51}, "meta_eval_prompt_tokens": {"value": 5092.0}, "meta_eval_completion_tokens": {"value": 2342.0}, "meta_eval_prompt_cost": {"value": 0.00162944}, "meta_eval_completion_cost": {"value": 0.00299776}}, "created": "2025-12-10T21:36:08.3177792Z"}
{"ref": "TQ19", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 27.218333}, "meta_inference_prompt_tokens": {"value": 17674.0}, "meta_inference_completion_tokens": {"value": 1338.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0035348}, "meta_inference_completion_cost": {"value": 0.0021408}, "meta_eval_time": {"value": 20.511}, "meta_eval_prompt_tokens": {"value": 12111.0}, "meta_eval_completion_tokens": {"value": 2180.0}, "meta_eval_prompt_cost": {"value": 0.00387552}, "meta_eval_completion_cost": {"value": 0.0027904}}, "created": "2025-12-10T21:36:08.9651228Z"}
{"ref": "TQ17", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.242706}, "meta_inference_prompt_tokens": {"value": 12665.0}, "meta_inference_completion_tokens": {"value": 936.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002533}, "meta_inference_completion_cost": {"value": 0.0014976}, "meta_eval_time": {"value": 25.76}, "meta_eval_prompt_tokens": {"value": 8262.0}, "meta_eval_completion_tokens": {"value": 2417.0}, "meta_eval_prompt_cost": {"value": 0.00264384}, "meta_eval_completion_cost": {"value": 0.00309376}}, "created": "2025-12-10T21:36:09.7583666Z"}
{"ref": "TQ19", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 25.956979}, "meta_inference_prompt_tokens": {"value": 15210.0}, "meta_inference_completion_tokens": {"value": 1509.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003042}, "meta_inference_completion_cost": {"value": 0.0024144}, "meta_eval_time": {"value": 27.628}, "meta_eval_prompt_tokens": {"value": 9738.0}, "meta_eval_completion_tokens": {"value": 2211.0}, "meta_eval_prompt_cost": {"value": 0.00311616}, "meta_eval_completion_cost": {"value": 0.00283008}}, "created": "2025-12-10T21:36:10.9600025Z"}
{"ref": "TQ16", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.974467}, "meta_inference_prompt_tokens": {"value": 9944.0}, "meta_inference_completion_tokens": {"value": 1176.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019888}, "meta_inference_completion_cost": {"value": 0.0018816}, "meta_eval_time": {"value": 31.097}, "meta_eval_prompt_tokens": {"value": 5847.0}, "meta_eval_completion_tokens": {"value": 3028.0}, "meta_eval_prompt_cost": {"value": 0.00187104}, "meta_eval_completion_cost": {"value": 0.00387584}}, "created": "2025-12-10T21:36:11.1895865Z"}
{"ref": "TQ22", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 21.233641}, "meta_inference_prompt_tokens": {"value": 13697.0}, "meta_inference_completion_tokens": {"value": 1177.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027394}, "meta_inference_completion_cost": {"value": 0.0018832}, "meta_eval_time": {"value": 12.651}, "meta_eval_prompt_tokens": {"value": 8081.0}, "meta_eval_completion_tokens": {"value": 1026.0}, "meta_eval_prompt_cost": {"value": 0.00258592}, "meta_eval_completion_cost": {"value": 0.00131328}}, "created": "2025-12-10T21:36:11.4041877Z"}
{"ref": "TQ151", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.96875}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 27.410388}, "meta_inference_prompt_tokens": {"value": 11673.0}, "meta_inference_completion_tokens": {"value": 1661.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023346}, "meta_inference_completion_cost": {"value": 0.0026576}, "meta_eval_time": {"value": 33.355}, "meta_eval_prompt_tokens": {"value": 7202.0}, "meta_eval_completion_tokens": {"value": 2946.0}, "meta_eval_prompt_cost": {"value": 0.00230464}, "meta_eval_completion_cost": {"value": 0.00377088}}, "created": "2025-12-10T21:36:11.9791311Z"}
{"ref": "TQ20", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.467827}, "meta_inference_prompt_tokens": {"value": 10545.0}, "meta_inference_completion_tokens": {"value": 1076.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002109}, "meta_inference_completion_cost": {"value": 0.0017216}, "meta_eval_time": {"value": 19.784}, "meta_eval_prompt_tokens": {"value": 5338.0}, "meta_eval_completion_tokens": {"value": 1910.0}, "meta_eval_prompt_cost": {"value": 0.00170816}, "meta_eval_completion_cost": {"value": 0.0024448}}, "created": "2025-12-10T21:36:12.0012519Z"}
{"ref": "TQ17", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.983273}, "meta_inference_prompt_tokens": {"value": 11782.0}, "meta_inference_completion_tokens": {"value": 1054.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023564}, "meta_inference_completion_cost": {"value": 0.0016864}, "meta_eval_time": {"value": 30.674}, "meta_eval_prompt_tokens": {"value": 7962.0}, "meta_eval_completion_tokens": {"value": 2961.0}, "meta_eval_prompt_cost": {"value": 0.00254784}, "meta_eval_completion_cost": {"value": 0.00379008}}, "created": "2025-12-10T21:36:12.4542705Z"}
{"ref": "TQ22", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.289064826317888}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 20.799555}, "meta_inference_prompt_tokens": {"value": 12075.0}, "meta_inference_completion_tokens": {"value": 988.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002415}, "meta_inference_completion_cost": {"value": 0.0015808}, "meta_eval_time": {"value": 9.258}, "meta_eval_prompt_tokens": {"value": 6426.0}, "meta_eval_completion_tokens": {"value": 782.0}, "meta_eval_prompt_cost": {"value": 0.00205632}, "meta_eval_completion_cost": {"value": 0.00100096}}, "created": "2025-12-10T21:36:12.8369832Z"}
{"ref": "TQ17", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.91304347826087}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.442253}, "meta_inference_prompt_tokens": {"value": 11915.0}, "meta_inference_completion_tokens": {"value": 1176.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002383}, "meta_inference_completion_cost": {"value": 0.0018816}, "meta_eval_time": {"value": 28.679}, "meta_eval_prompt_tokens": {"value": 7678.0}, "meta_eval_completion_tokens": {"value": 2879.0}, "meta_eval_prompt_cost": {"value": 0.00245696}, "meta_eval_completion_cost": {"value": 0.00368512}}, "created": "2025-12-10T21:36:14.022968Z"}
{"ref": "TQ22", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 29.64396}, "meta_inference_prompt_tokens": {"value": 12534.0}, "meta_inference_completion_tokens": {"value": 1764.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025068}, "meta_inference_completion_cost": {"value": 0.0028224}, "meta_eval_time": {"value": 13.375}, "meta_eval_prompt_tokens": {"value": 7068.0}, "meta_eval_completion_tokens": {"value": 1255.0}, "meta_eval_prompt_cost": {"value": 0.00226176}, "meta_eval_completion_cost": {"value": 0.0016064}}, "created": "2025-12-10T21:36:14.4630271Z"}
{"ref": "TQ16", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.81898}, "meta_inference_prompt_tokens": {"value": 10266.0}, "meta_inference_completion_tokens": {"value": 1254.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020532}, "meta_inference_completion_cost": {"value": 0.0020064}, "meta_eval_time": {"value": 28.427}, "meta_eval_prompt_tokens": {"value": 5658.0}, "meta_eval_completion_tokens": {"value": 2593.0}, "meta_eval_prompt_cost": {"value": 0.00181056}, "meta_eval_completion_cost": {"value": 0.00331904}}, "created": "2025-12-10T21:36:14.6045909Z"}
{"ref": "TQ20", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.938067}, "meta_inference_prompt_tokens": {"value": 11363.0}, "meta_inference_completion_tokens": {"value": 1089.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022726}, "meta_inference_completion_cost": {"value": 0.0017424}, "meta_eval_time": {"value": 21.013}, "meta_eval_prompt_tokens": {"value": 6300.0}, "meta_eval_completion_tokens": {"value": 1845.0}, "meta_eval_prompt_cost": {"value": 0.002016}, "meta_eval_completion_cost": {"value": 0.0023616}}, "created": "2025-12-10T21:36:17.348127Z"}
{"ref": "TQ25", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.356943}, "meta_inference_prompt_tokens": {"value": 11597.0}, "meta_inference_completion_tokens": {"value": 689.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023194}, "meta_inference_completion_cost": {"value": 0.0011024}, "meta_eval_time": {"value": 11.079}, "meta_eval_prompt_tokens": {"value": 5757.0}, "meta_eval_completion_tokens": {"value": 1017.0}, "meta_eval_prompt_cost": {"value": 0.00184224}, "meta_eval_completion_cost": {"value": 0.00130176}}, "created": "2025-12-10T21:36:17.4361785Z"}
{"ref": "TQ20", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.442242}, "meta_inference_prompt_tokens": {"value": 12734.0}, "meta_inference_completion_tokens": {"value": 1114.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025468}, "meta_inference_completion_cost": {"value": 0.0017824}, "meta_eval_time": {"value": 23.416}, "meta_eval_prompt_tokens": {"value": 7315.0}, "meta_eval_completion_tokens": {"value": 2098.0}, "meta_eval_prompt_cost": {"value": 0.0023408}, "meta_eval_completion_cost": {"value": 0.00268544}}, "created": "2025-12-10T21:36:17.876158Z"}
{"ref": "TQ25", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.828355}, "meta_inference_prompt_tokens": {"value": 12129.0}, "meta_inference_completion_tokens": {"value": 870.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024258}, "meta_inference_completion_cost": {"value": 0.001392}, "meta_eval_time": {"value": 14.223}, "meta_eval_prompt_tokens": {"value": 6340.0}, "meta_eval_completion_tokens": {"value": 1229.0}, "meta_eval_prompt_cost": {"value": 0.0020288}, "meta_eval_completion_cost": {"value": 0.00157312}}, "created": "2025-12-10T21:36:17.8975368Z"}
{"ref": "TQ23", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 19.963168}, "meta_inference_prompt_tokens": {"value": 12728.0}, "meta_inference_completion_tokens": {"value": 918.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025456}, "meta_inference_completion_cost": {"value": 0.0014688}, "meta_eval_time": {"value": 19.344}, "meta_eval_prompt_tokens": {"value": 6931.0}, "meta_eval_completion_tokens": {"value": 1867.0}, "meta_eval_prompt_cost": {"value": 0.00221792}, "meta_eval_completion_cost": {"value": 0.00238976}}, "created": "2025-12-10T21:36:19.311732Z"}
{"ref": "TQ19", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 0.95}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.517472}, "meta_inference_prompt_tokens": {"value": 15883.0}, "meta_inference_completion_tokens": {"value": 1365.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031766}, "meta_inference_completion_cost": {"value": 0.002184}, "meta_eval_time": {"value": 26.031}, "meta_eval_prompt_tokens": {"value": 10696.0}, "meta_eval_completion_tokens": {"value": 2334.0}, "meta_eval_prompt_cost": {"value": 0.00342272}, "meta_eval_completion_cost": {"value": 0.00298752}}, "created": "2025-12-10T21:36:20.2021613Z"}
{"ref": "TQ25", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.024981}, "meta_inference_prompt_tokens": {"value": 11742.0}, "meta_inference_completion_tokens": {"value": 534.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023484}, "meta_inference_completion_cost": {"value": 0.0008544}, "meta_eval_time": {"value": 13.325}, "meta_eval_prompt_tokens": {"value": 5915.0}, "meta_eval_completion_tokens": {"value": 994.0}, "meta_eval_prompt_cost": {"value": 0.0018928}, "meta_eval_completion_cost": {"value": 0.00127232}}, "created": "2025-12-10T21:36:20.3958294Z"}
{"ref": "TQ19", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.231486}, "meta_inference_prompt_tokens": {"value": 14435.0}, "meta_inference_completion_tokens": {"value": 1167.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002887}, "meta_inference_completion_cost": {"value": 0.0018672}, "meta_eval_time": {"value": 33.467}, "meta_eval_prompt_tokens": {"value": 9516.0}, "meta_eval_completion_tokens": {"value": 2905.0}, "meta_eval_prompt_cost": {"value": 0.00304512}, "meta_eval_completion_cost": {"value": 0.0037184}}, "created": "2025-12-10T21:36:20.5354778Z"}
{"ref": "TQ25", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.728953}, "meta_inference_prompt_tokens": {"value": 11742.0}, "meta_inference_completion_tokens": {"value": 988.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023484}, "meta_inference_completion_cost": {"value": 0.0015808}, "meta_eval_time": {"value": 14.803}, "meta_eval_prompt_tokens": {"value": 6120.0}, "meta_eval_completion_tokens": {"value": 1294.0}, "meta_eval_prompt_cost": {"value": 0.0019584}, "meta_eval_completion_cost": {"value": 0.00165632}}, "created": "2025-12-10T21:36:21.0746416Z"}
{"ref": "TQ20", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.507185}, "meta_inference_prompt_tokens": {"value": 11485.0}, "meta_inference_completion_tokens": {"value": 1128.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002297}, "meta_inference_completion_cost": {"value": 0.0018048}, "meta_eval_time": {"value": 26.329}, "meta_eval_prompt_tokens": {"value": 6241.0}, "meta_eval_completion_tokens": {"value": 2271.0}, "meta_eval_prompt_cost": {"value": 0.00199712}, "meta_eval_completion_cost": {"value": 0.00290688}}, "created": "2025-12-10T21:36:23.5300042Z"}
{"ref": "TQ24", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.894736842105263}, "generation_factuality_f1": {"value": 0.410958904109589}, "generation_factuality_precision": {"value": 0.272727272727273}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.222222222222222}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 22.092177}, "meta_inference_prompt_tokens": {"value": 12639.0}, "meta_inference_completion_tokens": {"value": 1000.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025278}, "meta_inference_completion_cost": {"value": 0.0016}, "meta_eval_time": {"value": 23.517}, "meta_eval_prompt_tokens": {"value": 7324.0}, "meta_eval_completion_tokens": {"value": 2142.0}, "meta_eval_prompt_cost": {"value": 0.00234368}, "meta_eval_completion_cost": {"value": 0.00274176}}, "created": "2025-12-10T21:36:25.1845348Z"}
{"ref": "TQ19", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.745163}, "meta_inference_prompt_tokens": {"value": 17147.0}, "meta_inference_completion_tokens": {"value": 1450.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0034294}, "meta_inference_completion_cost": {"value": 0.00232}, "meta_eval_time": {"value": 28.592}, "meta_eval_prompt_tokens": {"value": 11932.0}, "meta_eval_completion_tokens": {"value": 2507.0}, "meta_eval_prompt_cost": {"value": 0.00381824}, "meta_eval_completion_cost": {"value": 0.00320896}}, "created": "2025-12-10T21:36:25.8798495Z"}
{"ref": "TQ24", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.603036}, "meta_inference_prompt_tokens": {"value": 12732.0}, "meta_inference_completion_tokens": {"value": 849.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025464}, "meta_inference_completion_cost": {"value": 0.0013584}, "meta_eval_time": {"value": 24.172}, "meta_eval_prompt_tokens": {"value": 7071.0}, "meta_eval_completion_tokens": {"value": 2058.0}, "meta_eval_prompt_cost": {"value": 0.00226272}, "meta_eval_completion_cost": {"value": 0.00263424}}, "created": "2025-12-10T21:36:26.5566242Z"}
{"ref": "TQ22", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.5}, "generation_factuality_f1": {"value": 0.428571428571429}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 17.250326}, "meta_inference_prompt_tokens": {"value": 12300.0}, "meta_inference_completion_tokens": {"value": 713.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00246}, "meta_inference_completion_cost": {"value": 0.0011408}, "meta_eval_time": {"value": 15.657}, "meta_eval_prompt_tokens": {"value": 6650.0}, "meta_eval_completion_tokens": {"value": 1286.0}, "meta_eval_prompt_cost": {"value": 0.002128}, "meta_eval_completion_cost": {"value": 0.00164608}}, "created": "2025-12-10T21:36:26.9139762Z"}
{"ref": "TQ25", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.394411}, "meta_inference_prompt_tokens": {"value": 12085.0}, "meta_inference_completion_tokens": {"value": 779.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002417}, "meta_inference_completion_cost": {"value": 0.0012464}, "meta_eval_time": {"value": 19.762}, "meta_eval_prompt_tokens": {"value": 6368.0}, "meta_eval_completion_tokens": {"value": 1638.0}, "meta_eval_prompt_cost": {"value": 0.00203776}, "meta_eval_completion_cost": {"value": 0.00209664}}, "created": "2025-12-10T21:36:27.1922117Z"}
{"ref": "TQ26", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.745926}, "meta_inference_prompt_tokens": {"value": 12462.0}, "meta_inference_completion_tokens": {"value": 842.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024924}, "meta_inference_completion_cost": {"value": 0.0013472}, "meta_eval_time": {"value": 17.424}, "meta_eval_prompt_tokens": {"value": 6589.0}, "meta_eval_completion_tokens": {"value": 1578.0}, "meta_eval_prompt_cost": {"value": 0.00210848}, "meta_eval_completion_cost": {"value": 0.00201984}}, "created": "2025-12-10T21:36:27.2350547Z"}
{"ref": "TQ26", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.790647}, "meta_inference_prompt_tokens": {"value": 11159.0}, "meta_inference_completion_tokens": {"value": 1215.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022318}, "meta_inference_completion_cost": {"value": 0.001944}, "meta_eval_time": {"value": 21.238}, "meta_eval_prompt_tokens": {"value": 5613.0}, "meta_eval_completion_tokens": {"value": 1457.0}, "meta_eval_prompt_cost": {"value": 0.00179616}, "meta_eval_completion_cost": {"value": 0.00186496}}, "created": "2025-12-10T21:36:27.5727723Z"}
{"ref": "TQ28", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.550974}, "meta_inference_prompt_tokens": {"value": 13295.0}, "meta_inference_completion_tokens": {"value": 810.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002659}, "meta_inference_completion_cost": {"value": 0.001296}, "meta_eval_time": {"value": 14.336}, "meta_eval_prompt_tokens": {"value": 7194.0}, "meta_eval_completion_tokens": {"value": 1252.0}, "meta_eval_prompt_cost": {"value": 0.00230208}, "meta_eval_completion_cost": {"value": 0.00160256}}, "created": "2025-12-10T21:36:28.4066976Z"}
{"ref": "TQ27", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 20.798356}, "meta_inference_prompt_tokens": {"value": 11518.0}, "meta_inference_completion_tokens": {"value": 893.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023036}, "meta_inference_completion_cost": {"value": 0.0014288}, "meta_eval_time": {"value": 14.453}, "meta_eval_prompt_tokens": {"value": 5450.0}, "meta_eval_completion_tokens": {"value": 1192.0}, "meta_eval_prompt_cost": {"value": 0.001744}, "meta_eval_completion_cost": {"value": 0.00152576}}, "created": "2025-12-10T21:36:29.0319609Z"}
{"ref": "TQ26", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.615384615384615}, "retrieval_mrr": {"value": 0.466666666666667}, "retrieval_dcg": {"value": 2.86263630730883}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.444444444444444}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.671382}, "meta_inference_prompt_tokens": {"value": 14384.0}, "meta_inference_completion_tokens": {"value": 1049.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028768}, "meta_inference_completion_cost": {"value": 0.0016784}, "meta_eval_time": {"value": 17.281}, "meta_eval_prompt_tokens": {"value": 8128.0}, "meta_eval_completion_tokens": {"value": 1555.0}, "meta_eval_prompt_cost": {"value": 0.00260096}, "meta_eval_completion_cost": {"value": 0.0019904}}, "created": "2025-12-10T21:36:29.296415Z"}
{"ref": "TQ26", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.56160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.119812}, "meta_inference_prompt_tokens": {"value": 12465.0}, "meta_inference_completion_tokens": {"value": 1040.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002493}, "meta_inference_completion_cost": {"value": 0.001664}, "meta_eval_time": {"value": 18.326}, "meta_eval_prompt_tokens": {"value": 6492.0}, "meta_eval_completion_tokens": {"value": 1419.0}, "meta_eval_prompt_cost": {"value": 0.00207744}, "meta_eval_completion_cost": {"value": 0.00181632}}, "created": "2025-12-10T21:36:29.3312961Z"}
{"ref": "TQ28", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 0.846153846153846}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.582041}, "meta_inference_prompt_tokens": {"value": 10629.0}, "meta_inference_completion_tokens": {"value": 828.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021258}, "meta_inference_completion_cost": {"value": 0.0013248}, "meta_eval_time": {"value": 15.051}, "meta_eval_prompt_tokens": {"value": 5251.0}, "meta_eval_completion_tokens": {"value": 1407.0}, "meta_eval_prompt_cost": {"value": 0.00168032}, "meta_eval_completion_cost": {"value": 0.00180096}}, "created": "2025-12-10T21:36:29.705613Z"}
{"ref": "TQ26", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.56160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.97917}, "meta_inference_prompt_tokens": {"value": 12111.0}, "meta_inference_completion_tokens": {"value": 744.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024222}, "meta_inference_completion_cost": {"value": 0.0011904}, "meta_eval_time": {"value": 22.499}, "meta_eval_prompt_tokens": {"value": 6340.0}, "meta_eval_completion_tokens": {"value": 1932.0}, "meta_eval_prompt_cost": {"value": 0.0020288}, "meta_eval_completion_cost": {"value": 0.00247296}}, "created": "2025-12-10T21:36:30.0059725Z"}
{"ref": "TQ27", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 16.406443}, "meta_inference_prompt_tokens": {"value": 12372.0}, "meta_inference_completion_tokens": {"value": 885.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024744}, "meta_inference_completion_cost": {"value": 0.001416}, "meta_eval_time": {"value": 22.327}, "meta_eval_prompt_tokens": {"value": 6577.0}, "meta_eval_completion_tokens": {"value": 2030.0}, "meta_eval_prompt_cost": {"value": 0.00210464}, "meta_eval_completion_cost": {"value": 0.0025984}}, "created": "2025-12-10T21:36:30.7033912Z"}
{"ref": "TQ21", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.017782560806}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.533333333333333}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 22.376625}, "meta_inference_prompt_tokens": {"value": 12571.0}, "meta_inference_completion_tokens": {"value": 1211.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025142}, "meta_inference_completion_cost": {"value": 0.0019376}, "meta_eval_time": {"value": 31.833}, "meta_eval_prompt_tokens": {"value": 8259.0}, "meta_eval_completion_tokens": {"value": 2920.0}, "meta_eval_prompt_cost": {"value": 0.00264288}, "meta_eval_completion_cost": {"value": 0.0037376}}, "created": "2025-12-10T21:36:30.777303Z"}
{"ref": "TQ27", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 18.971738}, "meta_inference_prompt_tokens": {"value": 11993.0}, "meta_inference_completion_tokens": {"value": 881.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023986}, "meta_inference_completion_cost": {"value": 0.0014096}, "meta_eval_time": {"value": 18.802}, "meta_eval_prompt_tokens": {"value": 6075.0}, "meta_eval_completion_tokens": {"value": 1528.0}, "meta_eval_prompt_cost": {"value": 0.001944}, "meta_eval_completion_cost": {"value": 0.00195584}}, "created": "2025-12-10T21:36:31.6775966Z"}
{"ref": "TQ27", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 25.065933}, "meta_inference_prompt_tokens": {"value": 12615.0}, "meta_inference_completion_tokens": {"value": 1021.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002523}, "meta_inference_completion_cost": {"value": 0.0016336}, "meta_eval_time": {"value": 20.02}, "meta_eval_prompt_tokens": {"value": 6688.0}, "meta_eval_completion_tokens": {"value": 1961.0}, "meta_eval_prompt_cost": {"value": 0.00214016}, "meta_eval_completion_cost": {"value": 0.00251008}}, "created": "2025-12-10T21:36:32.057389Z"}
{"ref": "TQ24", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.017782560806}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.606888}, "meta_inference_prompt_tokens": {"value": 12139.0}, "meta_inference_completion_tokens": {"value": 1034.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024278}, "meta_inference_completion_cost": {"value": 0.0016544}, "meta_eval_time": {"value": 25.167}, "meta_eval_prompt_tokens": {"value": 6834.0}, "meta_eval_completion_tokens": {"value": 2274.0}, "meta_eval_prompt_cost": {"value": 0.00218688}, "meta_eval_completion_cost": {"value": 0.00291072}}, "created": "2025-12-10T21:36:32.5700589Z"}
{"ref": "TQ20", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.454865}, "meta_inference_prompt_tokens": {"value": 10682.0}, "meta_inference_completion_tokens": {"value": 981.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021364}, "meta_inference_completion_cost": {"value": 0.0015696}, "meta_eval_time": {"value": 20.176}, "meta_eval_prompt_tokens": {"value": 5510.0}, "meta_eval_completion_tokens": {"value": 1716.0}, "meta_eval_prompt_cost": {"value": 0.0017632}, "meta_eval_completion_cost": {"value": 0.00219648}}, "created": "2025-12-10T21:36:32.6700537Z"}
{"ref": "TQ21", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.931959749235439}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.436363636363636}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 24.493471}, "meta_inference_prompt_tokens": {"value": 11992.0}, "meta_inference_completion_tokens": {"value": 1444.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023984}, "meta_inference_completion_cost": {"value": 0.0023104}, "meta_eval_time": {"value": 37.834}, "meta_eval_prompt_tokens": {"value": 7977.0}, "meta_eval_completion_tokens": {"value": 3457.0}, "meta_eval_prompt_cost": {"value": 0.00255264}, "meta_eval_completion_cost": {"value": 0.00442496}}, "created": "2025-12-10T21:36:33.6760083Z"}
{"ref": "TQ28", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.16888}, "meta_inference_prompt_tokens": {"value": 12516.0}, "meta_inference_completion_tokens": {"value": 658.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025032}, "meta_inference_completion_cost": {"value": 0.0010528}, "meta_eval_time": {"value": 13.077}, "meta_eval_prompt_tokens": {"value": 6646.0}, "meta_eval_completion_tokens": {"value": 1292.0}, "meta_eval_prompt_cost": {"value": 0.00212672}, "meta_eval_completion_cost": {"value": 0.00165376}}, "created": "2025-12-10T21:36:34.1925989Z"}
{"ref": "TQ23", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8125}, "generation_factuality_f1": {"value": 0.380952380952381}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 27.432631}, "meta_inference_prompt_tokens": {"value": 12218.0}, "meta_inference_completion_tokens": {"value": 1527.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024436}, "meta_inference_completion_cost": {"value": 0.0024432}, "meta_eval_time": {"value": 30.114}, "meta_eval_prompt_tokens": {"value": 6961.0}, "meta_eval_completion_tokens": {"value": 2363.0}, "meta_eval_prompt_cost": {"value": 0.00222752}, "meta_eval_completion_cost": {"value": 0.00302464}}, "created": "2025-12-10T21:36:34.3467556Z"}
{"ref": "TQ24", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.931034482758621}, "generation_factuality_f1": {"value": 0.677966101694915}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 18.383042}, "meta_inference_prompt_tokens": {"value": 13213.0}, "meta_inference_completion_tokens": {"value": 834.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026426}, "meta_inference_completion_cost": {"value": 0.0013344}, "meta_eval_time": {"value": 31.071}, "meta_eval_prompt_tokens": {"value": 7637.0}, "meta_eval_completion_tokens": {"value": 2768.0}, "meta_eval_prompt_cost": {"value": 0.00244384}, "meta_eval_completion_cost": {"value": 0.00354304}}, "created": "2025-12-10T21:36:34.9874813Z"}
{"ref": "TQ21", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.98713694067948}, "generation_faithfulness": {"value": 0.935483870967742}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 22.051254}, "meta_inference_prompt_tokens": {"value": 12543.0}, "meta_inference_completion_tokens": {"value": 1215.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025086}, "meta_inference_completion_cost": {"value": 0.001944}, "meta_eval_time": {"value": 37.298}, "meta_eval_prompt_tokens": {"value": 8361.0}, "meta_eval_completion_tokens": {"value": 3320.0}, "meta_eval_prompt_cost": {"value": 0.00267552}, "meta_eval_completion_cost": {"value": 0.0042496}}, "created": "2025-12-10T21:36:35.0862594Z"}
{"ref": "TQ30", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.583879}, "meta_inference_prompt_tokens": {"value": 11882.0}, "meta_inference_completion_tokens": {"value": 883.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023764}, "meta_inference_completion_cost": {"value": 0.0014128}, "meta_eval_time": {"value": 14.566}, "meta_eval_prompt_tokens": {"value": 6191.0}, "meta_eval_completion_tokens": {"value": 1337.0}, "meta_eval_prompt_cost": {"value": 0.00198112}, "meta_eval_completion_cost": {"value": 0.00171136}}, "created": "2025-12-10T21:36:35.1507895Z"}
{"ref": "TQ28", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.718934}, "meta_inference_prompt_tokens": {"value": 10711.0}, "meta_inference_completion_tokens": {"value": 879.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021422}, "meta_inference_completion_cost": {"value": 0.0014064}, "meta_eval_time": {"value": 15.504}, "meta_eval_prompt_tokens": {"value": 5165.0}, "meta_eval_completion_tokens": {"value": 1369.0}, "meta_eval_prompt_cost": {"value": 0.0016528}, "meta_eval_completion_cost": {"value": 0.00175232}}, "created": "2025-12-10T21:36:35.9376555Z"}
{"ref": "TQ23", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 28.556298}, "meta_inference_prompt_tokens": {"value": 11173.0}, "meta_inference_completion_tokens": {"value": 1630.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022346}, "meta_inference_completion_cost": {"value": 0.002608}, "meta_eval_time": {"value": 32.844}, "meta_eval_prompt_tokens": {"value": 6109.0}, "meta_eval_completion_tokens": {"value": 2214.0}, "meta_eval_prompt_cost": {"value": 0.00195488}, "meta_eval_completion_cost": {"value": 0.00283392}}, "created": "2025-12-10T21:36:36.66801Z"}
{"ref": "TQ21", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.017782560806}, "generation_faithfulness": {"value": 0.828571428571429}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 47.511476}, "meta_inference_prompt_tokens": {"value": 11682.0}, "meta_inference_completion_tokens": {"value": 1354.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023364}, "meta_inference_completion_cost": {"value": 0.0021664}, "meta_eval_time": {"value": 37.992}, "meta_eval_prompt_tokens": {"value": 7443.0}, "meta_eval_completion_tokens": {"value": 3218.0}, "meta_eval_prompt_cost": {"value": 0.00238176}, "meta_eval_completion_cost": {"value": 0.00411904}}, "created": "2025-12-10T21:36:37.3846926Z"}
{"ref": "TQ27", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.7}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 23.333334}, "meta_inference_prompt_tokens": {"value": 12321.0}, "meta_inference_completion_tokens": {"value": 963.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024642}, "meta_inference_completion_cost": {"value": 0.0015408}, "meta_eval_time": {"value": 21.158}, "meta_eval_prompt_tokens": {"value": 6243.0}, "meta_eval_completion_tokens": {"value": 1923.0}, "meta_eval_prompt_cost": {"value": 0.00199776}, "meta_eval_completion_cost": {"value": 0.00246144}}, "created": "2025-12-10T21:36:38.6299773Z"}
{"ref": "TQ23", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 31.28123}, "meta_inference_prompt_tokens": {"value": 11491.0}, "meta_inference_completion_tokens": {"value": 1993.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022982}, "meta_inference_completion_cost": {"value": 0.0031888}, "meta_eval_time": {"value": 35.848}, "meta_eval_prompt_tokens": {"value": 6851.0}, "meta_eval_completion_tokens": {"value": 3407.0}, "meta_eval_prompt_cost": {"value": 0.00219232}, "meta_eval_completion_cost": {"value": 0.00436096}}, "created": "2025-12-10T21:36:39.1959619Z"}
{"ref": "TQ31", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.496934}, "meta_inference_prompt_tokens": {"value": 11302.0}, "meta_inference_completion_tokens": {"value": 877.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022604}, "meta_inference_completion_cost": {"value": 0.0014032}, "meta_eval_time": {"value": 12.863}, "meta_eval_prompt_tokens": {"value": 5911.0}, "meta_eval_completion_tokens": {"value": 1282.0}, "meta_eval_prompt_cost": {"value": 0.00189152}, "meta_eval_completion_cost": {"value": 0.00164096}}, "created": "2025-12-10T21:36:40.0973999Z"}
{"ref": "TQ30", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.962125}, "meta_inference_prompt_tokens": {"value": 12191.0}, "meta_inference_completion_tokens": {"value": 858.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024382}, "meta_inference_completion_cost": {"value": 0.0013728}, "meta_eval_time": {"value": 21.735}, "meta_eval_prompt_tokens": {"value": 6550.0}, "meta_eval_completion_tokens": {"value": 1853.0}, "meta_eval_prompt_cost": {"value": 0.002096}, "meta_eval_completion_cost": {"value": 0.00237184}}, "created": "2025-12-10T21:36:41.0995523Z"}
{"ref": "TQ24", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.869565217391304}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.432776}, "meta_inference_prompt_tokens": {"value": 11406.0}, "meta_inference_completion_tokens": {"value": 1011.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022812}, "meta_inference_completion_cost": {"value": 0.0016176}, "meta_eval_time": {"value": 32.627}, "meta_eval_prompt_tokens": {"value": 6176.0}, "meta_eval_completion_tokens": {"value": 2347.0}, "meta_eval_prompt_cost": {"value": 0.00197632}, "meta_eval_completion_cost": {"value": 0.00300416}}, "created": "2025-12-10T21:36:41.6329522Z"}
{"ref": "TQ35", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 19.036546}, "meta_inference_prompt_tokens": {"value": 12717.0}, "meta_inference_completion_tokens": {"value": 645.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025434}, "meta_inference_completion_cost": {"value": 0.001032}, "meta_eval_time": {"value": 9.074}, "meta_eval_prompt_tokens": {"value": 6817.0}, "meta_eval_completion_tokens": {"value": 699.0}, "meta_eval_prompt_cost": {"value": 0.00218144}, "meta_eval_completion_cost": {"value": 0.00089472}}, "created": "2025-12-10T21:36:41.6815928Z"}
{"ref": "TQ31", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.948541}, "meta_inference_prompt_tokens": {"value": 11791.0}, "meta_inference_completion_tokens": {"value": 968.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023582}, "meta_inference_completion_cost": {"value": 0.0015488}, "meta_eval_time": {"value": 15.798}, "meta_eval_prompt_tokens": {"value": 6411.0}, "meta_eval_completion_tokens": {"value": 1554.0}, "meta_eval_prompt_cost": {"value": 0.00205152}, "meta_eval_completion_cost": {"value": 0.00198912}}, "created": "2025-12-10T21:36:42.3909657Z"}
{"ref": "TQ31", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.591195}, "meta_inference_prompt_tokens": {"value": 11221.0}, "meta_inference_completion_tokens": {"value": 788.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022442}, "meta_inference_completion_cost": {"value": 0.0012608}, "meta_eval_time": {"value": 15.712}, "meta_eval_prompt_tokens": {"value": 5850.0}, "meta_eval_completion_tokens": {"value": 1373.0}, "meta_eval_prompt_cost": {"value": 0.001872}, "meta_eval_completion_cost": {"value": 0.00175744}}, "created": "2025-12-10T21:36:42.9832546Z"}
{"ref": "TQ29", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.95}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.631984}, "meta_inference_prompt_tokens": {"value": 14703.0}, "meta_inference_completion_tokens": {"value": 873.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029406}, "meta_inference_completion_cost": {"value": 0.0013968}, "meta_eval_time": {"value": 22.912}, "meta_eval_prompt_tokens": {"value": 9280.0}, "meta_eval_completion_tokens": {"value": 2205.0}, "meta_eval_prompt_cost": {"value": 0.0029696}, "meta_eval_completion_cost": {"value": 0.0028224}}, "created": "2025-12-10T21:36:43.1542615Z"}
{"ref": "TQ29", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.710326}, "meta_inference_prompt_tokens": {"value": 13515.0}, "meta_inference_completion_tokens": {"value": 789.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002703}, "meta_inference_completion_cost": {"value": 0.0012624}, "meta_eval_time": {"value": 25.382}, "meta_eval_prompt_tokens": {"value": 8365.0}, "meta_eval_completion_tokens": {"value": 2480.0}, "meta_eval_prompt_cost": {"value": 0.0026768}, "meta_eval_completion_cost": {"value": 0.0031744}}, "created": "2025-12-10T21:36:43.3231339Z"}
{"ref": "TQ30", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.092381}, "meta_inference_prompt_tokens": {"value": 11012.0}, "meta_inference_completion_tokens": {"value": 729.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022024}, "meta_inference_completion_cost": {"value": 0.0011664}, "meta_eval_time": {"value": 16.559}, "meta_eval_prompt_tokens": {"value": 5512.0}, "meta_eval_completion_tokens": {"value": 1534.0}, "meta_eval_prompt_cost": {"value": 0.00176384}, "meta_eval_completion_cost": {"value": 0.00196352}}, "created": "2025-12-10T21:36:43.5167611Z"}
{"ref": "TQ31", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.137324}, "meta_inference_prompt_tokens": {"value": 10767.0}, "meta_inference_completion_tokens": {"value": 993.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021534}, "meta_inference_completion_cost": {"value": 0.0015888}, "meta_eval_time": {"value": 18.325}, "meta_eval_prompt_tokens": {"value": 5576.0}, "meta_eval_completion_tokens": {"value": 1557.0}, "meta_eval_prompt_cost": {"value": 0.00178432}, "meta_eval_completion_cost": {"value": 0.00199296}}, "created": "2025-12-10T21:36:43.5507027Z"}
{"ref": "TQ34", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.666666666666667}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 14.606484}, "meta_inference_prompt_tokens": {"value": 7387.0}, "meta_inference_completion_tokens": {"value": 694.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0014774}, "meta_inference_completion_cost": {"value": 0.0011104}, "meta_eval_time": {"value": 9.899}, "meta_eval_prompt_tokens": {"value": 3905.0}, "meta_eval_completion_tokens": {"value": 900.0}, "meta_eval_prompt_cost": {"value": 0.0012496}, "meta_eval_completion_cost": {"value": 0.001152}}, "created": "2025-12-10T21:36:43.6121824Z"}
{"ref": "TQ28", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.97154}, "meta_inference_prompt_tokens": {"value": 13771.0}, "meta_inference_completion_tokens": {"value": 849.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027542}, "meta_inference_completion_cost": {"value": 0.0013584}, "meta_eval_time": {"value": 16.322}, "meta_eval_prompt_tokens": {"value": 7617.0}, "meta_eval_completion_tokens": {"value": 1450.0}, "meta_eval_prompt_cost": {"value": 0.00243744}, "meta_eval_completion_cost": {"value": 0.001856}}, "created": "2025-12-10T21:36:43.9336852Z"}
{"ref": "TQ34", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.857142857142857}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.93067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.689655172413793}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.75}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.75}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 18.178767}, "meta_inference_prompt_tokens": {"value": 7774.0}, "meta_inference_completion_tokens": {"value": 779.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0015548}, "meta_inference_completion_cost": {"value": 0.0012464}, "meta_eval_time": {"value": 14.749}, "meta_eval_prompt_tokens": {"value": 4125.0}, "meta_eval_completion_tokens": {"value": 1323.0}, "meta_eval_prompt_cost": {"value": 0.00132}, "meta_eval_completion_cost": {"value": 0.00169344}}, "created": "2025-12-10T21:36:44.4911279Z"}
{"ref": "TQ35", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.724254}, "meta_inference_prompt_tokens": {"value": 11098.0}, "meta_inference_completion_tokens": {"value": 1023.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022196}, "meta_inference_completion_cost": {"value": 0.0016368}, "meta_eval_time": {"value": 9.432}, "meta_eval_prompt_tokens": {"value": 5317.0}, "meta_eval_completion_tokens": {"value": 801.0}, "meta_eval_prompt_cost": {"value": 0.00170144}, "meta_eval_completion_cost": {"value": 0.00102528}}, "created": "2025-12-10T21:36:44.557273Z"}
{"ref": "TQ34", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 13.585868}, "meta_inference_prompt_tokens": {"value": 7957.0}, "meta_inference_completion_tokens": {"value": 589.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0015914}, "meta_inference_completion_cost": {"value": 0.0009424}, "meta_eval_time": {"value": 12.935}, "meta_eval_prompt_tokens": {"value": 4247.0}, "meta_eval_completion_tokens": {"value": 1238.0}, "meta_eval_prompt_cost": {"value": 0.00135904}, "meta_eval_completion_cost": {"value": 0.00158464}}, "created": "2025-12-10T21:36:44.6527141Z"}
{"ref": "TQ32", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.521743}, "meta_inference_prompt_tokens": {"value": 11248.0}, "meta_inference_completion_tokens": {"value": 995.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022496}, "meta_inference_completion_cost": {"value": 0.001592}, "meta_eval_time": {"value": 15.973}, "meta_eval_prompt_tokens": {"value": 5739.0}, "meta_eval_completion_tokens": {"value": 1435.0}, "meta_eval_prompt_cost": {"value": 0.00183648}, "meta_eval_completion_cost": {"value": 0.0018368}}, "created": "2025-12-10T21:36:45.0453931Z"}
{"ref": "TQ31", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.620653}, "meta_inference_prompt_tokens": {"value": 11729.0}, "meta_inference_completion_tokens": {"value": 786.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023458}, "meta_inference_completion_cost": {"value": 0.0012576}, "meta_eval_time": {"value": 17.629}, "meta_eval_prompt_tokens": {"value": 6393.0}, "meta_eval_completion_tokens": {"value": 1495.0}, "meta_eval_prompt_cost": {"value": 0.00204576}, "meta_eval_completion_cost": {"value": 0.0019136}}, "created": "2025-12-10T21:36:46.0740501Z"}
{"ref": "TQ35", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.631578947368421}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.111111111111111}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 14.304696}, "meta_inference_prompt_tokens": {"value": 12385.0}, "meta_inference_completion_tokens": {"value": 640.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002477}, "meta_inference_completion_cost": {"value": 0.001024}, "meta_eval_time": {"value": 11.332}, "meta_eval_prompt_tokens": {"value": 6753.0}, "meta_eval_completion_tokens": {"value": 870.0}, "meta_eval_prompt_cost": {"value": 0.00216096}, "meta_eval_completion_cost": {"value": 0.0011136}}, "created": "2025-12-10T21:36:47.3058526Z"}
{"ref": "TQ32", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.817759}, "meta_inference_prompt_tokens": {"value": 11293.0}, "meta_inference_completion_tokens": {"value": 1161.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022586}, "meta_inference_completion_cost": {"value": 0.0018576}, "meta_eval_time": {"value": 17.699}, "meta_eval_prompt_tokens": {"value": 5837.0}, "meta_eval_completion_tokens": {"value": 1589.0}, "meta_eval_prompt_cost": {"value": 0.00186784}, "meta_eval_completion_cost": {"value": 0.00203392}}, "created": "2025-12-10T21:36:47.7424073Z"}
{"ref": "TQ29", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.968748}, "meta_inference_prompt_tokens": {"value": 14694.0}, "meta_inference_completion_tokens": {"value": 1198.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029388}, "meta_inference_completion_cost": {"value": 0.0019168}, "meta_eval_time": {"value": 30.696}, "meta_eval_prompt_tokens": {"value": 9768.0}, "meta_eval_completion_tokens": {"value": 3107.0}, "meta_eval_prompt_cost": {"value": 0.00312576}, "meta_eval_completion_cost": {"value": 0.00397696}}, "created": "2025-12-10T21:36:48.0829884Z"}
{"ref": "TQ29", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.39119}, "meta_inference_prompt_tokens": {"value": 14280.0}, "meta_inference_completion_tokens": {"value": 1070.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002856}, "meta_inference_completion_cost": {"value": 0.001712}, "meta_eval_time": {"value": 30.295}, "meta_eval_prompt_tokens": {"value": 9372.0}, "meta_eval_completion_tokens": {"value": 2707.0}, "meta_eval_prompt_cost": {"value": 0.00299904}, "meta_eval_completion_cost": {"value": 0.00346496}}, "created": "2025-12-10T21:36:48.2316055Z"}
{"ref": "TQ35", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.091592}, "meta_inference_prompt_tokens": {"value": 11328.0}, "meta_inference_completion_tokens": {"value": 890.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022656}, "meta_inference_completion_cost": {"value": 0.001424}, "meta_eval_time": {"value": 13.378}, "meta_eval_prompt_tokens": {"value": 5459.0}, "meta_eval_completion_tokens": {"value": 990.0}, "meta_eval_prompt_cost": {"value": 0.00174688}, "meta_eval_completion_cost": {"value": 0.0012672}}, "created": "2025-12-10T21:36:48.5648827Z"}
{"ref": "TQ30", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.761904761904762}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.604515}, "meta_inference_prompt_tokens": {"value": 11432.0}, "meta_inference_completion_tokens": {"value": 891.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022864}, "meta_inference_completion_cost": {"value": 0.0014256}, "meta_eval_time": {"value": 25.165}, "meta_eval_prompt_tokens": {"value": 6076.0}, "meta_eval_completion_tokens": {"value": 2096.0}, "meta_eval_prompt_cost": {"value": 0.00194432}, "meta_eval_completion_cost": {"value": 0.00268288}}, "created": "2025-12-10T21:36:48.73214Z"}
{"ref": "TQ23", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.896551724137931}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 27.497854}, "meta_inference_prompt_tokens": {"value": 14931.0}, "meta_inference_completion_tokens": {"value": 1487.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029862}, "meta_inference_completion_cost": {"value": 0.0023792}, "meta_eval_time": {"value": 38.244}, "meta_eval_prompt_tokens": {"value": 9791.0}, "meta_eval_completion_tokens": {"value": 3142.0}, "meta_eval_prompt_cost": {"value": 0.00313312}, "meta_eval_completion_cost": {"value": 0.00402176}}, "created": "2025-12-10T21:36:49.6999062Z"}
{"ref": "TQ34", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.666666666666667}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 16.688963}, "meta_inference_prompt_tokens": {"value": 7390.0}, "meta_inference_completion_tokens": {"value": 850.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001478}, "meta_inference_completion_cost": {"value": 0.00136}, "meta_eval_time": {"value": 21.141}, "meta_eval_prompt_tokens": {"value": 4307.0}, "meta_eval_completion_tokens": {"value": 1833.0}, "meta_eval_prompt_cost": {"value": 0.00137824}, "meta_eval_completion_cost": {"value": 0.00234624}}, "created": "2025-12-10T21:36:50.4778938Z"}
{"ref": "TQ35", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.651766}, "meta_inference_prompt_tokens": {"value": 14984.0}, "meta_inference_completion_tokens": {"value": 946.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029968}, "meta_inference_completion_cost": {"value": 0.0015136}, "meta_eval_time": {"value": 15.785}, "meta_eval_prompt_tokens": {"value": 9090.0}, "meta_eval_completion_tokens": {"value": 1462.0}, "meta_eval_prompt_cost": {"value": 0.0029088}, "meta_eval_completion_cost": {"value": 0.00187136}}, "created": "2025-12-10T21:36:50.8098522Z"}
{"ref": "TQ30", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.954545454545454}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.007205}, "meta_inference_prompt_tokens": {"value": 11389.0}, "meta_inference_completion_tokens": {"value": 732.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022778}, "meta_inference_completion_cost": {"value": 0.0011712}, "meta_eval_time": {"value": 25.769}, "meta_eval_prompt_tokens": {"value": 6208.0}, "meta_eval_completion_tokens": {"value": 2235.0}, "meta_eval_prompt_cost": {"value": 0.00198656}, "meta_eval_completion_cost": {"value": 0.0028608}}, "created": "2025-12-10T21:36:51.6865239Z"}
{"ref": "TQ34", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 17.255588}, "meta_inference_prompt_tokens": {"value": 9760.0}, "meta_inference_completion_tokens": {"value": 774.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001952}, "meta_inference_completion_cost": {"value": 0.0012384}, "meta_eval_time": {"value": 15.221}, "meta_eval_prompt_tokens": {"value": 5675.0}, "meta_eval_completion_tokens": {"value": 1281.0}, "meta_eval_prompt_cost": {"value": 0.001816}, "meta_eval_completion_cost": {"value": 0.00163968}}, "created": "2025-12-10T21:36:51.9309279Z"}
{"ref": "TQ21", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.06160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.3}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 29.668002}, "meta_inference_prompt_tokens": {"value": 12980.0}, "meta_inference_completion_tokens": {"value": 1495.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002596}, "meta_inference_completion_cost": {"value": 0.002392}, "meta_eval_time": {"value": 53.19}, "meta_eval_prompt_tokens": {"value": 9114.0}, "meta_eval_completion_tokens": {"value": 4166.0}, "meta_eval_prompt_cost": {"value": 0.00291648}, "meta_eval_completion_cost": {"value": 0.00533248}}, "created": "2025-12-10T21:36:52.3480117Z"}
{"ref": "TQ32", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.310141}, "meta_inference_prompt_tokens": {"value": 11932.0}, "meta_inference_completion_tokens": {"value": 1051.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023864}, "meta_inference_completion_cost": {"value": 0.0016816}, "meta_eval_time": {"value": 15.527}, "meta_eval_prompt_tokens": {"value": 6458.0}, "meta_eval_completion_tokens": {"value": 1567.0}, "meta_eval_prompt_cost": {"value": 0.00206656}, "meta_eval_completion_cost": {"value": 0.00200576}}, "created": "2025-12-10T21:36:52.9614325Z"}
{"ref": "TQ29", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.030674}, "meta_inference_prompt_tokens": {"value": 14192.0}, "meta_inference_completion_tokens": {"value": 725.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028384}, "meta_inference_completion_cost": {"value": 0.00116}, "meta_eval_time": {"value": 25.281}, "meta_eval_prompt_tokens": {"value": 8863.0}, "meta_eval_completion_tokens": {"value": 2226.0}, "meta_eval_prompt_cost": {"value": 0.00283616}, "meta_eval_completion_cost": {"value": 0.00284928}}, "created": "2025-12-10T21:36:54.6648748Z"}
{"ref": "TQ32", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.954545454545454}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.538796}, "meta_inference_prompt_tokens": {"value": 11927.0}, "meta_inference_completion_tokens": {"value": 1254.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023854}, "meta_inference_completion_cost": {"value": 0.0020064}, "meta_eval_time": {"value": 23.935}, "meta_eval_prompt_tokens": {"value": 6787.0}, "meta_eval_completion_tokens": {"value": 2356.0}, "meta_eval_prompt_cost": {"value": 0.00217184}, "meta_eval_completion_cost": {"value": 0.00301568}}, "created": "2025-12-10T21:36:54.7574717Z"}
{"ref": "TQ33", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.814551}, "meta_inference_prompt_tokens": {"value": 12218.0}, "meta_inference_completion_tokens": {"value": 817.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024436}, "meta_inference_completion_cost": {"value": 0.0013072}, "meta_eval_time": {"value": 24.137}, "meta_eval_prompt_tokens": {"value": 7026.0}, "meta_eval_completion_tokens": {"value": 2152.0}, "meta_eval_prompt_cost": {"value": 0.00224832}, "meta_eval_completion_cost": {"value": 0.00275456}}, "created": "2025-12-10T21:36:54.8808771Z"}
{"ref": "TQ33", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 0.96}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.753527}, "meta_inference_prompt_tokens": {"value": 12950.0}, "meta_inference_completion_tokens": {"value": 1270.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00259}, "meta_inference_completion_cost": {"value": 0.002032}, "meta_eval_time": {"value": 25.223}, "meta_eval_prompt_tokens": {"value": 7625.0}, "meta_eval_completion_tokens": {"value": 2342.0}, "meta_eval_prompt_cost": {"value": 0.00244}, "meta_eval_completion_cost": {"value": 0.00299776}}, "created": "2025-12-10T21:36:57.3213534Z"}
{"ref": "TQ32", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.440442}, "meta_inference_prompt_tokens": {"value": 12322.0}, "meta_inference_completion_tokens": {"value": 1089.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024644}, "meta_inference_completion_cost": {"value": 0.0017424}, "meta_eval_time": {"value": 20.83}, "meta_eval_prompt_tokens": {"value": 6838.0}, "meta_eval_completion_tokens": {"value": 1930.0}, "meta_eval_prompt_cost": {"value": 0.00218816}, "meta_eval_completion_cost": {"value": 0.0024704}}, "created": "2025-12-10T21:36:59.4982577Z"}
{"ref": "TQ33", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.06160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.2}, "generation_factuality_precision": {"value": 0.111111111111111}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.012072}, "meta_inference_prompt_tokens": {"value": 13326.0}, "meta_inference_completion_tokens": {"value": 1302.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026652}, "meta_inference_completion_cost": {"value": 0.0020832}, "meta_eval_time": {"value": 28.912}, "meta_eval_prompt_tokens": {"value": 8419.0}, "meta_eval_completion_tokens": {"value": 2576.0}, "meta_eval_prompt_cost": {"value": 0.00269408}, "meta_eval_completion_cost": {"value": 0.00329728}}, "created": "2025-12-10T21:37:03.1404213Z"}
{"ref": "TQ33", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 0.962962962962963}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.418258}, "meta_inference_prompt_tokens": {"value": 12532.0}, "meta_inference_completion_tokens": {"value": 1147.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025064}, "meta_inference_completion_cost": {"value": 0.0018352}, "meta_eval_time": {"value": 29.063}, "meta_eval_prompt_tokens": {"value": 7456.0}, "meta_eval_completion_tokens": {"value": 2544.0}, "meta_eval_prompt_cost": {"value": 0.00238592}, "meta_eval_completion_cost": {"value": 0.00325632}}, "created": "2025-12-10T21:37:03.4481159Z"}
{"ref": "TQ39", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.818134}, "meta_inference_prompt_tokens": {"value": 12166.0}, "meta_inference_completion_tokens": {"value": 936.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024332}, "meta_inference_completion_cost": {"value": 0.0014976}, "meta_eval_time": {"value": 19.664}, "meta_eval_prompt_tokens": {"value": 6584.0}, "meta_eval_completion_tokens": {"value": 2054.0}, "meta_eval_prompt_cost": {"value": 0.00210688}, "meta_eval_completion_cost": {"value": 0.00262912}}, "created": "2025-12-10T21:37:04.193883Z"}
{"ref": "TQ33", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.96}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.831866}, "meta_inference_prompt_tokens": {"value": 12577.0}, "meta_inference_completion_tokens": {"value": 1090.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025154}, "meta_inference_completion_cost": {"value": 0.001744}, "meta_eval_time": {"value": 32.235}, "meta_eval_prompt_tokens": {"value": 7284.0}, "meta_eval_completion_tokens": {"value": 2341.0}, "meta_eval_prompt_cost": {"value": 0.00233088}, "meta_eval_completion_cost": {"value": 0.00299648}}, "created": "2025-12-10T21:37:04.9390527Z"}
{"ref": "TQ39", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.944444444444444}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.957741}, "meta_inference_prompt_tokens": {"value": 11977.0}, "meta_inference_completion_tokens": {"value": 1079.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023954}, "meta_inference_completion_cost": {"value": 0.0017264}, "meta_eval_time": {"value": 21.136}, "meta_eval_prompt_tokens": {"value": 6350.0}, "meta_eval_completion_tokens": {"value": 1969.0}, "meta_eval_prompt_cost": {"value": 0.002032}, "meta_eval_completion_cost": {"value": 0.00252032}}, "created": "2025-12-10T21:37:05.1166746Z"}
{"ref": "TQ37", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.404007}, "meta_inference_prompt_tokens": {"value": 11093.0}, "meta_inference_completion_tokens": {"value": 1243.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022186}, "meta_inference_completion_cost": {"value": 0.0019888}, "meta_eval_time": {"value": 24.366}, "meta_eval_prompt_tokens": {"value": 6668.0}, "meta_eval_completion_tokens": {"value": 2282.0}, "meta_eval_prompt_cost": {"value": 0.00213376}, "meta_eval_completion_cost": {"value": 0.00292096}}, "created": "2025-12-10T21:37:06.0903295Z"}
{"ref": "TQ37", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.831521}, "meta_inference_prompt_tokens": {"value": 11096.0}, "meta_inference_completion_tokens": {"value": 1220.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022192}, "meta_inference_completion_cost": {"value": 0.001952}, "meta_eval_time": {"value": 24.753}, "meta_eval_prompt_tokens": {"value": 6723.0}, "meta_eval_completion_tokens": {"value": 2172.0}, "meta_eval_prompt_cost": {"value": 0.00215136}, "meta_eval_completion_cost": {"value": 0.00278016}}, "created": "2025-12-10T21:37:06.4217816Z"}
{"ref": "TQ41", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.733333333333333}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 21.234062}, "meta_inference_prompt_tokens": {"value": 12204.0}, "meta_inference_completion_tokens": {"value": 1049.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024408}, "meta_inference_completion_cost": {"value": 0.0016784}, "meta_eval_time": {"value": 18.968}, "meta_eval_prompt_tokens": {"value": 6488.0}, "meta_eval_completion_tokens": {"value": 1673.0}, "meta_eval_prompt_cost": {"value": 0.00207616}, "meta_eval_completion_cost": {"value": 0.00214144}}, "created": "2025-12-10T21:37:07.7393843Z"}
{"ref": "TQ39", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.222635}, "meta_inference_prompt_tokens": {"value": 12601.0}, "meta_inference_completion_tokens": {"value": 1206.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025202}, "meta_inference_completion_cost": {"value": 0.0019296}, "meta_eval_time": {"value": 20.713}, "meta_eval_prompt_tokens": {"value": 7353.0}, "meta_eval_completion_tokens": {"value": 2121.0}, "meta_eval_prompt_cost": {"value": 0.00235296}, "meta_eval_completion_cost": {"value": 0.00271488}}, "created": "2025-12-10T21:37:08.0543677Z"}
{"ref": "TQ39", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.894736842105263}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.935967}, "meta_inference_prompt_tokens": {"value": 12209.0}, "meta_inference_completion_tokens": {"value": 1175.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024418}, "meta_inference_completion_cost": {"value": 0.00188}, "meta_eval_time": {"value": 22.402}, "meta_eval_prompt_tokens": {"value": 6697.0}, "meta_eval_completion_tokens": {"value": 2107.0}, "meta_eval_prompt_cost": {"value": 0.00214304}, "meta_eval_completion_cost": {"value": 0.00269696}}, "created": "2025-12-10T21:37:08.5167487Z"}
{"ref": "TQ41", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 19.930362}, "meta_inference_prompt_tokens": {"value": 12161.0}, "meta_inference_completion_tokens": {"value": 1057.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024322}, "meta_inference_completion_cost": {"value": 0.0016912}, "meta_eval_time": {"value": 17.81}, "meta_eval_prompt_tokens": {"value": 6450.0}, "meta_eval_completion_tokens": {"value": 1640.0}, "meta_eval_prompt_cost": {"value": 0.002064}, "meta_eval_completion_cost": {"value": 0.0020992}}, "created": "2025-12-10T21:37:09.4085761Z"}
{"ref": "TQ37", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.222222222222222}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.967873}, "meta_inference_prompt_tokens": {"value": 11096.0}, "meta_inference_completion_tokens": {"value": 1226.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022192}, "meta_inference_completion_cost": {"value": 0.0019616}, "meta_eval_time": {"value": 25.337}, "meta_eval_prompt_tokens": {"value": 6934.0}, "meta_eval_completion_tokens": {"value": 2297.0}, "meta_eval_prompt_cost": {"value": 0.00221888}, "meta_eval_completion_cost": {"value": 0.00294016}}, "created": "2025-12-10T21:37:09.4090163Z"}
{"ref": "TQ39", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.961538461538462}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.762483}, "meta_inference_prompt_tokens": {"value": 12353.0}, "meta_inference_completion_tokens": {"value": 1344.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024706}, "meta_inference_completion_cost": {"value": 0.0021504}, "meta_eval_time": {"value": 24.183}, "meta_eval_prompt_tokens": {"value": 6899.0}, "meta_eval_completion_tokens": {"value": 2446.0}, "meta_eval_prompt_cost": {"value": 0.00220768}, "meta_eval_completion_cost": {"value": 0.00313088}}, "created": "2025-12-10T21:37:09.4088866Z"}
{"ref": "TQ41", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.521739130434783}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 15.83152}, "meta_inference_prompt_tokens": {"value": 12206.0}, "meta_inference_completion_tokens": {"value": 698.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024412}, "meta_inference_completion_cost": {"value": 0.0011168}, "meta_eval_time": {"value": 14.18}, "meta_eval_prompt_tokens": {"value": 6361.0}, "meta_eval_completion_tokens": {"value": 1291.0}, "meta_eval_prompt_cost": {"value": 0.00203552}, "meta_eval_completion_cost": {"value": 0.00165248}}, "created": "2025-12-10T21:37:09.4091376Z"}
{"ref": "TQ36", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.967741935483871}, "generation_factuality_f1": {"value": 0.579710144927536}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 21.870472}, "meta_inference_prompt_tokens": {"value": 9922.0}, "meta_inference_completion_tokens": {"value": 1181.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019844}, "meta_inference_completion_cost": {"value": 0.0018896}, "meta_eval_time": {"value": 30.852}, "meta_eval_prompt_tokens": {"value": 5930.0}, "meta_eval_completion_tokens": {"value": 3247.0}, "meta_eval_prompt_cost": {"value": 0.0018976}, "meta_eval_completion_cost": {"value": 0.00415616}}, "created": "2025-12-10T21:37:10.0875813Z"}
{"ref": "TQ37", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.958333333333334}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.993182}, "meta_inference_prompt_tokens": {"value": 11098.0}, "meta_inference_completion_tokens": {"value": 1335.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022196}, "meta_inference_completion_cost": {"value": 0.002136}, "meta_eval_time": {"value": 29.255}, "meta_eval_prompt_tokens": {"value": 7055.0}, "meta_eval_completion_tokens": {"value": 2478.0}, "meta_eval_prompt_cost": {"value": 0.0022576}, "meta_eval_completion_cost": {"value": 0.00317184}}, "created": "2025-12-10T21:37:10.4187976Z"}
{"ref": "TQ36", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.96}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.001778}, "meta_inference_prompt_tokens": {"value": 9998.0}, "meta_inference_completion_tokens": {"value": 1341.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019996}, "meta_inference_completion_cost": {"value": 0.0021456}, "meta_eval_time": {"value": 27.908}, "meta_eval_prompt_tokens": {"value": 5764.0}, "meta_eval_completion_tokens": {"value": 2879.0}, "meta_eval_prompt_cost": {"value": 0.00184448}, "meta_eval_completion_cost": {"value": 0.00368512}}, "created": "2025-12-10T21:37:11.4623136Z"}
{"ref": "TQ43", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.7}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.189245}, "meta_inference_prompt_tokens": {"value": 9907.0}, "meta_inference_completion_tokens": {"value": 1149.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019814}, "meta_inference_completion_cost": {"value": 0.0018384}, "meta_eval_time": {"value": 14.594}, "meta_eval_prompt_tokens": {"value": 4562.0}, "meta_eval_completion_tokens": {"value": 1277.0}, "meta_eval_prompt_cost": {"value": 0.00145984}, "meta_eval_completion_cost": {"value": 0.00163456}}, "created": "2025-12-10T21:37:11.9537364Z"}
{"ref": "TQ40", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.884615384615384}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.742443}, "meta_inference_prompt_tokens": {"value": 13999.0}, "meta_inference_completion_tokens": {"value": 1140.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027998}, "meta_inference_completion_cost": {"value": 0.001824}, "meta_eval_time": {"value": 24.624}, "meta_eval_prompt_tokens": {"value": 8734.0}, "meta_eval_completion_tokens": {"value": 2428.0}, "meta_eval_prompt_cost": {"value": 0.00279488}, "meta_eval_completion_cost": {"value": 0.00310784}}, "created": "2025-12-10T21:37:12.4011179Z"}
{"ref": "TQ41", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.535063}, "meta_inference_prompt_tokens": {"value": 12221.0}, "meta_inference_completion_tokens": {"value": 1249.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024442}, "meta_inference_completion_cost": {"value": 0.0019984}, "meta_eval_time": {"value": 18.099}, "meta_eval_prompt_tokens": {"value": 6657.0}, "meta_eval_completion_tokens": {"value": 1724.0}, "meta_eval_prompt_cost": {"value": 0.00213024}, "meta_eval_completion_cost": {"value": 0.00220672}}, "created": "2025-12-10T21:37:12.8017076Z"}
{"ref": "TQ41", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.818181818181818}, "generation_factuality_f1": {"value": 0.521739130434783}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 25.241536}, "meta_inference_prompt_tokens": {"value": 10686.0}, "meta_inference_completion_tokens": {"value": 1306.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021372}, "meta_inference_completion_cost": {"value": 0.0020896}, "meta_eval_time": {"value": 24.894}, "meta_eval_prompt_tokens": {"value": 5553.0}, "meta_eval_completion_tokens": {"value": 2240.0}, "meta_eval_prompt_cost": {"value": 0.00177696}, "meta_eval_completion_cost": {"value": 0.0028672}}, "created": "2025-12-10T21:37:13.4980175Z"}
{"ref": "TQ38", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.945945945945946}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.069176}, "meta_inference_prompt_tokens": {"value": 11436.0}, "meta_inference_completion_tokens": {"value": 1532.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022872}, "meta_inference_completion_cost": {"value": 0.0024512}, "meta_eval_time": {"value": 30.843}, "meta_eval_prompt_tokens": {"value": 7017.0}, "meta_eval_completion_tokens": {"value": 3304.0}, "meta_eval_prompt_cost": {"value": 0.00224544}, "meta_eval_completion_cost": {"value": 0.00422912}}, "created": "2025-12-10T21:37:14.4926222Z"}
{"ref": "TQ40", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.931147}, "meta_inference_prompt_tokens": {"value": 14898.0}, "meta_inference_completion_tokens": {"value": 1054.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029796}, "meta_inference_completion_cost": {"value": 0.0016864}, "meta_eval_time": {"value": 27.47}, "meta_eval_prompt_tokens": {"value": 10006.0}, "meta_eval_completion_tokens": {"value": 2657.0}, "meta_eval_prompt_cost": {"value": 0.00320192}, "meta_eval_completion_cost": {"value": 0.00340096}}, "created": "2025-12-10T21:37:15.7424034Z"}
{"ref": "TQ37", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.769230769230769}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.592252}, "meta_inference_prompt_tokens": {"value": 11100.0}, "meta_inference_completion_tokens": {"value": 1448.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00222}, "meta_inference_completion_cost": {"value": 0.0023168}, "meta_eval_time": {"value": 30.82}, "meta_eval_prompt_tokens": {"value": 6964.0}, "meta_eval_completion_tokens": {"value": 2711.0}, "meta_eval_prompt_cost": {"value": 0.00222848}, "meta_eval_completion_cost": {"value": 0.00347008}}, "created": "2025-12-10T21:37:15.9183216Z"}
{"ref": "TQ36", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.517241379310345}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 27.399409}, "meta_inference_prompt_tokens": {"value": 10187.0}, "meta_inference_completion_tokens": {"value": 1761.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020374}, "meta_inference_completion_cost": {"value": 0.0028176}, "meta_eval_time": {"value": 36.014}, "meta_eval_prompt_tokens": {"value": 6373.0}, "meta_eval_completion_tokens": {"value": 3301.0}, "meta_eval_prompt_cost": {"value": 0.00203936}, "meta_eval_completion_cost": {"value": 0.00422528}}, "created": "2025-12-10T21:37:16.1544727Z"}
{"ref": "TQ43", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 48.513159}, "meta_inference_prompt_tokens": {"value": 9934.0}, "meta_inference_completion_tokens": {"value": 1014.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019868}, "meta_inference_completion_cost": {"value": 0.0016224}, "meta_eval_time": {"value": 12.658}, "meta_eval_prompt_tokens": {"value": 4638.0}, "meta_eval_completion_tokens": {"value": 1244.0}, "meta_eval_prompt_cost": {"value": 0.00148416}, "meta_eval_completion_cost": {"value": 0.00159232}}, "created": "2025-12-10T21:37:16.169767Z"}
{"ref": "TQ38", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.827586206896552}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.137559}, "meta_inference_prompt_tokens": {"value": 11590.0}, "meta_inference_completion_tokens": {"value": 1583.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002318}, "meta_inference_completion_cost": {"value": 0.0025328}, "meta_eval_time": {"value": 35.208}, "meta_eval_prompt_tokens": {"value": 7121.0}, "meta_eval_completion_tokens": {"value": 3018.0}, "meta_eval_prompt_cost": {"value": 0.00227872}, "meta_eval_completion_cost": {"value": 0.00386304}}, "created": "2025-12-10T21:37:17.6348133Z"}
{"ref": "TQ38", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.897104}, "meta_inference_prompt_tokens": {"value": 12679.0}, "meta_inference_completion_tokens": {"value": 1409.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025358}, "meta_inference_completion_cost": {"value": 0.0022544}, "meta_eval_time": {"value": 34.538}, "meta_eval_prompt_tokens": {"value": 7972.0}, "meta_eval_completion_tokens": {"value": 2871.0}, "meta_eval_prompt_cost": {"value": 0.00255104}, "meta_eval_completion_cost": {"value": 0.00367488}}, "created": "2025-12-10T21:37:17.7338049Z"}
{"ref": "TQ45", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.833344}, "meta_inference_prompt_tokens": {"value": 12292.0}, "meta_inference_completion_tokens": {"value": 885.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024584}, "meta_inference_completion_cost": {"value": 0.001416}, "meta_eval_time": {"value": 9.904}, "meta_eval_prompt_tokens": {"value": 6505.0}, "meta_eval_completion_tokens": {"value": 846.0}, "meta_eval_prompt_cost": {"value": 0.0020816}, "meta_eval_completion_cost": {"value": 0.00108288}}, "created": "2025-12-10T21:37:19.3301297Z"}
{"ref": "TQ44", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.537088}, "meta_inference_prompt_tokens": {"value": 9666.0}, "meta_inference_completion_tokens": {"value": 1201.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019332}, "meta_inference_completion_cost": {"value": 0.0019216}, "meta_eval_time": {"value": 14.977}, "meta_eval_prompt_tokens": {"value": 4349.0}, "meta_eval_completion_tokens": {"value": 1358.0}, "meta_eval_prompt_cost": {"value": 0.00139168}, "meta_eval_completion_cost": {"value": 0.00173824}}, "created": "2025-12-10T21:37:19.9546459Z"}
{"ref": "TQ44", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.29034}, "meta_inference_prompt_tokens": {"value": 7185.0}, "meta_inference_completion_tokens": {"value": 852.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001437}, "meta_inference_completion_cost": {"value": 0.0013632}, "meta_eval_time": {"value": 14.112}, "meta_eval_prompt_tokens": {"value": 3314.0}, "meta_eval_completion_tokens": {"value": 1462.0}, "meta_eval_prompt_cost": {"value": 0.00106048}, "meta_eval_completion_cost": {"value": 0.00187136}}, "created": "2025-12-10T21:37:20.5983009Z"}
{"ref": "TQ36", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.525371}, "meta_inference_prompt_tokens": {"value": 10157.0}, "meta_inference_completion_tokens": {"value": 1572.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020314}, "meta_inference_completion_cost": {"value": 0.0025152}, "meta_eval_time": {"value": 37.436}, "meta_eval_prompt_tokens": {"value": 6152.0}, "meta_eval_completion_tokens": {"value": 3417.0}, "meta_eval_prompt_cost": {"value": 0.00196864}, "meta_eval_completion_cost": {"value": 0.00437376}}, "created": "2025-12-10T21:37:20.7961259Z"}
{"ref": "TQ45", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.218215}, "meta_inference_prompt_tokens": {"value": 12979.0}, "meta_inference_completion_tokens": {"value": 629.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025958}, "meta_inference_completion_cost": {"value": 0.0010064}, "meta_eval_time": {"value": 11.324}, "meta_eval_prompt_tokens": {"value": 7274.0}, "meta_eval_completion_tokens": {"value": 1029.0}, "meta_eval_prompt_cost": {"value": 0.00232768}, "meta_eval_completion_cost": {"value": 0.00131712}}, "created": "2025-12-10T21:37:20.8091865Z"}
{"ref": "TQ38", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.904761904761905}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.546273}, "meta_inference_prompt_tokens": {"value": 11446.0}, "meta_inference_completion_tokens": {"value": 1689.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022892}, "meta_inference_completion_cost": {"value": 0.0027024}, "meta_eval_time": {"value": 36.455}, "meta_eval_prompt_tokens": {"value": 7576.0}, "meta_eval_completion_tokens": {"value": 3987.0}, "meta_eval_prompt_cost": {"value": 0.00242432}, "meta_eval_completion_cost": {"value": 0.00510336}}, "created": "2025-12-10T21:37:21.1451Z"}
{"ref": "TQ40", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.826086956521739}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 23.815201}, "meta_inference_prompt_tokens": {"value": 14135.0}, "meta_inference_completion_tokens": {"value": 1338.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002827}, "meta_inference_completion_cost": {"value": 0.0021408}, "meta_eval_time": {"value": 33.137}, "meta_eval_prompt_tokens": {"value": 9105.0}, "meta_eval_completion_tokens": {"value": 2482.0}, "meta_eval_prompt_cost": {"value": 0.0029136}, "meta_eval_completion_cost": {"value": 0.00317696}}, "created": "2025-12-10T21:37:21.2614882Z"}
{"ref": "TQ40", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.852941176470588}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.121637}, "meta_inference_prompt_tokens": {"value": 13552.0}, "meta_inference_completion_tokens": {"value": 1229.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027104}, "meta_inference_completion_cost": {"value": 0.0019664}, "meta_eval_time": {"value": 29.454}, "meta_eval_prompt_tokens": {"value": 9336.0}, "meta_eval_completion_tokens": {"value": 3229.0}, "meta_eval_prompt_cost": {"value": 0.00298752}, "meta_eval_completion_cost": {"value": 0.00413312}}, "created": "2025-12-10T21:37:21.4212846Z"}
{"ref": "TQ42", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.432335}, "meta_inference_prompt_tokens": {"value": 12124.0}, "meta_inference_completion_tokens": {"value": 1981.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024248}, "meta_inference_completion_cost": {"value": 0.0031696}, "meta_eval_time": {"value": 29.191}, "meta_eval_prompt_tokens": {"value": 7635.0}, "meta_eval_completion_tokens": {"value": 2939.0}, "meta_eval_prompt_cost": {"value": 0.0024432}, "meta_eval_completion_cost": {"value": 0.00376192}}, "created": "2025-12-10T21:37:21.5904893Z"}
{"ref": "TQ45", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.967365}, "meta_inference_prompt_tokens": {"value": 11598.0}, "meta_inference_completion_tokens": {"value": 834.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023196}, "meta_inference_completion_cost": {"value": 0.0013344}, "meta_eval_time": {"value": 12.523}, "meta_eval_prompt_tokens": {"value": 5977.0}, "meta_eval_completion_tokens": {"value": 1001.0}, "meta_eval_prompt_cost": {"value": 0.00191264}, "meta_eval_completion_cost": {"value": 0.00128128}}, "created": "2025-12-10T21:37:21.9733125Z"}
{"ref": "TQ44", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.777777777777778}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.516154}, "meta_inference_prompt_tokens": {"value": 9363.0}, "meta_inference_completion_tokens": {"value": 1263.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018726}, "meta_inference_completion_cost": {"value": 0.0020208}, "meta_eval_time": {"value": 14.025}, "meta_eval_prompt_tokens": {"value": 4152.0}, "meta_eval_completion_tokens": {"value": 1295.0}, "meta_eval_prompt_cost": {"value": 0.00132864}, "meta_eval_completion_cost": {"value": 0.0016576}}, "created": "2025-12-10T21:37:22.1197236Z"}
{"ref": "TQ42", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.084003}, "meta_inference_prompt_tokens": {"value": 10933.0}, "meta_inference_completion_tokens": {"value": 1234.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021866}, "meta_inference_completion_cost": {"value": 0.0019744}, "meta_eval_time": {"value": 31.049}, "meta_eval_prompt_tokens": {"value": 6503.0}, "meta_eval_completion_tokens": {"value": 2678.0}, "meta_eval_prompt_cost": {"value": 0.00208096}, "meta_eval_completion_cost": {"value": 0.00342784}}, "created": "2025-12-10T21:37:22.7713775Z"}
{"ref": "TQ43", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.583333333333333}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.161055}, "meta_inference_prompt_tokens": {"value": 9923.0}, "meta_inference_completion_tokens": {"value": 1262.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019846}, "meta_inference_completion_cost": {"value": 0.0020192}, "meta_eval_time": {"value": 19.052}, "meta_eval_prompt_tokens": {"value": 4798.0}, "meta_eval_completion_tokens": {"value": 1570.0}, "meta_eval_prompt_cost": {"value": 0.00153536}, "meta_eval_completion_cost": {"value": 0.0020096}}, "created": "2025-12-10T21:37:23.2881433Z"}
{"ref": "TQ42", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.978546}, "meta_inference_prompt_tokens": {"value": 13282.0}, "meta_inference_completion_tokens": {"value": 1198.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026564}, "meta_inference_completion_cost": {"value": 0.0019168}, "meta_eval_time": {"value": 28.554}, "meta_eval_prompt_tokens": {"value": 8397.0}, "meta_eval_completion_tokens": {"value": 2502.0}, "meta_eval_prompt_cost": {"value": 0.00268704}, "meta_eval_completion_cost": {"value": 0.00320256}}, "created": "2025-12-10T21:37:23.4697239Z"}
{"ref": "TQ44", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.223386}, "meta_inference_prompt_tokens": {"value": 7180.0}, "meta_inference_completion_tokens": {"value": 1000.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001436}, "meta_inference_completion_cost": {"value": 0.0016}, "meta_eval_time": {"value": 19.078}, "meta_eval_prompt_tokens": {"value": 3368.0}, "meta_eval_completion_tokens": {"value": 1512.0}, "meta_eval_prompt_cost": {"value": 0.00107776}, "meta_eval_completion_cost": {"value": 0.00193536}}, "created": "2025-12-10T21:37:24.2402317Z"}
{"ref": "TQ45", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.541206}, "meta_inference_prompt_tokens": {"value": 12244.0}, "meta_inference_completion_tokens": {"value": 691.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024488}, "meta_inference_completion_cost": {"value": 0.0011056}, "meta_eval_time": {"value": 14.98}, "meta_eval_prompt_tokens": {"value": 6683.0}, "meta_eval_completion_tokens": {"value": 1384.0}, "meta_eval_prompt_cost": {"value": 0.00213856}, "meta_eval_completion_cost": {"value": 0.00177152}}, "created": "2025-12-10T21:37:24.4651553Z"}
{"ref": "TQ49", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.593421}, "meta_inference_prompt_tokens": {"value": 13117.0}, "meta_inference_completion_tokens": {"value": 1166.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026234}, "meta_inference_completion_cost": {"value": 0.0018656}, "meta_eval_time": {"value": 15.234}, "meta_eval_prompt_tokens": {"value": 7445.0}, "meta_eval_completion_tokens": {"value": 1307.0}, "meta_eval_prompt_cost": {"value": 0.0023824}, "meta_eval_completion_cost": {"value": 0.00167296}}, "created": "2025-12-10T21:37:25.6902968Z"}
{"ref": "TQ38", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.975609756097561}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.831755}, "meta_inference_prompt_tokens": {"value": 12796.0}, "meta_inference_completion_tokens": {"value": 1535.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025592}, "meta_inference_completion_cost": {"value": 0.002456}, "meta_eval_time": {"value": 43.067}, "meta_eval_prompt_tokens": {"value": 9097.0}, "meta_eval_completion_tokens": {"value": 3953.0}, "meta_eval_prompt_cost": {"value": 0.00291104}, "meta_eval_completion_cost": {"value": 0.00505984}}, "created": "2025-12-10T21:37:26.0925783Z"}
{"ref": "TQ40", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.067329}, "meta_inference_prompt_tokens": {"value": 14201.0}, "meta_inference_completion_tokens": {"value": 1379.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028402}, "meta_inference_completion_cost": {"value": 0.0022064}, "meta_eval_time": {"value": 36.557}, "meta_eval_prompt_tokens": {"value": 9674.0}, "meta_eval_completion_tokens": {"value": 3367.0}, "meta_eval_prompt_cost": {"value": 0.00309568}, "meta_eval_completion_cost": {"value": 0.00430976}}, "created": "2025-12-10T21:37:26.293383Z"}
{"ref": "TQ43", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.80952380952381}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.295096}, "meta_inference_prompt_tokens": {"value": 9970.0}, "meta_inference_completion_tokens": {"value": 1356.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001994}, "meta_inference_completion_cost": {"value": 0.0021696}, "meta_eval_time": {"value": 27.199}, "meta_eval_prompt_tokens": {"value": 5575.0}, "meta_eval_completion_tokens": {"value": 2602.0}, "meta_eval_prompt_cost": {"value": 0.001784}, "meta_eval_completion_cost": {"value": 0.00333056}}, "created": "2025-12-10T21:37:26.7363668Z"}
{"ref": "TQ42", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.96875}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.308702}, "meta_inference_prompt_tokens": {"value": 12113.0}, "meta_inference_completion_tokens": {"value": 1217.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024226}, "meta_inference_completion_cost": {"value": 0.0019472}, "meta_eval_time": {"value": 37.45}, "meta_eval_prompt_tokens": {"value": 7890.0}, "meta_eval_completion_tokens": {"value": 3370.0}, "meta_eval_prompt_cost": {"value": 0.0025248}, "meta_eval_completion_cost": {"value": 0.0043136}}, "created": "2025-12-10T21:37:27.9635192Z"}
{"ref": "TQ45", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.881428}, "meta_inference_prompt_tokens": {"value": 11542.0}, "meta_inference_completion_tokens": {"value": 914.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023084}, "meta_inference_completion_cost": {"value": 0.0014624}, "meta_eval_time": {"value": 14.006}, "meta_eval_prompt_tokens": {"value": 5966.0}, "meta_eval_completion_tokens": {"value": 1042.0}, "meta_eval_prompt_cost": {"value": 0.00190912}, "meta_eval_completion_cost": {"value": 0.00133376}}, "created": "2025-12-10T21:37:28.5384983Z"}
{"ref": "TQ50", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.166666666666667}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 15.582288}, "meta_inference_prompt_tokens": {"value": 7470.0}, "meta_inference_completion_tokens": {"value": 635.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001494}, "meta_inference_completion_cost": {"value": 0.001016}, "meta_eval_time": {"value": 12.917}, "meta_eval_prompt_tokens": {"value": 3317.0}, "meta_eval_completion_tokens": {"value": 1266.0}, "meta_eval_prompt_cost": {"value": 0.00106144}, "meta_eval_completion_cost": {"value": 0.00162048}}, "created": "2025-12-10T21:37:29.1292697Z"}
{"ref": "TQ44", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.823529411764706}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.799014}, "meta_inference_prompt_tokens": {"value": 9502.0}, "meta_inference_completion_tokens": {"value": 1082.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019004}, "meta_inference_completion_cost": {"value": 0.0017312}, "meta_eval_time": {"value": 21.62}, "meta_eval_prompt_tokens": {"value": 4564.0}, "meta_eval_completion_tokens": {"value": 1912.0}, "meta_eval_prompt_cost": {"value": 0.00146048}, "meta_eval_completion_cost": {"value": 0.00244736}}, "created": "2025-12-10T21:37:29.4001822Z"}
{"ref": "TQ50", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 17.185648}, "meta_inference_prompt_tokens": {"value": 9463.0}, "meta_inference_completion_tokens": {"value": 551.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018926}, "meta_inference_completion_cost": {"value": 0.0008816}, "meta_eval_time": {"value": 13.722}, "meta_eval_prompt_tokens": {"value": 4173.0}, "meta_eval_completion_tokens": {"value": 1306.0}, "meta_eval_prompt_cost": {"value": 0.00133536}, "meta_eval_completion_cost": {"value": 0.00167168}}, "created": "2025-12-10T21:37:31.4096822Z"}
{"ref": "TQ42", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.266666666666667}, "generation_factuality_precision": {"value": 0.153846153846154}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.6393}, "meta_inference_prompt_tokens": {"value": 10987.0}, "meta_inference_completion_tokens": {"value": 1619.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021974}, "meta_inference_completion_cost": {"value": 0.0025904}, "meta_eval_time": {"value": 38.78}, "meta_eval_prompt_tokens": {"value": 6930.0}, "meta_eval_completion_tokens": {"value": 3149.0}, "meta_eval_prompt_cost": {"value": 0.0022176}, "meta_eval_completion_cost": {"value": 0.00403072}}, "created": "2025-12-10T21:37:31.7794426Z"}
{"ref": "TQ50", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 17.119306}, "meta_inference_prompt_tokens": {"value": 7376.0}, "meta_inference_completion_tokens": {"value": 568.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0014752}, "meta_inference_completion_cost": {"value": 0.0009088}, "meta_eval_time": {"value": 11.111}, "meta_eval_prompt_tokens": {"value": 3345.0}, "meta_eval_completion_tokens": {"value": 1055.0}, "meta_eval_prompt_cost": {"value": 0.0010704}, "meta_eval_completion_cost": {"value": 0.0013504}}, "created": "2025-12-10T21:37:31.9449062Z"}
{"ref": "TQ47", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.78688374518142}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.176424}, "meta_inference_prompt_tokens": {"value": 13424.0}, "meta_inference_completion_tokens": {"value": 1013.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026848}, "meta_inference_completion_cost": {"value": 0.0016208}, "meta_eval_time": {"value": 20.641}, "meta_eval_prompt_tokens": {"value": 9095.0}, "meta_eval_completion_tokens": {"value": 1906.0}, "meta_eval_prompt_cost": {"value": 0.0029104}, "meta_eval_completion_cost": {"value": 0.00243968}}, "created": "2025-12-10T21:37:32.1417294Z"}
{"ref": "TQ49", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.203555}, "meta_inference_prompt_tokens": {"value": 13962.0}, "meta_inference_completion_tokens": {"value": 1117.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027924}, "meta_inference_completion_cost": {"value": 0.0017872}, "meta_eval_time": {"value": 18.069}, "meta_eval_prompt_tokens": {"value": 8486.0}, "meta_eval_completion_tokens": {"value": 1756.0}, "meta_eval_prompt_cost": {"value": 0.00271552}, "meta_eval_completion_cost": {"value": 0.00224768}}, "created": "2025-12-10T21:37:34.026077Z"}
{"ref": "TQ49", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.742601}, "meta_inference_prompt_tokens": {"value": 13689.0}, "meta_inference_completion_tokens": {"value": 1237.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027378}, "meta_inference_completion_cost": {"value": 0.0019792}, "meta_eval_time": {"value": 22.135}, "meta_eval_prompt_tokens": {"value": 8331.0}, "meta_eval_completion_tokens": {"value": 2087.0}, "meta_eval_prompt_cost": {"value": 0.00266592}, "meta_eval_completion_cost": {"value": 0.00267136}}, "created": "2025-12-10T21:37:34.5756549Z"}
{"ref": "TQ47", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.78688374518142}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.127688}, "meta_inference_prompt_tokens": {"value": 13424.0}, "meta_inference_completion_tokens": {"value": 1389.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026848}, "meta_inference_completion_cost": {"value": 0.0022224}, "meta_eval_time": {"value": 19.122}, "meta_eval_prompt_tokens": {"value": 9113.0}, "meta_eval_completion_tokens": {"value": 1901.0}, "meta_eval_prompt_cost": {"value": 0.00291616}, "meta_eval_completion_cost": {"value": 0.00243328}}, "created": "2025-12-10T21:37:34.9036444Z"}
{"ref": "TQ50", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 13.630104}, "meta_inference_prompt_tokens": {"value": 8290.0}, "meta_inference_completion_tokens": {"value": 505.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001658}, "meta_inference_completion_cost": {"value": 0.000808}, "meta_eval_time": {"value": 13.772}, "meta_eval_prompt_tokens": {"value": 3528.0}, "meta_eval_completion_tokens": {"value": 1181.0}, "meta_eval_prompt_cost": {"value": 0.00112896}, "meta_eval_completion_cost": {"value": 0.00151168}}, "created": "2025-12-10T21:37:35.0920944Z"}
{"ref": "TQ50", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 19.865483}, "meta_inference_prompt_tokens": {"value": 10823.0}, "meta_inference_completion_tokens": {"value": 944.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021646}, "meta_inference_completion_cost": {"value": 0.0015104}, "meta_eval_time": {"value": 15.35}, "meta_eval_prompt_tokens": {"value": 5199.0}, "meta_eval_completion_tokens": {"value": 1326.0}, "meta_eval_prompt_cost": {"value": 0.00166368}, "meta_eval_completion_cost": {"value": 0.00169728}}, "created": "2025-12-10T21:37:36.9930228Z"}
{"ref": "TQ47", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.78688374518142}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.8274}, "meta_inference_prompt_tokens": {"value": 13421.0}, "meta_inference_completion_tokens": {"value": 912.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026842}, "meta_inference_completion_cost": {"value": 0.0014592}, "meta_eval_time": {"value": 23.502}, "meta_eval_prompt_tokens": {"value": 9169.0}, "meta_eval_completion_tokens": {"value": 1941.0}, "meta_eval_prompt_cost": {"value": 0.00293408}, "meta_eval_completion_cost": {"value": 0.00248448}}, "created": "2025-12-10T21:37:37.0366915Z"}
{"ref": "TQ47", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.78688374518142}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.151074}, "meta_inference_prompt_tokens": {"value": 13422.0}, "meta_inference_completion_tokens": {"value": 1282.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026844}, "meta_inference_completion_cost": {"value": 0.0020512}, "meta_eval_time": {"value": 15.723}, "meta_eval_prompt_tokens": {"value": 8873.0}, "meta_eval_completion_tokens": {"value": 1586.0}, "meta_eval_prompt_cost": {"value": 0.00283936}, "meta_eval_completion_cost": {"value": 0.00203008}}, "created": "2025-12-10T21:37:37.1889265Z"}
{"ref": "TQ43", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.892857142857143}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.03714}, "meta_inference_prompt_tokens": {"value": 9858.0}, "meta_inference_completion_tokens": {"value": 1417.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019716}, "meta_inference_completion_cost": {"value": 0.0022672}, "meta_eval_time": {"value": 34.085}, "meta_eval_prompt_tokens": {"value": 5616.0}, "meta_eval_completion_tokens": {"value": 3156.0}, "meta_eval_prompt_cost": {"value": 0.00179712}, "meta_eval_completion_cost": {"value": 0.00403968}}, "created": "2025-12-10T21:37:37.2692919Z"}
{"ref": "TQ46", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 25.58158}, "meta_inference_prompt_tokens": {"value": 12802.0}, "meta_inference_completion_tokens": {"value": 1420.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025604}, "meta_inference_completion_cost": {"value": 0.002272}, "meta_eval_time": {"value": 24.542}, "meta_eval_prompt_tokens": {"value": 8049.0}, "meta_eval_completion_tokens": {"value": 2327.0}, "meta_eval_prompt_cost": {"value": 0.00257568}, "meta_eval_completion_cost": {"value": 0.00297856}}, "created": "2025-12-10T21:37:37.3820848Z"}
{"ref": "TQ56", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.545454545454545}, "retrieval_mrr": {"value": 0.541666666666667}, "retrieval_dcg": {"value": 2.24305999434256}, "retrieval_accuracy": {"value": 0.375}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 34.595003}, "meta_inference_prompt_tokens": {"value": 19125.0}, "meta_inference_completion_tokens": {"value": 1840.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003825}, "meta_inference_completion_cost": {"value": 0.002944}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:37:37.4240599Z"}
{"ref": "TQ56", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 1.5}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 24.014265}, "meta_inference_prompt_tokens": {"value": 9544.0}, "meta_inference_completion_tokens": {"value": 1100.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019088}, "meta_inference_completion_cost": {"value": 0.00176}, "meta_eval_time": {"value": 0.004}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:37:37.466923Z"}
{"ref": "TQ51", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.777777777777778}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.956822}, "meta_inference_prompt_tokens": {"value": 10637.0}, "meta_inference_completion_tokens": {"value": 645.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021274}, "meta_inference_completion_cost": {"value": 0.001032}, "meta_eval_time": {"value": 14.345}, "meta_eval_prompt_tokens": {"value": 5304.0}, "meta_eval_completion_tokens": {"value": 1227.0}, "meta_eval_prompt_cost": {"value": 0.00169728}, "meta_eval_completion_cost": {"value": 0.00157056}}, "created": "2025-12-10T21:37:38.621997Z"}
{"ref": "TQ47", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.78688374518142}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.86282}, "meta_inference_prompt_tokens": {"value": 13424.0}, "meta_inference_completion_tokens": {"value": 1298.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026848}, "meta_inference_completion_cost": {"value": 0.0020768}, "meta_eval_time": {"value": 18.758}, "meta_eval_prompt_tokens": {"value": 8980.0}, "meta_eval_completion_tokens": {"value": 1882.0}, "meta_eval_prompt_cost": {"value": 0.0028736}, "meta_eval_completion_cost": {"value": 0.00240896}}, "created": "2025-12-10T21:37:38.7551204Z"}
{"ref": "TQ51", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.785714285714286}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.948129}, "meta_inference_prompt_tokens": {"value": 12335.0}, "meta_inference_completion_tokens": {"value": 742.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002467}, "meta_inference_completion_cost": {"value": 0.0011872}, "meta_eval_time": {"value": 16.983}, "meta_eval_prompt_tokens": {"value": 7017.0}, "meta_eval_completion_tokens": {"value": 1634.0}, "meta_eval_prompt_cost": {"value": 0.00224544}, "meta_eval_completion_cost": {"value": 0.00209152}}, "created": "2025-12-10T21:37:40.3347811Z"}
{"ref": "TQ56", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.8}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "retrieval_accuracy": {"value": 0.666666666666667}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 1.0}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 20.307778}, "meta_inference_prompt_tokens": {"value": 7051.0}, "meta_inference_completion_tokens": {"value": 832.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0014102}, "meta_inference_completion_cost": {"value": 0.0013312}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:37:40.3822693Z"}
{"ref": "TQ51", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.983104}, "meta_inference_prompt_tokens": {"value": 12104.0}, "meta_inference_completion_tokens": {"value": 990.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024208}, "meta_inference_completion_cost": {"value": 0.001584}, "meta_eval_time": {"value": 17.922}, "meta_eval_prompt_tokens": {"value": 6814.0}, "meta_eval_completion_tokens": {"value": 1606.0}, "meta_eval_prompt_cost": {"value": 0.00218048}, "meta_eval_completion_cost": {"value": 0.00205568}}, "created": "2025-12-10T21:37:40.7354593Z"}
{"ref": "TQ36", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.96875}, "generation_factuality_f1": {"value": 0.48}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 26.874641}, "meta_inference_prompt_tokens": {"value": 10042.0}, "meta_inference_completion_tokens": {"value": 1276.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020084}, "meta_inference_completion_cost": {"value": 0.0020416}, "meta_eval_time": {"value": 35.254}, "meta_eval_prompt_tokens": {"value": 5938.0}, "meta_eval_completion_tokens": {"value": 3342.0}, "meta_eval_prompt_cost": {"value": 0.00190016}, "meta_eval_completion_cost": {"value": 0.00427776}}, "created": "2025-12-10T21:37:41.391457Z"}
{"ref": "TQ49", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.831338}, "meta_inference_prompt_tokens": {"value": 16260.0}, "meta_inference_completion_tokens": {"value": 1129.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003252}, "meta_inference_completion_cost": {"value": 0.0018064}, "meta_eval_time": {"value": 20.275}, "meta_eval_prompt_tokens": {"value": 10476.0}, "meta_eval_completion_tokens": {"value": 1799.0}, "meta_eval_prompt_cost": {"value": 0.00335232}, "meta_eval_completion_cost": {"value": 0.00230272}}, "created": "2025-12-10T21:37:42.2948286Z"}
{"ref": "TQ46", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.801029995663981}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.111111111111111}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 23.915285}, "meta_inference_prompt_tokens": {"value": 12598.0}, "meta_inference_completion_tokens": {"value": 1291.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025196}, "meta_inference_completion_cost": {"value": 0.0020656}, "meta_eval_time": {"value": 33.824}, "meta_eval_prompt_tokens": {"value": 8000.0}, "meta_eval_completion_tokens": {"value": 3022.0}, "meta_eval_prompt_cost": {"value": 0.00256}, "meta_eval_completion_cost": {"value": 0.00386816}}, "created": "2025-12-10T21:37:43.3044271Z"}
{"ref": "TQ49", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.256943}, "meta_inference_prompt_tokens": {"value": 16715.0}, "meta_inference_completion_tokens": {"value": 1297.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003343}, "meta_inference_completion_cost": {"value": 0.0020752}, "meta_eval_time": {"value": 25.964}, "meta_eval_prompt_tokens": {"value": 11140.0}, "meta_eval_completion_tokens": {"value": 2277.0}, "meta_eval_prompt_cost": {"value": 0.0035648}, "meta_eval_completion_cost": {"value": 0.00291456}}, "created": "2025-12-10T21:37:43.735886Z"}
{"ref": "TQ52", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.687882802898523}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 21.266098}, "meta_inference_prompt_tokens": {"value": 12741.0}, "meta_inference_completion_tokens": {"value": 901.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025482}, "meta_inference_completion_cost": {"value": 0.0014416}, "meta_eval_time": {"value": 20.538}, "meta_eval_prompt_tokens": {"value": 7315.0}, "meta_eval_completion_tokens": {"value": 1810.0}, "meta_eval_prompt_cost": {"value": 0.0023408}, "meta_eval_completion_cost": {"value": 0.0023168}}, "created": "2025-12-10T21:37:44.0667061Z"}
{"ref": "TQ51", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.705882352941176}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 18.745197}, "meta_inference_prompt_tokens": {"value": 11730.0}, "meta_inference_completion_tokens": {"value": 794.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002346}, "meta_inference_completion_cost": {"value": 0.0012704}, "meta_eval_time": {"value": 17.93}, "meta_eval_prompt_tokens": {"value": 6597.0}, "meta_eval_completion_tokens": {"value": 1712.0}, "meta_eval_prompt_cost": {"value": 0.00211104}, "meta_eval_completion_cost": {"value": 0.00219136}}, "created": "2025-12-10T21:37:44.1225221Z"}
{"ref": "TQ5", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.733333333333333}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.193721}, "meta_inference_prompt_tokens": {"value": 11601.0}, "meta_inference_completion_tokens": {"value": 1456.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023202}, "meta_inference_completion_cost": {"value": 0.0023296}, "meta_eval_time": {"value": 23.71}, "meta_eval_prompt_tokens": {"value": 6796.0}, "meta_eval_completion_tokens": {"value": 2214.0}, "meta_eval_prompt_cost": {"value": 0.00217472}, "meta_eval_completion_cost": {"value": 0.00283392}}, "created": "2025-12-10T21:37:44.5797286Z"}
{"ref": "TQ5", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.782608695652174}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.004544}, "meta_inference_prompt_tokens": {"value": 12031.0}, "meta_inference_completion_tokens": {"value": 1845.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024062}, "meta_inference_completion_cost": {"value": 0.002952}, "meta_eval_time": {"value": 28.614}, "meta_eval_prompt_tokens": {"value": 7723.0}, "meta_eval_completion_tokens": {"value": 2999.0}, "meta_eval_prompt_cost": {"value": 0.00247136}, "meta_eval_completion_cost": {"value": 0.00383872}}, "created": "2025-12-10T21:37:44.8068715Z"}
{"ref": "TQ53", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.391932}, "meta_inference_prompt_tokens": {"value": 10561.0}, "meta_inference_completion_tokens": {"value": 1060.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021122}, "meta_inference_completion_cost": {"value": 0.001696}, "meta_eval_time": {"value": 17.323}, "meta_eval_prompt_tokens": {"value": 5635.0}, "meta_eval_completion_tokens": {"value": 1764.0}, "meta_eval_prompt_cost": {"value": 0.0018032}, "meta_eval_completion_cost": {"value": 0.00225792}}, "created": "2025-12-10T21:37:45.327276Z"}
{"ref": "TQ46", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.964263086904791}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 24.273974}, "meta_inference_prompt_tokens": {"value": 12495.0}, "meta_inference_completion_tokens": {"value": 1334.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002499}, "meta_inference_completion_cost": {"value": 0.0021344}, "meta_eval_time": {"value": 35.691}, "meta_eval_prompt_tokens": {"value": 7821.0}, "meta_eval_completion_tokens": {"value": 3148.0}, "meta_eval_prompt_cost": {"value": 0.00250272}, "meta_eval_completion_cost": {"value": 0.00402944}}, "created": "2025-12-10T21:37:45.8173467Z"}
{"ref": "TQ51", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 21.839144}, "meta_inference_prompt_tokens": {"value": 12341.0}, "meta_inference_completion_tokens": {"value": 1278.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024682}, "meta_inference_completion_cost": {"value": 0.0020448}, "meta_eval_time": {"value": 24.659}, "meta_eval_prompt_tokens": {"value": 7686.0}, "meta_eval_completion_tokens": {"value": 2552.0}, "meta_eval_prompt_cost": {"value": 0.00245952}, "meta_eval_completion_cost": {"value": 0.00326656}}, "created": "2025-12-10T21:37:45.842718Z"}
{"ref": "TQ46", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 27.36014}, "meta_inference_prompt_tokens": {"value": 13643.0}, "meta_inference_completion_tokens": {"value": 1448.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027286}, "meta_inference_completion_cost": {"value": 0.0023168}, "meta_eval_time": {"value": 35.832}, "meta_eval_prompt_tokens": {"value": 9073.0}, "meta_eval_completion_tokens": {"value": 3392.0}, "meta_eval_prompt_cost": {"value": 0.00290336}, "meta_eval_completion_cost": {"value": 0.00434176}}, "created": "2025-12-10T21:37:47.8330187Z"}
{"ref": "TQ5", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.863636363636364}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.9041}, "meta_inference_prompt_tokens": {"value": 11984.0}, "meta_inference_completion_tokens": {"value": 1588.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023968}, "meta_inference_completion_cost": {"value": 0.0025408}, "meta_eval_time": {"value": 27.7}, "meta_eval_prompt_tokens": {"value": 7582.0}, "meta_eval_completion_tokens": {"value": 2777.0}, "meta_eval_prompt_cost": {"value": 0.00242624}, "meta_eval_completion_cost": {"value": 0.00355456}}, "created": "2025-12-10T21:37:48.3491425Z"}
{"ref": "TQ54", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.444444444444444}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.28906482631789}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.285714285714286}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.148779}, "meta_inference_prompt_tokens": {"value": 15330.0}, "meta_inference_completion_tokens": {"value": 1001.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003066}, "meta_inference_completion_cost": {"value": 0.0016016}, "meta_eval_time": {"value": 22.672}, "meta_eval_prompt_tokens": {"value": 10625.0}, "meta_eval_completion_tokens": {"value": 2205.0}, "meta_eval_prompt_cost": {"value": 0.0034}, "meta_eval_completion_cost": {"value": 0.0028224}}, "created": "2025-12-10T21:37:49.0308929Z"}
{"ref": "TQ56", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.98982}, "meta_inference_prompt_tokens": {"value": 7091.0}, "meta_inference_completion_tokens": {"value": 1284.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0014182}, "meta_inference_completion_cost": {"value": 0.0020544}, "meta_eval_time": {"value": 10.815}, "meta_eval_prompt_tokens": {"value": 3823.0}, "meta_eval_completion_tokens": {"value": 761.0}, "meta_eval_prompt_cost": {"value": 0.00122336}, "meta_eval_completion_cost": {"value": 0.00097408}}, "created": "2025-12-10T21:37:49.6093377Z"}
{"ref": "TQ52", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.961538461538462}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.268769}, "meta_inference_prompt_tokens": {"value": 15302.0}, "meta_inference_completion_tokens": {"value": 1155.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030604}, "meta_inference_completion_cost": {"value": 0.001848}, "meta_eval_time": {"value": 23.927}, "meta_eval_prompt_tokens": {"value": 9954.0}, "meta_eval_completion_tokens": {"value": 2559.0}, "meta_eval_prompt_cost": {"value": 0.00318528}, "meta_eval_completion_cost": {"value": 0.00327552}}, "created": "2025-12-10T21:37:49.6702422Z"}
{"ref": "TQ5", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.571428571428571}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.392493}, "meta_inference_prompt_tokens": {"value": 11816.0}, "meta_inference_completion_tokens": {"value": 1506.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023632}, "meta_inference_completion_cost": {"value": 0.0024096}, "meta_eval_time": {"value": 28.294}, "meta_eval_prompt_tokens": {"value": 7033.0}, "meta_eval_completion_tokens": {"value": 2520.0}, "meta_eval_prompt_cost": {"value": 0.00225056}, "meta_eval_completion_cost": {"value": 0.0032256}}, "created": "2025-12-10T21:37:50.4573577Z"}
{"ref": "TQ52", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 21.679026}, "meta_inference_prompt_tokens": {"value": 13530.0}, "meta_inference_completion_tokens": {"value": 1096.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002706}, "meta_inference_completion_cost": {"value": 0.0017536}, "meta_eval_time": {"value": 24.19}, "meta_eval_prompt_tokens": {"value": 8323.0}, "meta_eval_completion_tokens": {"value": 2386.0}, "meta_eval_prompt_cost": {"value": 0.00266336}, "meta_eval_completion_cost": {"value": 0.00305408}}, "created": "2025-12-10T21:37:50.9667525Z"}
{"ref": "TQ53", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.842105263157895}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.579053}, "meta_inference_prompt_tokens": {"value": 10428.0}, "meta_inference_completion_tokens": {"value": 1148.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020856}, "meta_inference_completion_cost": {"value": 0.0018368}, "meta_eval_time": {"value": 21.724}, "meta_eval_prompt_tokens": {"value": 5864.0}, "meta_eval_completion_tokens": {"value": 2269.0}, "meta_eval_prompt_cost": {"value": 0.00187648}, "meta_eval_completion_cost": {"value": 0.00290432}}, "created": "2025-12-10T21:37:51.1597096Z"}
{"ref": "TQ46", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 24.56603}, "meta_inference_prompt_tokens": {"value": 13407.0}, "meta_inference_completion_tokens": {"value": 1244.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026814}, "meta_inference_completion_cost": {"value": 0.0019904}, "meta_eval_time": {"value": 31.87}, "meta_eval_prompt_tokens": {"value": 8772.0}, "meta_eval_completion_tokens": {"value": 3143.0}, "meta_eval_prompt_cost": {"value": 0.00280704}, "meta_eval_completion_cost": {"value": 0.00402304}}, "created": "2025-12-10T21:37:51.2392601Z"}
{"ref": "TQ5", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.555555555555556}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.907703}, "meta_inference_prompt_tokens": {"value": 9982.0}, "meta_inference_completion_tokens": {"value": 1326.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019964}, "meta_inference_completion_cost": {"value": 0.0021216}, "meta_eval_time": {"value": 27.395}, "meta_eval_prompt_tokens": {"value": 5296.0}, "meta_eval_completion_tokens": {"value": 2564.0}, "meta_eval_prompt_cost": {"value": 0.00169472}, "meta_eval_completion_cost": {"value": 0.00328192}}, "created": "2025-12-10T21:37:51.9064988Z"}
{"ref": "TQ54", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.296718}, "meta_inference_prompt_tokens": {"value": 13575.0}, "meta_inference_completion_tokens": {"value": 1107.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002715}, "meta_inference_completion_cost": {"value": 0.0017712}, "meta_eval_time": {"value": 18.209}, "meta_eval_prompt_tokens": {"value": 8696.0}, "meta_eval_completion_tokens": {"value": 1858.0}, "meta_eval_prompt_cost": {"value": 0.00278272}, "meta_eval_completion_cost": {"value": 0.00237824}}, "created": "2025-12-10T21:37:52.2734174Z"}
{"ref": "TQ54", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.444444444444444}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.285714285714286}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.770827}, "meta_inference_prompt_tokens": {"value": 15336.0}, "meta_inference_completion_tokens": {"value": 1094.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030672}, "meta_inference_completion_cost": {"value": 0.0017504}, "meta_eval_time": {"value": 23.789}, "meta_eval_prompt_tokens": {"value": 10695.0}, "meta_eval_completion_tokens": {"value": 2213.0}, "meta_eval_prompt_cost": {"value": 0.0034224}, "meta_eval_completion_cost": {"value": 0.00283264}}, "created": "2025-12-10T21:37:55.972894Z"}
{"ref": "TQ53", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.85}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.08032}, "meta_inference_prompt_tokens": {"value": 10368.0}, "meta_inference_completion_tokens": {"value": 1343.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020736}, "meta_inference_completion_cost": {"value": 0.0021488}, "meta_eval_time": {"value": 24.416}, "meta_eval_prompt_tokens": {"value": 5679.0}, "meta_eval_completion_tokens": {"value": 2249.0}, "meta_eval_prompt_cost": {"value": 0.00181728}, "meta_eval_completion_cost": {"value": 0.00287872}}, "created": "2025-12-10T21:37:56.2342699Z"}
{"ref": "TQ54", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.222222222222222}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.100828}, "meta_inference_prompt_tokens": {"value": 13574.0}, "meta_inference_completion_tokens": {"value": 938.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027148}, "meta_inference_completion_cost": {"value": 0.0015008}, "meta_eval_time": {"value": 25.279}, "meta_eval_prompt_tokens": {"value": 8973.0}, "meta_eval_completion_tokens": {"value": 2262.0}, "meta_eval_prompt_cost": {"value": 0.00287136}, "meta_eval_completion_cost": {"value": 0.00289536}}, "created": "2025-12-10T21:37:56.7515941Z"}
{"ref": "TQ56", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.625}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.076214}, "meta_inference_prompt_tokens": {"value": 7095.0}, "meta_inference_completion_tokens": {"value": 1463.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001419}, "meta_inference_completion_cost": {"value": 0.0023408}, "meta_eval_time": {"value": 12.328}, "meta_eval_prompt_tokens": {"value": 4154.0}, "meta_eval_completion_tokens": {"value": 1079.0}, "meta_eval_prompt_cost": {"value": 0.00132928}, "meta_eval_completion_cost": {"value": 0.00138112}}, "created": "2025-12-10T21:37:57.1882309Z"}
{"ref": "TQ58", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.00925096688576}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.204793}, "meta_inference_prompt_tokens": {"value": 15382.0}, "meta_inference_completion_tokens": {"value": 885.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030764}, "meta_inference_completion_cost": {"value": 0.001416}, "meta_eval_time": {"value": 15.211}, "meta_eval_prompt_tokens": {"value": 9644.0}, "meta_eval_completion_tokens": {"value": 1624.0}, "meta_eval_prompt_cost": {"value": 0.00308608}, "meta_eval_completion_cost": {"value": 0.00207872}}, "created": "2025-12-10T21:37:57.5460258Z"}
{"ref": "TQ52", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.657237182772003}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.811783}, "meta_inference_prompt_tokens": {"value": 14177.0}, "meta_inference_completion_tokens": {"value": 1493.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028354}, "meta_inference_completion_cost": {"value": 0.0023888}, "meta_eval_time": {"value": 28.524}, "meta_eval_prompt_tokens": {"value": 9007.0}, "meta_eval_completion_tokens": {"value": 2595.0}, "meta_eval_prompt_cost": {"value": 0.00288224}, "meta_eval_completion_cost": {"value": 0.0033216}}, "created": "2025-12-10T21:37:57.7185711Z"}
{"ref": "TQ59", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.23792}, "meta_inference_prompt_tokens": {"value": 14445.0}, "meta_inference_completion_tokens": {"value": 993.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002889}, "meta_inference_completion_cost": {"value": 0.0015888}, "meta_eval_time": {"value": 16.47}, "meta_eval_prompt_tokens": {"value": 8785.0}, "meta_eval_completion_tokens": {"value": 1325.0}, "meta_eval_prompt_cost": {"value": 0.0028112}, "meta_eval_completion_cost": {"value": 0.001696}}, "created": "2025-12-10T21:37:59.8150005Z"}
{"ref": "TQ52", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.333333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.307692307692308}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 27.743759}, "meta_inference_prompt_tokens": {"value": 16231.0}, "meta_inference_completion_tokens": {"value": 1224.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032462}, "meta_inference_completion_cost": {"value": 0.0019584}, "meta_eval_time": {"value": 23.674}, "meta_eval_prompt_tokens": {"value": 10692.0}, "meta_eval_completion_tokens": {"value": 2407.0}, "meta_eval_prompt_cost": {"value": 0.00342144}, "meta_eval_completion_cost": {"value": 0.00308096}}, "created": "2025-12-10T21:38:00.7048299Z"}
{"ref": "TQ55", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.791666666666666}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.418853}, "meta_inference_prompt_tokens": {"value": 10205.0}, "meta_inference_completion_tokens": {"value": 1418.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002041}, "meta_inference_completion_cost": {"value": 0.0022688}, "meta_eval_time": {"value": 26.399}, "meta_eval_prompt_tokens": {"value": 5370.0}, "meta_eval_completion_tokens": {"value": 2489.0}, "meta_eval_prompt_cost": {"value": 0.0017184}, "meta_eval_completion_cost": {"value": 0.00318592}}, "created": "2025-12-10T21:38:01.0124651Z"}
{"ref": "TQ55", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.938113}, "meta_inference_prompt_tokens": {"value": 9513.0}, "meta_inference_completion_tokens": {"value": 1208.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019026}, "meta_inference_completion_cost": {"value": 0.0019328}, "meta_eval_time": {"value": 26.162}, "meta_eval_prompt_tokens": {"value": 5057.0}, "meta_eval_completion_tokens": {"value": 2276.0}, "meta_eval_prompt_cost": {"value": 0.00161824}, "meta_eval_completion_cost": {"value": 0.00291328}}, "created": "2025-12-10T21:38:01.3001817Z"}
{"ref": "TQ55", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.818181818181818}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.881806}, "meta_inference_prompt_tokens": {"value": 12304.0}, "meta_inference_completion_tokens": {"value": 1061.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024608}, "meta_inference_completion_cost": {"value": 0.0016976}, "meta_eval_time": {"value": 29.731}, "meta_eval_prompt_tokens": {"value": 7675.0}, "meta_eval_completion_tokens": {"value": 2410.0}, "meta_eval_prompt_cost": {"value": 0.002456}, "meta_eval_completion_cost": {"value": 0.0030848}}, "created": "2025-12-10T21:38:01.7136155Z"}
{"ref": "TQ57", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.930676558073393}, "generation_faithfulness": {"value": 0.956521739130435}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.70171}, "meta_inference_prompt_tokens": {"value": 11543.0}, "meta_inference_completion_tokens": {"value": 907.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023086}, "meta_inference_completion_cost": {"value": 0.0014512}, "meta_eval_time": {"value": 21.68}, "meta_eval_prompt_tokens": {"value": 6652.0}, "meta_eval_completion_tokens": {"value": 2033.0}, "meta_eval_prompt_cost": {"value": 0.00212864}, "meta_eval_completion_cost": {"value": 0.00260224}}, "created": "2025-12-10T21:38:02.1066553Z"}
{"ref": "TQ53", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.2}, "generation_factuality_precision": {"value": 0.111111111111111}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.852523}, "meta_inference_prompt_tokens": {"value": 10365.0}, "meta_inference_completion_tokens": {"value": 1311.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002073}, "meta_inference_completion_cost": {"value": 0.0020976}, "meta_eval_time": {"value": 27.333}, "meta_eval_prompt_tokens": {"value": 5849.0}, "meta_eval_completion_tokens": {"value": 2794.0}, "meta_eval_prompt_cost": {"value": 0.00187168}, "meta_eval_completion_cost": {"value": 0.00357632}}, "created": "2025-12-10T21:38:02.2839713Z"}
{"ref": "TQ55", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.635644}, "meta_inference_prompt_tokens": {"value": 11070.0}, "meta_inference_completion_tokens": {"value": 1447.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002214}, "meta_inference_completion_cost": {"value": 0.0023152}, "meta_eval_time": {"value": 25.462}, "meta_eval_prompt_tokens": {"value": 6628.0}, "meta_eval_completion_tokens": {"value": 2449.0}, "meta_eval_prompt_cost": {"value": 0.00212096}, "meta_eval_completion_cost": {"value": 0.00313472}}, "created": "2025-12-10T21:38:02.6910179Z"}
{"ref": "TQ59", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.959914}, "meta_inference_prompt_tokens": {"value": 15564.0}, "meta_inference_completion_tokens": {"value": 825.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031128}, "meta_inference_completion_cost": {"value": 0.00132}, "meta_eval_time": {"value": 18.333}, "meta_eval_prompt_tokens": {"value": 9999.0}, "meta_eval_completion_tokens": {"value": 1881.0}, "meta_eval_prompt_cost": {"value": 0.00319968}, "meta_eval_completion_cost": {"value": 0.00240768}}, "created": "2025-12-10T21:38:02.9646125Z"}
{"ref": "TQ53", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.942857142857143}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.510057}, "meta_inference_prompt_tokens": {"value": 10506.0}, "meta_inference_completion_tokens": {"value": 1292.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021012}, "meta_inference_completion_cost": {"value": 0.0020672}, "meta_eval_time": {"value": 35.197}, "meta_eval_prompt_tokens": {"value": 6151.0}, "meta_eval_completion_tokens": {"value": 3163.0}, "meta_eval_prompt_cost": {"value": 0.00196832}, "meta_eval_completion_cost": {"value": 0.00404864}}, "created": "2025-12-10T21:38:03.7925593Z"}
{"ref": "TQ58", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.25}, "retrieval_dcg": {"value": 1.26529308256877}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.676151}, "meta_inference_prompt_tokens": {"value": 15532.0}, "meta_inference_completion_tokens": {"value": 807.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031064}, "meta_inference_completion_cost": {"value": 0.0012912}, "meta_eval_time": {"value": 20.214}, "meta_eval_prompt_tokens": {"value": 9620.0}, "meta_eval_completion_tokens": {"value": 1781.0}, "meta_eval_prompt_cost": {"value": 0.0030784}, "meta_eval_completion_cost": {"value": 0.00227968}}, "created": "2025-12-10T21:38:04.3571331Z"}
{"ref": "TQ58", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.43992752495916}, "generation_faithfulness": {"value": 0.95}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.252078}, "meta_inference_prompt_tokens": {"value": 15852.0}, "meta_inference_completion_tokens": {"value": 717.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031704}, "meta_inference_completion_cost": {"value": 0.0011472}, "meta_eval_time": {"value": 20.935}, "meta_eval_prompt_tokens": {"value": 10198.0}, "meta_eval_completion_tokens": {"value": 1954.0}, "meta_eval_prompt_cost": {"value": 0.00326336}, "meta_eval_completion_cost": {"value": 0.00250112}}, "created": "2025-12-10T21:38:05.1065228Z"}
{"ref": "TQ55", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.886629}, "meta_inference_prompt_tokens": {"value": 12305.0}, "meta_inference_completion_tokens": {"value": 1380.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002461}, "meta_inference_completion_cost": {"value": 0.002208}, "meta_eval_time": {"value": 28.428}, "meta_eval_prompt_tokens": {"value": 7895.0}, "meta_eval_completion_tokens": {"value": 2728.0}, "meta_eval_prompt_cost": {"value": 0.0025264}, "meta_eval_completion_cost": {"value": 0.00349184}}, "created": "2025-12-10T21:38:05.7349947Z"}
{"ref": "TQ6", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.701754385964912}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 20.877161}, "meta_inference_prompt_tokens": {"value": 10969.0}, "meta_inference_completion_tokens": {"value": 856.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021938}, "meta_inference_completion_cost": {"value": 0.0013696}, "meta_eval_time": {"value": 20.168}, "meta_eval_prompt_tokens": {"value": 5969.0}, "meta_eval_completion_tokens": {"value": 1962.0}, "meta_eval_prompt_cost": {"value": 0.00191008}, "meta_eval_completion_cost": {"value": 0.00251136}}, "created": "2025-12-10T21:38:06.0335279Z"}
{"ref": "TQ57", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.173602}, "meta_inference_prompt_tokens": {"value": 12084.0}, "meta_inference_completion_tokens": {"value": 1349.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024168}, "meta_inference_completion_cost": {"value": 0.0021584}, "meta_eval_time": {"value": 29.767}, "meta_eval_prompt_tokens": {"value": 7878.0}, "meta_eval_completion_tokens": {"value": 3072.0}, "meta_eval_prompt_cost": {"value": 0.00252096}, "meta_eval_completion_cost": {"value": 0.00393216}}, "created": "2025-12-10T21:38:07.2719087Z"}
{"ref": "TQ59", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.333333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.143524}, "meta_inference_prompt_tokens": {"value": 17130.0}, "meta_inference_completion_tokens": {"value": 965.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003426}, "meta_inference_completion_cost": {"value": 0.001544}, "meta_eval_time": {"value": 19.587}, "meta_eval_prompt_tokens": {"value": 11227.0}, "meta_eval_completion_tokens": {"value": 1661.0}, "meta_eval_prompt_cost": {"value": 0.00359264}, "meta_eval_completion_cost": {"value": 0.00212608}}, "created": "2025-12-10T21:38:07.4602824Z"}
{"ref": "TQ60", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.823529411764706}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.739942}, "meta_inference_prompt_tokens": {"value": 14057.0}, "meta_inference_completion_tokens": {"value": 879.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028114}, "meta_inference_completion_cost": {"value": 0.0014064}, "meta_eval_time": {"value": 19.487}, "meta_eval_prompt_tokens": {"value": 7861.0}, "meta_eval_completion_tokens": {"value": 1869.0}, "meta_eval_prompt_cost": {"value": 0.00251552}, "meta_eval_completion_cost": {"value": 0.00239232}}, "created": "2025-12-10T21:38:07.8786733Z"}
{"ref": "TQ59", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.333333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.2}, "generation_factuality_precision": {"value": 0.111111111111111}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.403246}, "meta_inference_prompt_tokens": {"value": 17957.0}, "meta_inference_completion_tokens": {"value": 1234.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0035914}, "meta_inference_completion_cost": {"value": 0.0019744}, "meta_eval_time": {"value": 17.157}, "meta_eval_prompt_tokens": {"value": 11944.0}, "meta_eval_completion_tokens": {"value": 1508.0}, "meta_eval_prompt_cost": {"value": 0.00382208}, "meta_eval_completion_cost": {"value": 0.00193024}}, "created": "2025-12-10T21:38:08.180647Z"}
{"ref": "TQ60", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.689502}, "meta_inference_prompt_tokens": {"value": 12958.0}, "meta_inference_completion_tokens": {"value": 718.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025916}, "meta_inference_completion_cost": {"value": 0.0011488}, "meta_eval_time": {"value": 17.723}, "meta_eval_prompt_tokens": {"value": 6846.0}, "meta_eval_completion_tokens": {"value": 1616.0}, "meta_eval_prompt_cost": {"value": 0.00219072}, "meta_eval_completion_cost": {"value": 0.00206848}}, "created": "2025-12-10T21:38:08.2202012Z"}
{"ref": "TQ54", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.222222222222222}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.456012}, "meta_inference_prompt_tokens": {"value": 13580.0}, "meta_inference_completion_tokens": {"value": 1167.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002716}, "meta_inference_completion_cost": {"value": 0.0018672}, "meta_eval_time": {"value": 31.507}, "meta_eval_prompt_tokens": {"value": 9091.0}, "meta_eval_completion_tokens": {"value": 2501.0}, "meta_eval_prompt_cost": {"value": 0.00290912}, "meta_eval_completion_cost": {"value": 0.00320128}}, "created": "2025-12-10T21:38:08.5817802Z"}
{"ref": "TQ61", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.312429}, "meta_inference_prompt_tokens": {"value": 15602.0}, "meta_inference_completion_tokens": {"value": 908.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031204}, "meta_inference_completion_cost": {"value": 0.0014528}, "meta_eval_time": {"value": 18.732}, "meta_eval_prompt_tokens": {"value": 9114.0}, "meta_eval_completion_tokens": {"value": 1547.0}, "meta_eval_prompt_cost": {"value": 0.00291648}, "meta_eval_completion_cost": {"value": 0.00198016}}, "created": "2025-12-10T21:38:10.0334971Z"}
{"ref": "TQ57", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.856207187108022}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.005819}, "meta_inference_prompt_tokens": {"value": 10820.0}, "meta_inference_completion_tokens": {"value": 1090.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002164}, "meta_inference_completion_cost": {"value": 0.001744}, "meta_eval_time": {"value": 28.63}, "meta_eval_prompt_tokens": {"value": 6466.0}, "meta_eval_completion_tokens": {"value": 2668.0}, "meta_eval_prompt_cost": {"value": 0.00206912}, "meta_eval_completion_cost": {"value": 0.00341504}}, "created": "2025-12-10T21:38:10.0720696Z"}
{"ref": "TQ57", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.06160631164485}, "generation_faithfulness": {"value": 0.976190476190476}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.299519}, "meta_inference_prompt_tokens": {"value": 10516.0}, "meta_inference_completion_tokens": {"value": 1154.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021032}, "meta_inference_completion_cost": {"value": 0.0018464}, "meta_eval_time": {"value": 31.821}, "meta_eval_prompt_tokens": {"value": 6232.0}, "meta_eval_completion_tokens": {"value": 3335.0}, "meta_eval_prompt_cost": {"value": 0.00199424}, "meta_eval_completion_cost": {"value": 0.0042688}}, "created": "2025-12-10T21:38:10.4801633Z"}
{"ref": "TQ62", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.545454545454545}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.948538}, "meta_inference_prompt_tokens": {"value": 14834.0}, "meta_inference_completion_tokens": {"value": 1470.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029668}, "meta_inference_completion_cost": {"value": 0.002352}, "meta_eval_time": {"value": 14.236}, "meta_eval_prompt_tokens": {"value": 8762.0}, "meta_eval_completion_tokens": {"value": 1349.0}, "meta_eval_prompt_cost": {"value": 0.00280384}, "meta_eval_completion_cost": {"value": 0.00172672}}, "created": "2025-12-10T21:38:11.8514783Z"}
{"ref": "TQ62", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.545454545454545}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.944757}, "meta_inference_prompt_tokens": {"value": 15182.0}, "meta_inference_completion_tokens": {"value": 1401.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030364}, "meta_inference_completion_cost": {"value": 0.0022416}, "meta_eval_time": {"value": 15.141}, "meta_eval_prompt_tokens": {"value": 8917.0}, "meta_eval_completion_tokens": {"value": 1263.0}, "meta_eval_prompt_cost": {"value": 0.00285344}, "meta_eval_completion_cost": {"value": 0.00161664}}, "created": "2025-12-10T21:38:11.9411946Z"}
{"ref": "TQ6", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.384967}, "meta_inference_prompt_tokens": {"value": 11034.0}, "meta_inference_completion_tokens": {"value": 964.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022068}, "meta_inference_completion_cost": {"value": 0.0015424}, "meta_eval_time": {"value": 22.324}, "meta_eval_prompt_tokens": {"value": 5946.0}, "meta_eval_completion_tokens": {"value": 1872.0}, "meta_eval_prompt_cost": {"value": 0.00190272}, "meta_eval_completion_cost": {"value": 0.00239616}}, "created": "2025-12-10T21:38:11.998219Z"}
{"ref": "TQ58", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.4375}, "retrieval_dcg": {"value": 1.61855936097192}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.167704}, "meta_inference_prompt_tokens": {"value": 15462.0}, "meta_inference_completion_tokens": {"value": 1206.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030924}, "meta_inference_completion_cost": {"value": 0.0019296}, "meta_eval_time": {"value": 28.546}, "meta_eval_prompt_tokens": {"value": 10049.0}, "meta_eval_completion_tokens": {"value": 2578.0}, "meta_eval_prompt_cost": {"value": 0.00321568}, "meta_eval_completion_cost": {"value": 0.00329984}}, "created": "2025-12-10T21:38:12.3261146Z"}
{"ref": "TQ57", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.06160631164485}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.282704}, "meta_inference_prompt_tokens": {"value": 10813.0}, "meta_inference_completion_tokens": {"value": 1176.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021626}, "meta_inference_completion_cost": {"value": 0.0018816}, "meta_eval_time": {"value": 31.618}, "meta_eval_prompt_tokens": {"value": 6259.0}, "meta_eval_completion_tokens": {"value": 2836.0}, "meta_eval_prompt_cost": {"value": 0.00200288}, "meta_eval_completion_cost": {"value": 0.00363008}}, "created": "2025-12-10T21:38:12.4003767Z"}
{"ref": "TQ6", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.576923076923077}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 19.98064}, "meta_inference_prompt_tokens": {"value": 10971.0}, "meta_inference_completion_tokens": {"value": 974.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021942}, "meta_inference_completion_cost": {"value": 0.0015584}, "meta_eval_time": {"value": 23.575}, "meta_eval_prompt_tokens": {"value": 5942.0}, "meta_eval_completion_tokens": {"value": 1935.0}, "meta_eval_prompt_cost": {"value": 0.00190144}, "meta_eval_completion_cost": {"value": 0.0024768}}, "created": "2025-12-10T21:38:13.2817724Z"}
{"ref": "TQ58", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 0.648798210119062}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.2}, "generation_factuality_precision": {"value": 0.111111111111111}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.219689}, "meta_inference_prompt_tokens": {"value": 14852.0}, "meta_inference_completion_tokens": {"value": 1086.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029704}, "meta_inference_completion_cost": {"value": 0.0017376}, "meta_eval_time": {"value": 28.596}, "meta_eval_prompt_tokens": {"value": 9772.0}, "meta_eval_completion_tokens": {"value": 2573.0}, "meta_eval_prompt_cost": {"value": 0.00312704}, "meta_eval_completion_cost": {"value": 0.00329344}}, "created": "2025-12-10T21:38:13.9626934Z"}
{"ref": "TQ60", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.105662}, "meta_inference_prompt_tokens": {"value": 12707.0}, "meta_inference_completion_tokens": {"value": 863.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025414}, "meta_inference_completion_cost": {"value": 0.0013808}, "meta_eval_time": {"value": 23.067}, "meta_eval_prompt_tokens": {"value": 6831.0}, "meta_eval_completion_tokens": {"value": 2077.0}, "meta_eval_prompt_cost": {"value": 0.00218592}, "meta_eval_completion_cost": {"value": 0.00265856}}, "created": "2025-12-10T21:38:14.2688576Z"}
{"ref": "TQ61", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 0.7}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.142857142857143}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.950441}, "meta_inference_prompt_tokens": {"value": 17624.0}, "meta_inference_completion_tokens": {"value": 1253.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0035248}, "meta_inference_completion_cost": {"value": 0.0020048}, "meta_eval_time": {"value": 17.799}, "meta_eval_prompt_tokens": {"value": 6824.0}, "meta_eval_completion_tokens": {"value": 1406.0}, "meta_eval_prompt_cost": {"value": 0.00218368}, "meta_eval_completion_cost": {"value": 0.00179968}}, "created": "2025-12-10T21:38:15.5592768Z"}
{"ref": "TQ62", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.818181818181818}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.138494}, "meta_inference_prompt_tokens": {"value": 14473.0}, "meta_inference_completion_tokens": {"value": 1544.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028946}, "meta_inference_completion_cost": {"value": 0.0024704}, "meta_eval_time": {"value": 15.456}, "meta_eval_prompt_tokens": {"value": 8381.0}, "meta_eval_completion_tokens": {"value": 1332.0}, "meta_eval_prompt_cost": {"value": 0.00268192}, "meta_eval_completion_cost": {"value": 0.00170496}}, "created": "2025-12-10T21:38:16.2248612Z"}
{"ref": "TQ61", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0833333333333333}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.224243824217575}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0434782608695652}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0333333333333333}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 62.671131}, "meta_inference_prompt_tokens": {"value": 55345.0}, "meta_inference_completion_tokens": {"value": 1383.0}, "meta_inference_tool_call_count": {"value": 3.0}, "meta_inference_prompt_cost": {"value": 0.011069}, "meta_inference_completion_cost": {"value": 0.0022128}, "meta_eval_time": {"value": 20.299}, "meta_eval_prompt_tokens": {"value": 16215.0}, "meta_eval_completion_tokens": {"value": 1342.0}, "meta_eval_prompt_cost": {"value": 0.0051888}, "meta_eval_completion_cost": {"value": 0.00171776}}, "created": "2025-12-10T21:38:16.321794Z"}
{"ref": "TQ62", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.722222222222222}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.177692}, "meta_inference_prompt_tokens": {"value": 14821.0}, "meta_inference_completion_tokens": {"value": 1329.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029642}, "meta_inference_completion_cost": {"value": 0.0021264}, "meta_eval_time": {"value": 24.234}, "meta_eval_prompt_tokens": {"value": 9293.0}, "meta_eval_completion_tokens": {"value": 2203.0}, "meta_eval_prompt_cost": {"value": 0.00297376}, "meta_eval_completion_cost": {"value": 0.00281984}}, "created": "2025-12-10T21:38:16.5493958Z"}
{"ref": "TQ60", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 17.424915}, "meta_inference_prompt_tokens": {"value": 15292.0}, "meta_inference_completion_tokens": {"value": 756.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030584}, "meta_inference_completion_cost": {"value": 0.0012096}, "meta_eval_time": {"value": 20.631}, "meta_eval_prompt_tokens": {"value": 8846.0}, "meta_eval_completion_tokens": {"value": 1720.0}, "meta_eval_prompt_cost": {"value": 0.00283072}, "meta_eval_completion_cost": {"value": 0.0022016}}, "created": "2025-12-10T21:38:16.9356921Z"}
{"ref": "TQ6", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.558139534883721}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 22.136736}, "meta_inference_prompt_tokens": {"value": 10356.0}, "meta_inference_completion_tokens": {"value": 1393.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020712}, "meta_inference_completion_cost": {"value": 0.0022288}, "meta_eval_time": {"value": 32.064}, "meta_eval_prompt_tokens": {"value": 5909.0}, "meta_eval_completion_tokens": {"value": 2820.0}, "meta_eval_prompt_cost": {"value": 0.00189088}, "meta_eval_completion_cost": {"value": 0.0036096}}, "created": "2025-12-10T21:38:17.9492921Z"}
{"ref": "TQ62", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.823529411764706}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.781331}, "meta_inference_prompt_tokens": {"value": 15580.0}, "meta_inference_completion_tokens": {"value": 1600.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003116}, "meta_inference_completion_cost": {"value": 0.00256}, "meta_eval_time": {"value": 21.772}, "meta_eval_prompt_tokens": {"value": 9804.0}, "meta_eval_completion_tokens": {"value": 2247.0}, "meta_eval_prompt_cost": {"value": 0.00313728}, "meta_eval_completion_cost": {"value": 0.00287616}}, "created": "2025-12-10T21:38:19.0034966Z"}
{"ref": "TQ61", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.8125}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.776074}, "meta_inference_prompt_tokens": {"value": 14222.0}, "meta_inference_completion_tokens": {"value": 1105.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028444}, "meta_inference_completion_cost": {"value": 0.001768}, "meta_eval_time": {"value": 19.283}, "meta_eval_prompt_tokens": {"value": 8156.0}, "meta_eval_completion_tokens": {"value": 1670.0}, "meta_eval_prompt_cost": {"value": 0.00260992}, "meta_eval_completion_cost": {"value": 0.0021376}}, "created": "2025-12-10T21:38:19.1401426Z"}
{"ref": "TQ60", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.695652173913044}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.138543}, "meta_inference_prompt_tokens": {"value": 12697.0}, "meta_inference_completion_tokens": {"value": 891.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025394}, "meta_inference_completion_cost": {"value": 0.0014256}, "meta_eval_time": {"value": 27.349}, "meta_eval_prompt_tokens": {"value": 6813.0}, "meta_eval_completion_tokens": {"value": 2095.0}, "meta_eval_prompt_cost": {"value": 0.00218016}, "meta_eval_completion_cost": {"value": 0.0026816}}, "created": "2025-12-10T21:38:19.3273944Z"}
{"ref": "TQ64", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.955806}, "meta_inference_prompt_tokens": {"value": 11368.0}, "meta_inference_completion_tokens": {"value": 858.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022736}, "meta_inference_completion_cost": {"value": 0.0013728}, "meta_eval_time": {"value": 14.974}, "meta_eval_prompt_tokens": {"value": 6000.0}, "meta_eval_completion_tokens": {"value": 1464.0}, "meta_eval_prompt_cost": {"value": 0.00192}, "meta_eval_completion_cost": {"value": 0.00187392}}, "created": "2025-12-10T21:38:19.3708818Z"}
{"ref": "TQ63", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 37.712651}, "meta_inference_prompt_tokens": {"value": 11468.0}, "meta_inference_completion_tokens": {"value": 1857.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022936}, "meta_inference_completion_cost": {"value": 0.0029712}, "meta_eval_time": {"value": 19.706}, "meta_eval_prompt_tokens": {"value": 6337.0}, "meta_eval_completion_tokens": {"value": 1814.0}, "meta_eval_prompt_cost": {"value": 0.00202784}, "meta_eval_completion_cost": {"value": 0.00232192}}, "created": "2025-12-10T21:38:20.7581742Z"}
{"ref": "TQ64", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.441266}, "meta_inference_prompt_tokens": {"value": 11533.0}, "meta_inference_completion_tokens": {"value": 1040.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023066}, "meta_inference_completion_cost": {"value": 0.001664}, "meta_eval_time": {"value": 19.244}, "meta_eval_prompt_tokens": {"value": 6223.0}, "meta_eval_completion_tokens": {"value": 1758.0}, "meta_eval_prompt_cost": {"value": 0.00199136}, "meta_eval_completion_cost": {"value": 0.00225024}}, "created": "2025-12-10T21:38:21.5653015Z"}
{"ref": "TQ64", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.944444444444444}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.117889}, "meta_inference_prompt_tokens": {"value": 11217.0}, "meta_inference_completion_tokens": {"value": 994.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022434}, "meta_inference_completion_cost": {"value": 0.0015904}, "meta_eval_time": {"value": 18.789}, "meta_eval_prompt_tokens": {"value": 6122.0}, "meta_eval_completion_tokens": {"value": 1928.0}, "meta_eval_prompt_cost": {"value": 0.00195904}, "meta_eval_completion_cost": {"value": 0.00246784}}, "created": "2025-12-10T21:38:22.6215284Z"}
{"ref": "TQ6", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.955585}, "meta_inference_prompt_tokens": {"value": 10966.0}, "meta_inference_completion_tokens": {"value": 1072.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021932}, "meta_inference_completion_cost": {"value": 0.0017152}, "meta_eval_time": {"value": 21.398}, "meta_eval_prompt_tokens": {"value": 6011.0}, "meta_eval_completion_tokens": {"value": 1816.0}, "meta_eval_prompt_cost": {"value": 0.00192352}, "meta_eval_completion_cost": {"value": 0.00232448}}, "created": "2025-12-10T21:38:23.1626215Z"}
{"ref": "TQ64", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.415133}, "meta_inference_prompt_tokens": {"value": 11005.0}, "meta_inference_completion_tokens": {"value": 1107.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002201}, "meta_inference_completion_cost": {"value": 0.0017712}, "meta_eval_time": {"value": 20.185}, "meta_eval_prompt_tokens": {"value": 5824.0}, "meta_eval_completion_tokens": {"value": 1774.0}, "meta_eval_prompt_cost": {"value": 0.00186368}, "meta_eval_completion_cost": {"value": 0.00227072}}, "created": "2025-12-10T21:38:23.1970681Z"}
{"ref": "TQ64", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.222222222222222}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.100868}, "meta_inference_prompt_tokens": {"value": 10431.0}, "meta_inference_completion_tokens": {"value": 733.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020862}, "meta_inference_completion_cost": {"value": 0.0011728}, "meta_eval_time": {"value": 17.496}, "meta_eval_prompt_tokens": {"value": 5217.0}, "meta_eval_completion_tokens": {"value": 1581.0}, "meta_eval_prompt_cost": {"value": 0.00166944}, "meta_eval_completion_cost": {"value": 0.00202368}}, "created": "2025-12-10T21:38:23.5683534Z"}
{"ref": "TQ59", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.538189}, "meta_inference_prompt_tokens": {"value": 15759.0}, "meta_inference_completion_tokens": {"value": 768.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031518}, "meta_inference_completion_cost": {"value": 0.0012288}, "meta_eval_time": {"value": 34.811}, "meta_eval_prompt_tokens": {"value": 10006.0}, "meta_eval_completion_tokens": {"value": 1672.0}, "meta_eval_prompt_cost": {"value": 0.00320192}, "meta_eval_completion_cost": {"value": 0.00214016}}, "created": "2025-12-10T21:38:23.890365Z"}
{"ref": "TQ61", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.201748}, "meta_inference_prompt_tokens": {"value": 15900.0}, "meta_inference_completion_tokens": {"value": 1000.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00318}, "meta_inference_completion_cost": {"value": 0.0016}, "meta_eval_time": {"value": 22.574}, "meta_eval_prompt_tokens": {"value": 9857.0}, "meta_eval_completion_tokens": {"value": 2055.0}, "meta_eval_prompt_cost": {"value": 0.00315424}, "meta_eval_completion_cost": {"value": 0.0026304}}, "created": "2025-12-10T21:38:23.9191785Z"}
{"ref": "TQ65", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.538461538461538}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.379671}, "meta_inference_prompt_tokens": {"value": 11112.0}, "meta_inference_completion_tokens": {"value": 1177.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022224}, "meta_inference_completion_cost": {"value": 0.0018832}, "meta_eval_time": {"value": 16.528}, "meta_eval_prompt_tokens": {"value": 5812.0}, "meta_eval_completion_tokens": {"value": 1601.0}, "meta_eval_prompt_cost": {"value": 0.00185984}, "meta_eval_completion_cost": {"value": 0.00204928}}, "created": "2025-12-10T21:38:24.0720973Z"}
{"ref": "TQ65", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.571428571428571}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.696175}, "meta_inference_prompt_tokens": {"value": 9930.0}, "meta_inference_completion_tokens": {"value": 1287.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001986}, "meta_inference_completion_cost": {"value": 0.0020592}, "meta_eval_time": {"value": 18.082}, "meta_eval_prompt_tokens": {"value": 4617.0}, "meta_eval_completion_tokens": {"value": 1621.0}, "meta_eval_prompt_cost": {"value": 0.00147744}, "meta_eval_completion_cost": {"value": 0.00207488}}, "created": "2025-12-10T21:38:25.4039127Z"}
{"ref": "TQ70", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 1.0}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.793068}, "meta_inference_prompt_tokens": {"value": 5640.0}, "meta_inference_completion_tokens": {"value": 629.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001128}, "meta_inference_completion_cost": {"value": 0.0010064}, "meta_eval_time": {"value": 7.29}, "meta_eval_prompt_tokens": {"value": 2649.0}, "meta_eval_completion_tokens": {"value": 608.0}, "meta_eval_prompt_cost": {"value": 0.00084768}, "meta_eval_completion_cost": {"value": 0.00077824}}, "created": "2025-12-10T21:38:26.3317438Z"}
{"ref": "TQ63", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.222222222222222}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.595432}, "meta_inference_prompt_tokens": {"value": 12580.0}, "meta_inference_completion_tokens": {"value": 1646.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002516}, "meta_inference_completion_cost": {"value": 0.0026336}, "meta_eval_time": {"value": 24.201}, "meta_eval_prompt_tokens": {"value": 7678.0}, "meta_eval_completion_tokens": {"value": 2383.0}, "meta_eval_prompt_cost": {"value": 0.00245696}, "meta_eval_completion_cost": {"value": 0.00305024}}, "created": "2025-12-10T21:38:26.3469992Z"}
{"ref": "TQ65", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.5}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.397104}, "meta_inference_prompt_tokens": {"value": 11111.0}, "meta_inference_completion_tokens": {"value": 1095.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022222}, "meta_inference_completion_cost": {"value": 0.001752}, "meta_eval_time": {"value": 18.36}, "meta_eval_prompt_tokens": {"value": 5682.0}, "meta_eval_completion_tokens": {"value": 1628.0}, "meta_eval_prompt_cost": {"value": 0.00181824}, "meta_eval_completion_cost": {"value": 0.00208384}}, "created": "2025-12-10T21:38:28.4331045Z"}
{"ref": "TQ70", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 1.0}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.571806}, "meta_inference_prompt_tokens": {"value": 5638.0}, "meta_inference_completion_tokens": {"value": 816.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0011276}, "meta_inference_completion_cost": {"value": 0.0013056}, "meta_eval_time": {"value": 5.939}, "meta_eval_prompt_tokens": {"value": 2639.0}, "meta_eval_completion_tokens": {"value": 514.0}, "meta_eval_prompt_cost": {"value": 0.00084448}, "meta_eval_completion_cost": {"value": 0.00065792}}, "created": "2025-12-10T21:38:29.1737675Z"}
{"ref": "TQ68", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 20.78253}, "meta_inference_prompt_tokens": {"value": 10230.0}, "meta_inference_completion_tokens": {"value": 971.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002046}, "meta_inference_completion_cost": {"value": 0.0015536}, "meta_eval_time": {"value": 17.165}, "meta_eval_prompt_tokens": {"value": 4924.0}, "meta_eval_completion_tokens": {"value": 1624.0}, "meta_eval_prompt_cost": {"value": 0.00157568}, "meta_eval_completion_cost": {"value": 0.00207872}}, "created": "2025-12-10T21:38:29.5415071Z"}
{"ref": "TQ70", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.445926}, "meta_inference_prompt_tokens": {"value": 7273.0}, "meta_inference_completion_tokens": {"value": 845.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0014546}, "meta_inference_completion_cost": {"value": 0.001352}, "meta_eval_time": {"value": 8.322}, "meta_eval_prompt_tokens": {"value": 4076.0}, "meta_eval_completion_tokens": {"value": 781.0}, "meta_eval_prompt_cost": {"value": 0.00130432}, "meta_eval_completion_cost": {"value": 0.00099968}}, "created": "2025-12-10T21:38:31.9317654Z"}
{"ref": "TQ70", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 1.0}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 0.7}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 1.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 1.0}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.615387}, "meta_inference_prompt_tokens": {"value": 7265.0}, "meta_inference_completion_tokens": {"value": 857.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001453}, "meta_inference_completion_cost": {"value": 0.0013712}, "meta_eval_time": {"value": 15.8}, "meta_eval_prompt_tokens": {"value": 3749.0}, "meta_eval_completion_tokens": {"value": 1354.0}, "meta_eval_prompt_cost": {"value": 0.00119968}, "meta_eval_completion_cost": {"value": 0.00173312}}, "created": "2025-12-10T21:38:34.9745147Z"}
{"ref": "TQ70", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.846214}, "meta_inference_prompt_tokens": {"value": 7275.0}, "meta_inference_completion_tokens": {"value": 850.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001455}, "meta_inference_completion_cost": {"value": 0.00136}, "meta_eval_time": {"value": 10.039}, "meta_eval_prompt_tokens": {"value": 3807.0}, "meta_eval_completion_tokens": {"value": 839.0}, "meta_eval_prompt_cost": {"value": 0.00121824}, "meta_eval_completion_cost": {"value": 0.00107392}}, "created": "2025-12-10T21:38:35.4891582Z"}
{"ref": "TQ65", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.5}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.569441}, "meta_inference_prompt_tokens": {"value": 10365.0}, "meta_inference_completion_tokens": {"value": 1573.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002073}, "meta_inference_completion_cost": {"value": 0.0025168}, "meta_eval_time": {"value": 25.016}, "meta_eval_prompt_tokens": {"value": 5054.0}, "meta_eval_completion_tokens": {"value": 1735.0}, "meta_eval_prompt_cost": {"value": 0.00161728}, "meta_eval_completion_cost": {"value": 0.0022208}}, "created": "2025-12-10T21:38:35.5319706Z"}
{"ref": "TQ68", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.823529411764706}, "generation_factuality_f1": {"value": 0.2}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 25.672647}, "meta_inference_prompt_tokens": {"value": 9662.0}, "meta_inference_completion_tokens": {"value": 1262.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019324}, "meta_inference_completion_cost": {"value": 0.0020192}, "meta_eval_time": {"value": 22.49}, "meta_eval_prompt_tokens": {"value": 4577.0}, "meta_eval_completion_tokens": {"value": 2068.0}, "meta_eval_prompt_cost": {"value": 0.00146464}, "meta_eval_completion_cost": {"value": 0.00264704}}, "created": "2025-12-10T21:38:35.8204908Z"}
{"ref": "TQ65", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.80952380952381}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.719189}, "meta_inference_prompt_tokens": {"value": 11061.0}, "meta_inference_completion_tokens": {"value": 1179.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022122}, "meta_inference_completion_cost": {"value": 0.0018864}, "meta_eval_time": {"value": 24.464}, "meta_eval_prompt_tokens": {"value": 5919.0}, "meta_eval_completion_tokens": {"value": 2201.0}, "meta_eval_prompt_cost": {"value": 0.00189408}, "meta_eval_completion_cost": {"value": 0.00281728}}, "created": "2025-12-10T21:38:36.4461501Z"}
{"ref": "TQ63", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.842105263157895}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.065773}, "meta_inference_prompt_tokens": {"value": 11613.0}, "meta_inference_completion_tokens": {"value": 1724.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023226}, "meta_inference_completion_cost": {"value": 0.0027584}, "meta_eval_time": {"value": 28.65}, "meta_eval_prompt_tokens": {"value": 7081.0}, "meta_eval_completion_tokens": {"value": 2302.0}, "meta_eval_prompt_cost": {"value": 0.00226592}, "meta_eval_completion_cost": {"value": 0.00294656}}, "created": "2025-12-10T21:38:36.5704837Z"}
{"ref": "TQ68", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.894736842105263}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 26.910287}, "meta_inference_prompt_tokens": {"value": 9660.0}, "meta_inference_completion_tokens": {"value": 1241.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001932}, "meta_inference_completion_cost": {"value": 0.0019856}, "meta_eval_time": {"value": 22.702}, "meta_eval_prompt_tokens": {"value": 4531.0}, "meta_eval_completion_tokens": {"value": 2139.0}, "meta_eval_prompt_cost": {"value": 0.00144992}, "meta_eval_completion_cost": {"value": 0.00273792}}, "created": "2025-12-10T21:38:37.012343Z"}
{"ref": "TQ63", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.600034}, "meta_inference_prompt_tokens": {"value": 11666.0}, "meta_inference_completion_tokens": {"value": 1726.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023332}, "meta_inference_completion_cost": {"value": 0.0027616}, "meta_eval_time": {"value": 37.377}, "meta_eval_prompt_tokens": {"value": 7543.0}, "meta_eval_completion_tokens": {"value": 3321.0}, "meta_eval_prompt_cost": {"value": 0.00241376}, "meta_eval_completion_cost": {"value": 0.00425088}}, "created": "2025-12-10T21:38:40.1059142Z"}
{"ref": "TQ68", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 25.608291}, "meta_inference_prompt_tokens": {"value": 11285.0}, "meta_inference_completion_tokens": {"value": 1252.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002257}, "meta_inference_completion_cost": {"value": 0.0020032}, "meta_eval_time": {"value": 25.01}, "meta_eval_prompt_tokens": {"value": 6209.0}, "meta_eval_completion_tokens": {"value": 2306.0}, "meta_eval_prompt_cost": {"value": 0.00198688}, "meta_eval_completion_cost": {"value": 0.00295168}}, "created": "2025-12-10T21:38:40.6105Z"}
{"ref": "TQ7", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.81419}, "meta_inference_prompt_tokens": {"value": 11060.0}, "meta_inference_completion_tokens": {"value": 1218.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002212}, "meta_inference_completion_cost": {"value": 0.0019488}, "meta_eval_time": {"value": 22.562}, "meta_eval_prompt_tokens": {"value": 6637.0}, "meta_eval_completion_tokens": {"value": 2464.0}, "meta_eval_prompt_cost": {"value": 0.00212384}, "meta_eval_completion_cost": {"value": 0.00315392}}, "created": "2025-12-10T21:38:41.9764931Z"}
{"ref": "TQ67", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.06160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.784482}, "meta_inference_prompt_tokens": {"value": 12432.0}, "meta_inference_completion_tokens": {"value": 1105.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024864}, "meta_inference_completion_cost": {"value": 0.001768}, "meta_eval_time": {"value": 31.227}, "meta_eval_prompt_tokens": {"value": 7963.0}, "meta_eval_completion_tokens": {"value": 3201.0}, "meta_eval_prompt_cost": {"value": 0.00254816}, "meta_eval_completion_cost": {"value": 0.00409728}}, "created": "2025-12-10T21:38:43.1174083Z"}
{"ref": "TQ71", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.2}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 23.672527}, "meta_inference_prompt_tokens": {"value": 12427.0}, "meta_inference_completion_tokens": {"value": 1526.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024854}, "meta_inference_completion_cost": {"value": 0.0024416}, "meta_eval_time": {"value": 19.93}, "meta_eval_prompt_tokens": {"value": 7114.0}, "meta_eval_completion_tokens": {"value": 2283.0}, "meta_eval_prompt_cost": {"value": 0.00227648}, "meta_eval_completion_cost": {"value": 0.00292224}}, "created": "2025-12-10T21:38:43.8598537Z"}
{"ref": "TQ72", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 24.227519}, "meta_inference_prompt_tokens": {"value": 14699.0}, "meta_inference_completion_tokens": {"value": 1479.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029398}, "meta_inference_completion_cost": {"value": 0.0023664}, "meta_eval_time": {"value": 18.057}, "meta_eval_prompt_tokens": {"value": 8836.0}, "meta_eval_completion_tokens": {"value": 2027.0}, "meta_eval_prompt_cost": {"value": 0.00282752}, "meta_eval_completion_cost": {"value": 0.00259456}}, "created": "2025-12-10T21:38:44.4261477Z"}
{"ref": "TQ67", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.946394630357186}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.62258}, "meta_inference_prompt_tokens": {"value": 12909.0}, "meta_inference_completion_tokens": {"value": 1379.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025818}, "meta_inference_completion_cost": {"value": 0.0022064}, "meta_eval_time": {"value": 37.752}, "meta_eval_prompt_tokens": {"value": 8791.0}, "meta_eval_completion_tokens": {"value": 3502.0}, "meta_eval_prompt_cost": {"value": 0.00281312}, "meta_eval_completion_cost": {"value": 0.00448256}}, "created": "2025-12-10T21:38:45.9725293Z"}
{"ref": "TQ71", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.111111111111111}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 64.966687}, "meta_inference_prompt_tokens": {"value": 13824.0}, "meta_inference_completion_tokens": {"value": 1828.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0027648}, "meta_inference_completion_cost": {"value": 0.0029248}, "meta_eval_time": {"value": 22.018}, "meta_eval_prompt_tokens": {"value": 6469.0}, "meta_eval_completion_tokens": {"value": 2372.0}, "meta_eval_prompt_cost": {"value": 0.00207008}, "meta_eval_completion_cost": {"value": 0.00303616}}, "created": "2025-12-10T21:38:45.9838275Z"}
{"ref": "TQ67", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.964263086904791}, "generation_faithfulness": {"value": 0.955555555555556}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.112996}, "meta_inference_prompt_tokens": {"value": 13778.0}, "meta_inference_completion_tokens": {"value": 1306.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027556}, "meta_inference_completion_cost": {"value": 0.0020896}, "meta_eval_time": {"value": 34.168}, "meta_eval_prompt_tokens": {"value": 9653.0}, "meta_eval_completion_tokens": {"value": 3797.0}, "meta_eval_prompt_cost": {"value": 0.00308896}, "meta_eval_completion_cost": {"value": 0.00486016}}, "created": "2025-12-10T21:38:46.257054Z"}
{"ref": "TQ69", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.67591763355243}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.166666666666667}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 21.307604}, "meta_inference_prompt_tokens": {"value": 11875.0}, "meta_inference_completion_tokens": {"value": 1111.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002375}, "meta_inference_completion_cost": {"value": 0.0017776}, "meta_eval_time": {"value": 29.786}, "meta_eval_prompt_tokens": {"value": 7041.0}, "meta_eval_completion_tokens": {"value": 2513.0}, "meta_eval_prompt_cost": {"value": 0.00225312}, "meta_eval_completion_cost": {"value": 0.00321664}}, "created": "2025-12-10T21:38:46.7594385Z"}
{"ref": "TQ74", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.146622}, "meta_inference_prompt_tokens": {"value": 12445.0}, "meta_inference_completion_tokens": {"value": 677.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002489}, "meta_inference_completion_cost": {"value": 0.0010832}, "meta_eval_time": {"value": 6.147}, "meta_eval_prompt_tokens": {"value": 6575.0}, "meta_eval_completion_tokens": {"value": 488.0}, "meta_eval_prompt_cost": {"value": 0.002104}, "meta_eval_completion_cost": {"value": 0.00062464}}, "created": "2025-12-10T21:38:48.1609221Z"}
{"ref": "TQ74", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.64527201342591}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.072662}, "meta_inference_prompt_tokens": {"value": 12527.0}, "meta_inference_completion_tokens": {"value": 503.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025054}, "meta_inference_completion_cost": {"value": 0.0008048}, "meta_eval_time": {"value": 7.805}, "meta_eval_prompt_tokens": {"value": 6599.0}, "meta_eval_completion_tokens": {"value": 567.0}, "meta_eval_prompt_cost": {"value": 0.00211168}, "meta_eval_completion_cost": {"value": 0.00072576}}, "created": "2025-12-10T21:38:48.4549959Z"}
{"ref": "TQ7", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.869565217391304}, "generation_factuality_f1": {"value": 0.645161290322581}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 21.808794}, "meta_inference_prompt_tokens": {"value": 10688.0}, "meta_inference_completion_tokens": {"value": 1203.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021376}, "meta_inference_completion_cost": {"value": 0.0019248}, "meta_eval_time": {"value": 29.594}, "meta_eval_prompt_tokens": {"value": 6612.0}, "meta_eval_completion_tokens": {"value": 2901.0}, "meta_eval_prompt_cost": {"value": 0.00211584}, "meta_eval_completion_cost": {"value": 0.00371328}}, "created": "2025-12-10T21:38:48.9879659Z"}
{"ref": "TQ7", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.931034482758621}, "generation_factuality_f1": {"value": 0.835820895522388}, "generation_factuality_precision": {"value": 0.875}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 24.05558}, "meta_inference_prompt_tokens": {"value": 11160.0}, "meta_inference_completion_tokens": {"value": 1169.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002232}, "meta_inference_completion_cost": {"value": 0.0018704}, "meta_eval_time": {"value": 32.831}, "meta_eval_prompt_tokens": {"value": 7167.0}, "meta_eval_completion_tokens": {"value": 3233.0}, "meta_eval_prompt_cost": {"value": 0.00229344}, "meta_eval_completion_cost": {"value": 0.00413824}}, "created": "2025-12-10T21:38:49.4200526Z"}
{"ref": "TQ7", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 1.53490097046095}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.167854}, "meta_inference_prompt_tokens": {"value": 26690.0}, "meta_inference_completion_tokens": {"value": 1428.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.005338}, "meta_inference_completion_cost": {"value": 0.0022848}, "meta_eval_time": {"value": 27.864}, "meta_eval_prompt_tokens": {"value": 10344.0}, "meta_eval_completion_tokens": {"value": 2748.0}, "meta_eval_prompt_cost": {"value": 0.00331008}, "meta_eval_completion_cost": {"value": 0.00351744}}, "created": "2025-12-10T21:38:49.4674597Z"}
{"ref": "TQ67", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.98713694067948}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.133333333333333}, "generation_factuality_precision": {"value": 0.0714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.335793}, "meta_inference_prompt_tokens": {"value": 14442.0}, "meta_inference_completion_tokens": {"value": 1291.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028884}, "meta_inference_completion_cost": {"value": 0.0020656}, "meta_eval_time": {"value": 39.582}, "meta_eval_prompt_tokens": {"value": 10029.0}, "meta_eval_completion_tokens": {"value": 3800.0}, "meta_eval_prompt_cost": {"value": 0.00320928}, "meta_eval_completion_cost": {"value": 0.004864}}, "created": "2025-12-10T21:38:49.7156233Z"}
{"ref": "TQ69", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.590094821981869}, "generation_faithfulness": {"value": 0.96875}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.731656}, "meta_inference_prompt_tokens": {"value": 11594.0}, "meta_inference_completion_tokens": {"value": 1176.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023188}, "meta_inference_completion_cost": {"value": 0.0018816}, "meta_eval_time": {"value": 33.455}, "meta_eval_prompt_tokens": {"value": 7214.0}, "meta_eval_completion_tokens": {"value": 3351.0}, "meta_eval_prompt_cost": {"value": 0.00230848}, "meta_eval_completion_cost": {"value": 0.00428928}}, "created": "2025-12-10T21:38:49.7174097Z"}
{"ref": "TQ74", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.607706}, "meta_inference_prompt_tokens": {"value": 12266.0}, "meta_inference_completion_tokens": {"value": 571.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024532}, "meta_inference_completion_cost": {"value": 0.0009136}, "meta_eval_time": {"value": 7.265}, "meta_eval_prompt_tokens": {"value": 6438.0}, "meta_eval_completion_tokens": {"value": 567.0}, "meta_eval_prompt_cost": {"value": 0.00206016}, "meta_eval_completion_cost": {"value": 0.00072576}}, "created": "2025-12-10T21:38:50.4184083Z"}
{"ref": "TQ74", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.08918}, "meta_inference_prompt_tokens": {"value": 12494.0}, "meta_inference_completion_tokens": {"value": 667.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024988}, "meta_inference_completion_cost": {"value": 0.0010672}, "meta_eval_time": {"value": 10.351}, "meta_eval_prompt_tokens": {"value": 6821.0}, "meta_eval_completion_tokens": {"value": 966.0}, "meta_eval_prompt_cost": {"value": 0.00218272}, "meta_eval_completion_cost": {"value": 0.00123648}}, "created": "2025-12-10T21:38:50.4987201Z"}
{"ref": "TQ69", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.336961}, "meta_inference_prompt_tokens": {"value": 10340.0}, "meta_inference_completion_tokens": {"value": 1117.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002068}, "meta_inference_completion_cost": {"value": 0.0017872}, "meta_eval_time": {"value": 30.257}, "meta_eval_prompt_tokens": {"value": 6163.0}, "meta_eval_completion_tokens": {"value": 2992.0}, "meta_eval_prompt_cost": {"value": 0.00197216}, "meta_eval_completion_cost": {"value": 0.00382976}}, "created": "2025-12-10T21:38:51.0558752Z"}
{"ref": "TQ71", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.894736842105263}, "generation_factuality_f1": {"value": 0.153846153846154}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 26.066364}, "meta_inference_prompt_tokens": {"value": 13825.0}, "meta_inference_completion_tokens": {"value": 1739.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002765}, "meta_inference_completion_cost": {"value": 0.0027824}, "meta_eval_time": {"value": 22.081}, "meta_eval_prompt_tokens": {"value": 8247.0}, "meta_eval_completion_tokens": {"value": 2197.0}, "meta_eval_prompt_cost": {"value": 0.00263904}, "meta_eval_completion_cost": {"value": 0.00281216}}, "created": "2025-12-10T21:38:51.3172842Z"}
{"ref": "TQ7", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 1.03490097046095}, "generation_faithfulness": {"value": 0.956521739130435}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.292101}, "meta_inference_prompt_tokens": {"value": 27478.0}, "meta_inference_completion_tokens": {"value": 1379.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0054956}, "meta_inference_completion_cost": {"value": 0.0022064}, "meta_eval_time": {"value": 29.003}, "meta_eval_prompt_tokens": {"value": 11353.0}, "meta_eval_completion_tokens": {"value": 2946.0}, "meta_eval_prompt_cost": {"value": 0.00363296}, "meta_eval_completion_cost": {"value": 0.00377088}}, "created": "2025-12-10T21:38:51.6617471Z"}
{"ref": "TQ69", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 25.824088}, "meta_inference_prompt_tokens": {"value": 11013.0}, "meta_inference_completion_tokens": {"value": 1521.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022026}, "meta_inference_completion_cost": {"value": 0.0024336}, "meta_eval_time": {"value": 33.725}, "meta_eval_prompt_tokens": {"value": 6608.0}, "meta_eval_completion_tokens": {"value": 2884.0}, "meta_eval_prompt_cost": {"value": 0.00211456}, "meta_eval_completion_cost": {"value": 0.00369152}}, "created": "2025-12-10T21:38:51.7232336Z"}
{"ref": "TQ71", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.111111111111111}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 29.326879}, "meta_inference_prompt_tokens": {"value": 11165.0}, "meta_inference_completion_tokens": {"value": 1715.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002233}, "meta_inference_completion_cost": {"value": 0.002744}, "meta_eval_time": {"value": 27.79}, "meta_eval_prompt_tokens": {"value": 6400.0}, "meta_eval_completion_tokens": {"value": 2696.0}, "meta_eval_prompt_cost": {"value": 0.002048}, "meta_eval_completion_cost": {"value": 0.00345088}}, "created": "2025-12-10T21:38:51.9320092Z"}
{"ref": "TQ63", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.485437}, "meta_inference_prompt_tokens": {"value": 12278.0}, "meta_inference_completion_tokens": {"value": 1299.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024556}, "meta_inference_completion_cost": {"value": 0.0020784}, "meta_eval_time": {"value": 25.575}, "meta_eval_prompt_tokens": {"value": 7910.0}, "meta_eval_completion_tokens": {"value": 2550.0}, "meta_eval_prompt_cost": {"value": 0.0025312}, "meta_eval_completion_cost": {"value": 0.003264}}, "created": "2025-12-10T21:38:51.9618034Z"}
{"ref": "TQ74", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.266727}, "meta_inference_prompt_tokens": {"value": 12456.0}, "meta_inference_completion_tokens": {"value": 595.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024912}, "meta_inference_completion_cost": {"value": 0.000952}, "meta_eval_time": {"value": 9.187}, "meta_eval_prompt_tokens": {"value": 6730.0}, "meta_eval_completion_tokens": {"value": 706.0}, "meta_eval_prompt_cost": {"value": 0.0021536}, "meta_eval_completion_cost": {"value": 0.00090368}}, "created": "2025-12-10T21:38:53.6539185Z"}
{"ref": "TQ72", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.333687}, "meta_inference_prompt_tokens": {"value": 15222.0}, "meta_inference_completion_tokens": {"value": 639.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030444}, "meta_inference_completion_cost": {"value": 0.0010224}, "meta_eval_time": {"value": 24.19}, "meta_eval_prompt_tokens": {"value": 9236.0}, "meta_eval_completion_tokens": {"value": 2421.0}, "meta_eval_prompt_cost": {"value": 0.00295552}, "meta_eval_completion_cost": {"value": 0.00309888}}, "created": "2025-12-10T21:38:53.8020924Z"}
{"ref": "TQ67", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.017782560806}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.458959}, "meta_inference_prompt_tokens": {"value": 13431.0}, "meta_inference_completion_tokens": {"value": 1179.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026862}, "meta_inference_completion_cost": {"value": 0.0018864}, "meta_eval_time": {"value": 41.449}, "meta_eval_prompt_tokens": {"value": 9351.0}, "meta_eval_completion_tokens": {"value": 3722.0}, "meta_eval_prompt_cost": {"value": 0.00299232}, "meta_eval_completion_cost": {"value": 0.00476416}}, "created": "2025-12-10T21:38:53.8902449Z"}
{"ref": "TQ72", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.757505}, "meta_inference_prompt_tokens": {"value": 14670.0}, "meta_inference_completion_tokens": {"value": 882.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002934}, "meta_inference_completion_cost": {"value": 0.0014112}, "meta_eval_time": {"value": 18.243}, "meta_eval_prompt_tokens": {"value": 8942.0}, "meta_eval_completion_tokens": {"value": 1646.0}, "meta_eval_prompt_cost": {"value": 0.00286144}, "meta_eval_completion_cost": {"value": 0.00210688}}, "created": "2025-12-10T21:38:54.1045882Z"}
{"ref": "TQ72", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.2}, "generation_factuality_precision": {"value": 0.111111111111111}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.603221}, "meta_inference_prompt_tokens": {"value": 14769.0}, "meta_inference_completion_tokens": {"value": 952.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029538}, "meta_inference_completion_cost": {"value": 0.0015232}, "meta_eval_time": {"value": 19.861}, "meta_eval_prompt_tokens": {"value": 8799.0}, "meta_eval_completion_tokens": {"value": 2053.0}, "meta_eval_prompt_cost": {"value": 0.00281568}, "meta_eval_completion_cost": {"value": 0.00262784}}, "created": "2025-12-10T21:38:56.9142916Z"}
{"ref": "TQ68", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.68421052631579}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.436282}, "meta_inference_prompt_tokens": {"value": 9400.0}, "meta_inference_completion_tokens": {"value": 1183.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00188}, "meta_inference_completion_cost": {"value": 0.0018928}, "meta_eval_time": {"value": 41.694}, "meta_eval_prompt_tokens": {"value": 4353.0}, "meta_eval_completion_tokens": {"value": 1862.0}, "meta_eval_prompt_cost": {"value": 0.00139296}, "meta_eval_completion_cost": {"value": 0.00238336}}, "created": "2025-12-10T21:38:58.0571298Z"}
{"ref": "TQ76", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 29.704534}, "meta_inference_prompt_tokens": {"value": 22152.0}, "meta_inference_completion_tokens": {"value": 1496.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0044304}, "meta_inference_completion_cost": {"value": 0.0023936}, "meta_eval_time": {"value": 13.207}, "meta_eval_prompt_tokens": {"value": 6304.0}, "meta_eval_completion_tokens": {"value": 1272.0}, "meta_eval_prompt_cost": {"value": 0.00201728}, "meta_eval_completion_cost": {"value": 0.00162816}}, "created": "2025-12-10T21:38:59.2186549Z"}
{"ref": "TQ69", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.648798210119062}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.449891}, "meta_inference_prompt_tokens": {"value": 11542.0}, "meta_inference_completion_tokens": {"value": 1414.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023084}, "meta_inference_completion_cost": {"value": 0.0022624}, "meta_eval_time": {"value": 45.669}, "meta_eval_prompt_tokens": {"value": 7711.0}, "meta_eval_completion_tokens": {"value": 4038.0}, "meta_eval_prompt_cost": {"value": 0.00246752}, "meta_eval_completion_cost": {"value": 0.00516864}}, "created": "2025-12-10T21:38:59.6927178Z"}
{"ref": "TQ66", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.862068965517241}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.485893}, "meta_inference_prompt_tokens": {"value": 12986.0}, "meta_inference_completion_tokens": {"value": 1965.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025972}, "meta_inference_completion_cost": {"value": 0.003144}, "meta_eval_time": {"value": 51.769}, "meta_eval_prompt_tokens": {"value": 10071.0}, "meta_eval_completion_tokens": {"value": 5202.0}, "meta_eval_prompt_cost": {"value": 0.00322272}, "meta_eval_completion_cost": {"value": 0.00665856}}, "created": "2025-12-10T21:39:00.0280971Z"}
{"ref": "TQ76", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 29.124797}, "meta_inference_prompt_tokens": {"value": 10138.0}, "meta_inference_completion_tokens": {"value": 1504.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020276}, "meta_inference_completion_cost": {"value": 0.0024064}, "meta_eval_time": {"value": 14.114}, "meta_eval_prompt_tokens": {"value": 4877.0}, "meta_eval_completion_tokens": {"value": 1480.0}, "meta_eval_prompt_cost": {"value": 0.00156064}, "meta_eval_completion_cost": {"value": 0.0018944}}, "created": "2025-12-10T21:39:00.4086864Z"}
{"ref": "TQ66", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.970588235294118}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.998876}, "meta_inference_prompt_tokens": {"value": 11763.0}, "meta_inference_completion_tokens": {"value": 1273.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023526}, "meta_inference_completion_cost": {"value": 0.0020368}, "meta_eval_time": {"value": 55.38}, "meta_eval_prompt_tokens": {"value": 8935.0}, "meta_eval_completion_tokens": {"value": 5505.0}, "meta_eval_prompt_cost": {"value": 0.0028592}, "meta_eval_completion_cost": {"value": 0.0070464}}, "created": "2025-12-10T21:39:01.1586082Z"}
{"ref": "TQ73", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.289064826317888}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.061952}, "meta_inference_prompt_tokens": {"value": 10023.0}, "meta_inference_completion_tokens": {"value": 1369.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020046}, "meta_inference_completion_cost": {"value": 0.0021904}, "meta_eval_time": {"value": 26.335}, "meta_eval_prompt_tokens": {"value": 5250.0}, "meta_eval_completion_tokens": {"value": 2150.0}, "meta_eval_prompt_cost": {"value": 0.00168}, "meta_eval_completion_cost": {"value": 0.002752}}, "created": "2025-12-10T21:39:01.3482175Z"}
{"ref": "TQ73", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.769230769230769}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 21.16502}, "meta_inference_prompt_tokens": {"value": 9923.0}, "meta_inference_completion_tokens": {"value": 1166.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019846}, "meta_inference_completion_cost": {"value": 0.0018656}, "meta_eval_time": {"value": 26.378}, "meta_eval_prompt_tokens": {"value": 5032.0}, "meta_eval_completion_tokens": {"value": 2649.0}, "meta_eval_prompt_cost": {"value": 0.00161024}, "meta_eval_completion_cost": {"value": 0.00339072}}, "created": "2025-12-10T21:39:01.9037133Z"}
{"ref": "TQ66", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.3967}, "meta_inference_prompt_tokens": {"value": 12818.0}, "meta_inference_completion_tokens": {"value": 1471.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025636}, "meta_inference_completion_cost": {"value": 0.0023536}, "meta_eval_time": {"value": 57.581}, "meta_eval_prompt_tokens": {"value": 10010.0}, "meta_eval_completion_tokens": {"value": 5644.0}, "meta_eval_prompt_cost": {"value": 0.0032032}, "meta_eval_completion_cost": {"value": 0.00722432}}, "created": "2025-12-10T21:39:02.730401Z"}
{"ref": "TQ73", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.96875}, "generation_factuality_f1": {"value": 0.173913043478261}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 52.093108}, "meta_inference_prompt_tokens": {"value": 10346.0}, "meta_inference_completion_tokens": {"value": 1582.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020692}, "meta_inference_completion_cost": {"value": 0.0025312}, "meta_eval_time": {"value": 31.523}, "meta_eval_prompt_tokens": {"value": 6003.0}, "meta_eval_completion_tokens": {"value": 3126.0}, "meta_eval_prompt_cost": {"value": 0.00192096}, "meta_eval_completion_cost": {"value": 0.00400128}}, "created": "2025-12-10T21:39:03.5045697Z"}
{"ref": "TQ76", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.1}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.262649535037194}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0526315789473684}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.05}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 27.979711}, "meta_inference_prompt_tokens": {"value": 27424.0}, "meta_inference_completion_tokens": {"value": 763.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0054848}, "meta_inference_completion_cost": {"value": 0.0012208}, "meta_eval_time": {"value": 15.531}, "meta_eval_prompt_tokens": {"value": 9008.0}, "meta_eval_completion_tokens": {"value": 1323.0}, "meta_eval_prompt_cost": {"value": 0.00288256}, "meta_eval_completion_cost": {"value": 0.00169344}}, "created": "2025-12-10T21:39:04.0251482Z"}
{"ref": "TQ77", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.142162}, "meta_inference_prompt_tokens": {"value": 12938.0}, "meta_inference_completion_tokens": {"value": 1542.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025876}, "meta_inference_completion_cost": {"value": 0.0024672}, "meta_eval_time": {"value": 15.021}, "meta_eval_prompt_tokens": {"value": 7311.0}, "meta_eval_completion_tokens": {"value": 1474.0}, "meta_eval_prompt_cost": {"value": 0.00233952}, "meta_eval_completion_cost": {"value": 0.00188672}}, "created": "2025-12-10T21:39:04.4936394Z"}
{"ref": "TQ71", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 0.935483870967742}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 29.420066}, "meta_inference_prompt_tokens": {"value": 12441.0}, "meta_inference_completion_tokens": {"value": 1492.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024882}, "meta_inference_completion_cost": {"value": 0.0023872}, "meta_eval_time": {"value": 41.994}, "meta_eval_prompt_tokens": {"value": 7720.0}, "meta_eval_completion_tokens": {"value": 2822.0}, "meta_eval_prompt_cost": {"value": 0.0024704}, "meta_eval_completion_cost": {"value": 0.00361216}}, "created": "2025-12-10T21:39:05.1954447Z"}
{"ref": "TQ72", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.886852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.166666666666667}, "generation_factuality_precision": {"value": 0.0909090909090909}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.802069}, "meta_inference_prompt_tokens": {"value": 13177.0}, "meta_inference_completion_tokens": {"value": 884.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026354}, "meta_inference_completion_cost": {"value": 0.0014144}, "meta_eval_time": {"value": 28.708}, "meta_eval_prompt_tokens": {"value": 7737.0}, "meta_eval_completion_tokens": {"value": 2835.0}, "meta_eval_prompt_cost": {"value": 0.00247584}, "meta_eval_completion_cost": {"value": 0.0036288}}, "created": "2025-12-10T21:39:05.3149466Z"}
{"ref": "TQ73", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.956521739130435}, "generation_factuality_f1": {"value": 0.521739130434783}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 34.082993}, "meta_inference_prompt_tokens": {"value": 9480.0}, "meta_inference_completion_tokens": {"value": 1660.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001896}, "meta_inference_completion_cost": {"value": 0.002656}, "meta_eval_time": {"value": 29.022}, "meta_eval_prompt_tokens": {"value": 5135.0}, "meta_eval_completion_tokens": {"value": 2644.0}, "meta_eval_prompt_cost": {"value": 0.0016432}, "meta_eval_completion_cost": {"value": 0.00338432}}, "created": "2025-12-10T21:39:05.519583Z"}
{"ref": "TQ75", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.987509}, "meta_inference_prompt_tokens": {"value": 11923.0}, "meta_inference_completion_tokens": {"value": 985.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023846}, "meta_inference_completion_cost": {"value": 0.001576}, "meta_eval_time": {"value": 19.631}, "meta_eval_prompt_tokens": {"value": 6755.0}, "meta_eval_completion_tokens": {"value": 1951.0}, "meta_eval_prompt_cost": {"value": 0.0021616}, "meta_eval_completion_cost": {"value": 0.00249728}}, "created": "2025-12-10T21:39:05.6543995Z"}
{"ref": "TQ77", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.318203}, "meta_inference_prompt_tokens": {"value": 11842.0}, "meta_inference_completion_tokens": {"value": 1298.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023684}, "meta_inference_completion_cost": {"value": 0.0020768}, "meta_eval_time": {"value": 16.76}, "meta_eval_prompt_tokens": {"value": 6325.0}, "meta_eval_completion_tokens": {"value": 1355.0}, "meta_eval_prompt_cost": {"value": 0.002024}, "meta_eval_completion_cost": {"value": 0.0017344}}, "created": "2025-12-10T21:39:06.266071Z"}
{"ref": "TQ75", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.139481}, "meta_inference_prompt_tokens": {"value": 12138.0}, "meta_inference_completion_tokens": {"value": 872.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024276}, "meta_inference_completion_cost": {"value": 0.0013952}, "meta_eval_time": {"value": 17.751}, "meta_eval_prompt_tokens": {"value": 6811.0}, "meta_eval_completion_tokens": {"value": 1663.0}, "meta_eval_prompt_cost": {"value": 0.00217952}, "meta_eval_completion_cost": {"value": 0.00212864}}, "created": "2025-12-10T21:39:06.7821121Z"}
{"ref": "TQ66", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 61.974336}, "meta_inference_prompt_tokens": {"value": 12743.0}, "meta_inference_completion_tokens": {"value": 1413.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025486}, "meta_inference_completion_cost": {"value": 0.0022608}, "meta_eval_time": {"value": 58.641}, "meta_eval_prompt_tokens": {"value": 10276.0}, "meta_eval_completion_tokens": {"value": 5605.0}, "meta_eval_prompt_cost": {"value": 0.00328832}, "meta_eval_completion_cost": {"value": 0.0071744}}, "created": "2025-12-10T21:39:07.2599803Z"}
{"ref": "TQ75", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.220036}, "meta_inference_prompt_tokens": {"value": 10736.0}, "meta_inference_completion_tokens": {"value": 883.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021472}, "meta_inference_completion_cost": {"value": 0.0014128}, "meta_eval_time": {"value": 21.437}, "meta_eval_prompt_tokens": {"value": 5787.0}, "meta_eval_completion_tokens": {"value": 2104.0}, "meta_eval_prompt_cost": {"value": 0.00185184}, "meta_eval_completion_cost": {"value": 0.00269312}}, "created": "2025-12-10T21:39:08.2357137Z"}
{"ref": "TQ75", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.841832}, "meta_inference_prompt_tokens": {"value": 9754.0}, "meta_inference_completion_tokens": {"value": 1093.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019508}, "meta_inference_completion_cost": {"value": 0.0017488}, "meta_eval_time": {"value": 24.618}, "meta_eval_prompt_tokens": {"value": 4791.0}, "meta_eval_completion_tokens": {"value": 1900.0}, "meta_eval_prompt_cost": {"value": 0.00153312}, "meta_eval_completion_cost": {"value": 0.002432}}, "created": "2025-12-10T21:39:08.5208963Z"}
{"ref": "TQ77", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.325267}, "meta_inference_prompt_tokens": {"value": 10820.0}, "meta_inference_completion_tokens": {"value": 1568.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002164}, "meta_inference_completion_cost": {"value": 0.0025088}, "meta_eval_time": {"value": 18.386}, "meta_eval_prompt_tokens": {"value": 5582.0}, "meta_eval_completion_tokens": {"value": 1644.0}, "meta_eval_prompt_cost": {"value": 0.00178624}, "meta_eval_completion_cost": {"value": 0.00210432}}, "created": "2025-12-10T21:39:08.8407636Z"}
{"ref": "TQ77", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.905028}, "meta_inference_prompt_tokens": {"value": 11958.0}, "meta_inference_completion_tokens": {"value": 989.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023916}, "meta_inference_completion_cost": {"value": 0.0015824}, "meta_eval_time": {"value": 18.259}, "meta_eval_prompt_tokens": {"value": 6069.0}, "meta_eval_completion_tokens": {"value": 1606.0}, "meta_eval_prompt_cost": {"value": 0.00194208}, "meta_eval_completion_cost": {"value": 0.00205568}}, "created": "2025-12-10T21:39:09.351961Z"}
{"ref": "TQ73", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.984667}, "meta_inference_prompt_tokens": {"value": 10806.0}, "meta_inference_completion_tokens": {"value": 1439.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021612}, "meta_inference_completion_cost": {"value": 0.0023024}, "meta_eval_time": {"value": 34.56}, "meta_eval_prompt_tokens": {"value": 6518.0}, "meta_eval_completion_tokens": {"value": 3340.0}, "meta_eval_prompt_cost": {"value": 0.00208576}, "meta_eval_completion_cost": {"value": 0.0042752}}, "created": "2025-12-10T21:39:10.1301697Z"}
{"ref": "TQ76", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 24.830613}, "meta_inference_prompt_tokens": {"value": 9948.0}, "meta_inference_completion_tokens": {"value": 1269.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019896}, "meta_inference_completion_cost": {"value": 0.0020304}, "meta_eval_time": {"value": 20.528}, "meta_eval_prompt_tokens": {"value": 4742.0}, "meta_eval_completion_tokens": {"value": 1936.0}, "meta_eval_prompt_cost": {"value": 0.00151744}, "meta_eval_completion_cost": {"value": 0.00247808}}, "created": "2025-12-10T21:39:10.2835707Z"}
{"ref": "TQ76", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.769230769230769}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 33.067102}, "meta_inference_prompt_tokens": {"value": 23717.0}, "meta_inference_completion_tokens": {"value": 1645.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0047434}, "meta_inference_completion_cost": {"value": 0.002632}, "meta_eval_time": {"value": 22.096}, "meta_eval_prompt_tokens": {"value": 8069.0}, "meta_eval_completion_tokens": {"value": 1873.0}, "meta_eval_prompt_cost": {"value": 0.00258208}, "meta_eval_completion_cost": {"value": 0.00239744}}, "created": "2025-12-10T21:39:10.2961732Z"}
{"ref": "TQ79", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.764792}, "meta_inference_prompt_tokens": {"value": 13763.0}, "meta_inference_completion_tokens": {"value": 920.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027526}, "meta_inference_completion_cost": {"value": 0.001472}, "meta_eval_time": {"value": 18.787}, "meta_eval_prompt_tokens": {"value": 7346.0}, "meta_eval_completion_tokens": {"value": 1618.0}, "meta_eval_prompt_cost": {"value": 0.00235072}, "meta_eval_completion_cost": {"value": 0.00207104}}, "created": "2025-12-10T21:39:10.7595078Z"}
{"ref": "TQ79", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.663412}, "meta_inference_prompt_tokens": {"value": 16369.0}, "meta_inference_completion_tokens": {"value": 881.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032738}, "meta_inference_completion_cost": {"value": 0.0014096}, "meta_eval_time": {"value": 17.045}, "meta_eval_prompt_tokens": {"value": 10276.0}, "meta_eval_completion_tokens": {"value": 1410.0}, "meta_eval_prompt_cost": {"value": 0.00328832}, "meta_eval_completion_cost": {"value": 0.0018048}}, "created": "2025-12-10T21:39:10.9742115Z"}
{"ref": "TQ79", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.883733}, "meta_inference_prompt_tokens": {"value": 13254.0}, "meta_inference_completion_tokens": {"value": 1078.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026508}, "meta_inference_completion_cost": {"value": 0.0017248}, "meta_eval_time": {"value": 19.329}, "meta_eval_prompt_tokens": {"value": 7823.0}, "meta_eval_completion_tokens": {"value": 1781.0}, "meta_eval_prompt_cost": {"value": 0.00250336}, "meta_eval_completion_cost": {"value": 0.00227968}}, "created": "2025-12-10T21:39:11.0361441Z"}
{"ref": "TQ77", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.844108}, "meta_inference_prompt_tokens": {"value": 11717.0}, "meta_inference_completion_tokens": {"value": 1337.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023434}, "meta_inference_completion_cost": {"value": 0.0021392}, "meta_eval_time": {"value": 20.482}, "meta_eval_prompt_tokens": {"value": 5800.0}, "meta_eval_completion_tokens": {"value": 1535.0}, "meta_eval_prompt_cost": {"value": 0.001856}, "meta_eval_completion_cost": {"value": 0.0019648}}, "created": "2025-12-10T21:39:11.0599204Z"}
{"ref": "TQ78", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.67167206389375}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.885305}, "meta_inference_prompt_tokens": {"value": 12848.0}, "meta_inference_completion_tokens": {"value": 795.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025696}, "meta_inference_completion_cost": {"value": 0.001272}, "meta_eval_time": {"value": 21.342}, "meta_eval_prompt_tokens": {"value": 7057.0}, "meta_eval_completion_tokens": {"value": 2085.0}, "meta_eval_prompt_cost": {"value": 0.00225824}, "meta_eval_completion_cost": {"value": 0.0026688}}, "created": "2025-12-10T21:39:12.7175998Z"}
{"ref": "TQ79", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.814724}, "meta_inference_prompt_tokens": {"value": 13838.0}, "meta_inference_completion_tokens": {"value": 934.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027676}, "meta_inference_completion_cost": {"value": 0.0014944}, "meta_eval_time": {"value": 21.379}, "meta_eval_prompt_tokens": {"value": 8209.0}, "meta_eval_completion_tokens": {"value": 1949.0}, "meta_eval_prompt_cost": {"value": 0.00262688}, "meta_eval_completion_cost": {"value": 0.00249472}}, "created": "2025-12-10T21:39:13.3775554Z"}
{"ref": "TQ75", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.630341}, "meta_inference_prompt_tokens": {"value": 9593.0}, "meta_inference_completion_tokens": {"value": 966.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019186}, "meta_inference_completion_cost": {"value": 0.0015456}, "meta_eval_time": {"value": 23.96}, "meta_eval_prompt_tokens": {"value": 4694.0}, "meta_eval_completion_tokens": {"value": 1987.0}, "meta_eval_prompt_cost": {"value": 0.00150208}, "meta_eval_completion_cost": {"value": 0.00254336}}, "created": "2025-12-10T21:39:13.7215791Z"}
{"ref": "TQ78", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.68954052044136}, "generation_faithfulness": {"value": 0.95}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.467121}, "meta_inference_prompt_tokens": {"value": 12994.0}, "meta_inference_completion_tokens": {"value": 1123.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025988}, "meta_inference_completion_cost": {"value": 0.0017968}, "meta_eval_time": {"value": 22.033}, "meta_eval_prompt_tokens": {"value": 7124.0}, "meta_eval_completion_tokens": {"value": 2047.0}, "meta_eval_prompt_cost": {"value": 0.00227968}, "meta_eval_completion_cost": {"value": 0.00262016}}, "created": "2025-12-10T21:39:13.7931564Z"}
{"ref": "TQ80", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.886852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.524914}, "meta_inference_prompt_tokens": {"value": 12120.0}, "meta_inference_completion_tokens": {"value": 791.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002424}, "meta_inference_completion_cost": {"value": 0.0012656}, "meta_eval_time": {"value": 15.642}, "meta_eval_prompt_tokens": {"value": 6303.0}, "meta_eval_completion_tokens": {"value": 1487.0}, "meta_eval_prompt_cost": {"value": 0.00201696}, "meta_eval_completion_cost": {"value": 0.00190336}}, "created": "2025-12-10T21:39:15.3781076Z"}
{"ref": "TQ8-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0833333333333333}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 30.366937}, "meta_inference_prompt_tokens": {"value": 23229.0}, "meta_inference_completion_tokens": {"value": 1347.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0046458}, "meta_inference_completion_cost": {"value": 0.0021552}, "meta_eval_time": {"value": 17.506}, "meta_eval_prompt_tokens": {"value": 9522.0}, "meta_eval_completion_tokens": {"value": 1691.0}, "meta_eval_prompt_cost": {"value": 0.00304704}, "meta_eval_completion_cost": {"value": 0.00216448}}, "created": "2025-12-10T21:39:15.6205308Z"}
{"ref": "TQ79", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.392321}, "meta_inference_prompt_tokens": {"value": 15492.0}, "meta_inference_completion_tokens": {"value": 819.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030984}, "meta_inference_completion_cost": {"value": 0.0013104}, "meta_eval_time": {"value": 21.828}, "meta_eval_prompt_tokens": {"value": 9821.0}, "meta_eval_completion_tokens": {"value": 1936.0}, "meta_eval_prompt_cost": {"value": 0.00314272}, "meta_eval_completion_cost": {"value": 0.00247808}}, "created": "2025-12-10T21:39:15.9718792Z"}
{"ref": "TQ8-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0625}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 30.711569}, "meta_inference_prompt_tokens": {"value": 26634.0}, "meta_inference_completion_tokens": {"value": 1152.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0053268}, "meta_inference_completion_cost": {"value": 0.0018432}, "meta_eval_time": {"value": 17.178}, "meta_eval_prompt_tokens": {"value": 11347.0}, "meta_eval_completion_tokens": {"value": 1486.0}, "meta_eval_prompt_cost": {"value": 0.00363104}, "meta_eval_completion_cost": {"value": 0.00190208}}, "created": "2025-12-10T21:39:17.2569067Z"}
{"ref": "TQ78", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.68954052044136}, "generation_faithfulness": {"value": 0.736842105263158}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.36455}, "meta_inference_prompt_tokens": {"value": 13238.0}, "meta_inference_completion_tokens": {"value": 1276.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026476}, "meta_inference_completion_cost": {"value": 0.0020416}, "meta_eval_time": {"value": 23.736}, "meta_eval_prompt_tokens": {"value": 7392.0}, "meta_eval_completion_tokens": {"value": 2182.0}, "meta_eval_prompt_cost": {"value": 0.00236544}, "meta_eval_completion_cost": {"value": 0.00279296}}, "created": "2025-12-10T21:39:17.6415021Z"}
{"ref": "TQ82", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.8}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.666666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.371701}, "meta_inference_prompt_tokens": {"value": 6532.0}, "meta_inference_completion_tokens": {"value": 541.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0013064}, "meta_inference_completion_cost": {"value": 0.0008656}, "meta_eval_time": {"value": 10.858}, "meta_eval_prompt_tokens": {"value": 2900.0}, "meta_eval_completion_tokens": {"value": 975.0}, "meta_eval_prompt_cost": {"value": 0.000928}, "meta_eval_completion_cost": {"value": 0.001248}}, "created": "2025-12-10T21:39:17.6796333Z"}
{"ref": "TQ80", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.196512}, "meta_inference_prompt_tokens": {"value": 13375.0}, "meta_inference_completion_tokens": {"value": 628.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002675}, "meta_inference_completion_cost": {"value": 0.0010048}, "meta_eval_time": {"value": 18.454}, "meta_eval_prompt_tokens": {"value": 7444.0}, "meta_eval_completion_tokens": {"value": 1600.0}, "meta_eval_prompt_cost": {"value": 0.00238208}, "meta_eval_completion_cost": {"value": 0.002048}}, "created": "2025-12-10T21:39:17.7149446Z"}
{"ref": "TQ82", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.257337}, "meta_inference_prompt_tokens": {"value": 7278.0}, "meta_inference_completion_tokens": {"value": 335.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0014556}, "meta_inference_completion_cost": {"value": 0.000536}, "meta_eval_time": {"value": 12.605}, "meta_eval_prompt_tokens": {"value": 3383.0}, "meta_eval_completion_tokens": {"value": 965.0}, "meta_eval_prompt_cost": {"value": 0.00108256}, "meta_eval_completion_cost": {"value": 0.0012352}}, "created": "2025-12-10T21:39:18.2998403Z"}
{"ref": "TQ81", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.538085}, "meta_inference_prompt_tokens": {"value": 11581.0}, "meta_inference_completion_tokens": {"value": 825.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023162}, "meta_inference_completion_cost": {"value": 0.00132}, "meta_eval_time": {"value": 16.39}, "meta_eval_prompt_tokens": {"value": 5862.0}, "meta_eval_completion_tokens": {"value": 1416.0}, "meta_eval_prompt_cost": {"value": 0.00187584}, "meta_eval_completion_cost": {"value": 0.00181248}}, "created": "2025-12-10T21:39:18.3324095Z"}
{"ref": "TQ80", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.720186140567875}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.132831}, "meta_inference_prompt_tokens": {"value": 15320.0}, "meta_inference_completion_tokens": {"value": 772.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003064}, "meta_inference_completion_cost": {"value": 0.0012352}, "meta_eval_time": {"value": 17.37}, "meta_eval_prompt_tokens": {"value": 9015.0}, "meta_eval_completion_tokens": {"value": 1535.0}, "meta_eval_prompt_cost": {"value": 0.0028848}, "meta_eval_completion_cost": {"value": 0.0019648}}, "created": "2025-12-10T21:39:18.7573853Z"}
{"ref": "TQ78", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.222222222222222}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.404239}, "meta_inference_prompt_tokens": {"value": 11444.0}, "meta_inference_completion_tokens": {"value": 953.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022888}, "meta_inference_completion_cost": {"value": 0.0015248}, "meta_eval_time": {"value": 22.937}, "meta_eval_prompt_tokens": {"value": 6073.0}, "meta_eval_completion_tokens": {"value": 2020.0}, "meta_eval_prompt_cost": {"value": 0.00194336}, "meta_eval_completion_cost": {"value": 0.0025856}}, "created": "2025-12-10T21:39:19.892313Z"}
{"ref": "TQ8-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0909090909090909}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 30.274996}, "meta_inference_prompt_tokens": {"value": 21849.0}, "meta_inference_completion_tokens": {"value": 1191.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0043698}, "meta_inference_completion_cost": {"value": 0.0019056}, "meta_eval_time": {"value": 19.065}, "meta_eval_prompt_tokens": {"value": 8601.0}, "meta_eval_completion_tokens": {"value": 1747.0}, "meta_eval_prompt_cost": {"value": 0.00275232}, "meta_eval_completion_cost": {"value": 0.00223616}}, "created": "2025-12-10T21:39:20.2627345Z"}
{"ref": "TQ8-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 49.770551}, "meta_inference_prompt_tokens": {"value": 9428.0}, "meta_inference_completion_tokens": {"value": 767.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018856}, "meta_inference_completion_cost": {"value": 0.0012272}, "meta_eval_time": {"value": 17.432}, "meta_eval_prompt_tokens": {"value": 5628.0}, "meta_eval_completion_tokens": {"value": 1554.0}, "meta_eval_prompt_cost": {"value": 0.00180096}, "meta_eval_completion_cost": {"value": 0.00198912}}, "created": "2025-12-10T21:39:20.9833598Z"}
{"ref": "TQ78", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.74305999434256}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.353725}, "meta_inference_prompt_tokens": {"value": 12634.0}, "meta_inference_completion_tokens": {"value": 947.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025268}, "meta_inference_completion_cost": {"value": 0.0015152}, "meta_eval_time": {"value": 27.505}, "meta_eval_prompt_tokens": {"value": 6594.0}, "meta_eval_completion_tokens": {"value": 1905.0}, "meta_eval_prompt_cost": {"value": 0.00211008}, "meta_eval_completion_cost": {"value": 0.0024384}}, "created": "2025-12-10T21:39:21.2038413Z"}
{"ref": "TQ8-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.64879821011906}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.754716981132076}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.133333333333333}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 26.678042}, "meta_inference_prompt_tokens": {"value": 25220.0}, "meta_inference_completion_tokens": {"value": 1210.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.005044}, "meta_inference_completion_cost": {"value": 0.001936}, "meta_eval_time": {"value": 21.576}, "meta_eval_prompt_tokens": {"value": 11139.0}, "meta_eval_completion_tokens": {"value": 1730.0}, "meta_eval_prompt_cost": {"value": 0.00356448}, "meta_eval_completion_cost": {"value": 0.0022144}}, "created": "2025-12-10T21:39:22.0481473Z"}
{"ref": "TQ81", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.777777777777778}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.042461}, "meta_inference_prompt_tokens": {"value": 12104.0}, "meta_inference_completion_tokens": {"value": 700.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024208}, "meta_inference_completion_cost": {"value": 0.00112}, "meta_eval_time": {"value": 15.47}, "meta_eval_prompt_tokens": {"value": 5847.0}, "meta_eval_completion_tokens": {"value": 1164.0}, "meta_eval_prompt_cost": {"value": 0.00187104}, "meta_eval_completion_cost": {"value": 0.00148992}}, "created": "2025-12-10T21:39:22.7822308Z"}
{"ref": "TQ90-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 15.384456}, "meta_inference_prompt_tokens": {"value": 9734.0}, "meta_inference_completion_tokens": {"value": 628.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019468}, "meta_inference_completion_cost": {"value": 0.0010048}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:39:22.8293851Z"}
{"ref": "TQ80", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.746141434859122}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.88098}, "meta_inference_prompt_tokens": {"value": 13280.0}, "meta_inference_completion_tokens": {"value": 788.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002656}, "meta_inference_completion_cost": {"value": 0.0012608}, "meta_eval_time": {"value": 21.646}, "meta_eval_prompt_tokens": {"value": 7309.0}, "meta_eval_completion_tokens": {"value": 1667.0}, "meta_eval_prompt_cost": {"value": 0.00233888}, "meta_eval_completion_cost": {"value": 0.00213376}}, "created": "2025-12-10T21:39:24.4198922Z"}
{"ref": "TQ82", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.8}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.666666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.731161}, "meta_inference_prompt_tokens": {"value": 6517.0}, "meta_inference_completion_tokens": {"value": 392.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0013034}, "meta_inference_completion_cost": {"value": 0.0006272}, "meta_eval_time": {"value": 18.133}, "meta_eval_prompt_tokens": {"value": 3095.0}, "meta_eval_completion_tokens": {"value": 1410.0}, "meta_eval_prompt_cost": {"value": 0.0009904}, "meta_eval_completion_cost": {"value": 0.0018048}}, "created": "2025-12-10T21:39:24.4476143Z"}
{"ref": "TQ90-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 28.966523}, "meta_inference_prompt_tokens": {"value": 13573.0}, "meta_inference_completion_tokens": {"value": 1225.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0027146}, "meta_inference_completion_cost": {"value": 0.00196}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:39:24.4857765Z"}
{"ref": "TQ90-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 16.669655}, "meta_inference_prompt_tokens": {"value": 8249.0}, "meta_inference_completion_tokens": {"value": 582.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0016498}, "meta_inference_completion_cost": {"value": 0.0009312}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:39:24.5253705Z"}
{"ref": "TQ83", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 25.025765}, "meta_inference_prompt_tokens": {"value": 12936.0}, "meta_inference_completion_tokens": {"value": 1016.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025872}, "meta_inference_completion_cost": {"value": 0.0016256}, "meta_eval_time": {"value": 15.518}, "meta_eval_prompt_tokens": {"value": 7746.0}, "meta_eval_completion_tokens": {"value": 1176.0}, "meta_eval_prompt_cost": {"value": 0.00247872}, "meta_eval_completion_cost": {"value": 0.00150528}}, "created": "2025-12-10T21:39:24.9133462Z"}
{"ref": "TQ81", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.090466}, "meta_inference_prompt_tokens": {"value": 11507.0}, "meta_inference_completion_tokens": {"value": 776.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023014}, "meta_inference_completion_cost": {"value": 0.0012416}, "meta_eval_time": {"value": 21.483}, "meta_eval_prompt_tokens": {"value": 5993.0}, "meta_eval_completion_tokens": {"value": 1714.0}, "meta_eval_prompt_cost": {"value": 0.00191776}, "meta_eval_completion_cost": {"value": 0.00219392}}, "created": "2025-12-10T21:39:26.0153526Z"}
{"ref": "TQ90-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 26.184812}, "meta_inference_prompt_tokens": {"value": 12481.0}, "meta_inference_completion_tokens": {"value": 598.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024962}, "meta_inference_completion_cost": {"value": 0.0009568}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:39:26.0575852Z"}
{"ref": "TQ80", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.70231768402027}, "generation_faithfulness": {"value": 0.944444444444444}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.62318}, "meta_inference_prompt_tokens": {"value": 12216.0}, "meta_inference_completion_tokens": {"value": 966.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024432}, "meta_inference_completion_cost": {"value": 0.0015456}, "meta_eval_time": {"value": 22.262}, "meta_eval_prompt_tokens": {"value": 6762.0}, "meta_eval_completion_tokens": {"value": 2077.0}, "meta_eval_prompt_cost": {"value": 0.00216384}, "meta_eval_completion_cost": {"value": 0.00265856}}, "created": "2025-12-10T21:39:26.3917345Z"}
{"ref": "TQ90-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 19.656804}, "meta_inference_prompt_tokens": {"value": 5294.0}, "meta_inference_completion_tokens": {"value": 833.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0010588}, "meta_inference_completion_cost": {"value": 0.0013328}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:39:26.4310016Z"}
{"ref": "TQ81", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.127159}, "meta_inference_prompt_tokens": {"value": 11638.0}, "meta_inference_completion_tokens": {"value": 1061.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023276}, "meta_inference_completion_cost": {"value": 0.0016976}, "meta_eval_time": {"value": 21.425}, "meta_eval_prompt_tokens": {"value": 6401.0}, "meta_eval_completion_tokens": {"value": 1834.0}, "meta_eval_prompt_cost": {"value": 0.00204832}, "meta_eval_completion_cost": {"value": 0.00234752}}, "created": "2025-12-10T21:39:26.793304Z"}
{"ref": "TQ81", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.06160631164485}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.268791}, "meta_inference_prompt_tokens": {"value": 11940.0}, "meta_inference_completion_tokens": {"value": 1159.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002388}, "meta_inference_completion_cost": {"value": 0.0018544}, "meta_eval_time": {"value": 21.73}, "meta_eval_prompt_tokens": {"value": 6343.0}, "meta_eval_completion_tokens": {"value": 1943.0}, "meta_eval_prompt_cost": {"value": 0.00202976}, "meta_eval_completion_cost": {"value": 0.00248704}}, "created": "2025-12-10T21:39:26.9656817Z"}
{"ref": "TQ86", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.356453}, "meta_inference_prompt_tokens": {"value": 9972.0}, "meta_inference_completion_tokens": {"value": 734.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019944}, "meta_inference_completion_cost": {"value": 0.0011744}, "meta_eval_time": {"value": 14.904}, "meta_eval_prompt_tokens": {"value": 4487.0}, "meta_eval_completion_tokens": {"value": 1179.0}, "meta_eval_prompt_cost": {"value": 0.00143584}, "meta_eval_completion_cost": {"value": 0.00150912}}, "created": "2025-12-10T21:39:28.7364602Z"}
{"ref": "TQ83", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 21.763252}, "meta_inference_prompt_tokens": {"value": 12732.0}, "meta_inference_completion_tokens": {"value": 985.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025464}, "meta_inference_completion_cost": {"value": 0.001576}, "meta_eval_time": {"value": 20.219}, "meta_eval_prompt_tokens": {"value": 7524.0}, "meta_eval_completion_tokens": {"value": 1773.0}, "meta_eval_prompt_cost": {"value": 0.00240768}, "meta_eval_completion_cost": {"value": 0.00226944}}, "created": "2025-12-10T21:39:28.7828276Z"}
{"ref": "TQ83", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.111111111111111}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 22.324048}, "meta_inference_prompt_tokens": {"value": 12215.0}, "meta_inference_completion_tokens": {"value": 1092.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002443}, "meta_inference_completion_cost": {"value": 0.0017472}, "meta_eval_time": {"value": 23.274}, "meta_eval_prompt_tokens": {"value": 7782.0}, "meta_eval_completion_tokens": {"value": 2113.0}, "meta_eval_prompt_cost": {"value": 0.00249024}, "meta_eval_completion_cost": {"value": 0.00270464}}, "created": "2025-12-10T21:39:28.8615364Z"}
{"ref": "TQ82", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 43.983685}, "meta_inference_prompt_tokens": {"value": 8375.0}, "meta_inference_completion_tokens": {"value": 651.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001675}, "meta_inference_completion_cost": {"value": 0.0010416}, "meta_eval_time": {"value": 20.615}, "meta_eval_prompt_tokens": {"value": 4745.0}, "meta_eval_completion_tokens": {"value": 1725.0}, "meta_eval_prompt_cost": {"value": 0.0015184}, "meta_eval_completion_cost": {"value": 0.002208}}, "created": "2025-12-10T21:39:28.8916919Z"}
{"ref": "TQ86", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.829496}, "meta_inference_prompt_tokens": {"value": 10131.0}, "meta_inference_completion_tokens": {"value": 695.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020262}, "meta_inference_completion_cost": {"value": 0.001112}, "meta_eval_time": {"value": 13.067}, "meta_eval_prompt_tokens": {"value": 4766.0}, "meta_eval_completion_tokens": {"value": 1322.0}, "meta_eval_prompt_cost": {"value": 0.00152512}, "meta_eval_completion_cost": {"value": 0.00169216}}, "created": "2025-12-10T21:39:29.0797066Z"}
{"ref": "TQ66", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 0.970588235294118}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.430313}, "meta_inference_prompt_tokens": {"value": 12064.0}, "meta_inference_completion_tokens": {"value": 1903.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024128}, "meta_inference_completion_cost": {"value": 0.0030448}, "meta_eval_time": {"value": 61.15}, "meta_eval_prompt_tokens": {"value": 9421.0}, "meta_eval_completion_tokens": {"value": 5939.0}, "meta_eval_prompt_cost": {"value": 0.00301472}, "meta_eval_completion_cost": {"value": 0.00760192}}, "created": "2025-12-10T21:39:29.628857Z"}
{"ref": "TQ86", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.680091}, "meta_inference_prompt_tokens": {"value": 9256.0}, "meta_inference_completion_tokens": {"value": 667.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018512}, "meta_inference_completion_cost": {"value": 0.0010672}, "meta_eval_time": {"value": 15.501}, "meta_eval_prompt_tokens": {"value": 4119.0}, "meta_eval_completion_tokens": {"value": 1441.0}, "meta_eval_prompt_cost": {"value": 0.00131808}, "meta_eval_completion_cost": {"value": 0.00184448}}, "created": "2025-12-10T21:39:31.1629205Z"}
{"ref": "TQ83", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 24.771699}, "meta_inference_prompt_tokens": {"value": 15553.0}, "meta_inference_completion_tokens": {"value": 1228.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031106}, "meta_inference_completion_cost": {"value": 0.0019648}, "meta_eval_time": {"value": 21.01}, "meta_eval_prompt_tokens": {"value": 10706.0}, "meta_eval_completion_tokens": {"value": 1837.0}, "meta_eval_prompt_cost": {"value": 0.00342592}, "meta_eval_completion_cost": {"value": 0.00235136}}, "created": "2025-12-10T21:39:31.347827Z"}
{"ref": "TQ86", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 70.93829}, "meta_inference_prompt_tokens": {"value": 9318.0}, "meta_inference_completion_tokens": {"value": 644.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018636}, "meta_inference_completion_cost": {"value": 0.0010304}, "meta_eval_time": {"value": 13.932}, "meta_eval_prompt_tokens": {"value": 3902.0}, "meta_eval_completion_tokens": {"value": 1173.0}, "meta_eval_prompt_cost": {"value": 0.00124864}, "meta_eval_completion_cost": {"value": 0.00150144}}, "created": "2025-12-10T21:39:31.6129194Z"}
{"ref": "TQ89", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.84105}, "meta_inference_prompt_tokens": {"value": 11644.0}, "meta_inference_completion_tokens": {"value": 1813.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023288}, "meta_inference_completion_cost": {"value": 0.0029008}, "meta_eval_time": {"value": 13.332}, "meta_eval_prompt_tokens": {"value": 6028.0}, "meta_eval_completion_tokens": {"value": 1056.0}, "meta_eval_prompt_cost": {"value": 0.00192896}, "meta_eval_completion_cost": {"value": 0.00135168}}, "created": "2025-12-10T21:39:31.7051014Z"}
{"ref": "TQ84", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 47.92616}, "meta_inference_prompt_tokens": {"value": 6867.0}, "meta_inference_completion_tokens": {"value": 745.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0013734}, "meta_inference_completion_cost": {"value": 0.001192}, "meta_eval_time": {"value": 20.961}, "meta_eval_prompt_tokens": {"value": 3632.0}, "meta_eval_completion_tokens": {"value": 1695.0}, "meta_eval_prompt_cost": {"value": 0.00116224}, "meta_eval_completion_cost": {"value": 0.0021696}}, "created": "2025-12-10T21:39:32.0350733Z"}
{"ref": "TQ83", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 19.158333}, "meta_inference_prompt_tokens": {"value": 12676.0}, "meta_inference_completion_tokens": {"value": 979.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025352}, "meta_inference_completion_cost": {"value": 0.0015664}, "meta_eval_time": {"value": 22.151}, "meta_eval_prompt_tokens": {"value": 7731.0}, "meta_eval_completion_tokens": {"value": 1946.0}, "meta_eval_prompt_cost": {"value": 0.00247392}, "meta_eval_completion_cost": {"value": 0.00249088}}, "created": "2025-12-10T21:39:32.4736097Z"}
{"ref": "TQ87", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.641158}, "meta_inference_prompt_tokens": {"value": 12491.0}, "meta_inference_completion_tokens": {"value": 984.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024982}, "meta_inference_completion_cost": {"value": 0.0015744}, "meta_eval_time": {"value": 15.826}, "meta_eval_prompt_tokens": {"value": 6733.0}, "meta_eval_completion_tokens": {"value": 1184.0}, "meta_eval_prompt_cost": {"value": 0.00215456}, "meta_eval_completion_cost": {"value": 0.00151552}}, "created": "2025-12-10T21:39:33.1217472Z"}
{"ref": "TQ89", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.303194}, "meta_inference_prompt_tokens": {"value": 12485.0}, "meta_inference_completion_tokens": {"value": 629.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002497}, "meta_inference_completion_cost": {"value": 0.0010064}, "meta_eval_time": {"value": 7.919}, "meta_eval_prompt_tokens": {"value": 6545.0}, "meta_eval_completion_tokens": {"value": 709.0}, "meta_eval_prompt_cost": {"value": 0.0020944}, "meta_eval_completion_cost": {"value": 0.00090752}}, "created": "2025-12-10T21:39:34.3871724Z"}
{"ref": "TQ87", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.787233}, "meta_inference_prompt_tokens": {"value": 14062.0}, "meta_inference_completion_tokens": {"value": 826.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028124}, "meta_inference_completion_cost": {"value": 0.0013216}, "meta_eval_time": {"value": 16.764}, "meta_eval_prompt_tokens": {"value": 8469.0}, "meta_eval_completion_tokens": {"value": 1492.0}, "meta_eval_prompt_cost": {"value": 0.00271008}, "meta_eval_completion_cost": {"value": 0.00190976}}, "created": "2025-12-10T21:39:34.4817671Z"}
{"ref": "TQ84", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.260869565217391}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 31.64946}, "meta_inference_prompt_tokens": {"value": 13227.0}, "meta_inference_completion_tokens": {"value": 1628.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026454}, "meta_inference_completion_cost": {"value": 0.0026048}, "meta_eval_time": {"value": 26.081}, "meta_eval_prompt_tokens": {"value": 7441.0}, "meta_eval_completion_tokens": {"value": 2447.0}, "meta_eval_prompt_cost": {"value": 0.00238112}, "meta_eval_completion_cost": {"value": 0.00313216}}, "created": "2025-12-10T21:39:34.9942341Z"}
{"ref": "TQ84", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.904761904761905}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 18.113534}, "meta_inference_prompt_tokens": {"value": 13872.0}, "meta_inference_completion_tokens": {"value": 1168.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027744}, "meta_inference_completion_cost": {"value": 0.0018688}, "meta_eval_time": {"value": 25.129}, "meta_eval_prompt_tokens": {"value": 8180.0}, "meta_eval_completion_tokens": {"value": 2400.0}, "meta_eval_prompt_cost": {"value": 0.0026176}, "meta_eval_completion_cost": {"value": 0.003072}}, "created": "2025-12-10T21:39:35.2996066Z"}
{"ref": "TQ87", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.846153846153846}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.330765}, "meta_inference_prompt_tokens": {"value": 12638.0}, "meta_inference_completion_tokens": {"value": 1098.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025276}, "meta_inference_completion_cost": {"value": 0.0017568}, "meta_eval_time": {"value": 17.895}, "meta_eval_prompt_tokens": {"value": 7109.0}, "meta_eval_completion_tokens": {"value": 1627.0}, "meta_eval_prompt_cost": {"value": 0.00227488}, "meta_eval_completion_cost": {"value": 0.00208256}}, "created": "2025-12-10T21:39:35.6471061Z"}
{"ref": "TQ89", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.727272727272727}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 50.53301}, "meta_inference_prompt_tokens": {"value": 12461.0}, "meta_inference_completion_tokens": {"value": 1308.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024922}, "meta_inference_completion_cost": {"value": 0.0020928}, "meta_eval_time": {"value": 14.889}, "meta_eval_prompt_tokens": {"value": 6884.0}, "meta_eval_completion_tokens": {"value": 1355.0}, "meta_eval_prompt_cost": {"value": 0.00220288}, "meta_eval_completion_cost": {"value": 0.0017344}}, "created": "2025-12-10T21:39:36.0429374Z"}
{"ref": "TQ87", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.304399}, "meta_inference_prompt_tokens": {"value": 13211.0}, "meta_inference_completion_tokens": {"value": 1043.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026422}, "meta_inference_completion_cost": {"value": 0.0016688}, "meta_eval_time": {"value": 17.5}, "meta_eval_prompt_tokens": {"value": 7603.0}, "meta_eval_completion_tokens": {"value": 1714.0}, "meta_eval_prompt_cost": {"value": 0.00243296}, "meta_eval_completion_cost": {"value": 0.00219392}}, "created": "2025-12-10T21:39:36.296276Z"}
{"ref": "TQ89", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.348902}, "meta_inference_prompt_tokens": {"value": 12495.0}, "meta_inference_completion_tokens": {"value": 1583.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002499}, "meta_inference_completion_cost": {"value": 0.0025328}, "meta_eval_time": {"value": 16.053}, "meta_eval_prompt_tokens": {"value": 6936.0}, "meta_eval_completion_tokens": {"value": 1373.0}, "meta_eval_prompt_cost": {"value": 0.00221952}, "meta_eval_completion_cost": {"value": 0.00175744}}, "created": "2025-12-10T21:39:36.3745273Z"}
{"ref": "TQ84", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.260869565217391}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 22.213784}, "meta_inference_prompt_tokens": {"value": 13217.0}, "meta_inference_completion_tokens": {"value": 1154.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026434}, "meta_inference_completion_cost": {"value": 0.0018464}, "meta_eval_time": {"value": 23.092}, "meta_eval_prompt_tokens": {"value": 7125.0}, "meta_eval_completion_tokens": {"value": 2082.0}, "meta_eval_prompt_cost": {"value": 0.00228}, "meta_eval_completion_cost": {"value": 0.00266496}}, "created": "2025-12-10T21:39:36.8524432Z"}
{"ref": "TQ85", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.111111111111111}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 24.973589}, "meta_inference_prompt_tokens": {"value": 14497.0}, "meta_inference_completion_tokens": {"value": 1231.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028994}, "meta_inference_completion_cost": {"value": 0.0019696}, "meta_eval_time": {"value": 22.239}, "meta_eval_prompt_tokens": {"value": 9241.0}, "meta_eval_completion_tokens": {"value": 2274.0}, "meta_eval_prompt_cost": {"value": 0.00295712}, "meta_eval_completion_cost": {"value": 0.00291072}}, "created": "2025-12-10T21:39:37.6610624Z"}
{"ref": "TQ85", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.954545454545454}, "generation_factuality_f1": {"value": 0.307692307692308}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 18.918726}, "meta_inference_prompt_tokens": {"value": 13661.0}, "meta_inference_completion_tokens": {"value": 869.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027322}, "meta_inference_completion_cost": {"value": 0.0013904}, "meta_eval_time": {"value": 27.275}, "meta_eval_prompt_tokens": {"value": 8600.0}, "meta_eval_completion_tokens": {"value": 2549.0}, "meta_eval_prompt_cost": {"value": 0.002752}, "meta_eval_completion_cost": {"value": 0.00326272}}, "created": "2025-12-10T21:39:38.0740316Z"}
{"ref": "TQ87", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.533566}, "meta_inference_prompt_tokens": {"value": 13050.0}, "meta_inference_completion_tokens": {"value": 871.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00261}, "meta_inference_completion_cost": {"value": 0.0013936}, "meta_eval_time": {"value": 20.376}, "meta_eval_prompt_tokens": {"value": 7599.0}, "meta_eval_completion_tokens": {"value": 1837.0}, "meta_eval_prompt_cost": {"value": 0.00243168}, "meta_eval_completion_cost": {"value": 0.00235136}}, "created": "2025-12-10T21:39:38.7380635Z"}
{"ref": "TQ86", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.531802}, "meta_inference_prompt_tokens": {"value": 9114.0}, "meta_inference_completion_tokens": {"value": 738.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018228}, "meta_inference_completion_cost": {"value": 0.0011808}, "meta_eval_time": {"value": 17.784}, "meta_eval_prompt_tokens": {"value": 3979.0}, "meta_eval_completion_tokens": {"value": 1604.0}, "meta_eval_prompt_cost": {"value": 0.00127328}, "meta_eval_completion_cost": {"value": 0.00205312}}, "created": "2025-12-10T21:39:42.3465309Z"}
{"ref": "TQ84", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.98713694067948}, "generation_faithfulness": {"value": 0.967741935483871}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.385803}, "meta_inference_prompt_tokens": {"value": 14407.0}, "meta_inference_completion_tokens": {"value": 1324.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028814}, "meta_inference_completion_cost": {"value": 0.0021184}, "meta_eval_time": {"value": 32.248}, "meta_eval_prompt_tokens": {"value": 8974.0}, "meta_eval_completion_tokens": {"value": 2986.0}, "meta_eval_prompt_cost": {"value": 0.00287168}, "meta_eval_completion_cost": {"value": 0.00382208}}, "created": "2025-12-10T21:39:43.353508Z"}
{"ref": "TQ91", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.789064826317888}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.889823}, "meta_inference_prompt_tokens": {"value": 10555.0}, "meta_inference_completion_tokens": {"value": 970.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002111}, "meta_inference_completion_cost": {"value": 0.001552}, "meta_eval_time": {"value": 14.683}, "meta_eval_prompt_tokens": {"value": 5172.0}, "meta_eval_completion_tokens": {"value": 1411.0}, "meta_eval_prompt_cost": {"value": 0.00165504}, "meta_eval_completion_cost": {"value": 0.00180608}}, "created": "2025-12-10T21:39:43.6114611Z"}
{"ref": "TQ91", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.007473}, "meta_inference_prompt_tokens": {"value": 10748.0}, "meta_inference_completion_tokens": {"value": 1166.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021496}, "meta_inference_completion_cost": {"value": 0.0018656}, "meta_eval_time": {"value": 14.95}, "meta_eval_prompt_tokens": {"value": 5240.0}, "meta_eval_completion_tokens": {"value": 1267.0}, "meta_eval_prompt_cost": {"value": 0.0016768}, "meta_eval_completion_cost": {"value": 0.00162176}}, "created": "2025-12-10T21:39:43.8517507Z"}
{"ref": "TQ91", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.165369}, "meta_inference_prompt_tokens": {"value": 11522.0}, "meta_inference_completion_tokens": {"value": 1329.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023044}, "meta_inference_completion_cost": {"value": 0.0021264}, "meta_eval_time": {"value": 17.943}, "meta_eval_prompt_tokens": {"value": 6296.0}, "meta_eval_completion_tokens": {"value": 1814.0}, "meta_eval_prompt_cost": {"value": 0.00201472}, "meta_eval_completion_cost": {"value": 0.00232192}}, "created": "2025-12-10T21:39:44.0636149Z"}
{"ref": "TQ89", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.566511}, "meta_inference_prompt_tokens": {"value": 12487.0}, "meta_inference_completion_tokens": {"value": 1511.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024974}, "meta_inference_completion_cost": {"value": 0.0024176}, "meta_eval_time": {"value": 19.932}, "meta_eval_prompt_tokens": {"value": 7101.0}, "meta_eval_completion_tokens": {"value": 1480.0}, "meta_eval_prompt_cost": {"value": 0.00227232}, "meta_eval_completion_cost": {"value": 0.0018944}}, "created": "2025-12-10T21:39:44.3909484Z"}
{"ref": "accepting-thorn", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.833281}, "meta_inference_prompt_tokens": {"value": 2262.0}, "meta_inference_completion_tokens": {"value": 687.0}, "meta_inference_prompt_cost": {"value": 0.0004524}, "meta_inference_completion_cost": {"value": 0.0010992}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:39:44.4354746Z"}
{"ref": "accepting-thorn", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.82023}, "meta_inference_prompt_tokens": {"value": 4672.0}, "meta_inference_completion_tokens": {"value": 1213.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009344}, "meta_inference_completion_cost": {"value": 0.0019408}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:39:44.4758904Z"}
{"ref": "TQ85", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.166666666666667}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 22.52687}, "meta_inference_prompt_tokens": {"value": 14004.0}, "meta_inference_completion_tokens": {"value": 1141.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028008}, "meta_inference_completion_cost": {"value": 0.0018256}, "meta_eval_time": {"value": 36.05}, "meta_eval_prompt_tokens": {"value": 9371.0}, "meta_eval_completion_tokens": {"value": 3069.0}, "meta_eval_prompt_cost": {"value": 0.00299872}, "meta_eval_completion_cost": {"value": 0.00392832}}, "created": "2025-12-10T21:39:47.0620468Z"}
{"ref": "accepting-thorn", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.746715}, "meta_inference_prompt_tokens": {"value": 4676.0}, "meta_inference_completion_tokens": {"value": 1593.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009352}, "meta_inference_completion_cost": {"value": 0.0025488}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:39:47.1308704Z"}
{"ref": "achromatic-molecule", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 7.632888}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 395.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.000632}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:39:47.1719304Z"}
{"ref": "achromatic-molecule", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 54.588041}, "meta_inference_prompt_tokens": {"value": 4632.0}, "meta_inference_completion_tokens": {"value": 1062.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009264}, "meta_inference_completion_cost": {"value": 0.0016992}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:39:47.2164074Z"}
{"ref": "achromatic-molecule", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 8.884272}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 328.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0005248}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:39:47.2594489Z"}
{"ref": "accepting-thorn", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.473289}, "meta_inference_prompt_tokens": {"value": 2262.0}, "meta_inference_completion_tokens": {"value": 664.0}, "meta_inference_prompt_cost": {"value": 0.0004524}, "meta_inference_completion_cost": {"value": 0.0010624}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:39:47.3001077Z"}
{"ref": "achromatic-molecule", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.388255}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 657.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0010512}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:39:47.3458778Z"}
{"ref": "TQ91", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.355305}, "meta_inference_prompt_tokens": {"value": 11336.0}, "meta_inference_completion_tokens": {"value": 1482.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022672}, "meta_inference_completion_cost": {"value": 0.0023712}, "meta_eval_time": {"value": 20.741}, "meta_eval_prompt_tokens": {"value": 6053.0}, "meta_eval_completion_tokens": {"value": 1862.0}, "meta_eval_prompt_cost": {"value": 0.00193696}, "meta_eval_completion_cost": {"value": 0.00238336}}, "created": "2025-12-10T21:39:47.7433588Z"}
{"ref": "TQ85", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.625}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 25.19381}, "meta_inference_prompt_tokens": {"value": 15286.0}, "meta_inference_completion_tokens": {"value": 1368.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030572}, "meta_inference_completion_cost": {"value": 0.0021888}, "meta_eval_time": {"value": 35.0}, "meta_eval_prompt_tokens": {"value": 10758.0}, "meta_eval_completion_tokens": {"value": 3216.0}, "meta_eval_prompt_cost": {"value": 0.00344256}, "meta_eval_completion_cost": {"value": 0.00411648}}, "created": "2025-12-10T21:39:47.7544774Z"}
{"ref": "accepting-thorn", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.18905}, "meta_inference_prompt_tokens": {"value": 4685.0}, "meta_inference_completion_tokens": {"value": 1167.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.000937}, "meta_inference_completion_cost": {"value": 0.0018672}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:39:47.8022836Z"}
{"ref": "TQ92", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 21.54784}, "meta_inference_prompt_tokens": {"value": 10049.0}, "meta_inference_completion_tokens": {"value": 1180.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020098}, "meta_inference_completion_cost": {"value": 0.001888}, "meta_eval_time": {"value": 18.607}, "meta_eval_prompt_tokens": {"value": 4910.0}, "meta_eval_completion_tokens": {"value": 1789.0}, "meta_eval_prompt_cost": {"value": 0.0015712}, "meta_eval_completion_cost": {"value": 0.00228992}}, "created": "2025-12-10T21:39:48.2962325Z"}
{"ref": "achromatic-molecule", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.578143}, "meta_inference_prompt_tokens": {"value": 4627.0}, "meta_inference_completion_tokens": {"value": 948.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009254}, "meta_inference_completion_cost": {"value": 0.0015168}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:39:48.3410148Z"}
{"ref": "TQ82", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.8}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.666666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.873221}, "meta_inference_prompt_tokens": {"value": 6528.0}, "meta_inference_completion_tokens": {"value": 694.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0013056}, "meta_inference_completion_cost": {"value": 0.0011104}, "meta_eval_time": {"value": 21.974}, "meta_eval_prompt_tokens": {"value": 3200.0}, "meta_eval_completion_tokens": {"value": 1539.0}, "meta_eval_prompt_cost": {"value": 0.001024}, "meta_eval_completion_cost": {"value": 0.00196992}}, "created": "2025-12-10T21:39:48.8302384Z"}
{"ref": "TQ92", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.210526315789474}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 26.945174}, "meta_inference_prompt_tokens": {"value": 10380.0}, "meta_inference_completion_tokens": {"value": 1194.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002076}, "meta_inference_completion_cost": {"value": 0.0019104}, "meta_eval_time": {"value": 20.092}, "meta_eval_prompt_tokens": {"value": 5482.0}, "meta_eval_completion_tokens": {"value": 2020.0}, "meta_eval_prompt_cost": {"value": 0.00175424}, "meta_eval_completion_cost": {"value": 0.0025856}}, "created": "2025-12-10T21:39:48.8717685Z"}
{"ref": "TQ92", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.413793103448276}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 22.152169}, "meta_inference_prompt_tokens": {"value": 11311.0}, "meta_inference_completion_tokens": {"value": 902.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022622}, "meta_inference_completion_cost": {"value": 0.0014432}, "meta_eval_time": {"value": 20.02}, "meta_eval_prompt_tokens": {"value": 6455.0}, "meta_eval_completion_tokens": {"value": 1962.0}, "meta_eval_prompt_cost": {"value": 0.0020656}, "meta_eval_completion_cost": {"value": 0.00251136}}, "created": "2025-12-10T21:39:49.1357199Z"}
{"ref": "TQ92", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.8125}, "generation_factuality_f1": {"value": 0.387096774193548}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 16.908081}, "meta_inference_prompt_tokens": {"value": 11424.0}, "meta_inference_completion_tokens": {"value": 895.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022848}, "meta_inference_completion_cost": {"value": 0.001432}, "meta_eval_time": {"value": 19.475}, "meta_eval_prompt_tokens": {"value": 6259.0}, "meta_eval_completion_tokens": {"value": 1836.0}, "meta_eval_prompt_cost": {"value": 0.00200288}, "meta_eval_completion_cost": {"value": 0.00235008}}, "created": "2025-12-10T21:39:50.6872961Z"}
{"ref": "TQ91", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.657237182772003}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.710881}, "meta_inference_prompt_tokens": {"value": 11505.0}, "meta_inference_completion_tokens": {"value": 1313.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002301}, "meta_inference_completion_cost": {"value": 0.0021008}, "meta_eval_time": {"value": 22.286}, "meta_eval_prompt_tokens": {"value": 6269.0}, "meta_eval_completion_tokens": {"value": 1637.0}, "meta_eval_prompt_cost": {"value": 0.00200608}, "meta_eval_completion_cost": {"value": 0.00209536}}, "created": "2025-12-10T21:39:51.117169Z"}
{"ref": "TQ98", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.850293}, "meta_inference_prompt_tokens": {"value": 5909.0}, "meta_inference_completion_tokens": {"value": 893.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0011818}, "meta_inference_completion_cost": {"value": 0.0014288}, "meta_eval_time": {"value": 16.446}, "meta_eval_prompt_tokens": {"value": 3192.0}, "meta_eval_completion_tokens": {"value": 1428.0}, "meta_eval_prompt_cost": {"value": 0.00102144}, "meta_eval_completion_cost": {"value": 0.00182784}}, "created": "2025-12-10T21:39:53.3454923Z"}
{"ref": "TQ85", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.428571428571429}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 27.569479}, "meta_inference_prompt_tokens": {"value": 13182.0}, "meta_inference_completion_tokens": {"value": 1423.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026364}, "meta_inference_completion_cost": {"value": 0.0022768}, "meta_eval_time": {"value": 40.466}, "meta_eval_prompt_tokens": {"value": 9222.0}, "meta_eval_completion_tokens": {"value": 4046.0}, "meta_eval_prompt_cost": {"value": 0.00295104}, "meta_eval_completion_cost": {"value": 0.00517888}}, "created": "2025-12-10T21:39:53.8993979Z"}
{"ref": "TQ92", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 21.210142}, "meta_inference_prompt_tokens": {"value": 10119.0}, "meta_inference_completion_tokens": {"value": 924.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020238}, "meta_inference_completion_cost": {"value": 0.0014784}, "meta_eval_time": {"value": 23.822}, "meta_eval_prompt_tokens": {"value": 5191.0}, "meta_eval_completion_tokens": {"value": 1917.0}, "meta_eval_prompt_cost": {"value": 0.00166112}, "meta_eval_completion_cost": {"value": 0.00245376}}, "created": "2025-12-10T21:39:55.2069923Z"}
{"ref": "TQ9", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.82151}, "meta_inference_prompt_tokens": {"value": 11196.0}, "meta_inference_completion_tokens": {"value": 1116.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022392}, "meta_inference_completion_cost": {"value": 0.0017856}, "meta_eval_time": {"value": 32.64}, "meta_eval_prompt_tokens": {"value": 7403.0}, "meta_eval_completion_tokens": {"value": 3126.0}, "meta_eval_prompt_cost": {"value": 0.00236896}, "meta_eval_completion_cost": {"value": 0.00400128}}, "created": "2025-12-10T21:39:55.5069325Z"}
{"ref": "TQ98", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.909226}, "meta_inference_prompt_tokens": {"value": 5909.0}, "meta_inference_completion_tokens": {"value": 739.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0011818}, "meta_inference_completion_cost": {"value": 0.0011824}, "meta_eval_time": {"value": 17.835}, "meta_eval_prompt_tokens": {"value": 3131.0}, "meta_eval_completion_tokens": {"value": 1472.0}, "meta_eval_prompt_cost": {"value": 0.00100192}, "meta_eval_completion_cost": {"value": 0.00188416}}, "created": "2025-12-10T21:40:00.2223124Z"}
{"ref": "TQ98", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.218329}, "meta_inference_prompt_tokens": {"value": 11470.0}, "meta_inference_completion_tokens": {"value": 795.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002294}, "meta_inference_completion_cost": {"value": 0.001272}, "meta_eval_time": {"value": 18.838}, "meta_eval_prompt_tokens": {"value": 6252.0}, "meta_eval_completion_tokens": {"value": 1592.0}, "meta_eval_prompt_cost": {"value": 0.00200064}, "meta_eval_completion_cost": {"value": 0.00203776}}, "created": "2025-12-10T21:40:01.5811632Z"}
{"ref": "TQ96", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 0.863636363636364}, "generation_factuality_f1": {"value": 0.307692307692308}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 23.998086}, "meta_inference_prompt_tokens": {"value": 11896.0}, "meta_inference_completion_tokens": {"value": 1440.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023792}, "meta_inference_completion_cost": {"value": 0.002304}, "meta_eval_time": {"value": 29.359}, "meta_eval_prompt_tokens": {"value": 7538.0}, "meta_eval_completion_tokens": {"value": 2535.0}, "meta_eval_prompt_cost": {"value": 0.00241216}, "meta_eval_completion_cost": {"value": 0.0032448}}, "created": "2025-12-10T21:40:01.8736292Z"}
{"ref": "TQ98", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.785714285714286}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.699488}, "meta_inference_prompt_tokens": {"value": 9765.0}, "meta_inference_completion_tokens": {"value": 921.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001953}, "meta_inference_completion_cost": {"value": 0.0014736}, "meta_eval_time": {"value": 26.517}, "meta_eval_prompt_tokens": {"value": 5083.0}, "meta_eval_completion_tokens": {"value": 1617.0}, "meta_eval_prompt_cost": {"value": 0.00162656}, "meta_eval_completion_cost": {"value": 0.00206976}}, "created": "2025-12-10T21:40:02.6005358Z"}
{"ref": "TQ9", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.705037}, "meta_inference_prompt_tokens": {"value": 11217.0}, "meta_inference_completion_tokens": {"value": 1870.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022434}, "meta_inference_completion_cost": {"value": 0.002992}, "meta_eval_time": {"value": 45.247}, "meta_eval_prompt_tokens": {"value": 8177.0}, "meta_eval_completion_tokens": {"value": 4324.0}, "meta_eval_prompt_cost": {"value": 0.00261664}, "meta_eval_completion_cost": {"value": 0.00553472}}, "created": "2025-12-10T21:40:05.1789521Z"}
{"ref": "TQ98", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.506733}, "meta_inference_prompt_tokens": {"value": 13589.0}, "meta_inference_completion_tokens": {"value": 827.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027178}, "meta_inference_completion_cost": {"value": 0.0013232}, "meta_eval_time": {"value": 21.634}, "meta_eval_prompt_tokens": {"value": 8014.0}, "meta_eval_completion_tokens": {"value": 1735.0}, "meta_eval_prompt_cost": {"value": 0.00256448}, "meta_eval_completion_cost": {"value": 0.0022208}}, "created": "2025-12-10T21:40:05.7730049Z"}
{"ref": "TQ9", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.836637}, "meta_inference_prompt_tokens": {"value": 10948.0}, "meta_inference_completion_tokens": {"value": 1520.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021896}, "meta_inference_completion_cost": {"value": 0.002432}, "meta_eval_time": {"value": 43.89}, "meta_eval_prompt_tokens": {"value": 7882.0}, "meta_eval_completion_tokens": {"value": 4321.0}, "meta_eval_prompt_cost": {"value": 0.00252224}, "meta_eval_completion_cost": {"value": 0.00553088}}, "created": "2025-12-10T21:40:05.9882256Z"}
{"ref": "TQ9", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 0.897435897435898}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 47.12074}, "meta_inference_prompt_tokens": {"value": 11210.0}, "meta_inference_completion_tokens": {"value": 2533.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002242}, "meta_inference_completion_cost": {"value": 0.0040528}, "meta_eval_time": {"value": 44.968}, "meta_eval_prompt_tokens": {"value": 8030.0}, "meta_eval_completion_tokens": {"value": 4052.0}, "meta_eval_prompt_cost": {"value": 0.0025696}, "meta_eval_completion_cost": {"value": 0.00518656}}, "created": "2025-12-10T21:40:06.2259647Z"}
{"ref": "TQ96", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.967741935483871}, "generation_factuality_f1": {"value": 0.375}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 24.870407}, "meta_inference_prompt_tokens": {"value": 11394.0}, "meta_inference_completion_tokens": {"value": 1340.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022788}, "meta_inference_completion_cost": {"value": 0.002144}, "meta_eval_time": {"value": 35.192}, "meta_eval_prompt_tokens": {"value": 7298.0}, "meta_eval_completion_tokens": {"value": 3019.0}, "meta_eval_prompt_cost": {"value": 0.00233536}, "meta_eval_completion_cost": {"value": 0.00386432}}, "created": "2025-12-10T21:40:06.9337247Z"}
{"ref": "TQ95", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.892857142857143}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 46.668112}, "meta_inference_prompt_tokens": {"value": 11532.0}, "meta_inference_completion_tokens": {"value": 2239.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023064}, "meta_inference_completion_cost": {"value": 0.0035824}, "meta_eval_time": {"value": 35.798}, "meta_eval_prompt_tokens": {"value": 7142.0}, "meta_eval_completion_tokens": {"value": 2963.0}, "meta_eval_prompt_cost": {"value": 0.00228544}, "meta_eval_completion_cost": {"value": 0.00379264}}, "created": "2025-12-10T21:40:07.4514226Z"}
{"ref": "TQ95", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.65}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.220127}, "meta_inference_prompt_tokens": {"value": 10622.0}, "meta_inference_completion_tokens": {"value": 1747.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021244}, "meta_inference_completion_cost": {"value": 0.0027952}, "meta_eval_time": {"value": 28.681}, "meta_eval_prompt_tokens": {"value": 6352.0}, "meta_eval_completion_tokens": {"value": 2507.0}, "meta_eval_prompt_cost": {"value": 0.00203264}, "meta_eval_completion_cost": {"value": 0.00320896}}, "created": "2025-12-10T21:40:07.5049717Z"}
{"ref": "TQ95", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.238382}, "meta_inference_prompt_tokens": {"value": 10371.0}, "meta_inference_completion_tokens": {"value": 1726.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020742}, "meta_inference_completion_cost": {"value": 0.0027616}, "meta_eval_time": {"value": 30.026}, "meta_eval_prompt_tokens": {"value": 5680.0}, "meta_eval_completion_tokens": {"value": 2223.0}, "meta_eval_prompt_cost": {"value": 0.0018176}, "meta_eval_completion_cost": {"value": 0.00284544}}, "created": "2025-12-10T21:40:08.1690806Z"}
{"ref": "TQ96", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.815464876785729}, "generation_faithfulness": {"value": 0.903225806451613}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 36.367675}, "meta_inference_prompt_tokens": {"value": 11076.0}, "meta_inference_completion_tokens": {"value": 1673.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022152}, "meta_inference_completion_cost": {"value": 0.0026768}, "meta_eval_time": {"value": 33.79}, "meta_eval_prompt_tokens": {"value": 6973.0}, "meta_eval_completion_tokens": {"value": 2991.0}, "meta_eval_prompt_cost": {"value": 0.00223136}, "meta_eval_completion_cost": {"value": 0.00382848}}, "created": "2025-12-10T21:40:09.4752871Z"}
{"ref": "TQ9", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.918918918918919}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.789102}, "meta_inference_prompt_tokens": {"value": 11158.0}, "meta_inference_completion_tokens": {"value": 1205.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022316}, "meta_inference_completion_cost": {"value": 0.001928}, "meta_eval_time": {"value": 46.288}, "meta_eval_prompt_tokens": {"value": 7656.0}, "meta_eval_completion_tokens": {"value": 3866.0}, "meta_eval_prompt_cost": {"value": 0.00244992}, "meta_eval_completion_cost": {"value": 0.00494848}}, "created": "2025-12-10T21:40:11.2359586Z"}
{"ref": "TQ96", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.307692307692308}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 25.945951}, "meta_inference_prompt_tokens": {"value": 10873.0}, "meta_inference_completion_tokens": {"value": 1641.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021746}, "meta_inference_completion_cost": {"value": 0.0026256}, "meta_eval_time": {"value": 38.238}, "meta_eval_prompt_tokens": {"value": 6881.0}, "meta_eval_completion_tokens": {"value": 3067.0}, "meta_eval_prompt_cost": {"value": 0.00220192}, "meta_eval_completion_cost": {"value": 0.00392576}}, "created": "2025-12-10T21:40:11.4058364Z"}
{"ref": "acoustic-jay", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.41781349875287}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.428571428571429}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 22.041966}, "meta_inference_prompt_tokens": {"value": 15530.0}, "meta_inference_completion_tokens": {"value": 886.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003106}, "meta_inference_completion_cost": {"value": 0.0014176}, "meta_eval_time": {"value": 24.239}, "meta_eval_prompt_tokens": {"value": 9992.0}, "meta_eval_completion_tokens": {"value": 2182.0}, "meta_eval_prompt_cost": {"value": 0.00319744}, "meta_eval_completion_cost": {"value": 0.00279296}}, "created": "2025-12-10T21:40:13.1530605Z"}
{"ref": "acoustic-jay", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.35111589413933}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 21.804625}, "meta_inference_prompt_tokens": {"value": 13686.0}, "meta_inference_completion_tokens": {"value": 975.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027372}, "meta_inference_completion_cost": {"value": 0.00156}, "meta_eval_time": {"value": 22.667}, "meta_eval_prompt_tokens": {"value": 8371.0}, "meta_eval_completion_tokens": {"value": 2100.0}, "meta_eval_prompt_cost": {"value": 0.00267872}, "meta_eval_completion_cost": {"value": 0.002688}}, "created": "2025-12-10T21:40:13.3999028Z"}
{"ref": "acidic-timing", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 0.95}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.2}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.2}, "meta_inference_time": {"value": 20.781328}, "meta_inference_prompt_tokens": {"value": 12488.0}, "meta_inference_completion_tokens": {"value": 1017.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024976}, "meta_inference_completion_cost": {"value": 0.0016272}, "meta_eval_time": {"value": 25.883}, "meta_eval_prompt_tokens": {"value": 7441.0}, "meta_eval_completion_tokens": {"value": 2173.0}, "meta_eval_prompt_cost": {"value": 0.00238112}, "meta_eval_completion_cost": {"value": 0.00278144}}, "created": "2025-12-10T21:40:13.6686759Z"}
{"ref": "adiabatic-effusion", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.521271}, "meta_inference_prompt_tokens": {"value": 10837.0}, "meta_inference_completion_tokens": {"value": 778.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021674}, "meta_inference_completion_cost": {"value": 0.0012448}, "meta_eval_time": {"value": 18.541}, "meta_eval_prompt_tokens": {"value": 5643.0}, "meta_eval_completion_tokens": {"value": 1438.0}, "meta_eval_prompt_cost": {"value": 0.00180576}, "meta_eval_completion_cost": {"value": 0.00184064}}, "created": "2025-12-10T21:40:14.0859308Z"}
{"ref": "TQ96", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 0.939393939393939}, "generation_factuality_f1": {"value": 0.166666666666667}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 34.940216}, "meta_inference_prompt_tokens": {"value": 11328.0}, "meta_inference_completion_tokens": {"value": 1975.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022656}, "meta_inference_completion_cost": {"value": 0.00316}, "meta_eval_time": {"value": 42.573}, "meta_eval_prompt_tokens": {"value": 7101.0}, "meta_eval_completion_tokens": {"value": 3339.0}, "meta_eval_prompt_cost": {"value": 0.00227232}, "meta_eval_completion_cost": {"value": 0.00427392}}, "created": "2025-12-10T21:40:14.6479863Z"}
{"ref": "TQ95", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.730769230769231}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.560029}, "meta_inference_prompt_tokens": {"value": 12898.0}, "meta_inference_completion_tokens": {"value": 1735.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025796}, "meta_inference_completion_cost": {"value": 0.002776}, "meta_eval_time": {"value": 40.128}, "meta_eval_prompt_tokens": {"value": 8751.0}, "meta_eval_completion_tokens": {"value": 3002.0}, "meta_eval_prompt_cost": {"value": 0.00280032}, "meta_eval_completion_cost": {"value": 0.00384256}}, "created": "2025-12-10T21:40:14.6555838Z"}
{"ref": "adiabatic-effusion", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.82843}, "meta_inference_prompt_tokens": {"value": 10838.0}, "meta_inference_completion_tokens": {"value": 643.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021676}, "meta_inference_completion_cost": {"value": 0.0010288}, "meta_eval_time": {"value": 15.118}, "meta_eval_prompt_tokens": {"value": 5620.0}, "meta_eval_completion_tokens": {"value": 1357.0}, "meta_eval_prompt_cost": {"value": 0.0017984}, "meta_eval_completion_cost": {"value": 0.00173696}}, "created": "2025-12-10T21:40:15.3799076Z"}
{"ref": "acyclic-pond", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.588235294117647}, "generation_factuality_precision": {"value": 0.454545454545454}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 23.730605}, "meta_inference_prompt_tokens": {"value": 12738.0}, "meta_inference_completion_tokens": {"value": 828.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025476}, "meta_inference_completion_cost": {"value": 0.0013248}, "meta_eval_time": {"value": 21.615}, "meta_eval_prompt_tokens": {"value": 8025.0}, "meta_eval_completion_tokens": {"value": 1997.0}, "meta_eval_prompt_cost": {"value": 0.002568}, "meta_eval_completion_cost": {"value": 0.00255616}}, "created": "2025-12-10T21:40:15.5502881Z"}
{"ref": "TQ97", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.050501}, "meta_inference_prompt_tokens": {"value": 10806.0}, "meta_inference_completion_tokens": {"value": 1177.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021612}, "meta_inference_completion_cost": {"value": 0.0018832}, "meta_eval_time": {"value": 42.87}, "meta_eval_prompt_tokens": {"value": 6973.0}, "meta_eval_completion_tokens": {"value": 3382.0}, "meta_eval_prompt_cost": {"value": 0.00223136}, "meta_eval_completion_cost": {"value": 0.00432896}}, "created": "2025-12-10T21:40:17.2943173Z"}
{"ref": "acidic-timing", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.133333333333333}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 0.2}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.2}, "meta_inference_time": {"value": 28.979344}, "meta_inference_prompt_tokens": {"value": 12299.0}, "meta_inference_completion_tokens": {"value": 1560.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024598}, "meta_inference_completion_cost": {"value": 0.002496}, "meta_eval_time": {"value": 31.762}, "meta_eval_prompt_tokens": {"value": 7654.0}, "meta_eval_completion_tokens": {"value": 2844.0}, "meta_eval_prompt_cost": {"value": 0.00244928}, "meta_eval_completion_cost": {"value": 0.00364032}}, "created": "2025-12-10T21:40:19.6031759Z"}
{"ref": "TQ97", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.458709}, "meta_inference_prompt_tokens": {"value": 11054.0}, "meta_inference_completion_tokens": {"value": 1251.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022108}, "meta_inference_completion_cost": {"value": 0.0020016}, "meta_eval_time": {"value": 44.15}, "meta_eval_prompt_tokens": {"value": 7373.0}, "meta_eval_completion_tokens": {"value": 4061.0}, "meta_eval_prompt_cost": {"value": 0.00235936}, "meta_eval_completion_cost": {"value": 0.00519808}}, "created": "2025-12-10T21:40:21.8568051Z"}
{"ref": "adiabatic-effusion", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.268606}, "meta_inference_prompt_tokens": {"value": 10836.0}, "meta_inference_completion_tokens": {"value": 911.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021672}, "meta_inference_completion_cost": {"value": 0.0014576}, "meta_eval_time": {"value": 19.494}, "meta_eval_prompt_tokens": {"value": 5692.0}, "meta_eval_completion_tokens": {"value": 1577.0}, "meta_eval_prompt_cost": {"value": 0.00182144}, "meta_eval_completion_cost": {"value": 0.00201856}}, "created": "2025-12-10T21:40:22.1387139Z"}
{"ref": "adiabatic-manifold", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.5}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.516495}, "meta_inference_prompt_tokens": {"value": 10217.0}, "meta_inference_completion_tokens": {"value": 969.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020434}, "meta_inference_completion_cost": {"value": 0.0015504}, "meta_eval_time": {"value": 14.302}, "meta_eval_prompt_tokens": {"value": 4882.0}, "meta_eval_completion_tokens": {"value": 1231.0}, "meta_eval_prompt_cost": {"value": 0.00156224}, "meta_eval_completion_cost": {"value": 0.00157568}}, "created": "2025-12-10T21:40:22.5230416Z"}
{"ref": "adiabatic-manifold", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.363636363636364}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.629675}, "meta_inference_prompt_tokens": {"value": 10602.0}, "meta_inference_completion_tokens": {"value": 1093.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021204}, "meta_inference_completion_cost": {"value": 0.0017488}, "meta_eval_time": {"value": 16.523}, "meta_eval_prompt_tokens": {"value": 5340.0}, "meta_eval_completion_tokens": {"value": 1416.0}, "meta_eval_prompt_cost": {"value": 0.0017088}, "meta_eval_completion_cost": {"value": 0.00181248}}, "created": "2025-12-10T21:40:22.7904249Z"}
{"ref": "adiabatic-manifold", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.363636363636364}, "generation_factuality_f1": {"value": 0.521739130434783}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 18.356351}, "meta_inference_prompt_tokens": {"value": 10587.0}, "meta_inference_completion_tokens": {"value": 864.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021174}, "meta_inference_completion_cost": {"value": 0.0013824}, "meta_eval_time": {"value": 16.151}, "meta_eval_prompt_tokens": {"value": 5213.0}, "meta_eval_completion_tokens": {"value": 1309.0}, "meta_eval_prompt_cost": {"value": 0.00166816}, "meta_eval_completion_cost": {"value": 0.00167552}}, "created": "2025-12-10T21:40:23.124089Z"}
{"ref": "TQ97", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.421052631578947}, "generation_factuality_precision": {"value": 0.266666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.998913}, "meta_inference_prompt_tokens": {"value": 10861.0}, "meta_inference_completion_tokens": {"value": 1534.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021722}, "meta_inference_completion_cost": {"value": 0.0024544}, "meta_eval_time": {"value": 47.781}, "meta_eval_prompt_tokens": {"value": 7698.0}, "meta_eval_completion_tokens": {"value": 4324.0}, "meta_eval_prompt_cost": {"value": 0.00246336}, "meta_eval_completion_cost": {"value": 0.00553472}}, "created": "2025-12-10T21:40:23.1261963Z"}
{"ref": "adiabatic-effusion", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.306031}, "meta_inference_prompt_tokens": {"value": 11318.0}, "meta_inference_completion_tokens": {"value": 674.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022636}, "meta_inference_completion_cost": {"value": 0.0010784}, "meta_eval_time": {"value": 16.411}, "meta_eval_prompt_tokens": {"value": 6178.0}, "meta_eval_completion_tokens": {"value": 1487.0}, "meta_eval_prompt_cost": {"value": 0.00197696}, "meta_eval_completion_cost": {"value": 0.00190336}}, "created": "2025-12-10T21:40:23.9549788Z"}
{"ref": "acyclic-pond", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.428571428571429}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.428571428571429}, "meta_inference_time": {"value": 31.00968}, "meta_inference_prompt_tokens": {"value": 19360.0}, "meta_inference_completion_tokens": {"value": 1567.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003872}, "meta_inference_completion_cost": {"value": 0.0025072}, "meta_eval_time": {"value": 33.202}, "meta_eval_prompt_tokens": {"value": 15316.0}, "meta_eval_completion_tokens": {"value": 2867.0}, "meta_eval_prompt_cost": {"value": 0.00490112}, "meta_eval_completion_cost": {"value": 0.00366976}}, "created": "2025-12-10T21:40:24.3617345Z"}
{"ref": "TQ97", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.453908}, "meta_inference_prompt_tokens": {"value": 11010.0}, "meta_inference_completion_tokens": {"value": 1491.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002202}, "meta_inference_completion_cost": {"value": 0.0023856}, "meta_eval_time": {"value": 48.147}, "meta_eval_prompt_tokens": {"value": 7965.0}, "meta_eval_completion_tokens": {"value": 4643.0}, "meta_eval_prompt_cost": {"value": 0.0025488}, "meta_eval_completion_cost": {"value": 0.00594304}}, "created": "2025-12-10T21:40:24.5088411Z"}
{"ref": "acidic-timing", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 27.934352}, "meta_inference_prompt_tokens": {"value": 11754.0}, "meta_inference_completion_tokens": {"value": 1096.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023508}, "meta_inference_completion_cost": {"value": 0.0017536}, "meta_eval_time": {"value": 35.817}, "meta_eval_prompt_tokens": {"value": 7083.0}, "meta_eval_completion_tokens": {"value": 2612.0}, "meta_eval_prompt_cost": {"value": 0.00226656}, "meta_eval_completion_cost": {"value": 0.00334336}}, "created": "2025-12-10T21:40:24.9980783Z"}
{"ref": "acidic-timing", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.289064826317888}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.436363636363636}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 23.8737}, "meta_inference_prompt_tokens": {"value": 11972.0}, "meta_inference_completion_tokens": {"value": 1371.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023944}, "meta_inference_completion_cost": {"value": 0.0021936}, "meta_eval_time": {"value": 37.363}, "meta_eval_prompt_tokens": {"value": 7579.0}, "meta_eval_completion_tokens": {"value": 3147.0}, "meta_eval_prompt_cost": {"value": 0.00242528}, "meta_eval_completion_cost": {"value": 0.00402816}}, "created": "2025-12-10T21:40:26.2323958Z"}
{"ref": "TQ95", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.53148}, "meta_inference_prompt_tokens": {"value": 10737.0}, "meta_inference_completion_tokens": {"value": 2212.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021474}, "meta_inference_completion_cost": {"value": 0.0035392}, "meta_eval_time": {"value": 51.629}, "meta_eval_prompt_tokens": {"value": 7545.0}, "meta_eval_completion_tokens": {"value": 3916.0}, "meta_eval_prompt_cost": {"value": 0.0024144}, "meta_eval_completion_cost": {"value": 0.00501248}}, "created": "2025-12-10T21:40:26.6686412Z"}
{"ref": "acidic-timing", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.387096774193548}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 24.950154}, "meta_inference_prompt_tokens": {"value": 11820.0}, "meta_inference_completion_tokens": {"value": 1409.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002364}, "meta_inference_completion_cost": {"value": 0.0022544}, "meta_eval_time": {"value": 38.459}, "meta_eval_prompt_tokens": {"value": 7726.0}, "meta_eval_completion_tokens": {"value": 3407.0}, "meta_eval_prompt_cost": {"value": 0.00247232}, "meta_eval_completion_cost": {"value": 0.00436096}}, "created": "2025-12-10T21:40:26.8419373Z"}
{"ref": "acoustic-jay", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.32047027401281}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.701754385964912}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 21.430765}, "meta_inference_prompt_tokens": {"value": 14801.0}, "meta_inference_completion_tokens": {"value": 1070.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029602}, "meta_inference_completion_cost": {"value": 0.001712}, "meta_eval_time": {"value": 33.639}, "meta_eval_prompt_tokens": {"value": 9725.0}, "meta_eval_completion_tokens": {"value": 2643.0}, "meta_eval_prompt_cost": {"value": 0.003112}, "meta_eval_completion_cost": {"value": 0.00338304}}, "created": "2025-12-10T21:40:27.0282848Z"}
{"ref": "TQ97", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.49745}, "meta_inference_prompt_tokens": {"value": 10756.0}, "meta_inference_completion_tokens": {"value": 1364.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021512}, "meta_inference_completion_cost": {"value": 0.0021824}, "meta_eval_time": {"value": 51.774}, "meta_eval_prompt_tokens": {"value": 7503.0}, "meta_eval_completion_tokens": {"value": 4635.0}, "meta_eval_prompt_cost": {"value": 0.00240096}, "meta_eval_completion_cost": {"value": 0.0059328}}, "created": "2025-12-10T21:40:28.1870727Z"}
{"ref": "TQ99", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.861111111111111}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 28.387493}, "meta_inference_prompt_tokens": {"value": 11398.0}, "meta_inference_completion_tokens": {"value": 1380.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022796}, "meta_inference_completion_cost": {"value": 0.002208}, "meta_eval_time": {"value": 44.875}, "meta_eval_prompt_tokens": {"value": 7261.0}, "meta_eval_completion_tokens": {"value": 3393.0}, "meta_eval_prompt_cost": {"value": 0.00232352}, "meta_eval_completion_cost": {"value": 0.00434304}}, "created": "2025-12-10T21:40:28.7678423Z"}
{"ref": "acoustic-jay", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.35111589413933}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.982217}, "meta_inference_prompt_tokens": {"value": 13330.0}, "meta_inference_completion_tokens": {"value": 968.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002666}, "meta_inference_completion_cost": {"value": 0.0015488}, "meta_eval_time": {"value": 34.569}, "meta_eval_prompt_tokens": {"value": 8602.0}, "meta_eval_completion_tokens": {"value": 2891.0}, "meta_eval_prompt_cost": {"value": 0.00275264}, "meta_eval_completion_cost": {"value": 0.00370048}}, "created": "2025-12-10T21:40:29.8163855Z"}
{"ref": "acoustic-jay", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.37398974791402}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.969813}, "meta_inference_prompt_tokens": {"value": 13764.0}, "meta_inference_completion_tokens": {"value": 872.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027528}, "meta_inference_completion_cost": {"value": 0.0013952}, "meta_eval_time": {"value": 26.482}, "meta_eval_prompt_tokens": {"value": 8563.0}, "meta_eval_completion_tokens": {"value": 2165.0}, "meta_eval_prompt_cost": {"value": 0.00274016}, "meta_eval_completion_cost": {"value": 0.0027712}}, "created": "2025-12-10T21:40:31.7065059Z"}
{"ref": "TQ99", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.822222222222222}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 33.861457}, "meta_inference_prompt_tokens": {"value": 12463.0}, "meta_inference_completion_tokens": {"value": 1761.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024926}, "meta_inference_completion_cost": {"value": 0.0028176}, "meta_eval_time": {"value": 47.411}, "meta_eval_prompt_tokens": {"value": 8957.0}, "meta_eval_completion_tokens": {"value": 4078.0}, "meta_eval_prompt_cost": {"value": 0.00286624}, "meta_eval_completion_cost": {"value": 0.00521984}}, "created": "2025-12-10T21:40:31.9288305Z"}
{"ref": "TQ99", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.877551020408163}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0833333333333333}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 33.233766}, "meta_inference_prompt_tokens": {"value": 12678.0}, "meta_inference_completion_tokens": {"value": 1633.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025356}, "meta_inference_completion_cost": {"value": 0.0026128}, "meta_eval_time": {"value": 44.751}, "meta_eval_prompt_tokens": {"value": 9003.0}, "meta_eval_completion_tokens": {"value": 4210.0}, "meta_eval_prompt_cost": {"value": 0.00288096}, "meta_eval_completion_cost": {"value": 0.0053888}}, "created": "2025-12-10T21:40:32.133871Z"}
{"ref": "acyclic-pond", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.64527201342591}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 22.468813}, "meta_inference_prompt_tokens": {"value": 17957.0}, "meta_inference_completion_tokens": {"value": 1178.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0035914}, "meta_inference_completion_cost": {"value": 0.0018848}, "meta_eval_time": {"value": 26.541}, "meta_eval_prompt_tokens": {"value": 13827.0}, "meta_eval_completion_tokens": {"value": 2772.0}, "meta_eval_prompt_cost": {"value": 0.00442464}, "meta_eval_completion_cost": {"value": 0.00354816}}, "created": "2025-12-10T21:40:32.3557903Z"}
{"ref": "adiabatic-manifold", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.5}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.25}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.764986}, "meta_inference_prompt_tokens": {"value": 6990.0}, "meta_inference_completion_tokens": {"value": 867.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001398}, "meta_inference_completion_cost": {"value": 0.0013872}, "meta_eval_time": {"value": 19.826}, "meta_eval_prompt_tokens": {"value": 3580.0}, "meta_eval_completion_tokens": {"value": 1767.0}, "meta_eval_prompt_cost": {"value": 0.0011456}, "meta_eval_completion_cost": {"value": 0.00226176}}, "created": "2025-12-10T21:40:33.5702446Z"}
{"ref": "acyclic-pond", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.684233}, "meta_inference_prompt_tokens": {"value": 12740.0}, "meta_inference_completion_tokens": {"value": 986.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002548}, "meta_inference_completion_cost": {"value": 0.0015776}, "meta_eval_time": {"value": 33.355}, "meta_eval_prompt_tokens": {"value": 8347.0}, "meta_eval_completion_tokens": {"value": 2549.0}, "meta_eval_prompt_cost": {"value": 0.00267104}, "meta_eval_completion_cost": {"value": 0.00326272}}, "created": "2025-12-10T21:40:35.2712887Z"}
{"ref": "adiabatic-effusion", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.632559}, "meta_inference_prompt_tokens": {"value": 10842.0}, "meta_inference_completion_tokens": {"value": 671.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021684}, "meta_inference_completion_cost": {"value": 0.0010736}, "meta_eval_time": {"value": 20.747}, "meta_eval_prompt_tokens": {"value": 5712.0}, "meta_eval_completion_tokens": {"value": 1565.0}, "meta_eval_prompt_cost": {"value": 0.00182784}, "meta_eval_completion_cost": {"value": 0.0020032}}, "created": "2025-12-10T21:40:36.339212Z"}
{"ref": "adventurous-decorator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 0.882352941176471}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.388336}, "meta_inference_prompt_tokens": {"value": 11415.0}, "meta_inference_completion_tokens": {"value": 509.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002283}, "meta_inference_completion_cost": {"value": 0.0008144}, "meta_eval_time": {"value": 21.131}, "meta_eval_prompt_tokens": {"value": 6077.0}, "meta_eval_completion_tokens": {"value": 1854.0}, "meta_eval_prompt_cost": {"value": 0.00194464}, "meta_eval_completion_cost": {"value": 0.00237312}}, "created": "2025-12-10T21:40:36.5478085Z"}
{"ref": "advanced-curd", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.944444444444444}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.655002}, "meta_inference_prompt_tokens": {"value": 10720.0}, "meta_inference_completion_tokens": {"value": 879.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002144}, "meta_inference_completion_cost": {"value": 0.0014064}, "meta_eval_time": {"value": 23.805}, "meta_eval_prompt_tokens": {"value": 5883.0}, "meta_eval_completion_tokens": {"value": 2136.0}, "meta_eval_prompt_cost": {"value": 0.00188256}, "meta_eval_completion_cost": {"value": 0.00273408}}, "created": "2025-12-10T21:40:37.9293234Z"}
{"ref": "TQ99", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.946428571428571}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0833333333333333}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 30.287864}, "meta_inference_prompt_tokens": {"value": 12424.0}, "meta_inference_completion_tokens": {"value": 1567.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024848}, "meta_inference_completion_cost": {"value": 0.0025072}, "meta_eval_time": {"value": 55.039}, "meta_eval_prompt_tokens": {"value": 9475.0}, "meta_eval_completion_tokens": {"value": 5002.0}, "meta_eval_prompt_cost": {"value": 0.003032}, "meta_eval_completion_cost": {"value": 0.00640256}}, "created": "2025-12-10T21:40:38.4332744Z"}
{"ref": "acyclic-pond", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 24.580811}, "meta_inference_prompt_tokens": {"value": 17817.0}, "meta_inference_completion_tokens": {"value": 1425.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0035634}, "meta_inference_completion_cost": {"value": 0.00228}, "meta_eval_time": {"value": 37.252}, "meta_eval_prompt_tokens": {"value": 13646.0}, "meta_eval_completion_tokens": {"value": 2889.0}, "meta_eval_prompt_cost": {"value": 0.00436672}, "meta_eval_completion_cost": {"value": 0.00369792}}, "created": "2025-12-10T21:40:38.8763357Z"}
{"ref": "TQ99", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 25.804285}, "meta_inference_prompt_tokens": {"value": 12462.0}, "meta_inference_completion_tokens": {"value": 1457.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024924}, "meta_inference_completion_cost": {"value": 0.0023312}, "meta_eval_time": {"value": 55.26}, "meta_eval_prompt_tokens": {"value": 9210.0}, "meta_eval_completion_tokens": {"value": 4809.0}, "meta_eval_prompt_cost": {"value": 0.0029472}, "meta_eval_completion_cost": {"value": 0.00615552}}, "created": "2025-12-10T21:40:38.9144116Z"}
{"ref": "adiabatic-manifold", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.611111111111111}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.142857142857143}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.029414}, "meta_inference_prompt_tokens": {"value": 8359.0}, "meta_inference_completion_tokens": {"value": 1382.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0016718}, "meta_inference_completion_cost": {"value": 0.0022112}, "meta_eval_time": {"value": 27.926}, "meta_eval_prompt_tokens": {"value": 4437.0}, "meta_eval_completion_tokens": {"value": 2015.0}, "meta_eval_prompt_cost": {"value": 0.00141984}, "meta_eval_completion_cost": {"value": 0.0025792}}, "created": "2025-12-10T21:40:39.2031464Z"}
{"ref": "adventurous-decorator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.526311}, "meta_inference_prompt_tokens": {"value": 11415.0}, "meta_inference_completion_tokens": {"value": 778.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002283}, "meta_inference_completion_cost": {"value": 0.0012448}, "meta_eval_time": {"value": 20.279}, "meta_eval_prompt_tokens": {"value": 6112.0}, "meta_eval_completion_tokens": {"value": 1732.0}, "meta_eval_prompt_cost": {"value": 0.00195584}, "meta_eval_completion_cost": {"value": 0.00221696}}, "created": "2025-12-10T21:40:39.9199366Z"}
{"ref": "adventurous-decorator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.879725}, "meta_inference_prompt_tokens": {"value": 11416.0}, "meta_inference_completion_tokens": {"value": 647.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022832}, "meta_inference_completion_cost": {"value": 0.0010352}, "meta_eval_time": {"value": 18.827}, "meta_eval_prompt_tokens": {"value": 6049.0}, "meta_eval_completion_tokens": {"value": 1897.0}, "meta_eval_prompt_cost": {"value": 0.00193568}, "meta_eval_completion_cost": {"value": 0.00242816}}, "created": "2025-12-10T21:40:40.7303297Z"}
{"ref": "adventurous-decorator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.39451}, "meta_inference_prompt_tokens": {"value": 10355.0}, "meta_inference_completion_tokens": {"value": 737.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002071}, "meta_inference_completion_cost": {"value": 0.0011792}, "meta_eval_time": {"value": 20.276}, "meta_eval_prompt_tokens": {"value": 5097.0}, "meta_eval_completion_tokens": {"value": 1748.0}, "meta_eval_prompt_cost": {"value": 0.00163104}, "meta_eval_completion_cost": {"value": 0.00223744}}, "created": "2025-12-10T21:40:43.4427145Z"}
{"ref": "adventurous-decorator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.01165}, "meta_inference_prompt_tokens": {"value": 12373.0}, "meta_inference_completion_tokens": {"value": 605.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024746}, "meta_inference_completion_cost": {"value": 0.000968}, "meta_eval_time": {"value": 15.285}, "meta_eval_prompt_tokens": {"value": 6897.0}, "meta_eval_completion_tokens": {"value": 1607.0}, "meta_eval_prompt_cost": {"value": 0.00220704}, "meta_eval_completion_cost": {"value": 0.00205696}}, "created": "2025-12-10T21:40:43.5100567Z"}
{"ref": "adventurous-generator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.28906482631789}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.799475}, "meta_inference_prompt_tokens": {"value": 10954.0}, "meta_inference_completion_tokens": {"value": 1315.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021908}, "meta_inference_completion_cost": {"value": 0.002104}, "meta_eval_time": {"value": 24.214}, "meta_eval_prompt_tokens": {"value": 6308.0}, "meta_eval_completion_tokens": {"value": 2381.0}, "meta_eval_prompt_cost": {"value": 0.00201856}, "meta_eval_completion_cost": {"value": 0.00304768}}, "created": "2025-12-10T21:40:47.3876004Z"}
{"ref": "adventurous-generator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.436855}, "meta_inference_prompt_tokens": {"value": 10559.0}, "meta_inference_completion_tokens": {"value": 1012.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021118}, "meta_inference_completion_cost": {"value": 0.0016192}, "meta_eval_time": {"value": 30.397}, "meta_eval_prompt_tokens": {"value": 5958.0}, "meta_eval_completion_tokens": {"value": 2788.0}, "meta_eval_prompt_cost": {"value": 0.00190656}, "meta_eval_completion_cost": {"value": 0.00356864}}, "created": "2025-12-10T21:40:47.7312239Z"}
{"ref": "adjacent-band", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.133333333333333}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0714285714285714}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.2}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 27.38719}, "meta_inference_prompt_tokens": {"value": 11005.0}, "meta_inference_completion_tokens": {"value": 1417.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002201}, "meta_inference_completion_cost": {"value": 0.0022672}, "meta_eval_time": {"value": 41.843}, "meta_eval_prompt_tokens": {"value": 7099.0}, "meta_eval_completion_tokens": {"value": 4034.0}, "meta_eval_prompt_cost": {"value": 0.00227168}, "meta_eval_completion_cost": {"value": 0.00516352}}, "created": "2025-12-10T21:40:51.3565103Z"}
{"ref": "adjacent-band", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.964263086904791}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.4}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.561626}, "meta_inference_prompt_tokens": {"value": 11549.0}, "meta_inference_completion_tokens": {"value": 1671.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023098}, "meta_inference_completion_cost": {"value": 0.0026736}, "meta_eval_time": {"value": 46.875}, "meta_eval_prompt_tokens": {"value": 8568.0}, "meta_eval_completion_tokens": {"value": 4615.0}, "meta_eval_prompt_cost": {"value": 0.00274176}, "meta_eval_completion_cost": {"value": 0.0059072}}, "created": "2025-12-10T21:40:52.9053083Z"}
{"ref": "advanced-curd", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.088586}, "meta_inference_prompt_tokens": {"value": 11576.0}, "meta_inference_completion_tokens": {"value": 1398.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023152}, "meta_inference_completion_cost": {"value": 0.0022368}, "meta_eval_time": {"value": 41.108}, "meta_eval_prompt_tokens": {"value": 7517.0}, "meta_eval_completion_tokens": {"value": 3517.0}, "meta_eval_prompt_cost": {"value": 0.00240544}, "meta_eval_completion_cost": {"value": 0.00450176}}, "created": "2025-12-10T21:40:54.5453379Z"}
{"ref": "aged-crate-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.930676558073393}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.947368421052632}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.499601}, "meta_inference_prompt_tokens": {"value": 17283.0}, "meta_inference_completion_tokens": {"value": 1024.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0034566}, "meta_inference_completion_cost": {"value": 0.0016384}, "meta_eval_time": {"value": 22.985}, "meta_eval_prompt_tokens": {"value": 11837.0}, "meta_eval_completion_tokens": {"value": 2264.0}, "meta_eval_prompt_cost": {"value": 0.00378784}, "meta_eval_completion_cost": {"value": 0.00289792}}, "created": "2025-12-10T21:40:54.9557162Z"}
{"ref": "adventurous-generator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.852929}, "meta_inference_prompt_tokens": {"value": 10056.0}, "meta_inference_completion_tokens": {"value": 1004.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020112}, "meta_inference_completion_cost": {"value": 0.0016064}, "meta_eval_time": {"value": 31.006}, "meta_eval_prompt_tokens": {"value": 5872.0}, "meta_eval_completion_tokens": {"value": 2886.0}, "meta_eval_prompt_cost": {"value": 0.00187904}, "meta_eval_completion_cost": {"value": 0.00369408}}, "created": "2025-12-10T21:40:55.5511149Z"}
{"ref": "advanced-curd", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 25.700009}, "meta_inference_prompt_tokens": {"value": 11573.0}, "meta_inference_completion_tokens": {"value": 1479.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023146}, "meta_inference_completion_cost": {"value": 0.0023664}, "meta_eval_time": {"value": 41.526}, "meta_eval_prompt_tokens": {"value": 7672.0}, "meta_eval_completion_tokens": {"value": 3743.0}, "meta_eval_prompt_cost": {"value": 0.00245504}, "meta_eval_completion_cost": {"value": 0.00479104}}, "created": "2025-12-10T21:40:56.2102737Z"}
{"ref": "aged-crate-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.588235294117647}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.63299424209366}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.416666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 0.714285714285714}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.315696}, "meta_inference_prompt_tokens": {"value": 19552.0}, "meta_inference_completion_tokens": {"value": 1112.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0039104}, "meta_inference_completion_cost": {"value": 0.0017792}, "meta_eval_time": {"value": 32.471}, "meta_eval_prompt_tokens": {"value": 15873.0}, "meta_eval_completion_tokens": {"value": 3248.0}, "meta_eval_prompt_cost": {"value": 0.00507936}, "meta_eval_completion_cost": {"value": 0.00415744}}, "created": "2025-12-10T21:40:56.888161Z"}
{"ref": "adjacent-band", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.133333333333333}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.930232558139535}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0714285714285714}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.2}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 30.720745}, "meta_inference_prompt_tokens": {"value": 11289.0}, "meta_inference_completion_tokens": {"value": 1445.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022578}, "meta_inference_completion_cost": {"value": 0.002312}, "meta_eval_time": {"value": 42.294}, "meta_eval_prompt_tokens": {"value": 7861.0}, "meta_eval_completion_tokens": {"value": 4254.0}, "meta_eval_prompt_cost": {"value": 0.00251552}, "meta_eval_completion_cost": {"value": 0.00544512}}, "created": "2025-12-10T21:40:56.9987066Z"}
{"ref": "adventurous-generator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 40.640344}, "meta_inference_prompt_tokens": {"value": 11040.0}, "meta_inference_completion_tokens": {"value": 1254.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002208}, "meta_inference_completion_cost": {"value": 0.0020064}, "meta_eval_time": {"value": 35.449}, "meta_eval_prompt_tokens": {"value": 7053.0}, "meta_eval_completion_tokens": {"value": 3253.0}, "meta_eval_prompt_cost": {"value": 0.00225696}, "meta_eval_completion_cost": {"value": 0.00416384}}, "created": "2025-12-10T21:40:57.628831Z"}
{"ref": "adventurous-ghoul", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.422928}, "meta_inference_prompt_tokens": {"value": 13248.0}, "meta_inference_completion_tokens": {"value": 1529.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026496}, "meta_inference_completion_cost": {"value": 0.0024464}, "meta_eval_time": {"value": 35.341}, "meta_eval_prompt_tokens": {"value": 9441.0}, "meta_eval_completion_tokens": {"value": 3602.0}, "meta_eval_prompt_cost": {"value": 0.00302112}, "meta_eval_completion_cost": {"value": 0.00461056}}, "created": "2025-12-10T21:40:57.906376Z"}
{"ref": "advanced-curd", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.616172}, "meta_inference_prompt_tokens": {"value": 11085.0}, "meta_inference_completion_tokens": {"value": 1416.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002217}, "meta_inference_completion_cost": {"value": 0.0022656}, "meta_eval_time": {"value": 35.347}, "meta_eval_prompt_tokens": {"value": 6959.0}, "meta_eval_completion_tokens": {"value": 3265.0}, "meta_eval_prompt_cost": {"value": 0.00222688}, "meta_eval_completion_cost": {"value": 0.0041792}}, "created": "2025-12-10T21:40:58.1769557Z"}
{"ref": "adjacent-band", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.133333333333333}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0714285714285714}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.2}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 26.026372}, "meta_inference_prompt_tokens": {"value": 12143.0}, "meta_inference_completion_tokens": {"value": 1377.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024286}, "meta_inference_completion_cost": {"value": 0.0022032}, "meta_eval_time": {"value": 47.216}, "meta_eval_prompt_tokens": {"value": 8495.0}, "meta_eval_completion_tokens": {"value": 4394.0}, "meta_eval_prompt_cost": {"value": 0.0027184}, "meta_eval_completion_cost": {"value": 0.00562432}}, "created": "2025-12-10T21:40:58.660108Z"}
{"ref": "advanced-curd", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.877551020408163}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.6532}, "meta_inference_prompt_tokens": {"value": 11600.0}, "meta_inference_completion_tokens": {"value": 1597.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00232}, "meta_inference_completion_cost": {"value": 0.0025552}, "meta_eval_time": {"value": 46.059}, "meta_eval_prompt_tokens": {"value": 8158.0}, "meta_eval_completion_tokens": {"value": 4429.0}, "meta_eval_prompt_cost": {"value": 0.00261056}, "meta_eval_completion_cost": {"value": 0.00566912}}, "created": "2025-12-10T21:40:59.2549504Z"}
{"ref": "antique-font", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.017782560806}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.718055}, "meta_inference_prompt_tokens": {"value": 11502.0}, "meta_inference_completion_tokens": {"value": 1033.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023004}, "meta_inference_completion_cost": {"value": 0.0016528}, "meta_eval_time": {"value": 19.344}, "meta_eval_prompt_tokens": {"value": 7894.0}, "meta_eval_completion_tokens": {"value": 1778.0}, "meta_eval_prompt_cost": {"value": 0.00252608}, "meta_eval_completion_cost": {"value": 0.00227584}}, "created": "2025-12-10T21:40:59.2998804Z"}
{"ref": "adventurous-ghoul", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.038225}, "meta_inference_prompt_tokens": {"value": 12788.0}, "meta_inference_completion_tokens": {"value": 1287.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025576}, "meta_inference_completion_cost": {"value": 0.0020592}, "meta_eval_time": {"value": 33.198}, "meta_eval_prompt_tokens": {"value": 8396.0}, "meta_eval_completion_tokens": {"value": 2842.0}, "meta_eval_prompt_cost": {"value": 0.00268672}, "meta_eval_completion_cost": {"value": 0.00363776}}, "created": "2025-12-10T21:40:59.9063254Z"}
{"ref": "aged-crate-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.886852807234542}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.309106}, "meta_inference_prompt_tokens": {"value": 15100.0}, "meta_inference_completion_tokens": {"value": 1222.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00302}, "meta_inference_completion_cost": {"value": 0.0019552}, "meta_eval_time": {"value": 27.965}, "meta_eval_prompt_tokens": {"value": 10173.0}, "meta_eval_completion_tokens": {"value": 2768.0}, "meta_eval_prompt_cost": {"value": 0.00325536}, "meta_eval_completion_cost": {"value": 0.00354304}}, "created": "2025-12-10T21:41:00.3579842Z"}
{"ref": "andante-agate", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.512820512820513}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 16.630271}, "meta_inference_prompt_tokens": {"value": 15303.0}, "meta_inference_completion_tokens": {"value": 845.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030606}, "meta_inference_completion_cost": {"value": 0.001352}, "meta_eval_time": {"value": 21.315}, "meta_eval_prompt_tokens": {"value": 9474.0}, "meta_eval_completion_tokens": {"value": 1837.0}, "meta_eval_prompt_cost": {"value": 0.00303168}, "meta_eval_completion_cost": {"value": 0.00235136}}, "created": "2025-12-10T21:41:00.5538479Z"}
{"ref": "adventurous-ghoul", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 29.781755}, "meta_inference_prompt_tokens": {"value": 12588.0}, "meta_inference_completion_tokens": {"value": 1337.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025176}, "meta_inference_completion_cost": {"value": 0.0021392}, "meta_eval_time": {"value": 35.515}, "meta_eval_prompt_tokens": {"value": 8518.0}, "meta_eval_completion_tokens": {"value": 3561.0}, "meta_eval_prompt_cost": {"value": 0.00272576}, "meta_eval_completion_cost": {"value": 0.00455808}}, "created": "2025-12-10T21:41:01.7861028Z"}
{"ref": "aged-crate-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.930676558073393}, "generation_faithfulness": {"value": 0.964285714285714}, "generation_factuality_f1": {"value": 0.818181818181818}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 25.917874}, "meta_inference_prompt_tokens": {"value": 13823.0}, "meta_inference_completion_tokens": {"value": 1080.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027646}, "meta_inference_completion_cost": {"value": 0.001728}, "meta_eval_time": {"value": 29.847}, "meta_eval_prompt_tokens": {"value": 8746.0}, "meta_eval_completion_tokens": {"value": 2968.0}, "meta_eval_prompt_cost": {"value": 0.00279872}, "meta_eval_completion_cost": {"value": 0.00379904}}, "created": "2025-12-10T21:41:02.0215306Z"}
{"ref": "antique-font", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.83333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.354299}, "meta_inference_prompt_tokens": {"value": 16011.0}, "meta_inference_completion_tokens": {"value": 863.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032022}, "meta_inference_completion_cost": {"value": 0.0013808}, "meta_eval_time": {"value": 18.834}, "meta_eval_prompt_tokens": {"value": 11145.0}, "meta_eval_completion_tokens": {"value": 1607.0}, "meta_eval_prompt_cost": {"value": 0.0035664}, "meta_eval_completion_cost": {"value": 0.00205696}}, "created": "2025-12-10T21:41:02.3299011Z"}
{"ref": "aged-crate-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.352941176470588}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 0.946302009089891}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.214285714285714}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.428571428571429}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.723273}, "meta_inference_prompt_tokens": {"value": 18985.0}, "meta_inference_completion_tokens": {"value": 1117.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003797}, "meta_inference_completion_cost": {"value": 0.0017872}, "meta_eval_time": {"value": 38.499}, "meta_eval_prompt_tokens": {"value": 15483.0}, "meta_eval_completion_tokens": {"value": 3517.0}, "meta_eval_prompt_cost": {"value": 0.00495456}, "meta_eval_completion_cost": {"value": 0.00450176}}, "created": "2025-12-10T21:41:02.4952476Z"}
{"ref": "adventurous-ghoul", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.28906482631789}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.914148}, "meta_inference_prompt_tokens": {"value": 12998.0}, "meta_inference_completion_tokens": {"value": 1536.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025996}, "meta_inference_completion_cost": {"value": 0.0024576}, "meta_eval_time": {"value": 36.014}, "meta_eval_prompt_tokens": {"value": 8985.0}, "meta_eval_completion_tokens": {"value": 3355.0}, "meta_eval_prompt_cost": {"value": 0.0028752}, "meta_eval_completion_cost": {"value": 0.0042944}}, "created": "2025-12-10T21:41:02.8966124Z"}
{"ref": "adventurous-generator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.28906482631789}, "generation_faithfulness": {"value": 0.939393939393939}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.814811}, "meta_inference_prompt_tokens": {"value": 10916.0}, "meta_inference_completion_tokens": {"value": 1141.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021832}, "meta_inference_completion_cost": {"value": 0.0018256}, "meta_eval_time": {"value": 38.437}, "meta_eval_prompt_tokens": {"value": 6764.0}, "meta_eval_completion_tokens": {"value": 3366.0}, "meta_eval_prompt_cost": {"value": 0.00216448}, "meta_eval_completion_cost": {"value": 0.00430848}}, "created": "2025-12-10T21:41:03.4738236Z"}
{"ref": "adjacent-band", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.133333333333333}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.413793103448276}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0714285714285714}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.2}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 25.830885}, "meta_inference_prompt_tokens": {"value": 11765.0}, "meta_inference_completion_tokens": {"value": 1496.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002353}, "meta_inference_completion_cost": {"value": 0.0023936}, "meta_eval_time": {"value": 56.304}, "meta_eval_prompt_tokens": {"value": 8738.0}, "meta_eval_completion_tokens": {"value": 5130.0}, "meta_eval_prompt_cost": {"value": 0.00279616}, "meta_eval_completion_cost": {"value": 0.0065664}}, "created": "2025-12-10T21:41:03.7967013Z"}
{"ref": "ash-run", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 12.537215}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 673.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0010768}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:41:03.8369786Z"}
{"ref": "ash-run", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 7.563039}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 338.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0005408}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:41:03.8754672Z"}
{"ref": "ash-run", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 15.887456}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 608.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0009728}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:41:03.9098354Z"}
{"ref": "antique-font", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.83333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.713151}, "meta_inference_prompt_tokens": {"value": 16013.0}, "meta_inference_completion_tokens": {"value": 794.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032026}, "meta_inference_completion_cost": {"value": 0.0012704}, "meta_eval_time": {"value": 17.127}, "meta_eval_prompt_tokens": {"value": 11155.0}, "meta_eval_completion_tokens": {"value": 1706.0}, "meta_eval_prompt_cost": {"value": 0.0035696}, "meta_eval_completion_cost": {"value": 0.00218368}}, "created": "2025-12-10T21:41:04.9051974Z"}
{"ref": "aged-crate-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.352941176470588}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.00334767968425}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.214285714285714}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.428571428571429}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 58.037649}, "meta_inference_prompt_tokens": {"value": 19352.0}, "meta_inference_completion_tokens": {"value": 1250.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0038704}, "meta_inference_completion_cost": {"value": 0.002}, "meta_eval_time": {"value": 37.404}, "meta_eval_prompt_tokens": {"value": 15668.0}, "meta_eval_completion_tokens": {"value": 3558.0}, "meta_eval_prompt_cost": {"value": 0.00501376}, "meta_eval_completion_cost": {"value": 0.00455424}}, "created": "2025-12-10T21:41:06.2901105Z"}
{"ref": "ash-run", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 8.270378}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 224.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0003584}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:41:06.3280475Z"}
{"ref": "aged-crate-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.473333333333333}, "retrieval_dcg": {"value": 2.20732308124735}, "generation_faithfulness": {"value": 0.870967741935484}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.571428571428571}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.561558}, "meta_inference_prompt_tokens": {"value": 18307.0}, "meta_inference_completion_tokens": {"value": 950.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0036614}, "meta_inference_completion_cost": {"value": 0.00152}, "meta_eval_time": {"value": 39.429}, "meta_eval_prompt_tokens": {"value": 14632.0}, "meta_eval_completion_tokens": {"value": 3271.0}, "meta_eval_prompt_cost": {"value": 0.00468224}, "meta_eval_completion_cost": {"value": 0.00418688}}, "created": "2025-12-10T21:41:07.2906396Z"}
{"ref": "ash-run", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 8.651629}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 274.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0004384}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:41:07.3306004Z"}
{"ref": "aged-crate-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.094106}, "meta_inference_prompt_tokens": {"value": 13405.0}, "meta_inference_completion_tokens": {"value": 900.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002681}, "meta_inference_completion_cost": {"value": 0.00144}, "meta_eval_time": {"value": 29.592}, "meta_eval_prompt_tokens": {"value": 8234.0}, "meta_eval_completion_tokens": {"value": 2617.0}, "meta_eval_prompt_cost": {"value": 0.00263488}, "meta_eval_completion_cost": {"value": 0.00334976}}, "created": "2025-12-10T21:41:08.5124529Z"}
{"ref": "andante-agate", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.863636363636364}, "generation_factuality_f1": {"value": 0.375}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 24.288463}, "meta_inference_prompt_tokens": {"value": 14231.0}, "meta_inference_completion_tokens": {"value": 879.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028462}, "meta_inference_completion_cost": {"value": 0.0014064}, "meta_eval_time": {"value": 28.841}, "meta_eval_prompt_tokens": {"value": 8901.0}, "meta_eval_completion_tokens": {"value": 2365.0}, "meta_eval_prompt_cost": {"value": 0.00284832}, "meta_eval_completion_cost": {"value": 0.0030272}}, "created": "2025-12-10T21:41:09.6098962Z"}
{"ref": "aged-crate-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.862068965517241}, "generation_factuality_f1": {"value": 0.724137931034483}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 64.500099}, "meta_inference_prompt_tokens": {"value": 14836.0}, "meta_inference_completion_tokens": {"value": 1708.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029672}, "meta_inference_completion_cost": {"value": 0.0027328}, "meta_eval_time": {"value": 31.424}, "meta_eval_prompt_tokens": {"value": 9942.0}, "meta_eval_completion_tokens": {"value": 3173.0}, "meta_eval_prompt_cost": {"value": 0.00318144}, "meta_eval_completion_cost": {"value": 0.00406144}}, "created": "2025-12-10T21:41:09.9046886Z"}
{"ref": "andante-agate", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 19.488904}, "meta_inference_prompt_tokens": {"value": 13973.0}, "meta_inference_completion_tokens": {"value": 750.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027946}, "meta_inference_completion_cost": {"value": 0.0012}, "meta_eval_time": {"value": 22.921}, "meta_eval_prompt_tokens": {"value": 8663.0}, "meta_eval_completion_tokens": {"value": 2038.0}, "meta_eval_prompt_cost": {"value": 0.00277216}, "meta_eval_completion_cost": {"value": 0.00260864}}, "created": "2025-12-10T21:41:10.348015Z"}
{"ref": "andante-agate", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 22.756266}, "meta_inference_prompt_tokens": {"value": 14582.0}, "meta_inference_completion_tokens": {"value": 1167.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029164}, "meta_inference_completion_cost": {"value": 0.0018672}, "meta_eval_time": {"value": 31.772}, "meta_eval_prompt_tokens": {"value": 9488.0}, "meta_eval_completion_tokens": {"value": 2685.0}, "meta_eval_prompt_cost": {"value": 0.00303616}, "meta_eval_completion_cost": {"value": 0.0034368}}, "created": "2025-12-10T21:41:10.7204622Z"}
{"ref": "allegro-anchor-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.445833333333333}, "retrieval_dcg": {"value": 2.43195974923544}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.842105263157895}, "generation_factuality_precision": {"value": 0.727272727272727}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.058038}, "meta_inference_prompt_tokens": {"value": 21032.0}, "meta_inference_completion_tokens": {"value": 915.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0042064}, "meta_inference_completion_cost": {"value": 0.001464}, "meta_eval_time": {"value": 35.734}, "meta_eval_prompt_tokens": {"value": 16183.0}, "meta_eval_completion_tokens": {"value": 3381.0}, "meta_eval_prompt_cost": {"value": 0.00517856}, "meta_eval_completion_cost": {"value": 0.00432768}}, "created": "2025-12-10T21:41:12.3250294Z"}
{"ref": "andante-agate", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.260869565217391}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.2}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.2}, "meta_inference_time": {"value": 22.035537}, "meta_inference_prompt_tokens": {"value": 12891.0}, "meta_inference_completion_tokens": {"value": 943.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025782}, "meta_inference_completion_cost": {"value": 0.0015088}, "meta_eval_time": {"value": 29.202}, "meta_eval_prompt_tokens": {"value": 7986.0}, "meta_eval_completion_tokens": {"value": 2573.0}, "meta_eval_prompt_cost": {"value": 0.00255552}, "meta_eval_completion_cost": {"value": 0.00329344}}, "created": "2025-12-10T21:41:12.7517212Z"}
{"ref": "adventurous-ghoul", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.364816}, "meta_inference_prompt_tokens": {"value": 12941.0}, "meta_inference_completion_tokens": {"value": 1778.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025882}, "meta_inference_completion_cost": {"value": 0.0028448}, "meta_eval_time": {"value": 42.115}, "meta_eval_prompt_tokens": {"value": 9564.0}, "meta_eval_completion_tokens": {"value": 4182.0}, "meta_eval_prompt_cost": {"value": 0.00306048}, "meta_eval_completion_cost": {"value": 0.00535296}}, "created": "2025-12-10T21:41:13.8675218Z"}
{"ref": "antique-font", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.83333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.397299}, "meta_inference_prompt_tokens": {"value": 16013.0}, "meta_inference_completion_tokens": {"value": 905.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032026}, "meta_inference_completion_cost": {"value": 0.001448}, "meta_eval_time": {"value": 19.924}, "meta_eval_prompt_tokens": {"value": 11305.0}, "meta_eval_completion_tokens": {"value": 1921.0}, "meta_eval_prompt_cost": {"value": 0.0036176}, "meta_eval_completion_cost": {"value": 0.00245888}}, "created": "2025-12-10T21:41:14.5112109Z"}
{"ref": "allegro-anchor-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.375}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.625}, "generation_factuality_precision": {"value": 0.454545454545454}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.230769230769231}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.261041}, "meta_inference_prompt_tokens": {"value": 20668.0}, "meta_inference_completion_tokens": {"value": 1009.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0041336}, "meta_inference_completion_cost": {"value": 0.0016144}, "meta_eval_time": {"value": 40.808}, "meta_eval_prompt_tokens": {"value": 16247.0}, "meta_eval_completion_tokens": {"value": 4543.0}, "meta_eval_prompt_cost": {"value": 0.00519904}, "meta_eval_completion_cost": {"value": 0.00581504}}, "created": "2025-12-10T21:41:16.1191972Z"}
{"ref": "antique-font", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.83333333333333}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 49.837734}, "meta_inference_prompt_tokens": {"value": 16015.0}, "meta_inference_completion_tokens": {"value": 818.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003203}, "meta_inference_completion_cost": {"value": 0.0013088}, "meta_eval_time": {"value": 22.469}, "meta_eval_prompt_tokens": {"value": 11269.0}, "meta_eval_completion_tokens": {"value": 2012.0}, "meta_eval_prompt_cost": {"value": 0.00360608}, "meta_eval_completion_cost": {"value": 0.00257536}}, "created": "2025-12-10T21:41:18.0677799Z"}
{"ref": "allegro-anchor-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.10234862196714}, "generation_faithfulness": {"value": 0.962264150943396}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.514752}, "meta_inference_prompt_tokens": {"value": 20175.0}, "meta_inference_completion_tokens": {"value": 1376.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.004035}, "meta_inference_completion_cost": {"value": 0.0022016}, "meta_eval_time": {"value": 44.541}, "meta_eval_prompt_tokens": {"value": 16156.0}, "meta_eval_completion_tokens": {"value": 4502.0}, "meta_eval_prompt_cost": {"value": 0.00516992}, "meta_eval_completion_cost": {"value": 0.00576256}}, "created": "2025-12-10T21:41:18.1492257Z"}
{"ref": "ash-human", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.004646}, "meta_inference_prompt_tokens": {"value": 14242.0}, "meta_inference_completion_tokens": {"value": 650.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028484}, "meta_inference_completion_cost": {"value": 0.00104}, "meta_eval_time": {"value": 18.438}, "meta_eval_prompt_tokens": {"value": 9165.0}, "meta_eval_completion_tokens": {"value": 1581.0}, "meta_eval_prompt_cost": {"value": 0.0029328}, "meta_eval_completion_cost": {"value": 0.00202368}}, "created": "2025-12-10T21:41:19.0681825Z"}
{"ref": "ash-human", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.444223}, "meta_inference_prompt_tokens": {"value": 14242.0}, "meta_inference_completion_tokens": {"value": 833.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028484}, "meta_inference_completion_cost": {"value": 0.0013328}, "meta_eval_time": {"value": 19.639}, "meta_eval_prompt_tokens": {"value": 9368.0}, "meta_eval_completion_tokens": {"value": 1989.0}, "meta_eval_prompt_cost": {"value": 0.00299776}, "meta_eval_completion_cost": {"value": 0.00254592}}, "created": "2025-12-10T21:41:19.0685315Z"}
{"ref": "ash-human", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.195866}, "meta_inference_prompt_tokens": {"value": 14245.0}, "meta_inference_completion_tokens": {"value": 682.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002849}, "meta_inference_completion_cost": {"value": 0.0010912}, "meta_eval_time": {"value": 19.825}, "meta_eval_prompt_tokens": {"value": 9317.0}, "meta_eval_completion_tokens": {"value": 2003.0}, "meta_eval_prompt_cost": {"value": 0.00298144}, "meta_eval_completion_cost": {"value": 0.00256384}}, "created": "2025-12-10T21:41:21.889314Z"}
{"ref": "ash-human", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.579509}, "meta_inference_prompt_tokens": {"value": 11884.0}, "meta_inference_completion_tokens": {"value": 734.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023768}, "meta_inference_completion_cost": {"value": 0.0011744}, "meta_eval_time": {"value": 22.258}, "meta_eval_prompt_tokens": {"value": 6931.0}, "meta_eval_completion_tokens": {"value": 2151.0}, "meta_eval_prompt_cost": {"value": 0.00221792}, "meta_eval_completion_cost": {"value": 0.00275328}}, "created": "2025-12-10T21:41:22.8522024Z"}
{"ref": "allegro-anchor-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.11855936097192}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 36.228658}, "meta_inference_prompt_tokens": {"value": 20218.0}, "meta_inference_completion_tokens": {"value": 1437.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0040436}, "meta_inference_completion_cost": {"value": 0.0022992}, "meta_eval_time": {"value": 45.294}, "meta_eval_prompt_tokens": {"value": 15950.0}, "meta_eval_completion_tokens": {"value": 4196.0}, "meta_eval_prompt_cost": {"value": 0.005104}, "meta_eval_completion_cost": {"value": 0.00537088}}, "created": "2025-12-10T21:41:23.2631358Z"}
{"ref": "asphalt-farad", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.548116}, "meta_inference_prompt_tokens": {"value": 10442.0}, "meta_inference_completion_tokens": {"value": 949.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020884}, "meta_inference_completion_cost": {"value": 0.0015184}, "meta_eval_time": {"value": 20.205}, "meta_eval_prompt_tokens": {"value": 5480.0}, "meta_eval_completion_tokens": {"value": 1827.0}, "meta_eval_prompt_cost": {"value": 0.0017536}, "meta_eval_completion_cost": {"value": 0.00233856}}, "created": "2025-12-10T21:41:24.1574806Z"}
{"ref": "aged-crate-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.375}, "retrieval_mrr": {"value": 0.633333333333333}, "retrieval_dcg": {"value": 1.4234281553152}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.230769230769231}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.428571428571429}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.273932}, "meta_inference_prompt_tokens": {"value": 18338.0}, "meta_inference_completion_tokens": {"value": 1611.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0036676}, "meta_inference_completion_cost": {"value": 0.0025776}, "meta_eval_time": {"value": 54.44}, "meta_eval_prompt_tokens": {"value": 15190.0}, "meta_eval_completion_tokens": {"value": 4242.0}, "meta_eval_prompt_cost": {"value": 0.0048608}, "meta_eval_completion_cost": {"value": 0.00542976}}, "created": "2025-12-10T21:41:24.2966863Z"}
{"ref": "allegro-anchor-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.375}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 1.93067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.230769230769231}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.909138}, "meta_inference_prompt_tokens": {"value": 21413.0}, "meta_inference_completion_tokens": {"value": 935.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0042826}, "meta_inference_completion_cost": {"value": 0.001496}, "meta_eval_time": {"value": 48.874}, "meta_eval_prompt_tokens": {"value": 16606.0}, "meta_eval_completion_tokens": {"value": 3969.0}, "meta_eval_prompt_cost": {"value": 0.00531392}, "meta_eval_completion_cost": {"value": 0.00508032}}, "created": "2025-12-10T21:41:25.2508498Z"}
{"ref": "ash-human", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.907572}, "meta_inference_prompt_tokens": {"value": 14243.0}, "meta_inference_completion_tokens": {"value": 589.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028486}, "meta_inference_completion_cost": {"value": 0.0009424}, "meta_eval_time": {"value": 23.624}, "meta_eval_prompt_tokens": {"value": 9179.0}, "meta_eval_completion_tokens": {"value": 1582.0}, "meta_eval_prompt_cost": {"value": 0.00293728}, "meta_eval_completion_cost": {"value": 0.00202496}}, "created": "2025-12-10T21:41:25.4494026Z"}
{"ref": "avocado-frame", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.538909}, "meta_inference_prompt_tokens": {"value": 11398.0}, "meta_inference_completion_tokens": {"value": 512.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022796}, "meta_inference_completion_cost": {"value": 0.0008192}, "meta_eval_time": {"value": 7.863}, "meta_eval_prompt_tokens": {"value": 5745.0}, "meta_eval_completion_tokens": {"value": 670.0}, "meta_eval_prompt_cost": {"value": 0.0018384}, "meta_eval_completion_cost": {"value": 0.0008576}}, "created": "2025-12-10T21:41:25.9743672Z"}
{"ref": "asymptotic-retriever", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.671076}, "meta_inference_prompt_tokens": {"value": 14597.0}, "meta_inference_completion_tokens": {"value": 939.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029194}, "meta_inference_completion_cost": {"value": 0.0015024}, "meta_eval_time": {"value": 19.07}, "meta_eval_prompt_tokens": {"value": 9049.0}, "meta_eval_completion_tokens": {"value": 1793.0}, "meta_eval_prompt_cost": {"value": 0.00289568}, "meta_eval_completion_cost": {"value": 0.00229504}}, "created": "2025-12-10T21:41:26.4390311Z"}
{"ref": "asphalt-farad", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.308745}, "meta_inference_prompt_tokens": {"value": 10685.0}, "meta_inference_completion_tokens": {"value": 1001.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002137}, "meta_inference_completion_cost": {"value": 0.0016016}, "meta_eval_time": {"value": 23.216}, "meta_eval_prompt_tokens": {"value": 5673.0}, "meta_eval_completion_tokens": {"value": 1714.0}, "meta_eval_prompt_cost": {"value": 0.00181536}, "meta_eval_completion_cost": {"value": 0.00219392}}, "created": "2025-12-10T21:41:26.7375112Z"}
{"ref": "avocado-frame", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.571428571428571}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.957016}, "meta_inference_prompt_tokens": {"value": 8838.0}, "meta_inference_completion_tokens": {"value": 692.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0017676}, "meta_inference_completion_cost": {"value": 0.0011072}, "meta_eval_time": {"value": 11.482}, "meta_eval_prompt_tokens": {"value": 3881.0}, "meta_eval_completion_tokens": {"value": 956.0}, "meta_eval_prompt_cost": {"value": 0.00124192}, "meta_eval_completion_cost": {"value": 0.00122368}}, "created": "2025-12-10T21:41:27.639263Z"}
{"ref": "arctic-neutrino", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 33.228692}, "meta_inference_prompt_tokens": {"value": 11255.0}, "meta_inference_completion_tokens": {"value": 1782.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002251}, "meta_inference_completion_cost": {"value": 0.0028512}, "meta_eval_time": {"value": 36.549}, "meta_eval_prompt_tokens": {"value": 7320.0}, "meta_eval_completion_tokens": {"value": 3628.0}, "meta_eval_prompt_cost": {"value": 0.0023424}, "meta_eval_completion_cost": {"value": 0.00464384}}, "created": "2025-12-10T21:41:27.944515Z"}
{"ref": "asphalt-farad", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.882352941176471}, "generation_factuality_f1": {"value": 0.875}, "generation_factuality_precision": {"value": 0.777777777777778}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.055559}, "meta_inference_prompt_tokens": {"value": 10636.0}, "meta_inference_completion_tokens": {"value": 958.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021272}, "meta_inference_completion_cost": {"value": 0.0015328}, "meta_eval_time": {"value": 19.417}, "meta_eval_prompt_tokens": {"value": 5603.0}, "meta_eval_completion_tokens": {"value": 1739.0}, "meta_eval_prompt_cost": {"value": 0.00179296}, "meta_eval_completion_cost": {"value": 0.00222592}}, "created": "2025-12-10T21:41:27.9685221Z"}
{"ref": "asphalt-farad", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.950357}, "meta_inference_prompt_tokens": {"value": 10753.0}, "meta_inference_completion_tokens": {"value": 999.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021506}, "meta_inference_completion_cost": {"value": 0.0015984}, "meta_eval_time": {"value": 23.205}, "meta_eval_prompt_tokens": {"value": 5977.0}, "meta_eval_completion_tokens": {"value": 2135.0}, "meta_eval_prompt_cost": {"value": 0.00191264}, "meta_eval_completion_cost": {"value": 0.0027328}}, "created": "2025-12-10T21:41:28.1477868Z"}
{"ref": "arctic-neutrino", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 1.28906482631789}, "generation_faithfulness": {"value": 0.925925925925926}, "generation_factuality_f1": {"value": 0.166666666666667}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 30.406794}, "meta_inference_prompt_tokens": {"value": 13530.0}, "meta_inference_completion_tokens": {"value": 1603.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002706}, "meta_inference_completion_cost": {"value": 0.0025648}, "meta_eval_time": {"value": 30.905}, "meta_eval_prompt_tokens": {"value": 8834.0}, "meta_eval_completion_tokens": {"value": 2848.0}, "meta_eval_prompt_cost": {"value": 0.00282688}, "meta_eval_completion_cost": {"value": 0.00364544}}, "created": "2025-12-10T21:41:28.5718331Z"}
{"ref": "ascent-quanta-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 0.1875}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.72289156626506}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 26.691577}, "meta_inference_prompt_tokens": {"value": 13790.0}, "meta_inference_completion_tokens": {"value": 1379.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002758}, "meta_inference_completion_cost": {"value": 0.0022064}, "meta_eval_time": {"value": 29.469}, "meta_eval_prompt_tokens": {"value": 9173.0}, "meta_eval_completion_tokens": {"value": 3175.0}, "meta_eval_prompt_cost": {"value": 0.00293536}, "meta_eval_completion_cost": {"value": 0.004064}}, "created": "2025-12-10T21:41:28.7650281Z"}
{"ref": "avocado-frame", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.166666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.095635}, "meta_inference_prompt_tokens": {"value": 7818.0}, "meta_inference_completion_tokens": {"value": 649.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0015636}, "meta_inference_completion_cost": {"value": 0.0010384}, "meta_eval_time": {"value": 9.987}, "meta_eval_prompt_tokens": {"value": 3405.0}, "meta_eval_completion_tokens": {"value": 773.0}, "meta_eval_prompt_cost": {"value": 0.0010896}, "meta_eval_completion_cost": {"value": 0.00098944}}, "created": "2025-12-10T21:41:29.1143234Z"}
{"ref": "ascent-quanta-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 0.166666666666667}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 30.938523}, "meta_inference_prompt_tokens": {"value": 11965.0}, "meta_inference_completion_tokens": {"value": 1576.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002393}, "meta_inference_completion_cost": {"value": 0.0025216}, "meta_eval_time": {"value": 36.042}, "meta_eval_prompt_tokens": {"value": 7960.0}, "meta_eval_completion_tokens": {"value": 3522.0}, "meta_eval_prompt_cost": {"value": 0.0025472}, "meta_eval_completion_cost": {"value": 0.00450816}}, "created": "2025-12-10T21:41:31.0438037Z"}
{"ref": "avocado-frame", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.192897}, "meta_inference_prompt_tokens": {"value": 10703.0}, "meta_inference_completion_tokens": {"value": 658.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021406}, "meta_inference_completion_cost": {"value": 0.0010528}, "meta_eval_time": {"value": 9.409}, "meta_eval_prompt_tokens": {"value": 5077.0}, "meta_eval_completion_tokens": {"value": 757.0}, "meta_eval_prompt_cost": {"value": 0.00162464}, "meta_eval_completion_cost": {"value": 0.00096896}}, "created": "2025-12-10T21:41:31.3424522Z"}
{"ref": "asphalt-farad", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.68421052631579}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.807931}, "meta_inference_prompt_tokens": {"value": 10777.0}, "meta_inference_completion_tokens": {"value": 1023.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021554}, "meta_inference_completion_cost": {"value": 0.0016368}, "meta_eval_time": {"value": 25.504}, "meta_eval_prompt_tokens": {"value": 6003.0}, "meta_eval_completion_tokens": {"value": 2116.0}, "meta_eval_prompt_cost": {"value": 0.00192096}, "meta_eval_completion_cost": {"value": 0.00270848}}, "created": "2025-12-10T21:41:31.8742253Z"}
{"ref": "bisque-sub-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.936553}, "meta_inference_prompt_tokens": {"value": 10184.0}, "meta_inference_completion_tokens": {"value": 773.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020368}, "meta_inference_completion_cost": {"value": 0.0012368}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:41:31.9156909Z"}
{"ref": "arctic-neutrino", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 24.350406}, "meta_inference_prompt_tokens": {"value": 12992.0}, "meta_inference_completion_tokens": {"value": 1277.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025984}, "meta_inference_completion_cost": {"value": 0.0020432}, "meta_eval_time": {"value": 35.573}, "meta_eval_prompt_tokens": {"value": 8420.0}, "meta_eval_completion_tokens": {"value": 2937.0}, "meta_eval_prompt_cost": {"value": 0.0026944}, "meta_eval_completion_cost": {"value": 0.00375936}}, "created": "2025-12-10T21:41:32.5017889Z"}
{"ref": "bisque-sub-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.646771}, "meta_inference_prompt_tokens": {"value": 10188.0}, "meta_inference_completion_tokens": {"value": 722.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020376}, "meta_inference_completion_cost": {"value": 0.0011552}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:41:32.5449599Z"}
{"ref": "asymptotic-retriever", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.533333333333333}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 25.473159}, "meta_inference_prompt_tokens": {"value": 13016.0}, "meta_inference_completion_tokens": {"value": 1153.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026032}, "meta_inference_completion_cost": {"value": 0.0018448}, "meta_eval_time": {"value": 22.519}, "meta_eval_prompt_tokens": {"value": 7876.0}, "meta_eval_completion_tokens": {"value": 2324.0}, "meta_eval_prompt_cost": {"value": 0.00252032}, "meta_eval_completion_cost": {"value": 0.00297472}}, "created": "2025-12-10T21:41:33.2784205Z"}
{"ref": "ascent-quanta-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 0.1875}, "retrieval_dcg": {"value": 0.833333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.799207}, "meta_inference_prompt_tokens": {"value": 14338.0}, "meta_inference_completion_tokens": {"value": 1845.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028676}, "meta_inference_completion_cost": {"value": 0.002952}, "meta_eval_time": {"value": 35.781}, "meta_eval_prompt_tokens": {"value": 9969.0}, "meta_eval_completion_tokens": {"value": 3319.0}, "meta_eval_prompt_cost": {"value": 0.00319008}, "meta_eval_completion_cost": {"value": 0.00424832}}, "created": "2025-12-10T21:41:34.0071835Z"}
{"ref": "ascent-quanta-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.235294117647059}, "retrieval_mrr": {"value": 0.375}, "retrieval_dcg": {"value": 0.833333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.770642201834862}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.133333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 21.736199}, "meta_inference_prompt_tokens": {"value": 15322.0}, "meta_inference_completion_tokens": {"value": 1243.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030644}, "meta_inference_completion_cost": {"value": 0.0019888}, "meta_eval_time": {"value": 31.845}, "meta_eval_prompt_tokens": {"value": 10214.0}, "meta_eval_completion_tokens": {"value": 2936.0}, "meta_eval_prompt_cost": {"value": 0.00326848}, "meta_eval_completion_cost": {"value": 0.00375808}}, "created": "2025-12-10T21:41:34.7912607Z"}
{"ref": "avocado-frame", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.949901}, "meta_inference_prompt_tokens": {"value": 11959.0}, "meta_inference_completion_tokens": {"value": 701.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023918}, "meta_inference_completion_cost": {"value": 0.0011216}, "meta_eval_time": {"value": 10.407}, "meta_eval_prompt_tokens": {"value": 6366.0}, "meta_eval_completion_tokens": {"value": 833.0}, "meta_eval_prompt_cost": {"value": 0.00203712}, "meta_eval_completion_cost": {"value": 0.00106624}}, "created": "2025-12-10T21:41:35.8956769Z"}
{"ref": "bisque-sub-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.046646}, "meta_inference_prompt_tokens": {"value": 10183.0}, "meta_inference_completion_tokens": {"value": 806.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020366}, "meta_inference_completion_cost": {"value": 0.0012896}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:41:35.9362566Z"}
{"ref": "ascent-quanta-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 0.966666666666667}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.985222}, "meta_inference_prompt_tokens": {"value": 13794.0}, "meta_inference_completion_tokens": {"value": 1227.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027588}, "meta_inference_completion_cost": {"value": 0.0019632}, "meta_eval_time": {"value": 34.276}, "meta_eval_prompt_tokens": {"value": 9635.0}, "meta_eval_completion_tokens": {"value": 3360.0}, "meta_eval_prompt_cost": {"value": 0.0030832}, "meta_eval_completion_cost": {"value": 0.0043008}}, "created": "2025-12-10T21:41:36.8181245Z"}
{"ref": "arctic-neutrino", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.222222222222222}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 30.264072}, "meta_inference_prompt_tokens": {"value": 10213.0}, "meta_inference_completion_tokens": {"value": 1689.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020426}, "meta_inference_completion_cost": {"value": 0.0027024}, "meta_eval_time": {"value": 41.074}, "meta_eval_prompt_tokens": {"value": 6661.0}, "meta_eval_completion_tokens": {"value": 4059.0}, "meta_eval_prompt_cost": {"value": 0.00213152}, "meta_eval_completion_cost": {"value": 0.00519552}}, "created": "2025-12-10T21:41:37.3499334Z"}
{"ref": "asymptotic-retriever", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.421052631578947}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 20.578943}, "meta_inference_prompt_tokens": {"value": 12594.0}, "meta_inference_completion_tokens": {"value": 931.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025188}, "meta_inference_completion_cost": {"value": 0.0014896}, "meta_eval_time": {"value": 18.474}, "meta_eval_prompt_tokens": {"value": 7239.0}, "meta_eval_completion_tokens": {"value": 1781.0}, "meta_eval_prompt_cost": {"value": 0.00231648}, "meta_eval_completion_cost": {"value": 0.00227968}}, "created": "2025-12-10T21:41:37.6070225Z"}
{"ref": "bisque-sub-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.44702}, "meta_inference_prompt_tokens": {"value": 10180.0}, "meta_inference_completion_tokens": {"value": 893.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002036}, "meta_inference_completion_cost": {"value": 0.0014288}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:41:37.6501982Z"}
{"ref": "bisque-sub-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.106962}, "meta_inference_prompt_tokens": {"value": 10827.0}, "meta_inference_completion_tokens": {"value": 826.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021654}, "meta_inference_completion_cost": {"value": 0.0013216}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:41:37.6888253Z"}
{"ref": "arctic-neutrino", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 31.132698}, "meta_inference_prompt_tokens": {"value": 11124.0}, "meta_inference_completion_tokens": {"value": 1868.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022248}, "meta_inference_completion_cost": {"value": 0.0029888}, "meta_eval_time": {"value": 40.832}, "meta_eval_prompt_tokens": {"value": 6947.0}, "meta_eval_completion_tokens": {"value": 3526.0}, "meta_eval_prompt_cost": {"value": 0.00222304}, "meta_eval_completion_cost": {"value": 0.00451328}}, "created": "2025-12-10T21:41:37.8736397Z"}
{"ref": "asymptotic-retriever", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.01504}, "meta_inference_prompt_tokens": {"value": 13814.0}, "meta_inference_completion_tokens": {"value": 1232.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027628}, "meta_inference_completion_cost": {"value": 0.0019712}, "meta_eval_time": {"value": 28.503}, "meta_eval_prompt_tokens": {"value": 9018.0}, "meta_eval_completion_tokens": {"value": 2520.0}, "meta_eval_prompt_cost": {"value": 0.00288576}, "meta_eval_completion_cost": {"value": 0.0032256}}, "created": "2025-12-10T21:41:38.4480829Z"}
{"ref": "asymptotic-retriever", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.439768}, "meta_inference_prompt_tokens": {"value": 12877.0}, "meta_inference_completion_tokens": {"value": 1214.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025754}, "meta_inference_completion_cost": {"value": 0.0019424}, "meta_eval_time": {"value": 29.103}, "meta_eval_prompt_tokens": {"value": 7789.0}, "meta_eval_completion_tokens": {"value": 2385.0}, "meta_eval_prompt_cost": {"value": 0.00249248}, "meta_eval_completion_cost": {"value": 0.0030528}}, "created": "2025-12-10T21:41:38.7523822Z"}
{"ref": "ascent-quanta-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 0.931959749235439}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.298404}, "meta_inference_prompt_tokens": {"value": 12616.0}, "meta_inference_completion_tokens": {"value": 1573.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025232}, "meta_inference_completion_cost": {"value": 0.0025168}, "meta_eval_time": {"value": 46.749}, "meta_eval_prompt_tokens": {"value": 9605.0}, "meta_eval_completion_tokens": {"value": 4551.0}, "meta_eval_prompt_cost": {"value": 0.0030736}, "meta_eval_completion_cost": {"value": 0.00582528}}, "created": "2025-12-10T21:41:39.6937416Z"}
{"ref": "ascent-quanta-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.191666666666667}, "retrieval_dcg": {"value": 1.0879137408454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.875}, "generation_factuality_precision": {"value": 0.875}, "generation_factuality_recall": {"value": 0.875}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.375}, "generation_correctness": {"value": 0.875}, "meta_inference_time": {"value": 26.514432}, "meta_inference_prompt_tokens": {"value": 14816.0}, "meta_inference_completion_tokens": {"value": 1370.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029632}, "meta_inference_completion_cost": {"value": 0.002192}, "meta_eval_time": {"value": 41.235}, "meta_eval_prompt_tokens": {"value": 10376.0}, "meta_eval_completion_tokens": {"value": 3842.0}, "meta_eval_prompt_cost": {"value": 0.00332032}, "meta_eval_completion_cost": {"value": 0.00491776}}, "created": "2025-12-10T21:41:41.6336447Z"}
{"ref": "average-lacquer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.470588235294118}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 28.827078}, "meta_inference_prompt_tokens": {"value": 13308.0}, "meta_inference_completion_tokens": {"value": 786.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026616}, "meta_inference_completion_cost": {"value": 0.0012576}, "meta_eval_time": {"value": 29.927}, "meta_eval_prompt_tokens": {"value": 8710.0}, "meta_eval_completion_tokens": {"value": 2938.0}, "meta_eval_prompt_cost": {"value": 0.0027872}, "meta_eval_completion_cost": {"value": 0.00376064}}, "created": "2025-12-10T21:41:42.2915328Z"}
{"ref": "azure-halo-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.116994}, "meta_inference_prompt_tokens": {"value": 10699.0}, "meta_inference_completion_tokens": {"value": 538.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021398}, "meta_inference_completion_cost": {"value": 0.0008608}, "meta_eval_time": {"value": 18.178}, "meta_eval_prompt_tokens": {"value": 5631.0}, "meta_eval_completion_tokens": {"value": 1524.0}, "meta_eval_prompt_cost": {"value": 0.00180192}, "meta_eval_completion_cost": {"value": 0.00195072}}, "created": "2025-12-10T21:41:43.4729632Z"}
{"ref": "average-lacquer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.470588235294118}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 21.479437}, "meta_inference_prompt_tokens": {"value": 13309.0}, "meta_inference_completion_tokens": {"value": 918.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026618}, "meta_inference_completion_cost": {"value": 0.0014688}, "meta_eval_time": {"value": 29.695}, "meta_eval_prompt_tokens": {"value": 8711.0}, "meta_eval_completion_tokens": {"value": 2786.0}, "meta_eval_prompt_cost": {"value": 0.00278752}, "meta_eval_completion_cost": {"value": 0.00356608}}, "created": "2025-12-10T21:41:44.2430066Z"}
{"ref": "ascent-quanta-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 0.166666666666667}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.520269}, "meta_inference_prompt_tokens": {"value": 14803.0}, "meta_inference_completion_tokens": {"value": 1479.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029606}, "meta_inference_completion_cost": {"value": 0.0023664}, "meta_eval_time": {"value": 48.896}, "meta_eval_prompt_tokens": {"value": 11184.0}, "meta_eval_completion_tokens": {"value": 4269.0}, "meta_eval_prompt_cost": {"value": 0.00357888}, "meta_eval_completion_cost": {"value": 0.00546432}}, "created": "2025-12-10T21:41:46.8416982Z"}
{"ref": "azure-halo-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.190459}, "meta_inference_prompt_tokens": {"value": 10702.0}, "meta_inference_completion_tokens": {"value": 705.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021404}, "meta_inference_completion_cost": {"value": 0.001128}, "meta_eval_time": {"value": 20.863}, "meta_eval_prompt_tokens": {"value": 5712.0}, "meta_eval_completion_tokens": {"value": 1767.0}, "meta_eval_prompt_cost": {"value": 0.00182784}, "meta_eval_completion_cost": {"value": 0.00226176}}, "created": "2025-12-10T21:41:46.886294Z"}
{"ref": "atomic-manuscript", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.257588}, "meta_inference_prompt_tokens": {"value": 13460.0}, "meta_inference_completion_tokens": {"value": 1736.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002692}, "meta_inference_completion_cost": {"value": 0.0027776}, "meta_eval_time": {"value": 35.949}, "meta_eval_prompt_tokens": {"value": 9134.0}, "meta_eval_completion_tokens": {"value": 3193.0}, "meta_eval_prompt_cost": {"value": 0.00292288}, "meta_eval_completion_cost": {"value": 0.00408704}}, "created": "2025-12-10T21:41:48.7415789Z"}
{"ref": "ascent-quanta-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 0.1875}, "retrieval_dcg": {"value": 0.886852807234542}, "generation_faithfulness": {"value": 0.951219512195122}, "generation_factuality_f1": {"value": 0.707070707070707}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 0.714285714285714}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.714285714285714}, "meta_inference_time": {"value": 26.268643}, "meta_inference_prompt_tokens": {"value": 15311.0}, "meta_inference_completion_tokens": {"value": 1313.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030622}, "meta_inference_completion_cost": {"value": 0.0021008}, "meta_eval_time": {"value": 46.352}, "meta_eval_prompt_tokens": {"value": 11088.0}, "meta_eval_completion_tokens": {"value": 4212.0}, "meta_eval_prompt_cost": {"value": 0.00354816}, "meta_eval_completion_cost": {"value": 0.00539136}}, "created": "2025-12-10T21:41:48.7982911Z"}
{"ref": "azure-halo-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.95}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.918307}, "meta_inference_prompt_tokens": {"value": 11087.0}, "meta_inference_completion_tokens": {"value": 833.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022174}, "meta_inference_completion_cost": {"value": 0.0013328}, "meta_eval_time": {"value": 21.985}, "meta_eval_prompt_tokens": {"value": 6114.0}, "meta_eval_completion_tokens": {"value": 1921.0}, "meta_eval_prompt_cost": {"value": 0.00195648}, "meta_eval_completion_cost": {"value": 0.00245888}}, "created": "2025-12-10T21:41:50.1758291Z"}
{"ref": "azure-halo-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.842105263157895}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.43306}, "meta_inference_prompt_tokens": {"value": 11083.0}, "meta_inference_completion_tokens": {"value": 817.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022166}, "meta_inference_completion_cost": {"value": 0.0013072}, "meta_eval_time": {"value": 25.011}, "meta_eval_prompt_tokens": {"value": 6034.0}, "meta_eval_completion_tokens": {"value": 1983.0}, "meta_eval_prompt_cost": {"value": 0.00193088}, "meta_eval_completion_cost": {"value": 0.00253824}}, "created": "2025-12-10T21:41:53.024145Z"}
{"ref": "ascent-quanta-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 0.166666666666667}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.850069}, "meta_inference_prompt_tokens": {"value": 12788.0}, "meta_inference_completion_tokens": {"value": 1502.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025576}, "meta_inference_completion_cost": {"value": 0.0024032}, "meta_eval_time": {"value": 55.391}, "meta_eval_prompt_tokens": {"value": 9360.0}, "meta_eval_completion_tokens": {"value": 4649.0}, "meta_eval_prompt_cost": {"value": 0.0029952}, "meta_eval_completion_cost": {"value": 0.00595072}}, "created": "2025-12-10T21:41:54.0906264Z"}
{"ref": "baked-preference", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.777777777777778}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 33.430212}, "meta_inference_prompt_tokens": {"value": 12471.0}, "meta_inference_completion_tokens": {"value": 1966.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024942}, "meta_inference_completion_cost": {"value": 0.0031456}, "meta_eval_time": {"value": 31.222}, "meta_eval_prompt_tokens": {"value": 8466.0}, "meta_eval_completion_tokens": {"value": 2781.0}, "meta_eval_prompt_cost": {"value": 0.00270912}, "meta_eval_completion_cost": {"value": 0.00355968}}, "created": "2025-12-10T21:41:54.1141052Z"}
{"ref": "azure-halo-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.452043}, "meta_inference_prompt_tokens": {"value": 10872.0}, "meta_inference_completion_tokens": {"value": 729.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021744}, "meta_inference_completion_cost": {"value": 0.0011664}, "meta_eval_time": {"value": 29.86}, "meta_eval_prompt_tokens": {"value": 6079.0}, "meta_eval_completion_tokens": {"value": 2359.0}, "meta_eval_prompt_cost": {"value": 0.00194528}, "meta_eval_completion_cost": {"value": 0.00301952}}, "created": "2025-12-10T21:41:54.199026Z"}
{"ref": "average-lacquer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.533333333333333}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 22.911749}, "meta_inference_prompt_tokens": {"value": 13693.0}, "meta_inference_completion_tokens": {"value": 1185.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027386}, "meta_inference_completion_cost": {"value": 0.001896}, "meta_eval_time": {"value": 37.32}, "meta_eval_prompt_tokens": {"value": 9546.0}, "meta_eval_completion_tokens": {"value": 3888.0}, "meta_eval_prompt_cost": {"value": 0.00305472}, "meta_eval_completion_cost": {"value": 0.00497664}}, "created": "2025-12-10T21:41:55.5081964Z"}
{"ref": "baked-preference", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.84}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 36.612902}, "meta_inference_prompt_tokens": {"value": 12723.0}, "meta_inference_completion_tokens": {"value": 1628.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025446}, "meta_inference_completion_cost": {"value": 0.0026048}, "meta_eval_time": {"value": 30.219}, "meta_eval_prompt_tokens": {"value": 8574.0}, "meta_eval_completion_tokens": {"value": 2715.0}, "meta_eval_prompt_cost": {"value": 0.00274368}, "meta_eval_completion_cost": {"value": 0.0034752}}, "created": "2025-12-10T21:41:56.7112718Z"}
{"ref": "baked-preference", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.777777777777778}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 32.025557}, "meta_inference_prompt_tokens": {"value": 8059.0}, "meta_inference_completion_tokens": {"value": 1516.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0016118}, "meta_inference_completion_cost": {"value": 0.0024256}, "meta_eval_time": {"value": 34.063}, "meta_eval_prompt_tokens": {"value": 5463.0}, "meta_eval_completion_tokens": {"value": 3335.0}, "meta_eval_prompt_cost": {"value": 0.00174816}, "meta_eval_completion_cost": {"value": 0.0042688}}, "created": "2025-12-10T21:41:57.3662471Z"}
{"ref": "beveled-highlight", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 0.846153846153846}, "generation_factuality_f1": {"value": 0.375}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 22.054013}, "meta_inference_prompt_tokens": {"value": 16603.0}, "meta_inference_completion_tokens": {"value": 828.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0033206}, "meta_inference_completion_cost": {"value": 0.0013248}, "meta_eval_time": {"value": 27.063}, "meta_eval_prompt_tokens": {"value": 11745.0}, "meta_eval_completion_tokens": {"value": 2309.0}, "meta_eval_prompt_cost": {"value": 0.0037584}, "meta_eval_completion_cost": {"value": 0.00295552}}, "created": "2025-12-10T21:41:58.4548492Z"}
{"ref": "baked-preference", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.303266}, "meta_inference_prompt_tokens": {"value": 10894.0}, "meta_inference_completion_tokens": {"value": 1278.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021788}, "meta_inference_completion_cost": {"value": 0.0020448}, "meta_eval_time": {"value": 33.418}, "meta_eval_prompt_tokens": {"value": 6619.0}, "meta_eval_completion_tokens": {"value": 3111.0}, "meta_eval_prompt_cost": {"value": 0.00211808}, "meta_eval_completion_cost": {"value": 0.00398208}}, "created": "2025-12-10T21:42:01.0999564Z"}
{"ref": "bold-citadel", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.247272}, "meta_inference_prompt_tokens": {"value": 4667.0}, "meta_inference_completion_tokens": {"value": 1283.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009334}, "meta_inference_completion_cost": {"value": 0.0020528}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:01.1383835Z"}
{"ref": "bold-citadel", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 9.039658}, "meta_inference_prompt_tokens": {"value": 2246.0}, "meta_inference_completion_tokens": {"value": 404.0}, "meta_inference_prompt_cost": {"value": 0.0004492}, "meta_inference_completion_cost": {"value": 0.0006464}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:01.1760679Z"}
{"ref": "baked-preference", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.96969696969697}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 46.984362}, "meta_inference_prompt_tokens": {"value": 12286.0}, "meta_inference_completion_tokens": {"value": 1302.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024572}, "meta_inference_completion_cost": {"value": 0.0020832}, "meta_eval_time": {"value": 38.269}, "meta_eval_prompt_tokens": {"value": 8289.0}, "meta_eval_completion_tokens": {"value": 3241.0}, "meta_eval_prompt_cost": {"value": 0.00265248}, "meta_eval_completion_cost": {"value": 0.00414848}}, "created": "2025-12-10T21:42:02.4721941Z"}
{"ref": "bold-citadel", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.737935}, "meta_inference_prompt_tokens": {"value": 2246.0}, "meta_inference_completion_tokens": {"value": 581.0}, "meta_inference_prompt_cost": {"value": 0.0004492}, "meta_inference_completion_cost": {"value": 0.0009296}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:02.5105638Z"}
{"ref": "bold-citadel", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.893013}, "meta_inference_prompt_tokens": {"value": 2246.0}, "meta_inference_completion_tokens": {"value": 515.0}, "meta_inference_prompt_cost": {"value": 0.0004492}, "meta_inference_completion_cost": {"value": 0.000824}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:02.5813147Z"}
{"ref": "atomic-manuscript", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.222222222222222}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.06888}, "meta_inference_prompt_tokens": {"value": 12805.0}, "meta_inference_completion_tokens": {"value": 1605.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002561}, "meta_inference_completion_cost": {"value": 0.002568}, "meta_eval_time": {"value": 49.19}, "meta_eval_prompt_tokens": {"value": 8996.0}, "meta_eval_completion_tokens": {"value": 4203.0}, "meta_eval_prompt_cost": {"value": 0.00287872}, "meta_eval_completion_cost": {"value": 0.00537984}}, "created": "2025-12-10T21:42:03.0964586Z"}
{"ref": "beveled-highlight", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 39.149119}, "meta_inference_prompt_tokens": {"value": 16602.0}, "meta_inference_completion_tokens": {"value": 733.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0033204}, "meta_inference_completion_cost": {"value": 0.0011728}, "meta_eval_time": {"value": 26.538}, "meta_eval_prompt_tokens": {"value": 11510.0}, "meta_eval_completion_tokens": {"value": 2117.0}, "meta_eval_prompt_cost": {"value": 0.0036832}, "meta_eval_completion_cost": {"value": 0.00270976}}, "created": "2025-12-10T21:42:03.3981731Z"}
{"ref": "bold-citadel", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.125635}, "meta_inference_prompt_tokens": {"value": 2246.0}, "meta_inference_completion_tokens": {"value": 452.0}, "meta_inference_prompt_cost": {"value": 0.0004492}, "meta_inference_completion_cost": {"value": 0.0007232}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:03.4415194Z"}
{"ref": "beveled-highlight", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.93067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.645161290322581}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 24.411943}, "meta_inference_prompt_tokens": {"value": 17324.0}, "meta_inference_completion_tokens": {"value": 1138.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0034648}, "meta_inference_completion_cost": {"value": 0.0018208}, "meta_eval_time": {"value": 32.116}, "meta_eval_prompt_tokens": {"value": 12884.0}, "meta_eval_completion_tokens": {"value": 2828.0}, "meta_eval_prompt_cost": {"value": 0.00412288}, "meta_eval_completion_cost": {"value": 0.00361984}}, "created": "2025-12-10T21:42:04.0694803Z"}
{"ref": "beveled-highlight", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.266666666666667}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 52.343519}, "meta_inference_prompt_tokens": {"value": 15587.0}, "meta_inference_completion_tokens": {"value": 1037.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031174}, "meta_inference_completion_cost": {"value": 0.0016592}, "meta_eval_time": {"value": 33.818}, "meta_eval_prompt_tokens": {"value": 11551.0}, "meta_eval_completion_tokens": {"value": 3157.0}, "meta_eval_prompt_cost": {"value": 0.00369632}, "meta_eval_completion_cost": {"value": 0.00404096}}, "created": "2025-12-10T21:42:06.4098119Z"}
{"ref": "atomic-manuscript", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.886363636363636}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.172908}, "meta_inference_prompt_tokens": {"value": 13261.0}, "meta_inference_completion_tokens": {"value": 1600.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026522}, "meta_inference_completion_cost": {"value": 0.00256}, "meta_eval_time": {"value": 56.589}, "meta_eval_prompt_tokens": {"value": 8855.0}, "meta_eval_completion_tokens": {"value": 3883.0}, "meta_eval_prompt_cost": {"value": 0.0028336}, "meta_eval_completion_cost": {"value": 0.00497024}}, "created": "2025-12-10T21:42:06.9840242Z"}
{"ref": "beveled-highlight", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 18.038579}, "meta_inference_prompt_tokens": {"value": 16602.0}, "meta_inference_completion_tokens": {"value": 841.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0033204}, "meta_inference_completion_cost": {"value": 0.0013456}, "meta_eval_time": {"value": 32.443}, "meta_eval_prompt_tokens": {"value": 11889.0}, "meta_eval_completion_tokens": {"value": 2640.0}, "meta_eval_prompt_cost": {"value": 0.00380448}, "meta_eval_completion_cost": {"value": 0.0033792}}, "created": "2025-12-10T21:42:07.274639Z"}
{"ref": "basic-cymbal-A", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 1.0}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 71.573017}, "meta_inference_prompt_tokens": {"value": 13399.0}, "meta_inference_completion_tokens": {"value": 1612.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026798}, "meta_inference_completion_cost": {"value": 0.0025792}, "meta_eval_time": {"value": 40.491}, "meta_eval_prompt_tokens": {"value": 8646.0}, "meta_eval_completion_tokens": {"value": 4047.0}, "meta_eval_prompt_cost": {"value": 0.00276672}, "meta_eval_completion_cost": {"value": 0.00518016}}, "created": "2025-12-10T21:42:09.2973362Z"}
{"ref": "atomic-manuscript", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.974358974358974}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.25}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.818762}, "meta_inference_prompt_tokens": {"value": 11261.0}, "meta_inference_completion_tokens": {"value": 1452.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022522}, "meta_inference_completion_cost": {"value": 0.0023232}, "meta_eval_time": {"value": 41.255}, "meta_eval_prompt_tokens": {"value": 7932.0}, "meta_eval_completion_tokens": {"value": 3896.0}, "meta_eval_prompt_cost": {"value": 0.00253824}, "meta_eval_completion_cost": {"value": 0.00498688}}, "created": "2025-12-10T21:42:09.3037163Z"}
{"ref": "blended-dowel-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.945945945945946}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 26.24238}, "meta_inference_prompt_tokens": {"value": 10767.0}, "meta_inference_completion_tokens": {"value": 1396.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021534}, "meta_inference_completion_cost": {"value": 0.0022336}, "meta_eval_time": {"value": 36.962}, "meta_eval_prompt_tokens": {"value": 7017.0}, "meta_eval_completion_tokens": {"value": 3331.0}, "meta_eval_prompt_cost": {"value": 0.00224544}, "meta_eval_completion_cost": {"value": 0.00426368}}, "created": "2025-12-10T21:42:14.3680639Z"}
{"ref": "average-lacquer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 0.953488372093023}, "generation_factuality_f1": {"value": 0.436363636363636}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 18.702807}, "meta_inference_prompt_tokens": {"value": 13434.0}, "meta_inference_completion_tokens": {"value": 921.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026868}, "meta_inference_completion_cost": {"value": 0.0014736}, "meta_eval_time": {"value": 37.942}, "meta_eval_prompt_tokens": {"value": 8834.0}, "meta_eval_completion_tokens": {"value": 3522.0}, "meta_eval_prompt_cost": {"value": 0.00282688}, "meta_eval_completion_cost": {"value": 0.00450816}}, "created": "2025-12-10T21:42:15.6697306Z"}
{"ref": "blended-dowel-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.931818181818182}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 32.163788}, "meta_inference_prompt_tokens": {"value": 11889.0}, "meta_inference_completion_tokens": {"value": 1242.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023778}, "meta_inference_completion_cost": {"value": 0.0019872}, "meta_eval_time": {"value": 39.823}, "meta_eval_prompt_tokens": {"value": 7978.0}, "meta_eval_completion_tokens": {"value": 3759.0}, "meta_eval_prompt_cost": {"value": 0.00255296}, "meta_eval_completion_cost": {"value": 0.00481152}}, "created": "2025-12-10T21:42:15.8101742Z"}
{"ref": "basic-cymbal-A", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 1.0}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 35.375427}, "meta_inference_prompt_tokens": {"value": 14603.0}, "meta_inference_completion_tokens": {"value": 2002.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029206}, "meta_inference_completion_cost": {"value": 0.0032032}, "meta_eval_time": {"value": 46.939}, "meta_eval_prompt_tokens": {"value": 10307.0}, "meta_eval_completion_tokens": {"value": 4669.0}, "meta_eval_prompt_cost": {"value": 0.00329824}, "meta_eval_completion_cost": {"value": 0.00597632}}, "created": "2025-12-10T21:42:16.0926368Z"}
{"ref": "basic-cymbal-A", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 1.0}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 77.255932}, "meta_inference_prompt_tokens": {"value": 13520.0}, "meta_inference_completion_tokens": {"value": 1871.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002704}, "meta_inference_completion_cost": {"value": 0.0029936}, "meta_eval_time": {"value": 48.808}, "meta_eval_prompt_tokens": {"value": 8816.0}, "meta_eval_completion_tokens": {"value": 4332.0}, "meta_eval_prompt_cost": {"value": 0.00282112}, "meta_eval_completion_cost": {"value": 0.00554496}}, "created": "2025-12-10T21:42:17.4187964Z"}
{"ref": "average-lacquer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.347826086956522}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 32.067509}, "meta_inference_prompt_tokens": {"value": 13312.0}, "meta_inference_completion_tokens": {"value": 1184.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026624}, "meta_inference_completion_cost": {"value": 0.0018944}, "meta_eval_time": {"value": 51.077}, "meta_eval_prompt_tokens": {"value": 9198.0}, "meta_eval_completion_tokens": {"value": 3772.0}, "meta_eval_prompt_cost": {"value": 0.00294336}, "meta_eval_completion_cost": {"value": 0.00482816}}, "created": "2025-12-10T21:42:17.8553123Z"}
{"ref": "blue-poltergeist", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.875}, "generation_factuality_precision": {"value": 0.777777777777778}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.813137}, "meta_inference_prompt_tokens": {"value": 11365.0}, "meta_inference_completion_tokens": {"value": 1051.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002273}, "meta_inference_completion_cost": {"value": 0.0016816}, "meta_eval_time": {"value": 24.075}, "meta_eval_prompt_tokens": {"value": 6340.0}, "meta_eval_completion_tokens": {"value": 2181.0}, "meta_eval_prompt_cost": {"value": 0.0020288}, "meta_eval_completion_cost": {"value": 0.00279168}}, "created": "2025-12-10T21:42:18.3177302Z"}
{"ref": "atomic-manuscript", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.942857142857143}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.285714285714286}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.240275}, "meta_inference_prompt_tokens": {"value": 11073.0}, "meta_inference_completion_tokens": {"value": 1667.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022146}, "meta_inference_completion_cost": {"value": 0.0026672}, "meta_eval_time": {"value": 40.262}, "meta_eval_prompt_tokens": {"value": 7573.0}, "meta_eval_completion_tokens": {"value": 3320.0}, "meta_eval_prompt_cost": {"value": 0.00242336}, "meta_eval_completion_cost": {"value": 0.0042496}}, "created": "2025-12-10T21:42:18.7747377Z"}
{"ref": "breezy-crop", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.454545454545454}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.778668}, "meta_inference_prompt_tokens": {"value": 9674.0}, "meta_inference_completion_tokens": {"value": 675.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019348}, "meta_inference_completion_cost": {"value": 0.00108}, "meta_eval_time": {"value": 12.347}, "meta_eval_prompt_tokens": {"value": 4376.0}, "meta_eval_completion_tokens": {"value": 1240.0}, "meta_eval_prompt_cost": {"value": 0.00140032}, "meta_eval_completion_cost": {"value": 0.0015872}}, "created": "2025-12-10T21:42:19.6658928Z"}
{"ref": "blocky-net", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 0.25}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.409466}, "meta_inference_prompt_tokens": {"value": 10937.0}, "meta_inference_completion_tokens": {"value": 2005.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021874}, "meta_inference_completion_cost": {"value": 0.003208}, "meta_eval_time": {"value": 35.622}, "meta_eval_prompt_tokens": {"value": 6668.0}, "meta_eval_completion_tokens": {"value": 3021.0}, "meta_eval_prompt_cost": {"value": 0.00213376}, "meta_eval_completion_cost": {"value": 0.00386688}}, "created": "2025-12-10T21:42:19.9127003Z"}
{"ref": "blended-dowel-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.980769230769231}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 25.161727}, "meta_inference_prompt_tokens": {"value": 11530.0}, "meta_inference_completion_tokens": {"value": 1821.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002306}, "meta_inference_completion_cost": {"value": 0.0029136}, "meta_eval_time": {"value": 47.224}, "meta_eval_prompt_tokens": {"value": 8224.0}, "meta_eval_completion_tokens": {"value": 4556.0}, "meta_eval_prompt_cost": {"value": 0.00263168}, "meta_eval_completion_cost": {"value": 0.00583168}}, "created": "2025-12-10T21:42:21.2866916Z"}
{"ref": "blended-dowel-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.573854}, "meta_inference_prompt_tokens": {"value": 11797.0}, "meta_inference_completion_tokens": {"value": 1735.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023594}, "meta_inference_completion_cost": {"value": 0.002776}, "meta_eval_time": {"value": 40.78}, "meta_eval_prompt_tokens": {"value": 7574.0}, "meta_eval_completion_tokens": {"value": 3896.0}, "meta_eval_prompt_cost": {"value": 0.00242368}, "meta_eval_completion_cost": {"value": 0.00498688}}, "created": "2025-12-10T21:42:23.1249123Z"}
{"ref": "blue-hint", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.352941176470588}, "retrieval_mrr": {"value": 0.26984126984127}, "retrieval_dcg": {"value": 1.46426308690479}, "generation_faithfulness": {"value": 0.961538461538462}, "generation_factuality_f1": {"value": 0.625}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.214285714285714}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.428571428571429}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 20.065759}, "meta_inference_prompt_tokens": {"value": 14696.0}, "meta_inference_completion_tokens": {"value": 976.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029392}, "meta_inference_completion_cost": {"value": 0.0015616}, "meta_eval_time": {"value": 30.077}, "meta_eval_prompt_tokens": {"value": 8774.0}, "meta_eval_completion_tokens": {"value": 2707.0}, "meta_eval_prompt_cost": {"value": 0.00280768}, "meta_eval_completion_cost": {"value": 0.00346496}}, "created": "2025-12-10T21:42:23.1531555Z"}
{"ref": "blocky-net", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 0.25}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.545098}, "meta_inference_prompt_tokens": {"value": 11114.0}, "meta_inference_completion_tokens": {"value": 1887.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022228}, "meta_inference_completion_cost": {"value": 0.0030192}, "meta_eval_time": {"value": 40.676}, "meta_eval_prompt_tokens": {"value": 7533.0}, "meta_eval_completion_tokens": {"value": 3966.0}, "meta_eval_prompt_cost": {"value": 0.00241056}, "meta_eval_completion_cost": {"value": 0.00507648}}, "created": "2025-12-10T21:42:24.2198395Z"}
{"ref": "blue-poltergeist", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.894736842105263}, "generation_factuality_f1": {"value": 0.933333333333333}, "generation_factuality_precision": {"value": 0.875}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.946636}, "meta_inference_prompt_tokens": {"value": 11722.0}, "meta_inference_completion_tokens": {"value": 791.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023444}, "meta_inference_completion_cost": {"value": 0.0012656}, "meta_eval_time": {"value": 26.091}, "meta_eval_prompt_tokens": {"value": 6540.0}, "meta_eval_completion_tokens": {"value": 2137.0}, "meta_eval_prompt_cost": {"value": 0.0020928}, "meta_eval_completion_cost": {"value": 0.00273536}}, "created": "2025-12-10T21:42:24.5895171Z"}
{"ref": "blue-hint", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.235294117647059}, "retrieval_mrr": {"value": 0.154761904761905}, "retrieval_dcg": {"value": 0.731706553737374}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.133333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.285714285714286}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 20.280561}, "meta_inference_prompt_tokens": {"value": 14932.0}, "meta_inference_completion_tokens": {"value": 1041.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029864}, "meta_inference_completion_cost": {"value": 0.0016656}, "meta_eval_time": {"value": 30.68}, "meta_eval_prompt_tokens": {"value": 8780.0}, "meta_eval_completion_tokens": {"value": 2375.0}, "meta_eval_prompt_cost": {"value": 0.0028096}, "meta_eval_completion_cost": {"value": 0.00304}}, "created": "2025-12-10T21:42:24.8415974Z"}
{"ref": "basic-cymbal-A", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 1.0}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 34.801229}, "meta_inference_prompt_tokens": {"value": 14959.0}, "meta_inference_completion_tokens": {"value": 1898.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029918}, "meta_inference_completion_cost": {"value": 0.0030368}, "meta_eval_time": {"value": 52.138}, "meta_eval_prompt_tokens": {"value": 10700.0}, "meta_eval_completion_tokens": {"value": 5329.0}, "meta_eval_prompt_cost": {"value": 0.003424}, "meta_eval_completion_cost": {"value": 0.00682112}}, "created": "2025-12-10T21:42:25.4604081Z"}
{"ref": "blue-poltergeist", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.91026}, "meta_inference_prompt_tokens": {"value": 11365.0}, "meta_inference_completion_tokens": {"value": 1011.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002273}, "meta_inference_completion_cost": {"value": 0.0016176}, "meta_eval_time": {"value": 30.467}, "meta_eval_prompt_tokens": {"value": 6641.0}, "meta_eval_completion_tokens": {"value": 2734.0}, "meta_eval_prompt_cost": {"value": 0.00212512}, "meta_eval_completion_cost": {"value": 0.00349952}}, "created": "2025-12-10T21:42:26.5897913Z"}
{"ref": "blocky-net", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.375}, "retrieval_dcg": {"value": 1.28906482631789}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 37.895052}, "meta_inference_prompt_tokens": {"value": 11733.0}, "meta_inference_completion_tokens": {"value": 1896.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023466}, "meta_inference_completion_cost": {"value": 0.0030336}, "meta_eval_time": {"value": 37.901}, "meta_eval_prompt_tokens": {"value": 8010.0}, "meta_eval_completion_tokens": {"value": 3657.0}, "meta_eval_prompt_cost": {"value": 0.0025632}, "meta_eval_completion_cost": {"value": 0.00468096}}, "created": "2025-12-10T21:42:26.7415317Z"}
{"ref": "blended-dowel-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.980769230769231}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.194057}, "meta_inference_prompt_tokens": {"value": 12071.0}, "meta_inference_completion_tokens": {"value": 1692.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024142}, "meta_inference_completion_cost": {"value": 0.0027072}, "meta_eval_time": {"value": 47.509}, "meta_eval_prompt_tokens": {"value": 7475.0}, "meta_eval_completion_tokens": {"value": 4400.0}, "meta_eval_prompt_cost": {"value": 0.002392}, "meta_eval_completion_cost": {"value": 0.005632}}, "created": "2025-12-10T21:42:27.2775089Z"}
{"ref": "breezy-crop", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.466666666666667}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.644161}, "meta_inference_prompt_tokens": {"value": 10634.0}, "meta_inference_completion_tokens": {"value": 813.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021268}, "meta_inference_completion_cost": {"value": 0.0013008}, "meta_eval_time": {"value": 17.952}, "meta_eval_prompt_tokens": {"value": 5282.0}, "meta_eval_completion_tokens": {"value": 1528.0}, "meta_eval_prompt_cost": {"value": 0.00169024}, "meta_eval_completion_cost": {"value": 0.00195584}}, "created": "2025-12-10T21:42:27.3282898Z"}
{"ref": "blended-dowel-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.6}, "retrieval_dcg": {"value": 0.789064826317888}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.682812}, "meta_inference_prompt_tokens": {"value": 12852.0}, "meta_inference_completion_tokens": {"value": 1778.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025704}, "meta_inference_completion_cost": {"value": 0.0028448}, "meta_eval_time": {"value": 45.736}, "meta_eval_prompt_tokens": {"value": 8432.0}, "meta_eval_completion_tokens": {"value": 4152.0}, "meta_eval_prompt_cost": {"value": 0.00269824}, "meta_eval_completion_cost": {"value": 0.00531456}}, "created": "2025-12-10T21:42:27.4311705Z"}
{"ref": "blended-dowel-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.956521739130435}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 33.119033}, "meta_inference_prompt_tokens": {"value": 11602.0}, "meta_inference_completion_tokens": {"value": 1381.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023204}, "meta_inference_completion_cost": {"value": 0.0022096}, "meta_eval_time": {"value": 48.906}, "meta_eval_prompt_tokens": {"value": 8326.0}, "meta_eval_completion_tokens": {"value": 4460.0}, "meta_eval_prompt_cost": {"value": 0.00266432}, "meta_eval_completion_cost": {"value": 0.0057088}}, "created": "2025-12-10T21:42:27.7044096Z"}
{"ref": "blue-hint", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.352941176470588}, "retrieval_mrr": {"value": 0.186507936507936}, "retrieval_dcg": {"value": 1.03520626117701}, "generation_faithfulness": {"value": 0.925925925925926}, "generation_factuality_f1": {"value": 0.625}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.214285714285714}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.428571428571429}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 26.043013}, "meta_inference_prompt_tokens": {"value": 14878.0}, "meta_inference_completion_tokens": {"value": 1285.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029756}, "meta_inference_completion_cost": {"value": 0.002056}, "meta_eval_time": {"value": 31.048}, "meta_eval_prompt_tokens": {"value": 9144.0}, "meta_eval_completion_tokens": {"value": 2724.0}, "meta_eval_prompt_cost": {"value": 0.00292608}, "meta_eval_completion_cost": {"value": 0.00348672}}, "created": "2025-12-10T21:42:27.8111206Z"}
{"ref": "blue-poltergeist", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.804563}, "meta_inference_prompt_tokens": {"value": 13495.0}, "meta_inference_completion_tokens": {"value": 1287.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002699}, "meta_inference_completion_cost": {"value": 0.0020592}, "meta_eval_time": {"value": 34.377}, "meta_eval_prompt_tokens": {"value": 9109.0}, "meta_eval_completion_tokens": {"value": 3025.0}, "meta_eval_prompt_cost": {"value": 0.00291488}, "meta_eval_completion_cost": {"value": 0.003872}}, "created": "2025-12-10T21:42:28.5099094Z"}
{"ref": "blocky-net", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 0.25}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.96875}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.59832}, "meta_inference_prompt_tokens": {"value": 11170.0}, "meta_inference_completion_tokens": {"value": 1945.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002234}, "meta_inference_completion_cost": {"value": 0.003112}, "meta_eval_time": {"value": 43.555}, "meta_eval_prompt_tokens": {"value": 7105.0}, "meta_eval_completion_tokens": {"value": 3752.0}, "meta_eval_prompt_cost": {"value": 0.0022736}, "meta_eval_completion_cost": {"value": 0.00480256}}, "created": "2025-12-10T21:42:30.48087Z"}
{"ref": "breezy-crop", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.642857142857143}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 36.154133}, "meta_inference_prompt_tokens": {"value": 9739.0}, "meta_inference_completion_tokens": {"value": 883.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019478}, "meta_inference_completion_cost": {"value": 0.0014128}, "meta_eval_time": {"value": 14.697}, "meta_eval_prompt_tokens": {"value": 4509.0}, "meta_eval_completion_tokens": {"value": 1391.0}, "meta_eval_prompt_cost": {"value": 0.00144288}, "meta_eval_completion_cost": {"value": 0.00178048}}, "created": "2025-12-10T21:42:30.8680106Z"}
{"ref": "broad-crest", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.060615}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 726.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0011616}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:30.9096797Z"}
{"ref": "bronze-float", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.429483}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 777.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.0012432}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:30.9466685Z"}
{"ref": "bronze-float", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.902961}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 516.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.0008256}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:31.0691241Z"}
{"ref": "bronze-float", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.619115}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 458.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.0007328}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:31.1052378Z"}
{"ref": "brass-log", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.590094821981869}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.113577}, "meta_inference_prompt_tokens": {"value": 11585.0}, "meta_inference_completion_tokens": {"value": 1309.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002317}, "meta_inference_completion_cost": {"value": 0.0020944}, "meta_eval_time": {"value": 24.652}, "meta_eval_prompt_tokens": {"value": 7359.0}, "meta_eval_completion_tokens": {"value": 2427.0}, "meta_eval_prompt_cost": {"value": 0.00235488}, "meta_eval_completion_cost": {"value": 0.00310656}}, "created": "2025-12-10T21:42:31.7006292Z"}
{"ref": "burning-cask", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.280109}, "meta_inference_prompt_tokens": {"value": 5322.0}, "meta_inference_completion_tokens": {"value": 967.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0010644}, "meta_inference_completion_cost": {"value": 0.0015472}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:31.7452546Z"}
{"ref": "broad-crest", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 37.257475}, "meta_inference_prompt_tokens": {"value": 5874.0}, "meta_inference_completion_tokens": {"value": 2358.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0011748}, "meta_inference_completion_cost": {"value": 0.0037728}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:31.8411836Z"}
{"ref": "broad-crest", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.483667}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 795.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.001272}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:31.8787176Z"}
{"ref": "burning-cask", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.110105}, "meta_inference_prompt_tokens": {"value": 5357.0}, "meta_inference_completion_tokens": {"value": 738.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0010714}, "meta_inference_completion_cost": {"value": 0.0011808}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:31.918722Z"}
{"ref": "bronze-float", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 57.250049}, "meta_inference_prompt_tokens": {"value": 12150.0}, "meta_inference_completion_tokens": {"value": 1174.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00243}, "meta_inference_completion_cost": {"value": 0.0018784}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:31.9594891Z"}
{"ref": "burning-cask", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.040473}, "meta_inference_prompt_tokens": {"value": 5319.0}, "meta_inference_completion_tokens": {"value": 701.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0010638}, "meta_inference_completion_cost": {"value": 0.0011216}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:32.011374Z"}
{"ref": "blue-hint", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.207482993197279}, "retrieval_dcg": {"value": 2.87839107719427}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.51063829787234}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.571428571428571}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 33.192044}, "meta_inference_prompt_tokens": {"value": 39543.0}, "meta_inference_completion_tokens": {"value": 1769.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0079086}, "meta_inference_completion_cost": {"value": 0.0028304}, "meta_eval_time": {"value": 35.479}, "meta_eval_prompt_tokens": {"value": 15794.0}, "meta_eval_completion_tokens": {"value": 2860.0}, "meta_eval_prompt_cost": {"value": 0.00505408}, "meta_eval_completion_cost": {"value": 0.0036608}}, "created": "2025-12-10T21:42:32.8857398Z"}
{"ref": "blended-dowel-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.375}, "retrieval_mrr": {"value": 0.455555555555556}, "retrieval_dcg": {"value": 1.23170655373737}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.230769230769231}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.066374}, "meta_inference_prompt_tokens": {"value": 13314.0}, "meta_inference_completion_tokens": {"value": 1494.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026628}, "meta_inference_completion_cost": {"value": 0.0023904}, "meta_eval_time": {"value": 43.439}, "meta_eval_prompt_tokens": {"value": 8527.0}, "meta_eval_completion_tokens": {"value": 3881.0}, "meta_eval_prompt_cost": {"value": 0.00272864}, "meta_eval_completion_cost": {"value": 0.00496768}}, "created": "2025-12-10T21:42:33.6562617Z"}
{"ref": "blue-poltergeist", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.082283}, "meta_inference_prompt_tokens": {"value": 11360.0}, "meta_inference_completion_tokens": {"value": 1111.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002272}, "meta_inference_completion_cost": {"value": 0.0017776}, "meta_eval_time": {"value": 31.008}, "meta_eval_prompt_tokens": {"value": 6681.0}, "meta_eval_completion_tokens": {"value": 2523.0}, "meta_eval_prompt_cost": {"value": 0.00213792}, "meta_eval_completion_cost": {"value": 0.00322944}}, "created": "2025-12-10T21:42:34.1433856Z"}
{"ref": "brass-log", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.590094821981869}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 40.76856}, "meta_inference_prompt_tokens": {"value": 11591.0}, "meta_inference_completion_tokens": {"value": 1057.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023182}, "meta_inference_completion_cost": {"value": 0.0016912}, "meta_eval_time": {"value": 32.738}, "meta_eval_prompt_tokens": {"value": 7232.0}, "meta_eval_completion_tokens": {"value": 2709.0}, "meta_eval_prompt_cost": {"value": 0.00231424}, "meta_eval_completion_cost": {"value": 0.00346752}}, "created": "2025-12-10T21:42:35.3604685Z"}
{"ref": "blue-hint", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.117647058823529}, "retrieval_mrr": {"value": 0.166666666666667}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.19047619047619}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.0625}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.142857142857143}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 23.588205}, "meta_inference_prompt_tokens": {"value": 13310.0}, "meta_inference_completion_tokens": {"value": 1121.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002662}, "meta_inference_completion_cost": {"value": 0.0017936}, "meta_eval_time": {"value": 31.972}, "meta_eval_prompt_tokens": {"value": 7948.0}, "meta_eval_completion_tokens": {"value": 2953.0}, "meta_eval_prompt_cost": {"value": 0.00254336}, "meta_eval_completion_cost": {"value": 0.00377984}}, "created": "2025-12-10T21:42:35.4488644Z"}
{"ref": "blended-dowel-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.925}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 26.166051}, "meta_inference_prompt_tokens": {"value": 11412.0}, "meta_inference_completion_tokens": {"value": 1433.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022824}, "meta_inference_completion_cost": {"value": 0.0022928}, "meta_eval_time": {"value": 57.589}, "meta_eval_prompt_tokens": {"value": 7992.0}, "meta_eval_completion_tokens": {"value": 3952.0}, "meta_eval_prompt_cost": {"value": 0.00255744}, "meta_eval_completion_cost": {"value": 0.00505856}}, "created": "2025-12-10T21:42:35.5032728Z"}
{"ref": "burning-cask", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.884443}, "meta_inference_prompt_tokens": {"value": 5368.0}, "meta_inference_completion_tokens": {"value": 1147.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0010736}, "meta_inference_completion_cost": {"value": 0.0018352}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:35.5723151Z"}
{"ref": "breezy-crop", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8125}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.261951}, "meta_inference_prompt_tokens": {"value": 9319.0}, "meta_inference_completion_tokens": {"value": 629.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018638}, "meta_inference_completion_cost": {"value": 0.0010064}, "meta_eval_time": {"value": 20.224}, "meta_eval_prompt_tokens": {"value": 4316.0}, "meta_eval_completion_tokens": {"value": 1748.0}, "meta_eval_prompt_cost": {"value": 0.00138112}, "meta_eval_completion_cost": {"value": 0.00223744}}, "created": "2025-12-10T21:42:35.9538452Z"}
{"ref": "bright-cache", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 43.943139}, "meta_inference_prompt_tokens": {"value": 11064.0}, "meta_inference_completion_tokens": {"value": 791.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022128}, "meta_inference_completion_cost": {"value": 0.0012656}, "meta_eval_time": {"value": 20.378}, "meta_eval_prompt_tokens": {"value": 6914.0}, "meta_eval_completion_tokens": {"value": 2063.0}, "meta_eval_prompt_cost": {"value": 0.00221248}, "meta_eval_completion_cost": {"value": 0.00264064}}, "created": "2025-12-10T21:42:36.2331795Z"}
{"ref": "burning-cask", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.647544}, "meta_inference_prompt_tokens": {"value": 5319.0}, "meta_inference_completion_tokens": {"value": 902.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0010638}, "meta_inference_completion_cost": {"value": 0.0014432}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:36.2706647Z"}
{"ref": "bronze-float", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.436118}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 921.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.0014736}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:36.3108192Z"}
{"ref": "breezy-crop", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.727272727272727}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.736756}, "meta_inference_prompt_tokens": {"value": 10628.0}, "meta_inference_completion_tokens": {"value": 541.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021256}, "meta_inference_completion_cost": {"value": 0.0008656}, "meta_eval_time": {"value": 13.557}, "meta_eval_prompt_tokens": {"value": 5207.0}, "meta_eval_completion_tokens": {"value": 1229.0}, "meta_eval_prompt_cost": {"value": 0.00166624}, "meta_eval_completion_cost": {"value": 0.00157312}}, "created": "2025-12-10T21:42:36.7578683Z"}
{"ref": "bright-cache", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.944444444444444}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.374221}, "meta_inference_prompt_tokens": {"value": 13369.0}, "meta_inference_completion_tokens": {"value": 1159.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026738}, "meta_inference_completion_cost": {"value": 0.0018544}, "meta_eval_time": {"value": 22.36}, "meta_eval_prompt_tokens": {"value": 8913.0}, "meta_eval_completion_tokens": {"value": 2144.0}, "meta_eval_prompt_cost": {"value": 0.00285216}, "meta_eval_completion_cost": {"value": 0.00274432}}, "created": "2025-12-10T21:42:36.7691407Z"}
{"ref": "candied-agent-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.108631}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 440.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.000704}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:36.8068899Z"}
{"ref": "candied-agent-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.425344}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 453.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0007248}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:36.8548131Z"}
{"ref": "candied-agent-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.222216}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 389.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0006224}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:36.8644958Z"}
{"ref": "broad-crest", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.927726}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 582.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0009312}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:36.9135144Z"}
{"ref": "broad-crest", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.385628}, "meta_inference_prompt_tokens": {"value": 5870.0}, "meta_inference_completion_tokens": {"value": 1936.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001174}, "meta_inference_completion_cost": {"value": 0.0030976}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:36.9112283Z"}
{"ref": "candied-agent-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.837711}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 897.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0014352}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:36.9564828Z"}
{"ref": "candied-agent-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.154341}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 585.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.000936}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:37.0040429Z"}
{"ref": "bright-cache", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.996751}, "meta_inference_prompt_tokens": {"value": 11061.0}, "meta_inference_completion_tokens": {"value": 897.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022122}, "meta_inference_completion_cost": {"value": 0.0014352}, "meta_eval_time": {"value": 18.385}, "meta_eval_prompt_tokens": {"value": 6985.0}, "meta_eval_completion_tokens": {"value": 1808.0}, "meta_eval_prompt_cost": {"value": 0.0022352}, "meta_eval_completion_cost": {"value": 0.00231424}}, "created": "2025-12-10T21:42:37.2008462Z"}
{"ref": "bright-credits-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.62239815965122}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.629746}, "meta_inference_prompt_tokens": {"value": 15649.0}, "meta_inference_completion_tokens": {"value": 1188.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031298}, "meta_inference_completion_cost": {"value": 0.0019008}, "meta_eval_time": {"value": 32.967}, "meta_eval_prompt_tokens": {"value": 11562.0}, "meta_eval_completion_tokens": {"value": 3162.0}, "meta_eval_prompt_cost": {"value": 0.00369984}, "meta_eval_completion_cost": {"value": 0.00404736}}, "created": "2025-12-10T21:42:39.4241343Z"}
{"ref": "bright-ridge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.846153846153846}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.404975}, "meta_inference_prompt_tokens": {"value": 10407.0}, "meta_inference_completion_tokens": {"value": 821.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020814}, "meta_inference_completion_cost": {"value": 0.0013136}, "meta_eval_time": {"value": 15.182}, "meta_eval_prompt_tokens": {"value": 5238.0}, "meta_eval_completion_tokens": {"value": 1407.0}, "meta_eval_prompt_cost": {"value": 0.00167616}, "meta_eval_completion_cost": {"value": 0.00180096}}, "created": "2025-12-10T21:42:40.061487Z"}
{"ref": "blocky-net", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 0.25}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 33.638984}, "meta_inference_prompt_tokens": {"value": 10893.0}, "meta_inference_completion_tokens": {"value": 2314.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021786}, "meta_inference_completion_cost": {"value": 0.0037024}, "meta_eval_time": {"value": 53.725}, "meta_eval_prompt_tokens": {"value": 7010.0}, "meta_eval_completion_tokens": {"value": 3889.0}, "meta_eval_prompt_cost": {"value": 0.0022432}, "meta_eval_completion_cost": {"value": 0.00497792}}, "created": "2025-12-10T21:42:40.6093042Z"}
{"ref": "bright-ridge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.192913}, "meta_inference_prompt_tokens": {"value": 10160.0}, "meta_inference_completion_tokens": {"value": 865.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002032}, "meta_inference_completion_cost": {"value": 0.001384}, "meta_eval_time": {"value": 17.466}, "meta_eval_prompt_tokens": {"value": 5133.0}, "meta_eval_completion_tokens": {"value": 1620.0}, "meta_eval_prompt_cost": {"value": 0.00164256}, "meta_eval_completion_cost": {"value": 0.0020736}}, "created": "2025-12-10T21:42:40.636825Z"}
{"ref": "brass-log", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.590094821981869}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 54.06062}, "meta_inference_prompt_tokens": {"value": 11588.0}, "meta_inference_completion_tokens": {"value": 1288.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023176}, "meta_inference_completion_cost": {"value": 0.0020608}, "meta_eval_time": {"value": 41.659}, "meta_eval_prompt_tokens": {"value": 7541.0}, "meta_eval_completion_tokens": {"value": 2966.0}, "meta_eval_prompt_cost": {"value": 0.00241312}, "meta_eval_completion_cost": {"value": 0.00379648}}, "created": "2025-12-10T21:42:42.8972326Z"}
{"ref": "bright-credits-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.96426308690479}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.941176470588235}, "generation_factuality_precision": {"value": 0.888888888888889}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.469188}, "meta_inference_prompt_tokens": {"value": 15742.0}, "meta_inference_completion_tokens": {"value": 840.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031484}, "meta_inference_completion_cost": {"value": 0.001344}, "meta_eval_time": {"value": 24.99}, "meta_eval_prompt_tokens": {"value": 11348.0}, "meta_eval_completion_tokens": {"value": 2536.0}, "meta_eval_prompt_cost": {"value": 0.00363136}, "meta_eval_completion_cost": {"value": 0.00324608}}, "created": "2025-12-10T21:42:42.9004112Z"}
{"ref": "bright-credits-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.85620718710802}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.829493087557604}, "generation_factuality_precision": {"value": 0.769230769230769}, "generation_factuality_recall": {"value": 0.9}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.9}, "meta_inference_time": {"value": 23.391295}, "meta_inference_prompt_tokens": {"value": 14307.0}, "meta_inference_completion_tokens": {"value": 826.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028614}, "meta_inference_completion_cost": {"value": 0.0013216}, "meta_eval_time": {"value": 23.288}, "meta_eval_prompt_tokens": {"value": 9593.0}, "meta_eval_completion_tokens": {"value": 2375.0}, "meta_eval_prompt_cost": {"value": 0.00306976}, "meta_eval_completion_cost": {"value": 0.00304}}, "created": "2025-12-10T21:42:42.9929766Z"}
{"ref": "bright-credits-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.85620718710802}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.018293}, "meta_inference_prompt_tokens": {"value": 14303.0}, "meta_inference_completion_tokens": {"value": 690.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028606}, "meta_inference_completion_cost": {"value": 0.001104}, "meta_eval_time": {"value": 21.682}, "meta_eval_prompt_tokens": {"value": 9538.0}, "meta_eval_completion_tokens": {"value": 2059.0}, "meta_eval_prompt_cost": {"value": 0.00305216}, "meta_eval_completion_cost": {"value": 0.00263552}}, "created": "2025-12-10T21:42:43.0112879Z"}
{"ref": "bright-credits-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.85620718710802}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.947368421052632}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.561021}, "meta_inference_prompt_tokens": {"value": 14305.0}, "meta_inference_completion_tokens": {"value": 768.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002861}, "meta_inference_completion_cost": {"value": 0.0012288}, "meta_eval_time": {"value": 24.488}, "meta_eval_prompt_tokens": {"value": 9642.0}, "meta_eval_completion_tokens": {"value": 2565.0}, "meta_eval_prompt_cost": {"value": 0.00308544}, "meta_eval_completion_cost": {"value": 0.0032832}}, "created": "2025-12-10T21:42:44.4404735Z"}
{"ref": "blended-dowel-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.083646}, "meta_inference_prompt_tokens": {"value": 11536.0}, "meta_inference_completion_tokens": {"value": 1528.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023072}, "meta_inference_completion_cost": {"value": 0.0024448}, "meta_eval_time": {"value": 55.658}, "meta_eval_prompt_tokens": {"value": 7785.0}, "meta_eval_completion_tokens": {"value": 5290.0}, "meta_eval_prompt_cost": {"value": 0.0024912}, "meta_eval_completion_cost": {"value": 0.0067712}}, "created": "2025-12-10T21:42:44.441846Z"}
{"ref": "bright-ridge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.764705882352941}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.21265}, "meta_inference_prompt_tokens": {"value": 10291.0}, "meta_inference_completion_tokens": {"value": 798.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020582}, "meta_inference_completion_cost": {"value": 0.0012768}, "meta_eval_time": {"value": 21.33}, "meta_eval_prompt_tokens": {"value": 5428.0}, "meta_eval_completion_tokens": {"value": 1950.0}, "meta_eval_prompt_cost": {"value": 0.00173696}, "meta_eval_completion_cost": {"value": 0.002496}}, "created": "2025-12-10T21:42:46.8290535Z"}
{"ref": "basic-cymbal-A", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 1.0}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 29.0651}, "meta_inference_prompt_tokens": {"value": 15477.0}, "meta_inference_completion_tokens": {"value": 1750.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030954}, "meta_inference_completion_cost": {"value": 0.0028}, "meta_eval_time": {"value": 76.183}, "meta_eval_prompt_tokens": {"value": 11262.0}, "meta_eval_completion_tokens": {"value": 5894.0}, "meta_eval_prompt_cost": {"value": 0.00360384}, "meta_eval_completion_cost": {"value": 0.00754432}}, "created": "2025-12-10T21:42:47.3005058Z"}
{"ref": "bright-ridge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.904761904761905}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.463659}, "meta_inference_prompt_tokens": {"value": 10159.0}, "meta_inference_completion_tokens": {"value": 952.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020318}, "meta_inference_completion_cost": {"value": 0.0015232}, "meta_eval_time": {"value": 23.362}, "meta_eval_prompt_tokens": {"value": 5308.0}, "meta_eval_completion_tokens": {"value": 2195.0}, "meta_eval_prompt_cost": {"value": 0.00169856}, "meta_eval_completion_cost": {"value": 0.0028096}}, "created": "2025-12-10T21:42:47.9922031Z"}
{"ref": "bright-cache", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.94}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 41.988676}, "meta_inference_prompt_tokens": {"value": 14474.0}, "meta_inference_completion_tokens": {"value": 1280.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028948}, "meta_inference_completion_cost": {"value": 0.002048}, "meta_eval_time": {"value": 39.386}, "meta_eval_prompt_tokens": {"value": 10293.0}, "meta_eval_completion_tokens": {"value": 3846.0}, "meta_eval_prompt_cost": {"value": 0.00329376}, "meta_eval_completion_cost": {"value": 0.00492288}}, "created": "2025-12-10T21:42:48.7549247Z"}
{"ref": "bright-cache", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.774891}, "meta_inference_prompt_tokens": {"value": 13252.0}, "meta_inference_completion_tokens": {"value": 1147.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026504}, "meta_inference_completion_cost": {"value": 0.0018352}, "meta_eval_time": {"value": 31.746}, "meta_eval_prompt_tokens": {"value": 8744.0}, "meta_eval_completion_tokens": {"value": 2903.0}, "meta_eval_prompt_cost": {"value": 0.00279808}, "meta_eval_completion_cost": {"value": 0.00371584}}, "created": "2025-12-10T21:42:49.2321056Z"}
{"ref": "brass-log", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.742635}, "meta_inference_prompt_tokens": {"value": 11709.0}, "meta_inference_completion_tokens": {"value": 1490.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023418}, "meta_inference_completion_cost": {"value": 0.002384}, "meta_eval_time": {"value": 31.106}, "meta_eval_prompt_tokens": {"value": 7838.0}, "meta_eval_completion_tokens": {"value": 3160.0}, "meta_eval_prompt_cost": {"value": 0.00250816}, "meta_eval_completion_cost": {"value": 0.0040448}}, "created": "2025-12-10T21:42:49.4660968Z"}
{"ref": "briny-river", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.509836}, "meta_inference_prompt_tokens": {"value": 17799.0}, "meta_inference_completion_tokens": {"value": 1667.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0035598}, "meta_inference_completion_cost": {"value": 0.0026672}, "meta_eval_time": {"value": 23.694}, "meta_eval_prompt_tokens": {"value": 12334.0}, "meta_eval_completion_tokens": {"value": 2079.0}, "meta_eval_prompt_cost": {"value": 0.00394688}, "meta_eval_completion_cost": {"value": 0.00266112}}, "created": "2025-12-10T21:42:51.0161403Z"}
{"ref": "bright-ridge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.6}, "generation_factuality_f1": {"value": 0.307692307692308}, "generation_factuality_precision": {"value": 0.181818181818182}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.973663}, "meta_inference_prompt_tokens": {"value": 10163.0}, "meta_inference_completion_tokens": {"value": 844.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020326}, "meta_inference_completion_cost": {"value": 0.0013504}, "meta_eval_time": {"value": 27.36}, "meta_eval_prompt_tokens": {"value": 5564.0}, "meta_eval_completion_tokens": {"value": 2524.0}, "meta_eval_prompt_cost": {"value": 0.00178048}, "meta_eval_completion_cost": {"value": 0.00323072}}, "created": "2025-12-10T21:42:53.9953754Z"}
{"ref": "burning-playa", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.017146}, "meta_inference_prompt_tokens": {"value": 10652.0}, "meta_inference_completion_tokens": {"value": 1171.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021304}, "meta_inference_completion_cost": {"value": 0.0018736}, "meta_eval_time": {"value": 22.994}, "meta_eval_prompt_tokens": {"value": 5831.0}, "meta_eval_completion_tokens": {"value": 2082.0}, "meta_eval_prompt_cost": {"value": 0.00186592}, "meta_eval_completion_cost": {"value": 0.00266496}}, "created": "2025-12-10T21:42:55.0414964Z"}
{"ref": "brass-log", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 41.274718}, "meta_inference_prompt_tokens": {"value": 13229.0}, "meta_inference_completion_tokens": {"value": 1958.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026458}, "meta_inference_completion_cost": {"value": 0.0031328}, "meta_eval_time": {"value": 52.165}, "meta_eval_prompt_tokens": {"value": 9808.0}, "meta_eval_completion_tokens": {"value": 4154.0}, "meta_eval_prompt_cost": {"value": 0.00313856}, "meta_eval_completion_cost": {"value": 0.00531712}}, "created": "2025-12-10T21:42:56.2826926Z"}
{"ref": "briny-river", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.033876}, "meta_inference_prompt_tokens": {"value": 15993.0}, "meta_inference_completion_tokens": {"value": 1598.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031986}, "meta_inference_completion_cost": {"value": 0.0025568}, "meta_eval_time": {"value": 28.12}, "meta_eval_prompt_tokens": {"value": 10713.0}, "meta_eval_completion_tokens": {"value": 2297.0}, "meta_eval_prompt_cost": {"value": 0.00342816}, "meta_eval_completion_cost": {"value": 0.00294016}}, "created": "2025-12-10T21:42:56.6708805Z"}
{"ref": "burning-playa", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 30.031889}, "meta_inference_prompt_tokens": {"value": 12161.0}, "meta_inference_completion_tokens": {"value": 1369.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024322}, "meta_inference_completion_cost": {"value": 0.0021904}, "meta_eval_time": {"value": 22.216}, "meta_eval_prompt_tokens": {"value": 7034.0}, "meta_eval_completion_tokens": {"value": 2141.0}, "meta_eval_prompt_cost": {"value": 0.00225088}, "meta_eval_completion_cost": {"value": 0.00274048}}, "created": "2025-12-10T21:42:57.6148027Z"}
{"ref": "careful-effect-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.943925}, "meta_inference_prompt_tokens": {"value": 2260.0}, "meta_inference_completion_tokens": {"value": 728.0}, "meta_inference_prompt_cost": {"value": 0.000452}, "meta_inference_completion_cost": {"value": 0.0011648}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:57.6546766Z"}
{"ref": "briny-river", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.862068965517241}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 41.700777}, "meta_inference_prompt_tokens": {"value": 18368.0}, "meta_inference_completion_tokens": {"value": 2148.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0036736}, "meta_inference_completion_cost": {"value": 0.0034368}, "meta_eval_time": {"value": 30.226}, "meta_eval_prompt_tokens": {"value": 13565.0}, "meta_eval_completion_tokens": {"value": 3246.0}, "meta_eval_prompt_cost": {"value": 0.0043408}, "meta_eval_completion_cost": {"value": 0.00415488}}, "created": "2025-12-10T21:42:57.9860995Z"}
{"ref": "careful-effect-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.94856}, "meta_inference_prompt_tokens": {"value": 2260.0}, "meta_inference_completion_tokens": {"value": 421.0}, "meta_inference_prompt_cost": {"value": 0.000452}, "meta_inference_completion_cost": {"value": 0.0006736}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:58.0314549Z"}
{"ref": "broad-bulldozer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.566666666666667}, "retrieval_dcg": {"value": 1.56160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.648648648648649}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 42.34351}, "meta_inference_prompt_tokens": {"value": 11222.0}, "meta_inference_completion_tokens": {"value": 1290.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022444}, "meta_inference_completion_cost": {"value": 0.002064}, "meta_eval_time": {"value": 31.8}, "meta_eval_prompt_tokens": {"value": 6972.0}, "meta_eval_completion_tokens": {"value": 3182.0}, "meta_eval_prompt_cost": {"value": 0.00223104}, "meta_eval_completion_cost": {"value": 0.00407296}}, "created": "2025-12-10T21:42:58.5819573Z"}
{"ref": "careful-effect-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.135184}, "meta_inference_prompt_tokens": {"value": 2260.0}, "meta_inference_completion_tokens": {"value": 408.0}, "meta_inference_prompt_cost": {"value": 0.000452}, "meta_inference_completion_cost": {"value": 0.0006528}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:58.622189Z"}
{"ref": "careful-effect-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.696014}, "meta_inference_prompt_tokens": {"value": 4711.0}, "meta_inference_completion_tokens": {"value": 1106.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009422}, "meta_inference_completion_cost": {"value": 0.0017696}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:58.6624211Z"}
{"ref": "careful-effect-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.822929}, "meta_inference_prompt_tokens": {"value": 2260.0}, "meta_inference_completion_tokens": {"value": 386.0}, "meta_inference_prompt_cost": {"value": 0.000452}, "meta_inference_completion_cost": {"value": 0.0006176}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:42:58.7030969Z"}
{"ref": "calm-turbine", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.444444444444444}, "retrieval_mrr": {"value": 0.252380952380952}, "retrieval_dcg": {"value": 2.517782560806}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.285714285714286}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 19.05768}, "meta_inference_prompt_tokens": {"value": 14160.0}, "meta_inference_completion_tokens": {"value": 919.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002832}, "meta_inference_completion_cost": {"value": 0.0014704}, "meta_eval_time": {"value": 22.291}, "meta_eval_prompt_tokens": {"value": 9372.0}, "meta_eval_completion_tokens": {"value": 2089.0}, "meta_eval_prompt_cost": {"value": 0.00299904}, "meta_eval_completion_cost": {"value": 0.00267392}}, "created": "2025-12-10T21:42:59.6152741Z"}
{"ref": "briny-river", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.715281}, "meta_inference_prompt_tokens": {"value": 16033.0}, "meta_inference_completion_tokens": {"value": 1565.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032066}, "meta_inference_completion_cost": {"value": 0.002504}, "meta_eval_time": {"value": 36.342}, "meta_eval_prompt_tokens": {"value": 11020.0}, "meta_eval_completion_tokens": {"value": 3077.0}, "meta_eval_prompt_cost": {"value": 0.0035264}, "meta_eval_completion_cost": {"value": 0.00393856}}, "created": "2025-12-10T21:43:00.6015785Z"}
{"ref": "briny-river", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.962962962962963}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 42.740741}, "meta_inference_prompt_tokens": {"value": 16669.0}, "meta_inference_completion_tokens": {"value": 2281.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0033338}, "meta_inference_completion_cost": {"value": 0.0036496}, "meta_eval_time": {"value": 29.948}, "meta_eval_prompt_tokens": {"value": 11638.0}, "meta_eval_completion_tokens": {"value": 2977.0}, "meta_eval_prompt_cost": {"value": 0.00372416}, "meta_eval_completion_cost": {"value": 0.00381056}}, "created": "2025-12-10T21:43:01.0903676Z"}
{"ref": "calm-turbine", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.444444444444444}, "retrieval_mrr": {"value": 0.252380952380952}, "retrieval_dcg": {"value": 2.48713694067948}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.51063829787234}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.285714285714286}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 24.212642}, "meta_inference_prompt_tokens": {"value": 14371.0}, "meta_inference_completion_tokens": {"value": 1121.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028742}, "meta_inference_completion_cost": {"value": 0.0017936}, "meta_eval_time": {"value": 28.847}, "meta_eval_prompt_tokens": {"value": 9811.0}, "meta_eval_completion_tokens": {"value": 2636.0}, "meta_eval_prompt_cost": {"value": 0.00313952}, "meta_eval_completion_cost": {"value": 0.00337408}}, "created": "2025-12-10T21:43:03.0480937Z"}
{"ref": "calm-turbine", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.444444444444444}, "retrieval_mrr": {"value": 0.252380952380952}, "retrieval_dcg": {"value": 2.46426308690479}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.48}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.285714285714286}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 24.632376}, "meta_inference_prompt_tokens": {"value": 14163.0}, "meta_inference_completion_tokens": {"value": 1243.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028326}, "meta_inference_completion_cost": {"value": 0.0019888}, "meta_eval_time": {"value": 31.6}, "meta_eval_prompt_tokens": {"value": 9842.0}, "meta_eval_completion_tokens": {"value": 3044.0}, "meta_eval_prompt_cost": {"value": 0.00314944}, "meta_eval_completion_cost": {"value": 0.00389632}}, "created": "2025-12-10T21:43:05.2966512Z"}
{"ref": "candied-alignment", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.616834}, "meta_inference_prompt_tokens": {"value": 16547.0}, "meta_inference_completion_tokens": {"value": 1308.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0033094}, "meta_inference_completion_cost": {"value": 0.0020928}, "meta_eval_time": {"value": 25.812}, "meta_eval_prompt_tokens": {"value": 11270.0}, "meta_eval_completion_tokens": {"value": 2716.0}, "meta_eval_prompt_cost": {"value": 0.0036064}, "meta_eval_completion_cost": {"value": 0.00347648}}, "created": "2025-12-10T21:43:06.0028256Z"}
{"ref": "candied-step-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.580105}, "meta_inference_prompt_tokens": {"value": 11597.0}, "meta_inference_completion_tokens": {"value": 1082.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023194}, "meta_inference_completion_cost": {"value": 0.0017312}, "meta_eval_time": {"value": 21.747}, "meta_eval_prompt_tokens": {"value": 6646.0}, "meta_eval_completion_tokens": {"value": 2033.0}, "meta_eval_prompt_cost": {"value": 0.00212672}, "meta_eval_completion_cost": {"value": 0.00260224}}, "created": "2025-12-10T21:43:06.2273733Z"}
{"ref": "burning-playa", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.944444444444444}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 31.034332}, "meta_inference_prompt_tokens": {"value": 11881.0}, "meta_inference_completion_tokens": {"value": 1314.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023762}, "meta_inference_completion_cost": {"value": 0.0021024}, "meta_eval_time": {"value": 31.206}, "meta_eval_prompt_tokens": {"value": 7174.0}, "meta_eval_completion_tokens": {"value": 2902.0}, "meta_eval_prompt_cost": {"value": 0.00229568}, "meta_eval_completion_cost": {"value": 0.00371456}}, "created": "2025-12-10T21:43:06.6917829Z"}
{"ref": "candied-alignment", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.573391}, "meta_inference_prompt_tokens": {"value": 14588.0}, "meta_inference_completion_tokens": {"value": 1200.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029176}, "meta_inference_completion_cost": {"value": 0.00192}, "meta_eval_time": {"value": 29.735}, "meta_eval_prompt_tokens": {"value": 9561.0}, "meta_eval_completion_tokens": {"value": 2612.0}, "meta_eval_prompt_cost": {"value": 0.00305952}, "meta_eval_completion_cost": {"value": 0.00334336}}, "created": "2025-12-10T21:43:06.7825234Z"}
{"ref": "calm-turbine", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.444444444444444}, "retrieval_mrr": {"value": 0.252380952380952}, "retrieval_dcg": {"value": 2.48713694067948}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.285714285714286}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.319815}, "meta_inference_prompt_tokens": {"value": 15227.0}, "meta_inference_completion_tokens": {"value": 1149.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030454}, "meta_inference_completion_cost": {"value": 0.0018384}, "meta_eval_time": {"value": 32.259}, "meta_eval_prompt_tokens": {"value": 10977.0}, "meta_eval_completion_tokens": {"value": 3061.0}, "meta_eval_prompt_cost": {"value": 0.00351264}, "meta_eval_completion_cost": {"value": 0.00391808}}, "created": "2025-12-10T21:43:07.8691561Z"}
{"ref": "broad-bulldozer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.508333333333333}, "retrieval_dcg": {"value": 2.0879137408454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 38.445298}, "meta_inference_prompt_tokens": {"value": 11768.0}, "meta_inference_completion_tokens": {"value": 1686.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023536}, "meta_inference_completion_cost": {"value": 0.0026976}, "meta_eval_time": {"value": 41.477}, "meta_eval_prompt_tokens": {"value": 7935.0}, "meta_eval_completion_tokens": {"value": 3963.0}, "meta_eval_prompt_cost": {"value": 0.0025392}, "meta_eval_completion_cost": {"value": 0.00507264}}, "created": "2025-12-10T21:43:08.9596362Z"}
{"ref": "candied-merge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.947368421052632}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.102916}, "meta_inference_prompt_tokens": {"value": 10558.0}, "meta_inference_completion_tokens": {"value": 916.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021116}, "meta_inference_completion_cost": {"value": 0.0014656}, "meta_eval_time": {"value": 26.642}, "meta_eval_prompt_tokens": {"value": 6143.0}, "meta_eval_completion_tokens": {"value": 2559.0}, "meta_eval_prompt_cost": {"value": 0.00196576}, "meta_eval_completion_cost": {"value": 0.00327552}}, "created": "2025-12-10T21:43:09.6879403Z"}
{"ref": "candied-step-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.740740740740741}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 18.798454}, "meta_inference_prompt_tokens": {"value": 10075.0}, "meta_inference_completion_tokens": {"value": 1119.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002015}, "meta_inference_completion_cost": {"value": 0.0017904}, "meta_eval_time": {"value": 21.22}, "meta_eval_prompt_tokens": {"value": 5008.0}, "meta_eval_completion_tokens": {"value": 1911.0}, "meta_eval_prompt_cost": {"value": 0.00160256}, "meta_eval_completion_cost": {"value": 0.00244608}}, "created": "2025-12-10T21:43:10.7260979Z"}
{"ref": "candied-alignment", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 50.561905}, "meta_inference_prompt_tokens": {"value": 14911.0}, "meta_inference_completion_tokens": {"value": 1281.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029822}, "meta_inference_completion_cost": {"value": 0.0020496}, "meta_eval_time": {"value": 33.682}, "meta_eval_prompt_tokens": {"value": 9869.0}, "meta_eval_completion_tokens": {"value": 3150.0}, "meta_eval_prompt_cost": {"value": 0.00315808}, "meta_eval_completion_cost": {"value": 0.004032}}, "created": "2025-12-10T21:43:10.9242303Z"}
{"ref": "candied-step-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.95}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.553498}, "meta_inference_prompt_tokens": {"value": 11658.0}, "meta_inference_completion_tokens": {"value": 1172.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023316}, "meta_inference_completion_cost": {"value": 0.0018752}, "meta_eval_time": {"value": 24.437}, "meta_eval_prompt_tokens": {"value": 6715.0}, "meta_eval_completion_tokens": {"value": 2294.0}, "meta_eval_prompt_cost": {"value": 0.0021488}, "meta_eval_completion_cost": {"value": 0.00293632}}, "created": "2025-12-10T21:43:11.7882634Z"}
{"ref": "broad-bulldozer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.74742462602117}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.101814}, "meta_inference_prompt_tokens": {"value": 11199.0}, "meta_inference_completion_tokens": {"value": 1601.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022398}, "meta_inference_completion_cost": {"value": 0.0025616}, "meta_eval_time": {"value": 41.185}, "meta_eval_prompt_tokens": {"value": 7781.0}, "meta_eval_completion_tokens": {"value": 4336.0}, "meta_eval_prompt_cost": {"value": 0.00248992}, "meta_eval_completion_cost": {"value": 0.00555008}}, "created": "2025-12-10T21:43:11.7879763Z"}
{"ref": "candied-merge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.509539}, "meta_inference_prompt_tokens": {"value": 11279.0}, "meta_inference_completion_tokens": {"value": 1070.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022558}, "meta_inference_completion_cost": {"value": 0.001712}, "meta_eval_time": {"value": 32.673}, "meta_eval_prompt_tokens": {"value": 7076.0}, "meta_eval_completion_tokens": {"value": 3196.0}, "meta_eval_prompt_cost": {"value": 0.00226432}, "meta_eval_completion_cost": {"value": 0.00409088}}, "created": "2025-12-10T21:43:12.1373036Z"}
{"ref": "burning-playa", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.787234042553192}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 29.069717}, "meta_inference_prompt_tokens": {"value": 13214.0}, "meta_inference_completion_tokens": {"value": 1630.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026428}, "meta_inference_completion_cost": {"value": 0.002608}, "meta_eval_time": {"value": 39.974}, "meta_eval_prompt_tokens": {"value": 8942.0}, "meta_eval_completion_tokens": {"value": 3916.0}, "meta_eval_prompt_cost": {"value": 0.00286144}, "meta_eval_completion_cost": {"value": 0.00501248}}, "created": "2025-12-10T21:43:12.8988911Z"}
{"ref": "cheerful-bow", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 7.708212}, "meta_inference_prompt_tokens": {"value": 2254.0}, "meta_inference_completion_tokens": {"value": 278.0}, "meta_inference_prompt_cost": {"value": 0.0004508}, "meta_inference_completion_cost": {"value": 0.0004448}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:12.9499191Z"}
{"ref": "cheerful-bow", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.574252}, "meta_inference_prompt_tokens": {"value": 2254.0}, "meta_inference_completion_tokens": {"value": 657.0}, "meta_inference_prompt_cost": {"value": 0.0004508}, "meta_inference_completion_cost": {"value": 0.0010512}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:12.9866892Z"}
{"ref": "candied-alignment", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.28906482631789}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.745101}, "meta_inference_prompt_tokens": {"value": 11287.0}, "meta_inference_completion_tokens": {"value": 1194.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022574}, "meta_inference_completion_cost": {"value": 0.0019104}, "meta_eval_time": {"value": 30.111}, "meta_eval_prompt_tokens": {"value": 6594.0}, "meta_eval_completion_tokens": {"value": 2696.0}, "meta_eval_prompt_cost": {"value": 0.00211008}, "meta_eval_completion_cost": {"value": 0.00345088}}, "created": "2025-12-10T21:43:13.05241Z"}
{"ref": "burning-playa", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 46.806917}, "meta_inference_prompt_tokens": {"value": 11896.0}, "meta_inference_completion_tokens": {"value": 1302.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023792}, "meta_inference_completion_cost": {"value": 0.0020832}, "meta_eval_time": {"value": 37.241}, "meta_eval_prompt_tokens": {"value": 7641.0}, "meta_eval_completion_tokens": {"value": 3247.0}, "meta_eval_prompt_cost": {"value": 0.00244512}, "meta_eval_completion_cost": {"value": 0.00415616}}, "created": "2025-12-10T21:43:13.2396514Z"}
{"ref": "cheerful-bow", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.113028}, "meta_inference_prompt_tokens": {"value": 2254.0}, "meta_inference_completion_tokens": {"value": 646.0}, "meta_inference_prompt_cost": {"value": 0.0004508}, "meta_inference_completion_cost": {"value": 0.0010336}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:13.2826487Z"}
{"ref": "candied-alignment", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 0.705882352941176}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.849839}, "meta_inference_prompt_tokens": {"value": 12115.0}, "meta_inference_completion_tokens": {"value": 1083.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002423}, "meta_inference_completion_cost": {"value": 0.0017328}, "meta_eval_time": {"value": 32.999}, "meta_eval_prompt_tokens": {"value": 7451.0}, "meta_eval_completion_tokens": {"value": 3050.0}, "meta_eval_prompt_cost": {"value": 0.00238432}, "meta_eval_completion_cost": {"value": 0.003904}}, "created": "2025-12-10T21:43:13.6554313Z"}
{"ref": "chocolate-quiver", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.702126}, "meta_inference_prompt_tokens": {"value": 10746.0}, "meta_inference_completion_tokens": {"value": 1133.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021492}, "meta_inference_completion_cost": {"value": 0.0018128}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:13.7010084Z"}
{"ref": "chocolate-quiver", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.134521}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 774.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0012384}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:13.7377397Z"}
{"ref": "chalky-analyst", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 17.500946}, "meta_inference_prompt_tokens": {"value": 11211.0}, "meta_inference_completion_tokens": {"value": 709.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022422}, "meta_inference_completion_cost": {"value": 0.0011344}, "meta_eval_time": {"value": 10.802}, "meta_eval_prompt_tokens": {"value": 5909.0}, "meta_eval_completion_tokens": {"value": 945.0}, "meta_eval_prompt_cost": {"value": 0.00189088}, "meta_eval_completion_cost": {"value": 0.0012096}}, "created": "2025-12-10T21:43:13.9013728Z"}
{"ref": "chocolate-quiver", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.703162}, "meta_inference_prompt_tokens": {"value": 10746.0}, "meta_inference_completion_tokens": {"value": 1137.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021492}, "meta_inference_completion_cost": {"value": 0.0018192}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:13.9376054Z"}
{"ref": "broad-bulldozer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.508333333333333}, "retrieval_dcg": {"value": 1.47270205955773}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 35.247544}, "meta_inference_prompt_tokens": {"value": 11744.0}, "meta_inference_completion_tokens": {"value": 1817.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023488}, "meta_inference_completion_cost": {"value": 0.0029072}, "meta_eval_time": {"value": 46.108}, "meta_eval_prompt_tokens": {"value": 7909.0}, "meta_eval_completion_tokens": {"value": 4226.0}, "meta_eval_prompt_cost": {"value": 0.00253088}, "meta_eval_completion_cost": {"value": 0.00540928}}, "created": "2025-12-10T21:43:13.9594724Z"}
{"ref": "cheerful-bow", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.702466}, "meta_inference_prompt_tokens": {"value": 2254.0}, "meta_inference_completion_tokens": {"value": 531.0}, "meta_inference_prompt_cost": {"value": 0.0004508}, "meta_inference_completion_cost": {"value": 0.0008496}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:13.9735217Z"}
{"ref": "calm-turbine", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.444444444444444}, "retrieval_mrr": {"value": 0.252380952380952}, "retrieval_dcg": {"value": 2.43195974923544}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.285714285714286}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.076632}, "meta_inference_prompt_tokens": {"value": 14804.0}, "meta_inference_completion_tokens": {"value": 1336.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029608}, "meta_inference_completion_cost": {"value": 0.0021376}, "meta_eval_time": {"value": 40.209}, "meta_eval_prompt_tokens": {"value": 10917.0}, "meta_eval_completion_tokens": {"value": 3943.0}, "meta_eval_prompt_cost": {"value": 0.00349344}, "meta_eval_completion_cost": {"value": 0.00504704}}, "created": "2025-12-10T21:43:16.5567082Z"}
{"ref": "chalky-analyst", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.820453}, "meta_inference_prompt_tokens": {"value": 11213.0}, "meta_inference_completion_tokens": {"value": 572.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022426}, "meta_inference_completion_cost": {"value": 0.0009152}, "meta_eval_time": {"value": 16.551}, "meta_eval_prompt_tokens": {"value": 6091.0}, "meta_eval_completion_tokens": {"value": 1145.0}, "meta_eval_prompt_cost": {"value": 0.00194912}, "meta_eval_completion_cost": {"value": 0.0014656}}, "created": "2025-12-10T21:43:17.683111Z"}
{"ref": "candied-merge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.892857142857143}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.650958}, "meta_inference_prompt_tokens": {"value": 10242.0}, "meta_inference_completion_tokens": {"value": 929.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020484}, "meta_inference_completion_cost": {"value": 0.0014864}, "meta_eval_time": {"value": 34.842}, "meta_eval_prompt_tokens": {"value": 5987.0}, "meta_eval_completion_tokens": {"value": 3175.0}, "meta_eval_prompt_cost": {"value": 0.00191584}, "meta_eval_completion_cost": {"value": 0.004064}}, "created": "2025-12-10T21:43:17.8944215Z"}
{"ref": "careful-passenger-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.285714285714286}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.131823}, "meta_inference_prompt_tokens": {"value": 9645.0}, "meta_inference_completion_tokens": {"value": 884.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001929}, "meta_inference_completion_cost": {"value": 0.0014144}, "meta_eval_time": {"value": 18.264}, "meta_eval_prompt_tokens": {"value": 5606.0}, "meta_eval_completion_tokens": {"value": 1678.0}, "meta_eval_prompt_cost": {"value": 0.00179392}, "meta_eval_completion_cost": {"value": 0.00214784}}, "created": "2025-12-10T21:43:17.9550939Z"}
{"ref": "candied-step-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.904761904761905}, "generation_factuality_f1": {"value": 0.729166666666666}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 0.875}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.875}, "meta_inference_time": {"value": 20.859905}, "meta_inference_prompt_tokens": {"value": 11884.0}, "meta_inference_completion_tokens": {"value": 984.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023768}, "meta_inference_completion_cost": {"value": 0.0015744}, "meta_eval_time": {"value": 29.796}, "meta_eval_prompt_tokens": {"value": 6752.0}, "meta_eval_completion_tokens": {"value": 2438.0}, "meta_eval_prompt_cost": {"value": 0.00216064}, "meta_eval_completion_cost": {"value": 0.00312064}}, "created": "2025-12-10T21:43:19.0668912Z"}
{"ref": "chocolate-quiver", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.668007}, "meta_inference_prompt_tokens": {"value": 10745.0}, "meta_inference_completion_tokens": {"value": 1403.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002149}, "meta_inference_completion_cost": {"value": 0.0022448}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:19.1095676Z"}
{"ref": "candied-step-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.291666666666667}, "retrieval_dcg": {"value": 0.67591763355243}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.771582}, "meta_inference_prompt_tokens": {"value": 12108.0}, "meta_inference_completion_tokens": {"value": 1079.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024216}, "meta_inference_completion_cost": {"value": 0.0017264}, "meta_eval_time": {"value": 29.013}, "meta_eval_prompt_tokens": {"value": 6911.0}, "meta_eval_completion_tokens": {"value": 2037.0}, "meta_eval_prompt_cost": {"value": 0.00221152}, "meta_eval_completion_cost": {"value": 0.00260736}}, "created": "2025-12-10T21:43:20.0708143Z"}
{"ref": "broad-bulldozer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.68400447129607}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.671036}, "meta_inference_prompt_tokens": {"value": 11691.0}, "meta_inference_completion_tokens": {"value": 1271.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023382}, "meta_inference_completion_cost": {"value": 0.0020336}, "meta_eval_time": {"value": 53.59}, "meta_eval_prompt_tokens": {"value": 7579.0}, "meta_eval_completion_tokens": {"value": 3701.0}, "meta_eval_prompt_cost": {"value": 0.00242528}, "meta_eval_completion_cost": {"value": 0.00473728}}, "created": "2025-12-10T21:43:20.9603562Z"}
{"ref": "chalky-analyst", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.259486}, "meta_inference_prompt_tokens": {"value": 11217.0}, "meta_inference_completion_tokens": {"value": 753.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022434}, "meta_inference_completion_cost": {"value": 0.0012048}, "meta_eval_time": {"value": 15.094}, "meta_eval_prompt_tokens": {"value": 6106.0}, "meta_eval_completion_tokens": {"value": 1398.0}, "meta_eval_prompt_cost": {"value": 0.00195392}, "meta_eval_completion_cost": {"value": 0.00178944}}, "created": "2025-12-10T21:43:21.1441745Z"}
{"ref": "chalky-analyst", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.774193548387097}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 21.060427}, "meta_inference_prompt_tokens": {"value": 11212.0}, "meta_inference_completion_tokens": {"value": 630.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022424}, "meta_inference_completion_cost": {"value": 0.001008}, "meta_eval_time": {"value": 14.87}, "meta_eval_prompt_tokens": {"value": 6065.0}, "meta_eval_completion_tokens": {"value": 1157.0}, "meta_eval_prompt_cost": {"value": 0.0019408}, "meta_eval_completion_cost": {"value": 0.00148096}}, "created": "2025-12-10T21:43:21.1516788Z"}
{"ref": "chunky-strategy", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.654845}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 779.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0012464}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:21.1834773Z"}
{"ref": "chocolate-quiver", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.03276}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 762.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0012192}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:21.1964882Z"}
{"ref": "cheerful-bow", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.533616}, "meta_inference_prompt_tokens": {"value": 2254.0}, "meta_inference_completion_tokens": {"value": 663.0}, "meta_inference_prompt_cost": {"value": 0.0004508}, "meta_inference_completion_cost": {"value": 0.0010608}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:21.2328581Z"}
{"ref": "candied-merge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 0.947368421052632}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.655315}, "meta_inference_prompt_tokens": {"value": 10586.0}, "meta_inference_completion_tokens": {"value": 1027.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021172}, "meta_inference_completion_cost": {"value": 0.0016432}, "meta_eval_time": {"value": 38.496}, "meta_eval_prompt_tokens": {"value": 6506.0}, "meta_eval_completion_tokens": {"value": 3335.0}, "meta_eval_prompt_cost": {"value": 0.00208192}, "meta_eval_completion_cost": {"value": 0.0042688}}, "created": "2025-12-10T21:43:21.4403834Z"}
{"ref": "chunky-strategy", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.334051}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 397.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0006352}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:21.4829824Z"}
{"ref": "candied-merge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.584481}, "meta_inference_prompt_tokens": {"value": 11073.0}, "meta_inference_completion_tokens": {"value": 1160.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022146}, "meta_inference_completion_cost": {"value": 0.001856}, "meta_eval_time": {"value": 42.138}, "meta_eval_prompt_tokens": {"value": 7139.0}, "meta_eval_completion_tokens": {"value": 3659.0}, "meta_eval_prompt_cost": {"value": 0.00228448}, "meta_eval_completion_cost": {"value": 0.00468352}}, "created": "2025-12-10T21:43:22.810478Z"}
{"ref": "clever-base", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.592306}, "meta_inference_prompt_tokens": {"value": 4647.0}, "meta_inference_completion_tokens": {"value": 1650.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009294}, "meta_inference_completion_cost": {"value": 0.00264}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:22.8496906Z"}
{"ref": "chunky-strategy", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.960427}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 842.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0013472}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:22.8890152Z"}
{"ref": "champagne-distance", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.142331}, "meta_inference_prompt_tokens": {"value": 11597.0}, "meta_inference_completion_tokens": {"value": 724.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023194}, "meta_inference_completion_cost": {"value": 0.0011584}, "meta_eval_time": {"value": 13.239}, "meta_eval_prompt_tokens": {"value": 6175.0}, "meta_eval_completion_tokens": {"value": 941.0}, "meta_eval_prompt_cost": {"value": 0.001976}, "meta_eval_completion_cost": {"value": 0.00120448}}, "created": "2025-12-10T21:43:25.1050632Z"}
{"ref": "clever-base", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 41.921023}, "meta_inference_prompt_tokens": {"value": 4646.0}, "meta_inference_completion_tokens": {"value": 1068.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009292}, "meta_inference_completion_cost": {"value": 0.0017088}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:25.1482904Z"}
{"ref": "chalky-analyst", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.727272727272727}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.392836}, "meta_inference_prompt_tokens": {"value": 11211.0}, "meta_inference_completion_tokens": {"value": 586.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022422}, "meta_inference_completion_cost": {"value": 0.0009376}, "meta_eval_time": {"value": 17.154}, "meta_eval_prompt_tokens": {"value": 6176.0}, "meta_eval_completion_tokens": {"value": 1425.0}, "meta_eval_prompt_cost": {"value": 0.00197632}, "meta_eval_completion_cost": {"value": 0.001824}}, "created": "2025-12-10T21:43:26.1567701Z"}
{"ref": "champagne-distance", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.08}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.13093742868009}, "generation_faithfulness": {"value": 0.285714285714286}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0416666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0333333333333333}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 39.287923}, "meta_inference_prompt_tokens": {"value": 48508.0}, "meta_inference_completion_tokens": {"value": 1318.0}, "meta_inference_tool_call_count": {"value": 3.0}, "meta_inference_prompt_cost": {"value": 0.0097016}, "meta_inference_completion_cost": {"value": 0.0021088}, "meta_eval_time": {"value": 14.424}, "meta_eval_prompt_tokens": {"value": 12929.0}, "meta_eval_completion_tokens": {"value": 1168.0}, "meta_eval_prompt_cost": {"value": 0.00413728}, "meta_eval_completion_cost": {"value": 0.00149504}}, "created": "2025-12-10T21:43:26.2736156Z"}
{"ref": "clever-base", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.690693}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 773.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0012368}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:26.3129175Z"}
{"ref": "champagne-distance", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.5}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.767098}, "meta_inference_prompt_tokens": {"value": 10611.0}, "meta_inference_completion_tokens": {"value": 1064.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021222}, "meta_inference_completion_cost": {"value": 0.0017024}, "meta_eval_time": {"value": 15.469}, "meta_eval_prompt_tokens": {"value": 5095.0}, "meta_eval_completion_tokens": {"value": 1091.0}, "meta_eval_prompt_cost": {"value": 0.0016304}, "meta_eval_completion_cost": {"value": 0.00139648}}, "created": "2025-12-10T21:43:27.2907996Z"}
{"ref": "clever-base", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.338729}, "meta_inference_prompt_tokens": {"value": 4683.0}, "meta_inference_completion_tokens": {"value": 1092.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009366}, "meta_inference_completion_cost": {"value": 0.0017472}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:27.3584439Z"}
{"ref": "careful-passenger-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 0.944444444444444}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.309048}, "meta_inference_prompt_tokens": {"value": 11170.0}, "meta_inference_completion_tokens": {"value": 1190.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002234}, "meta_inference_completion_cost": {"value": 0.001904}, "meta_eval_time": {"value": 22.472}, "meta_eval_prompt_tokens": {"value": 6491.0}, "meta_eval_completion_tokens": {"value": 2009.0}, "meta_eval_prompt_cost": {"value": 0.00207712}, "meta_eval_completion_cost": {"value": 0.00257152}}, "created": "2025-12-10T21:43:27.8123397Z"}
{"ref": "champagne-distance", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 0.4}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.102958}, "meta_inference_prompt_tokens": {"value": 11800.0}, "meta_inference_completion_tokens": {"value": 782.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00236}, "meta_inference_completion_cost": {"value": 0.0012512}, "meta_eval_time": {"value": 14.841}, "meta_eval_prompt_tokens": {"value": 6343.0}, "meta_eval_completion_tokens": {"value": 1294.0}, "meta_eval_prompt_cost": {"value": 0.00202976}, "meta_eval_completion_cost": {"value": 0.00165632}}, "created": "2025-12-10T21:43:27.8632736Z"}
{"ref": "coffee-mustard-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.930969}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 909.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.0014544}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:27.9039421Z"}
{"ref": "coffee-mustard-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.457149}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 522.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.0008352}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:27.944148Z"}
{"ref": "careful-passenger-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.91304347826087}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.25}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.797963}, "meta_inference_prompt_tokens": {"value": 10180.0}, "meta_inference_completion_tokens": {"value": 1209.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002036}, "meta_inference_completion_cost": {"value": 0.0019344}, "meta_eval_time": {"value": 28.084}, "meta_eval_prompt_tokens": {"value": 6279.0}, "meta_eval_completion_tokens": {"value": 2495.0}, "meta_eval_prompt_cost": {"value": 0.00200928}, "meta_eval_completion_cost": {"value": 0.0031936}}, "created": "2025-12-10T21:43:28.7444862Z"}
{"ref": "champagne-distance", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.533333333333333}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.147877}, "meta_inference_prompt_tokens": {"value": 12501.0}, "meta_inference_completion_tokens": {"value": 746.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025002}, "meta_inference_completion_cost": {"value": 0.0011936}, "meta_eval_time": {"value": 18.502}, "meta_eval_prompt_tokens": {"value": 7363.0}, "meta_eval_completion_tokens": {"value": 1569.0}, "meta_eval_prompt_cost": {"value": 0.00235616}, "meta_eval_completion_cost": {"value": 0.00200832}}, "created": "2025-12-10T21:43:30.7028271Z"}
{"ref": "coffee-mustard-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.037182}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 390.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.000624}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:30.744393Z"}
{"ref": "clever-base", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.657934}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 517.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0008272}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:30.7826258Z"}
{"ref": "coffee-mustard-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.979682}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 647.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.0010352}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:30.8164528Z"}
{"ref": "chocolate-spec", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.957267}, "meta_inference_prompt_tokens": {"value": 8249.0}, "meta_inference_completion_tokens": {"value": 1194.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0016498}, "meta_inference_completion_cost": {"value": 0.0019104}, "meta_eval_time": {"value": 15.49}, "meta_eval_prompt_tokens": {"value": 4563.0}, "meta_eval_completion_tokens": {"value": 1487.0}, "meta_eval_prompt_cost": {"value": 0.00146016}, "meta_eval_completion_cost": {"value": 0.00190336}}, "created": "2025-12-10T21:43:33.2119756Z"}
{"ref": "careful-passenger-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.178907}, "meta_inference_prompt_tokens": {"value": 11638.0}, "meta_inference_completion_tokens": {"value": 1186.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023276}, "meta_inference_completion_cost": {"value": 0.0018976}, "meta_eval_time": {"value": 26.404}, "meta_eval_prompt_tokens": {"value": 6849.0}, "meta_eval_completion_tokens": {"value": 2227.0}, "meta_eval_prompt_cost": {"value": 0.00219168}, "meta_eval_completion_cost": {"value": 0.00285056}}, "created": "2025-12-10T21:43:33.2292383Z"}
{"ref": "caramelized-action-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.235294117647059}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.72}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.133333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.285714285714286}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 21.71237}, "meta_inference_prompt_tokens": {"value": 15138.0}, "meta_inference_completion_tokens": {"value": 1393.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030276}, "meta_inference_completion_cost": {"value": 0.0022288}, "meta_eval_time": {"value": 52.887}, "meta_eval_prompt_tokens": {"value": 12700.0}, "meta_eval_completion_tokens": {"value": 5250.0}, "meta_eval_prompt_cost": {"value": 0.004064}, "meta_eval_completion_cost": {"value": 0.00672}}, "created": "2025-12-10T21:43:37.3725197Z"}
{"ref": "chocolate-spec", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.222222222222222}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.242287}, "meta_inference_prompt_tokens": {"value": 12706.0}, "meta_inference_completion_tokens": {"value": 1024.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025412}, "meta_inference_completion_cost": {"value": 0.0016384}, "meta_eval_time": {"value": 20.228}, "meta_eval_prompt_tokens": {"value": 7233.0}, "meta_eval_completion_tokens": {"value": 1932.0}, "meta_eval_prompt_cost": {"value": 0.00231456}, "meta_eval_completion_cost": {"value": 0.00247296}}, "created": "2025-12-10T21:43:38.1665885Z"}
{"ref": "coffee-mustard-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.566188}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 462.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.0007392}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:38.2080372Z"}
{"ref": "chalky-bilge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.605893}, "meta_inference_prompt_tokens": {"value": 10451.0}, "meta_inference_completion_tokens": {"value": 1246.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020902}, "meta_inference_completion_cost": {"value": 0.0019936}, "meta_eval_time": {"value": 30.349}, "meta_eval_prompt_tokens": {"value": 6169.0}, "meta_eval_completion_tokens": {"value": 3024.0}, "meta_eval_prompt_cost": {"value": 0.00197408}, "meta_eval_completion_cost": {"value": 0.00387072}}, "created": "2025-12-10T21:43:38.2640351Z"}
{"ref": "chalky-bilge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.719741384391281}, "generation_faithfulness": {"value": 0.869565217391304}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.966166}, "meta_inference_prompt_tokens": {"value": 10966.0}, "meta_inference_completion_tokens": {"value": 1441.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021932}, "meta_inference_completion_cost": {"value": 0.0023056}, "meta_eval_time": {"value": 28.614}, "meta_eval_prompt_tokens": {"value": 6423.0}, "meta_eval_completion_tokens": {"value": 2588.0}, "meta_eval_prompt_cost": {"value": 0.00205536}, "meta_eval_completion_cost": {"value": 0.00331264}}, "created": "2025-12-10T21:43:39.3811317Z"}
{"ref": "chunky-strategy", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.666666666666667}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 28.156471}, "meta_inference_prompt_tokens": {"value": 17479.0}, "meta_inference_completion_tokens": {"value": 791.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0034958}, "meta_inference_completion_cost": {"value": 0.0012656}, "meta_eval_time": {"value": 16.726}, "meta_eval_prompt_tokens": {"value": 11643.0}, "meta_eval_completion_tokens": {"value": 1657.0}, "meta_eval_prompt_cost": {"value": 0.00372576}, "meta_eval_completion_cost": {"value": 0.00212096}}, "created": "2025-12-10T21:43:39.6484406Z"}
{"ref": "colorful-nucleus", "set": "20251210152915", "metrics": {"generation_should_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 14.480164}, "meta_inference_prompt_tokens": {"value": 2274.0}, "meta_inference_completion_tokens": {"value": 842.0}, "meta_inference_prompt_cost": {"value": 0.0004548}, "meta_inference_completion_cost": {"value": 0.0013472}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:39.6964909Z"}
{"ref": "complete-theme-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.55765}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 916.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0014656}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:39.755335Z"}
{"ref": "chocolate-spec", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.25}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.430339}, "meta_inference_prompt_tokens": {"value": 12593.0}, "meta_inference_completion_tokens": {"value": 1195.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025186}, "meta_inference_completion_cost": {"value": 0.001912}, "meta_eval_time": {"value": 18.773}, "meta_eval_prompt_tokens": {"value": 7245.0}, "meta_eval_completion_tokens": {"value": 1651.0}, "meta_eval_prompt_cost": {"value": 0.0023184}, "meta_eval_completion_cost": {"value": 0.00211328}}, "created": "2025-12-10T21:43:40.0407995Z"}
{"ref": "complete-theme-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.510462}, "meta_inference_prompt_tokens": {"value": 14285.0}, "meta_inference_completion_tokens": {"value": 1686.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002857}, "meta_inference_completion_cost": {"value": 0.0026976}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:40.0842537Z"}
{"ref": "chocolaty-depth", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.974442}, "meta_inference_prompt_tokens": {"value": 13838.0}, "meta_inference_completion_tokens": {"value": 1170.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027676}, "meta_inference_completion_cost": {"value": 0.001872}, "meta_eval_time": {"value": 26.08}, "meta_eval_prompt_tokens": {"value": 9004.0}, "meta_eval_completion_tokens": {"value": 2282.0}, "meta_eval_prompt_cost": {"value": 0.00288128}, "meta_eval_completion_cost": {"value": 0.00292096}}, "created": "2025-12-10T21:43:40.0941896Z"}
{"ref": "colorful-nucleus", "set": "20251210152915", "metrics": {"generation_should_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 13.499106}, "meta_inference_prompt_tokens": {"value": 2274.0}, "meta_inference_completion_tokens": {"value": 701.0}, "meta_inference_prompt_cost": {"value": 0.0004548}, "meta_inference_completion_cost": {"value": 0.0011216}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:40.1274018Z"}
{"ref": "colorful-nucleus", "set": "20251210152915", "metrics": {"generation_should_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 13.361106}, "meta_inference_prompt_tokens": {"value": 2274.0}, "meta_inference_completion_tokens": {"value": 720.0}, "meta_inference_prompt_cost": {"value": 0.0004548}, "meta_inference_completion_cost": {"value": 0.001152}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:40.1357522Z"}
{"ref": "complete-theme-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.645096}, "meta_inference_prompt_tokens": {"value": 14703.0}, "meta_inference_completion_tokens": {"value": 1259.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029406}, "meta_inference_completion_cost": {"value": 0.0020144}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:40.8816946Z"}
{"ref": "colorful-nucleus", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0952380952380952}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 2.37720310370038}, "retrieval_accuracy": {"value": 0.05}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.0125}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 110.033389}, "meta_inference_prompt_tokens": {"value": 531737.0}, "meta_inference_completion_tokens": {"value": 5232.0}, "meta_inference_tool_call_count": {"value": 8.0}, "meta_inference_prompt_cost": {"value": 0.1063474}, "meta_inference_completion_cost": {"value": 0.0083712}, "meta_eval_time": {"value": 0.004}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:40.8819833Z"}
{"ref": "chocolate-spec", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.8}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.904761904761905}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.666666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.980282}, "meta_inference_prompt_tokens": {"value": 7515.0}, "meta_inference_completion_tokens": {"value": 1367.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001503}, "meta_inference_completion_cost": {"value": 0.0021872}, "meta_eval_time": {"value": 23.8}, "meta_eval_prompt_tokens": {"value": 4322.0}, "meta_eval_completion_tokens": {"value": 2069.0}, "meta_eval_prompt_cost": {"value": 0.00138304}, "meta_eval_completion_cost": {"value": 0.00264832}}, "created": "2025-12-10T21:43:40.8821233Z"}
{"ref": "chalky-bilge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.347826086956522}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 24.379688}, "meta_inference_prompt_tokens": {"value": 10218.0}, "meta_inference_completion_tokens": {"value": 1185.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020436}, "meta_inference_completion_cost": {"value": 0.001896}, "meta_eval_time": {"value": 33.742}, "meta_eval_prompt_tokens": {"value": 5927.0}, "meta_eval_completion_tokens": {"value": 3338.0}, "meta_eval_prompt_cost": {"value": 0.00189664}, "meta_eval_completion_cost": {"value": 0.00427264}}, "created": "2025-12-10T21:43:40.8822736Z"}
{"ref": "cheerful-store", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.777777777777778}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.927356}, "meta_inference_prompt_tokens": {"value": 9837.0}, "meta_inference_completion_tokens": {"value": 1264.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019674}, "meta_inference_completion_cost": {"value": 0.0020224}, "meta_eval_time": {"value": 26.652}, "meta_eval_prompt_tokens": {"value": 5230.0}, "meta_eval_completion_tokens": {"value": 2685.0}, "meta_eval_prompt_cost": {"value": 0.0016736}, "meta_eval_completion_cost": {"value": 0.0034368}}, "created": "2025-12-10T21:43:40.8824146Z"}
{"ref": "caramelized-action-B", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "generation_should_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.239715}, "meta_inference_prompt_tokens": {"value": 17655.0}, "meta_inference_completion_tokens": {"value": 1917.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003531}, "meta_inference_completion_cost": {"value": 0.0030672}, "meta_eval_time": {"value": 45.667}, "meta_eval_prompt_tokens": {"value": 14262.0}, "meta_eval_completion_tokens": {"value": 4516.0}, "meta_eval_prompt_cost": {"value": 0.00456384}, "meta_eval_completion_cost": {"value": 0.00578048}}, "created": "2025-12-10T21:43:40.882581Z"}
{"ref": "caramelized-action-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.235294117647059}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.133333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.285714285714286}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 28.435808}, "meta_inference_prompt_tokens": {"value": 14302.0}, "meta_inference_completion_tokens": {"value": 1754.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028604}, "meta_inference_completion_cost": {"value": 0.0028064}, "meta_eval_time": {"value": 52.075}, "meta_eval_prompt_tokens": {"value": 12054.0}, "meta_eval_completion_tokens": {"value": 4967.0}, "meta_eval_prompt_cost": {"value": 0.00385728}, "meta_eval_completion_cost": {"value": 0.00635776}}, "created": "2025-12-10T21:43:40.8827333Z"}
{"ref": "complete-theme-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.732948}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 509.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0008144}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:40.9336997Z"}
{"ref": "complete-theme-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.219109}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 582.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0009312}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:40.9915793Z"}
{"ref": "cheerful-store", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.88}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.462405}, "meta_inference_prompt_tokens": {"value": 9495.0}, "meta_inference_completion_tokens": {"value": 1047.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001899}, "meta_inference_completion_cost": {"value": 0.0016752}, "meta_eval_time": {"value": 28.124}, "meta_eval_prompt_tokens": {"value": 5039.0}, "meta_eval_completion_tokens": {"value": 2759.0}, "meta_eval_prompt_cost": {"value": 0.00161248}, "meta_eval_completion_cost": {"value": 0.00353152}}, "created": "2025-12-10T21:43:41.2179617Z"}
{"ref": "chocolate-spec", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.8}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.761904761904762}, "generation_factuality_f1": {"value": 0.470588235294118}, "generation_factuality_precision": {"value": 0.307692307692308}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.666666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.787567}, "meta_inference_prompt_tokens": {"value": 7534.0}, "meta_inference_completion_tokens": {"value": 979.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0015068}, "meta_inference_completion_cost": {"value": 0.0015664}, "meta_eval_time": {"value": 24.248}, "meta_eval_prompt_tokens": {"value": 4493.0}, "meta_eval_completion_tokens": {"value": 2226.0}, "meta_eval_prompt_cost": {"value": 0.00143776}, "meta_eval_completion_cost": {"value": 0.00284928}}, "created": "2025-12-10T21:43:42.2480125Z"}
{"ref": "caramelized-action-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.117647058823529}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0625}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.142857142857143}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.097733}, "meta_inference_prompt_tokens": {"value": 13888.0}, "meta_inference_completion_tokens": {"value": 2132.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027776}, "meta_inference_completion_cost": {"value": 0.0034112}, "meta_eval_time": {"value": 49.36}, "meta_eval_prompt_tokens": {"value": 11319.0}, "meta_eval_completion_tokens": {"value": 5056.0}, "meta_eval_prompt_cost": {"value": 0.00362208}, "meta_eval_completion_cost": {"value": 0.00647168}}, "created": "2025-12-10T21:43:43.3990507Z"}
{"ref": "chunky-strategy", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.727272727272727}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 26.212559}, "meta_inference_prompt_tokens": {"value": 17581.0}, "meta_inference_completion_tokens": {"value": 1244.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0035162}, "meta_inference_completion_cost": {"value": 0.0019904}, "meta_eval_time": {"value": 18.52}, "meta_eval_prompt_tokens": {"value": 11739.0}, "meta_eval_completion_tokens": {"value": 1688.0}, "meta_eval_prompt_cost": {"value": 0.00375648}, "meta_eval_completion_cost": {"value": 0.00216064}}, "created": "2025-12-10T21:43:43.7076303Z"}
{"ref": "chalky-bilge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.836734693877551}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.784369}, "meta_inference_prompt_tokens": {"value": 10690.0}, "meta_inference_completion_tokens": {"value": 1559.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002138}, "meta_inference_completion_cost": {"value": 0.0024944}, "meta_eval_time": {"value": 45.317}, "meta_eval_prompt_tokens": {"value": 6926.0}, "meta_eval_completion_tokens": {"value": 4255.0}, "meta_eval_prompt_cost": {"value": 0.00221632}, "meta_eval_completion_cost": {"value": 0.0054464}}, "created": "2025-12-10T21:43:44.0577885Z"}
{"ref": "caramelized-action-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.235294117647059}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.847058823529412}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.133333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.285714285714286}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 34.887162}, "meta_inference_prompt_tokens": {"value": 13560.0}, "meta_inference_completion_tokens": {"value": 1829.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002712}, "meta_inference_completion_cost": {"value": 0.0029264}, "meta_eval_time": {"value": 56.603}, "meta_eval_prompt_tokens": {"value": 11498.0}, "meta_eval_completion_tokens": {"value": 5563.0}, "meta_eval_prompt_cost": {"value": 0.00367936}, "meta_eval_completion_cost": {"value": 0.00712064}}, "created": "2025-12-10T21:43:44.6408339Z"}
{"ref": "coffee-snare", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 20.546344}, "meta_inference_prompt_tokens": {"value": 10668.0}, "meta_inference_completion_tokens": {"value": 944.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021336}, "meta_inference_completion_cost": {"value": 0.0015104}, "meta_eval_time": {"value": 17.235}, "meta_eval_prompt_tokens": {"value": 5253.0}, "meta_eval_completion_tokens": {"value": 1540.0}, "meta_eval_prompt_cost": {"value": 0.00168096}, "meta_eval_completion_cost": {"value": 0.0019712}}, "created": "2025-12-10T21:43:45.8997574Z"}
{"ref": "chalky-bilge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 24.825114}, "meta_inference_prompt_tokens": {"value": 10533.0}, "meta_inference_completion_tokens": {"value": 1252.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021066}, "meta_inference_completion_cost": {"value": 0.0020032}, "meta_eval_time": {"value": 35.577}, "meta_eval_prompt_tokens": {"value": 6624.0}, "meta_eval_completion_tokens": {"value": 3399.0}, "meta_eval_prompt_cost": {"value": 0.00211968}, "meta_eval_completion_cost": {"value": 0.00435072}}, "created": "2025-12-10T21:43:45.9001609Z"}
{"ref": "caramelized-action-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.235294117647059}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 0.980392156862745}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.133333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.285714285714286}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.581829}, "meta_inference_prompt_tokens": {"value": 13566.0}, "meta_inference_completion_tokens": {"value": 1825.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027132}, "meta_inference_completion_cost": {"value": 0.00292}, "meta_eval_time": {"value": 59.092}, "meta_eval_prompt_tokens": {"value": 11506.0}, "meta_eval_completion_tokens": {"value": 5406.0}, "meta_eval_prompt_cost": {"value": 0.00368192}, "meta_eval_completion_cost": {"value": 0.00691968}}, "created": "2025-12-10T21:43:45.9608262Z"}
{"ref": "cheerful-store", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.885714285714286}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 45.181931}, "meta_inference_prompt_tokens": {"value": 11055.0}, "meta_inference_completion_tokens": {"value": 1530.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002211}, "meta_inference_completion_cost": {"value": 0.002448}, "meta_eval_time": {"value": 32.546}, "meta_eval_prompt_tokens": {"value": 6512.0}, "meta_eval_completion_tokens": {"value": 3172.0}, "meta_eval_prompt_cost": {"value": 0.00208384}, "meta_eval_completion_cost": {"value": 0.00406016}}, "created": "2025-12-10T21:43:46.3206666Z"}
{"ref": "caramelized-action-B", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.958333333333334}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "generation_should_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 40.933075}, "meta_inference_prompt_tokens": {"value": 16427.0}, "meta_inference_completion_tokens": {"value": 2366.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032854}, "meta_inference_completion_cost": {"value": 0.0037856}, "meta_eval_time": {"value": 49.271}, "meta_eval_prompt_tokens": {"value": 12895.0}, "meta_eval_completion_tokens": {"value": 4953.0}, "meta_eval_prompt_cost": {"value": 0.0041264}, "meta_eval_completion_cost": {"value": 0.00633984}}, "created": "2025-12-10T21:43:46.9657209Z"}
{"ref": "caramelized-action-B", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.851063829787234}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "generation_should_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.316384}, "meta_inference_prompt_tokens": {"value": 15698.0}, "meta_inference_completion_tokens": {"value": 1573.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031396}, "meta_inference_completion_cost": {"value": 0.0025168}, "meta_eval_time": {"value": 49.022}, "meta_eval_prompt_tokens": {"value": 12020.0}, "meta_eval_completion_tokens": {"value": 4712.0}, "meta_eval_prompt_cost": {"value": 0.0038464}, "meta_eval_completion_cost": {"value": 0.00603136}}, "created": "2025-12-10T21:43:47.1287329Z"}
{"ref": "cheerful-store", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.794117647058824}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.60605}, "meta_inference_prompt_tokens": {"value": 9611.0}, "meta_inference_completion_tokens": {"value": 1365.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019222}, "meta_inference_completion_cost": {"value": 0.002184}, "meta_eval_time": {"value": 34.709}, "meta_eval_prompt_tokens": {"value": 5575.0}, "meta_eval_completion_tokens": {"value": 3372.0}, "meta_eval_prompt_cost": {"value": 0.001784}, "meta_eval_completion_cost": {"value": 0.00431616}}, "created": "2025-12-10T21:43:48.0266858Z"}
{"ref": "complicated-chino", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.971451}, "meta_inference_prompt_tokens": {"value": 13122.0}, "meta_inference_completion_tokens": {"value": 781.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026244}, "meta_inference_completion_cost": {"value": 0.0012496}, "meta_eval_time": {"value": 8.387}, "meta_eval_prompt_tokens": {"value": 6383.0}, "meta_eval_completion_tokens": {"value": 729.0}, "meta_eval_prompt_cost": {"value": 0.00204256}, "meta_eval_completion_cost": {"value": 0.00093312}}, "created": "2025-12-10T21:43:49.3491861Z"}
{"ref": "coffee-snare", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.761904761904762}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 24.84175}, "meta_inference_prompt_tokens": {"value": 10634.0}, "meta_inference_completion_tokens": {"value": 926.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021268}, "meta_inference_completion_cost": {"value": 0.0014816}, "meta_eval_time": {"value": 19.27}, "meta_eval_prompt_tokens": {"value": 5380.0}, "meta_eval_completion_tokens": {"value": 1980.0}, "meta_eval_prompt_cost": {"value": 0.0017216}, "meta_eval_completion_cost": {"value": 0.0025344}}, "created": "2025-12-10T21:43:50.122918Z"}
{"ref": "caramelized-action-B", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "generation_should_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.787014}, "meta_inference_prompt_tokens": {"value": 15649.0}, "meta_inference_completion_tokens": {"value": 1483.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031298}, "meta_inference_completion_cost": {"value": 0.0023728}, "meta_eval_time": {"value": 53.523}, "meta_eval_prompt_tokens": {"value": 12135.0}, "meta_eval_completion_tokens": {"value": 4883.0}, "meta_eval_prompt_cost": {"value": 0.0038832}, "meta_eval_completion_cost": {"value": 0.00625024}}, "created": "2025-12-10T21:43:50.2385323Z"}
{"ref": "coffee-snare", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 16.54968}, "meta_inference_prompt_tokens": {"value": 10634.0}, "meta_inference_completion_tokens": {"value": 710.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021268}, "meta_inference_completion_cost": {"value": 0.001136}, "meta_eval_time": {"value": 12.167}, "meta_eval_prompt_tokens": {"value": 5054.0}, "meta_eval_completion_tokens": {"value": 1129.0}, "meta_eval_prompt_cost": {"value": 0.00161728}, "meta_eval_completion_cost": {"value": 0.00144512}}, "created": "2025-12-10T21:43:50.47501Z"}
{"ref": "complicated-chino", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.737592}, "meta_inference_prompt_tokens": {"value": 11896.0}, "meta_inference_completion_tokens": {"value": 677.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023792}, "meta_inference_completion_cost": {"value": 0.0010832}, "meta_eval_time": {"value": 10.272}, "meta_eval_prompt_tokens": {"value": 5903.0}, "meta_eval_completion_tokens": {"value": 818.0}, "meta_eval_prompt_cost": {"value": 0.00188896}, "meta_eval_completion_cost": {"value": 0.00104704}}, "created": "2025-12-10T21:43:51.2407337Z"}
{"ref": "complicated-chino", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.362351}, "meta_inference_prompt_tokens": {"value": 12889.0}, "meta_inference_completion_tokens": {"value": 925.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025778}, "meta_inference_completion_cost": {"value": 0.00148}, "meta_eval_time": {"value": 10.589}, "meta_eval_prompt_tokens": {"value": 6399.0}, "meta_eval_completion_tokens": {"value": 829.0}, "meta_eval_prompt_cost": {"value": 0.00204768}, "meta_eval_completion_cost": {"value": 0.00106112}}, "created": "2025-12-10T21:43:51.5204172Z"}
{"ref": "complicated-chino", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.03539}, "meta_inference_prompt_tokens": {"value": 12887.0}, "meta_inference_completion_tokens": {"value": 951.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025774}, "meta_inference_completion_cost": {"value": 0.0015216}, "meta_eval_time": {"value": 11.135}, "meta_eval_prompt_tokens": {"value": 6411.0}, "meta_eval_completion_tokens": {"value": 980.0}, "meta_eval_prompt_cost": {"value": 0.00205152}, "meta_eval_completion_cost": {"value": 0.0012544}}, "created": "2025-12-10T21:43:52.1384419Z"}
{"ref": "chocolaty-depth", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.020539}, "meta_inference_prompt_tokens": {"value": 13604.0}, "meta_inference_completion_tokens": {"value": 1060.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027208}, "meta_inference_completion_cost": {"value": 0.001696}, "meta_eval_time": {"value": 32.79}, "meta_eval_prompt_tokens": {"value": 9167.0}, "meta_eval_completion_tokens": {"value": 3409.0}, "meta_eval_prompt_cost": {"value": 0.00293344}, "meta_eval_completion_cost": {"value": 0.00436352}}, "created": "2025-12-10T21:43:52.9050067Z"}
{"ref": "chocolaty-depth", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.321688}, "meta_inference_prompt_tokens": {"value": 13235.0}, "meta_inference_completion_tokens": {"value": 1195.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002647}, "meta_inference_completion_cost": {"value": 0.001912}, "meta_eval_time": {"value": 32.391}, "meta_eval_prompt_tokens": {"value": 9001.0}, "meta_eval_completion_tokens": {"value": 3345.0}, "meta_eval_prompt_cost": {"value": 0.00288032}, "meta_eval_completion_cost": {"value": 0.0042816}}, "created": "2025-12-10T21:43:53.3925126Z"}
{"ref": "complicated-chino", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.251284}, "meta_inference_prompt_tokens": {"value": 13023.0}, "meta_inference_completion_tokens": {"value": 1263.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026046}, "meta_inference_completion_cost": {"value": 0.0020208}, "meta_eval_time": {"value": 14.306}, "meta_eval_prompt_tokens": {"value": 6770.0}, "meta_eval_completion_tokens": {"value": 1321.0}, "meta_eval_prompt_cost": {"value": 0.0021664}, "meta_eval_completion_cost": {"value": 0.00169088}}, "created": "2025-12-10T21:43:55.307711Z"}
{"ref": "coffee-snare", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 16.456648}, "meta_inference_prompt_tokens": {"value": 10838.0}, "meta_inference_completion_tokens": {"value": 743.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021676}, "meta_inference_completion_cost": {"value": 0.0011888}, "meta_eval_time": {"value": 18.052}, "meta_eval_prompt_tokens": {"value": 5363.0}, "meta_eval_completion_tokens": {"value": 1512.0}, "meta_eval_prompt_cost": {"value": 0.00171616}, "meta_eval_completion_cost": {"value": 0.00193536}}, "created": "2025-12-10T21:43:55.5022678Z"}
{"ref": "chocolaty-depth", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.200759}, "meta_inference_prompt_tokens": {"value": 15541.0}, "meta_inference_completion_tokens": {"value": 1050.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031082}, "meta_inference_completion_cost": {"value": 0.00168}, "meta_eval_time": {"value": 34.39}, "meta_eval_prompt_tokens": {"value": 11323.0}, "meta_eval_completion_tokens": {"value": 3545.0}, "meta_eval_prompt_cost": {"value": 0.00362336}, "meta_eval_completion_cost": {"value": 0.0045376}}, "created": "2025-12-10T21:43:55.610121Z"}
{"ref": "convoluted-collie", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.019358}, "meta_inference_prompt_tokens": {"value": 2252.0}, "meta_inference_completion_tokens": {"value": 577.0}, "meta_inference_prompt_cost": {"value": 0.0004504}, "meta_inference_completion_cost": {"value": 0.0009232}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:55.6478409Z"}
{"ref": "cold-speaker-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 37.131706}, "meta_inference_prompt_tokens": {"value": 9683.0}, "meta_inference_completion_tokens": {"value": 1013.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019366}, "meta_inference_completion_cost": {"value": 0.0016208}, "meta_eval_time": {"value": 26.871}, "meta_eval_prompt_tokens": {"value": 4999.0}, "meta_eval_completion_tokens": {"value": 2508.0}, "meta_eval_prompt_cost": {"value": 0.00159968}, "meta_eval_completion_cost": {"value": 0.00321024}}, "created": "2025-12-10T21:43:55.6569482Z"}
{"ref": "convoluted-collie", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.911432}, "meta_inference_prompt_tokens": {"value": 2252.0}, "meta_inference_completion_tokens": {"value": 388.0}, "meta_inference_prompt_cost": {"value": 0.0004504}, "meta_inference_completion_cost": {"value": 0.0006208}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:55.7046853Z"}
{"ref": "convoluted-collie", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.379085}, "meta_inference_prompt_tokens": {"value": 2252.0}, "meta_inference_completion_tokens": {"value": 575.0}, "meta_inference_prompt_cost": {"value": 0.0004504}, "meta_inference_completion_cost": {"value": 0.00092}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:55.7412886Z"}
{"ref": "claret-window", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.771428571428571}, "generation_factuality_f1": {"value": 0.428571428571429}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 23.271483}, "meta_inference_prompt_tokens": {"value": 12536.0}, "meta_inference_completion_tokens": {"value": 1276.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025072}, "meta_inference_completion_cost": {"value": 0.0020416}, "meta_eval_time": {"value": 36.104}, "meta_eval_prompt_tokens": {"value": 8572.0}, "meta_eval_completion_tokens": {"value": 3530.0}, "meta_eval_prompt_cost": {"value": 0.00274304}, "meta_eval_completion_cost": {"value": 0.0045184}}, "created": "2025-12-10T21:43:57.6291194Z"}
{"ref": "careful-passenger-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.882352941176471}, "generation_factuality_f1": {"value": 0.705882352941176}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 25.794337}, "meta_inference_prompt_tokens": {"value": 11318.0}, "meta_inference_completion_tokens": {"value": 1205.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022636}, "meta_inference_completion_cost": {"value": 0.001928}, "meta_eval_time": {"value": 18.775}, "meta_eval_prompt_tokens": {"value": 6163.0}, "meta_eval_completion_tokens": {"value": 1813.0}, "meta_eval_prompt_cost": {"value": 0.00197216}, "meta_eval_completion_cost": {"value": 0.00232064}}, "created": "2025-12-10T21:43:58.1996583Z"}
{"ref": "convoluted-collie", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.801417}, "meta_inference_prompt_tokens": {"value": 4633.0}, "meta_inference_completion_tokens": {"value": 890.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009266}, "meta_inference_completion_cost": {"value": 0.001424}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:43:58.239645Z"}
{"ref": "caramelized-action-B", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "generation_should_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 38.717634}, "meta_inference_prompt_tokens": {"value": 15861.0}, "meta_inference_completion_tokens": {"value": 2056.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031722}, "meta_inference_completion_cost": {"value": 0.0032896}, "meta_eval_time": {"value": 62.939}, "meta_eval_prompt_tokens": {"value": 13280.0}, "meta_eval_completion_tokens": {"value": 6750.0}, "meta_eval_prompt_cost": {"value": 0.0042496}, "meta_eval_completion_cost": {"value": 0.00864}}, "created": "2025-12-10T21:43:59.2673921Z"}
{"ref": "cold-speaker-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.966666666666667}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.167668}, "meta_inference_prompt_tokens": {"value": 10254.0}, "meta_inference_completion_tokens": {"value": 1589.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020508}, "meta_inference_completion_cost": {"value": 0.0025424}, "meta_eval_time": {"value": 26.153}, "meta_eval_prompt_tokens": {"value": 6356.0}, "meta_eval_completion_tokens": {"value": 2773.0}, "meta_eval_prompt_cost": {"value": 0.00203392}, "meta_eval_completion_cost": {"value": 0.00354944}}, "created": "2025-12-10T21:43:59.4304966Z"}
{"ref": "chocolaty-depth", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.217102}, "meta_inference_prompt_tokens": {"value": 14422.0}, "meta_inference_completion_tokens": {"value": 1074.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028844}, "meta_inference_completion_cost": {"value": 0.0017184}, "meta_eval_time": {"value": 41.046}, "meta_eval_prompt_tokens": {"value": 10253.0}, "meta_eval_completion_tokens": {"value": 3641.0}, "meta_eval_prompt_cost": {"value": 0.00328096}, "meta_eval_completion_cost": {"value": 0.00466048}}, "created": "2025-12-10T21:44:00.1963165Z"}
{"ref": "connected-accent", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.875}, "generation_factuality_precision": {"value": 0.777777777777778}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.746626}, "meta_inference_prompt_tokens": {"value": 11032.0}, "meta_inference_completion_tokens": {"value": 659.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022064}, "meta_inference_completion_cost": {"value": 0.0010544}, "meta_eval_time": {"value": 14.874}, "meta_eval_prompt_tokens": {"value": 5561.0}, "meta_eval_completion_tokens": {"value": 1343.0}, "meta_eval_prompt_cost": {"value": 0.00177952}, "meta_eval_completion_cost": {"value": 0.00171904}}, "created": "2025-12-10T21:44:01.8766745Z"}
{"ref": "claret-window", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.951219512195122}, "generation_factuality_f1": {"value": 0.19047619047619}, "generation_factuality_precision": {"value": 0.111111111111111}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 20.638342}, "meta_inference_prompt_tokens": {"value": 12259.0}, "meta_inference_completion_tokens": {"value": 1012.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024518}, "meta_inference_completion_cost": {"value": 0.0016192}, "meta_eval_time": {"value": 35.834}, "meta_eval_prompt_tokens": {"value": 7990.0}, "meta_eval_completion_tokens": {"value": 3601.0}, "meta_eval_prompt_cost": {"value": 0.0025568}, "meta_eval_completion_cost": {"value": 0.00460928}}, "created": "2025-12-10T21:44:02.1890857Z"}
{"ref": "claret-window", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.813953488372093}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 22.581537}, "meta_inference_prompt_tokens": {"value": 12018.0}, "meta_inference_completion_tokens": {"value": 1328.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024036}, "meta_inference_completion_cost": {"value": 0.0021248}, "meta_eval_time": {"value": 38.367}, "meta_eval_prompt_tokens": {"value": 8100.0}, "meta_eval_completion_tokens": {"value": 3836.0}, "meta_eval_prompt_cost": {"value": 0.002592}, "meta_eval_completion_cost": {"value": 0.00491008}}, "created": "2025-12-10T21:44:04.5650219Z"}
{"ref": "claret-window", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.972222222222222}, "generation_factuality_f1": {"value": 0.421052631578947}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 26.831042}, "meta_inference_prompt_tokens": {"value": 11613.0}, "meta_inference_completion_tokens": {"value": 1479.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023226}, "meta_inference_completion_cost": {"value": 0.0023664}, "meta_eval_time": {"value": 38.039}, "meta_eval_prompt_tokens": {"value": 7769.0}, "meta_eval_completion_tokens": {"value": 3607.0}, "meta_eval_prompt_cost": {"value": 0.00248608}, "meta_eval_completion_cost": {"value": 0.00461696}}, "created": "2025-12-10T21:44:05.891678Z"}
{"ref": "cold-speaker-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.94639463035719}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.256291}, "meta_inference_prompt_tokens": {"value": 10116.0}, "meta_inference_completion_tokens": {"value": 1473.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020232}, "meta_inference_completion_cost": {"value": 0.0023568}, "meta_eval_time": {"value": 27.651}, "meta_eval_prompt_tokens": {"value": 5694.0}, "meta_eval_completion_tokens": {"value": 2729.0}, "meta_eval_prompt_cost": {"value": 0.00182208}, "meta_eval_completion_cost": {"value": 0.00349312}}, "created": "2025-12-10T21:44:05.8963372Z"}
{"ref": "colorful-nucleus", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0689655172413793}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 2.43305321913192}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0357142857142857}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.012987012987013}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 107.818507}, "meta_inference_prompt_tokens": {"value": 486445.0}, "meta_inference_completion_tokens": {"value": 5557.0}, "meta_inference_tool_call_count": {"value": 8.0}, "meta_inference_prompt_cost": {"value": 0.097289}, "meta_inference_completion_cost": {"value": 0.0088912}, "meta_eval_time": {"value": 26.19}, "meta_eval_prompt_tokens": {"value": 86078.0}, "meta_eval_completion_tokens": {"value": 1963.0}, "meta_eval_prompt_cost": {"value": 0.02754496}, "meta_eval_completion_cost": {"value": 0.00251264}}, "created": "2025-12-10T21:44:05.9840413Z"}
{"ref": "connected-accent", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.548103}, "meta_inference_prompt_tokens": {"value": 10955.0}, "meta_inference_completion_tokens": {"value": 713.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002191}, "meta_inference_completion_cost": {"value": 0.0011408}, "meta_eval_time": {"value": 16.837}, "meta_eval_prompt_tokens": {"value": 5665.0}, "meta_eval_completion_tokens": {"value": 1545.0}, "meta_eval_prompt_cost": {"value": 0.0018128}, "meta_eval_completion_cost": {"value": 0.0019776}}, "created": "2025-12-10T21:44:06.2232493Z"}
{"ref": "connected-accent", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.941176470588235}, "generation_factuality_precision": {"value": 0.888888888888889}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 43.270138}, "meta_inference_prompt_tokens": {"value": 11366.0}, "meta_inference_completion_tokens": {"value": 540.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022732}, "meta_inference_completion_cost": {"value": 0.000864}, "meta_eval_time": {"value": 16.15}, "meta_eval_prompt_tokens": {"value": 5959.0}, "meta_eval_completion_tokens": {"value": 1435.0}, "meta_eval_prompt_cost": {"value": 0.00190688}, "meta_eval_completion_cost": {"value": 0.0018368}}, "created": "2025-12-10T21:44:06.4277613Z"}
{"ref": "coffee-snare", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.88}, "generation_factuality_f1": {"value": 0.428571428571429}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 27.004954}, "meta_inference_prompt_tokens": {"value": 10835.0}, "meta_inference_completion_tokens": {"value": 1064.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002167}, "meta_inference_completion_cost": {"value": 0.0017024}, "meta_eval_time": {"value": 25.437}, "meta_eval_prompt_tokens": {"value": 5994.0}, "meta_eval_completion_tokens": {"value": 2382.0}, "meta_eval_prompt_cost": {"value": 0.00191808}, "meta_eval_completion_cost": {"value": 0.00304896}}, "created": "2025-12-10T21:44:06.69342Z"}
{"ref": "cold-speaker-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 41.964335}, "meta_inference_prompt_tokens": {"value": 10330.0}, "meta_inference_completion_tokens": {"value": 1052.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002066}, "meta_inference_completion_cost": {"value": 0.0016832}, "meta_eval_time": {"value": 26.173}, "meta_eval_prompt_tokens": {"value": 5649.0}, "meta_eval_completion_tokens": {"value": 2618.0}, "meta_eval_prompt_cost": {"value": 0.00180768}, "meta_eval_completion_cost": {"value": 0.00335104}}, "created": "2025-12-10T21:44:07.1444933Z"}
{"ref": "cold-speaker-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.36263630730883}, "generation_faithfulness": {"value": 0.976190476190476}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.783222}, "meta_inference_prompt_tokens": {"value": 11229.0}, "meta_inference_completion_tokens": {"value": 1568.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022458}, "meta_inference_completion_cost": {"value": 0.0025088}, "meta_eval_time": {"value": 34.032}, "meta_eval_prompt_tokens": {"value": 7152.0}, "meta_eval_completion_tokens": {"value": 3444.0}, "meta_eval_prompt_cost": {"value": 0.00228864}, "meta_eval_completion_cost": {"value": 0.00440832}}, "created": "2025-12-10T21:44:07.2902861Z"}
{"ref": "contemporary-estimator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.029582}, "meta_inference_prompt_tokens": {"value": 11294.0}, "meta_inference_completion_tokens": {"value": 1006.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022588}, "meta_inference_completion_cost": {"value": 0.0016096}, "meta_eval_time": {"value": 16.302}, "meta_eval_prompt_tokens": {"value": 5981.0}, "meta_eval_completion_tokens": {"value": 1426.0}, "meta_eval_prompt_cost": {"value": 0.00191392}, "meta_eval_completion_cost": {"value": 0.00182528}}, "created": "2025-12-10T21:44:08.4809343Z"}
{"ref": "connected-accent", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.846153846153846}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.412204}, "meta_inference_prompt_tokens": {"value": 10807.0}, "meta_inference_completion_tokens": {"value": 718.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021614}, "meta_inference_completion_cost": {"value": 0.0011488}, "meta_eval_time": {"value": 17.908}, "meta_eval_prompt_tokens": {"value": 5450.0}, "meta_eval_completion_tokens": {"value": 1542.0}, "meta_eval_prompt_cost": {"value": 0.001744}, "meta_eval_completion_cost": {"value": 0.00197376}}, "created": "2025-12-10T21:44:09.4666594Z"}
{"ref": "connected-accent", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.384929}, "meta_inference_prompt_tokens": {"value": 11007.0}, "meta_inference_completion_tokens": {"value": 795.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022014}, "meta_inference_completion_cost": {"value": 0.001272}, "meta_eval_time": {"value": 21.908}, "meta_eval_prompt_tokens": {"value": 5849.0}, "meta_eval_completion_tokens": {"value": 1974.0}, "meta_eval_prompt_cost": {"value": 0.00187168}, "meta_eval_completion_cost": {"value": 0.00252672}}, "created": "2025-12-10T21:44:09.9741622Z"}
{"ref": "concrete-boutique", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.469868}, "meta_inference_prompt_tokens": {"value": 11438.0}, "meta_inference_completion_tokens": {"value": 1576.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022876}, "meta_inference_completion_cost": {"value": 0.0025216}, "meta_eval_time": {"value": 24.127}, "meta_eval_prompt_tokens": {"value": 7033.0}, "meta_eval_completion_tokens": {"value": 2220.0}, "meta_eval_prompt_cost": {"value": 0.00225056}, "meta_eval_completion_cost": {"value": 0.0028416}}, "created": "2025-12-10T21:44:11.2904209Z"}
{"ref": "cheerful-store", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.793103448275862}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.796352}, "meta_inference_prompt_tokens": {"value": 9636.0}, "meta_inference_completion_tokens": {"value": 1162.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019272}, "meta_inference_completion_cost": {"value": 0.0018592}, "meta_eval_time": {"value": 30.305}, "meta_eval_prompt_tokens": {"value": 5411.0}, "meta_eval_completion_tokens": {"value": 3111.0}, "meta_eval_prompt_cost": {"value": 0.00173152}, "meta_eval_completion_cost": {"value": 0.00398208}}, "created": "2025-12-10T21:44:11.3352126Z"}
{"ref": "composite-dam", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.91304347826087}, "generation_factuality_f1": {"value": 0.533333333333333}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 35.952619}, "meta_inference_prompt_tokens": {"value": 12187.0}, "meta_inference_completion_tokens": {"value": 1487.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024374}, "meta_inference_completion_cost": {"value": 0.0023792}, "meta_eval_time": {"value": 28.11}, "meta_eval_prompt_tokens": {"value": 7959.0}, "meta_eval_completion_tokens": {"value": 2702.0}, "meta_eval_prompt_cost": {"value": 0.00254688}, "meta_eval_completion_cost": {"value": 0.00345856}}, "created": "2025-12-10T21:44:11.5497171Z"}
{"ref": "concrete-boutique", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.000727}, "meta_inference_prompt_tokens": {"value": 11872.0}, "meta_inference_completion_tokens": {"value": 1134.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023744}, "meta_inference_completion_cost": {"value": 0.0018144}, "meta_eval_time": {"value": 27.329}, "meta_eval_prompt_tokens": {"value": 7042.0}, "meta_eval_completion_tokens": {"value": 2176.0}, "meta_eval_prompt_cost": {"value": 0.00225344}, "meta_eval_completion_cost": {"value": 0.00278528}}, "created": "2025-12-10T21:44:13.6897672Z"}
{"ref": "contemporary-estimator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 72.09638}, "meta_inference_prompt_tokens": {"value": 11151.0}, "meta_inference_completion_tokens": {"value": 1203.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022302}, "meta_inference_completion_cost": {"value": 0.0019248}, "meta_eval_time": {"value": 23.537}, "meta_eval_prompt_tokens": {"value": 6110.0}, "meta_eval_completion_tokens": {"value": 2119.0}, "meta_eval_prompt_cost": {"value": 0.0019552}, "meta_eval_completion_cost": {"value": 0.00271232}}, "created": "2025-12-10T21:44:13.7030926Z"}
{"ref": "composite-dam", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.0467}, "meta_inference_prompt_tokens": {"value": 12017.0}, "meta_inference_completion_tokens": {"value": 1132.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024034}, "meta_inference_completion_cost": {"value": 0.0018112}, "meta_eval_time": {"value": 31.92}, "meta_eval_prompt_tokens": {"value": 7902.0}, "meta_eval_completion_tokens": {"value": 2954.0}, "meta_eval_prompt_cost": {"value": 0.00252864}, "meta_eval_completion_cost": {"value": 0.00378112}}, "created": "2025-12-10T21:44:14.2101545Z"}
{"ref": "contemporary-estimator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.97682}, "meta_inference_prompt_tokens": {"value": 12121.0}, "meta_inference_completion_tokens": {"value": 957.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024242}, "meta_inference_completion_cost": {"value": 0.0015312}, "meta_eval_time": {"value": 19.688}, "meta_eval_prompt_tokens": {"value": 6972.0}, "meta_eval_completion_tokens": {"value": 1813.0}, "meta_eval_prompt_cost": {"value": 0.00223104}, "meta_eval_completion_cost": {"value": 0.00232064}}, "created": "2025-12-10T21:44:15.2262312Z"}
{"ref": "claret-window", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.927272727272727}, "generation_factuality_f1": {"value": 0.508474576271187}, "generation_factuality_precision": {"value": 0.384615384615385}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 27.352355}, "meta_inference_prompt_tokens": {"value": 12641.0}, "meta_inference_completion_tokens": {"value": 1642.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025282}, "meta_inference_completion_cost": {"value": 0.0026272}, "meta_eval_time": {"value": 47.933}, "meta_eval_prompt_tokens": {"value": 8998.0}, "meta_eval_completion_tokens": {"value": 4633.0}, "meta_eval_prompt_cost": {"value": 0.00287936}, "meta_eval_completion_cost": {"value": 0.00593024}}, "created": "2025-12-10T21:44:15.3297901Z"}
{"ref": "concrete-boutique", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.964285714285714}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.262805}, "meta_inference_prompt_tokens": {"value": 11663.0}, "meta_inference_completion_tokens": {"value": 1390.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023326}, "meta_inference_completion_cost": {"value": 0.002224}, "meta_eval_time": {"value": 30.073}, "meta_eval_prompt_tokens": {"value": 7177.0}, "meta_eval_completion_tokens": {"value": 2841.0}, "meta_eval_prompt_cost": {"value": 0.00229664}, "meta_eval_completion_cost": {"value": 0.00363648}}, "created": "2025-12-10T21:44:16.04295Z"}
{"ref": "creamy-driver", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.900192}, "meta_inference_prompt_tokens": {"value": 10123.0}, "meta_inference_completion_tokens": {"value": 666.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020246}, "meta_inference_completion_cost": {"value": 0.0010656}, "meta_eval_time": {"value": 14.896}, "meta_eval_prompt_tokens": {"value": 4769.0}, "meta_eval_completion_tokens": {"value": 1291.0}, "meta_eval_prompt_cost": {"value": 0.00152608}, "meta_eval_completion_cost": {"value": 0.00165248}}, "created": "2025-12-10T21:44:17.312319Z"}
{"ref": "creamy-driver", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.442508}, "meta_inference_prompt_tokens": {"value": 9728.0}, "meta_inference_completion_tokens": {"value": 970.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019456}, "meta_inference_completion_cost": {"value": 0.001552}, "meta_eval_time": {"value": 19.001}, "meta_eval_prompt_tokens": {"value": 4557.0}, "meta_eval_completion_tokens": {"value": 1718.0}, "meta_eval_prompt_cost": {"value": 0.00145824}, "meta_eval_completion_cost": {"value": 0.00219904}}, "created": "2025-12-10T21:44:18.4702067Z"}
{"ref": "creamy-driver", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.769230769230769}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.164891}, "meta_inference_prompt_tokens": {"value": 9836.0}, "meta_inference_completion_tokens": {"value": 1131.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019672}, "meta_inference_completion_cost": {"value": 0.0018096}, "meta_eval_time": {"value": 16.938}, "meta_eval_prompt_tokens": {"value": 4753.0}, "meta_eval_completion_tokens": {"value": 1653.0}, "meta_eval_prompt_cost": {"value": 0.00152096}, "meta_eval_completion_cost": {"value": 0.00211584}}, "created": "2025-12-10T21:44:19.1770108Z"}
{"ref": "concrete-boutique", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.956521739130435}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.421658}, "meta_inference_prompt_tokens": {"value": 12792.0}, "meta_inference_completion_tokens": {"value": 1402.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025584}, "meta_inference_completion_cost": {"value": 0.0022432}, "meta_eval_time": {"value": 25.798}, "meta_eval_prompt_tokens": {"value": 8195.0}, "meta_eval_completion_tokens": {"value": 2558.0}, "meta_eval_prompt_cost": {"value": 0.0026224}, "meta_eval_completion_cost": {"value": 0.00327424}}, "created": "2025-12-10T21:44:19.2382514Z"}
{"ref": "contemporary-estimator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.909872699222587}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.05}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 41.669318}, "meta_inference_prompt_tokens": {"value": 27320.0}, "meta_inference_completion_tokens": {"value": 1387.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.005464}, "meta_inference_completion_cost": {"value": 0.0022192}, "meta_eval_time": {"value": 23.847}, "meta_eval_prompt_tokens": {"value": 9802.0}, "meta_eval_completion_tokens": {"value": 2447.0}, "meta_eval_prompt_cost": {"value": 0.00313664}, "meta_eval_completion_cost": {"value": 0.00313216}}, "created": "2025-12-10T21:44:19.5454065Z"}
{"ref": "composite-dam", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.220043}, "meta_inference_prompt_tokens": {"value": 12018.0}, "meta_inference_completion_tokens": {"value": 1051.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024036}, "meta_inference_completion_cost": {"value": 0.0016816}, "meta_eval_time": {"value": 35.836}, "meta_eval_prompt_tokens": {"value": 8102.0}, "meta_eval_completion_tokens": {"value": 3454.0}, "meta_eval_prompt_cost": {"value": 0.00259264}, "meta_eval_completion_cost": {"value": 0.00442112}}, "created": "2025-12-10T21:44:19.9432819Z"}
{"ref": "deafening-surface-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.414586}, "meta_inference_prompt_tokens": {"value": 4658.0}, "meta_inference_completion_tokens": {"value": 624.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009316}, "meta_inference_completion_cost": {"value": 0.0009984}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:44:19.9812862Z"}
{"ref": "deafening-surface-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.840381}, "meta_inference_prompt_tokens": {"value": 4637.0}, "meta_inference_completion_tokens": {"value": 749.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009274}, "meta_inference_completion_cost": {"value": 0.0011984}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:44:20.0200007Z"}
{"ref": "deafening-surface-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.532407}, "meta_inference_prompt_tokens": {"value": 4632.0}, "meta_inference_completion_tokens": {"value": 412.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009264}, "meta_inference_completion_cost": {"value": 0.0006592}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:44:20.061328Z"}
{"ref": "connected-airway", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.833333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.521739130434783}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 28.381861}, "meta_inference_prompt_tokens": {"value": 14473.0}, "meta_inference_completion_tokens": {"value": 1234.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028946}, "meta_inference_completion_cost": {"value": 0.0019744}, "meta_eval_time": {"value": 29.625}, "meta_eval_prompt_tokens": {"value": 9869.0}, "meta_eval_completion_tokens": {"value": 2615.0}, "meta_eval_prompt_cost": {"value": 0.00315808}, "meta_eval_completion_cost": {"value": 0.0033472}}, "created": "2025-12-10T21:44:20.1374548Z"}
{"ref": "composite-dam", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 21.389411}, "meta_inference_prompt_tokens": {"value": 12020.0}, "meta_inference_completion_tokens": {"value": 804.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002404}, "meta_inference_completion_cost": {"value": 0.0012864}, "meta_eval_time": {"value": 37.12}, "meta_eval_prompt_tokens": {"value": 7786.0}, "meta_eval_completion_tokens": {"value": 3662.0}, "meta_eval_prompt_cost": {"value": 0.00249152}, "meta_eval_completion_cost": {"value": 0.00468736}}, "created": "2025-12-10T21:44:20.8663556Z"}
{"ref": "creamy-driver", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.818181818181818}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.993747}, "meta_inference_prompt_tokens": {"value": 10124.0}, "meta_inference_completion_tokens": {"value": 957.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020248}, "meta_inference_completion_cost": {"value": 0.0015312}, "meta_eval_time": {"value": 16.318}, "meta_eval_prompt_tokens": {"value": 4868.0}, "meta_eval_completion_tokens": {"value": 1423.0}, "meta_eval_prompt_cost": {"value": 0.00155776}, "meta_eval_completion_cost": {"value": 0.00182144}}, "created": "2025-12-10T21:44:20.9299162Z"}
{"ref": "creamy-driver", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.636363636363636}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 20.251379}, "meta_inference_prompt_tokens": {"value": 9871.0}, "meta_inference_completion_tokens": {"value": 959.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019742}, "meta_inference_completion_cost": {"value": 0.0015344}, "meta_eval_time": {"value": 15.657}, "meta_eval_prompt_tokens": {"value": 4632.0}, "meta_eval_completion_tokens": {"value": 1453.0}, "meta_eval_prompt_cost": {"value": 0.00148224}, "meta_eval_completion_cost": {"value": 0.00185984}}, "created": "2025-12-10T21:44:21.5861823Z"}
{"ref": "connected-airway", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.833333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 23.794831}, "meta_inference_prompt_tokens": {"value": 14466.0}, "meta_inference_completion_tokens": {"value": 1098.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028932}, "meta_inference_completion_cost": {"value": 0.0017568}, "meta_eval_time": {"value": 26.723}, "meta_eval_prompt_tokens": {"value": 9738.0}, "meta_eval_completion_tokens": {"value": 2789.0}, "meta_eval_prompt_cost": {"value": 0.00311616}, "meta_eval_completion_cost": {"value": 0.00356992}}, "created": "2025-12-10T21:44:22.0778406Z"}
{"ref": "composite-dam", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.964652}, "meta_inference_prompt_tokens": {"value": 11833.0}, "meta_inference_completion_tokens": {"value": 1318.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023666}, "meta_inference_completion_cost": {"value": 0.0021088}, "meta_eval_time": {"value": 36.343}, "meta_eval_prompt_tokens": {"value": 7606.0}, "meta_eval_completion_tokens": {"value": 3251.0}, "meta_eval_prompt_cost": {"value": 0.00243392}, "meta_eval_completion_cost": {"value": 0.00416128}}, "created": "2025-12-10T21:44:23.0868198Z"}
{"ref": "connected-airway", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 2.26400989140673}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 19.325712}, "meta_inference_prompt_tokens": {"value": 13352.0}, "meta_inference_completion_tokens": {"value": 1245.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026704}, "meta_inference_completion_cost": {"value": 0.001992}, "meta_eval_time": {"value": 36.505}, "meta_eval_prompt_tokens": {"value": 9397.0}, "meta_eval_completion_tokens": {"value": 3538.0}, "meta_eval_prompt_cost": {"value": 0.00300704}, "meta_eval_completion_cost": {"value": 0.00452864}}, "created": "2025-12-10T21:44:23.0872215Z"}
{"ref": "contemporary-estimator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.864451}, "meta_inference_prompt_tokens": {"value": 11092.0}, "meta_inference_completion_tokens": {"value": 1370.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022184}, "meta_inference_completion_cost": {"value": 0.002192}, "meta_eval_time": {"value": 15.787}, "meta_eval_prompt_tokens": {"value": 5733.0}, "meta_eval_completion_tokens": {"value": 1404.0}, "meta_eval_prompt_cost": {"value": 0.00183456}, "meta_eval_completion_cost": {"value": 0.00179712}}, "created": "2025-12-10T21:44:25.2951928Z"}
{"ref": "denim-wattage", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.25}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 22.406708}, "meta_inference_prompt_tokens": {"value": 7033.0}, "meta_inference_completion_tokens": {"value": 1198.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0014066}, "meta_inference_completion_cost": {"value": 0.0019168}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:44:25.3368955Z"}
{"ref": "convoluted-collie", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.37021}, "meta_inference_prompt_tokens": {"value": 2252.0}, "meta_inference_completion_tokens": {"value": 523.0}, "meta_inference_prompt_cost": {"value": 0.0004504}, "meta_inference_completion_cost": {"value": 0.0008368}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:44:25.3751467Z"}
{"ref": "concrete-boutique", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.971428571428571}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.1768}, "meta_inference_prompt_tokens": {"value": 11767.0}, "meta_inference_completion_tokens": {"value": 1286.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023534}, "meta_inference_completion_cost": {"value": 0.0020576}, "meta_eval_time": {"value": 40.723}, "meta_eval_prompt_tokens": {"value": 7596.0}, "meta_eval_completion_tokens": {"value": 3758.0}, "meta_eval_prompt_cost": {"value": 0.00243072}, "meta_eval_completion_cost": {"value": 0.00481024}}, "created": "2025-12-10T21:44:25.4011765Z"}
{"ref": "denim-wattage", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 22.500916}, "meta_inference_prompt_tokens": {"value": 11354.0}, "meta_inference_completion_tokens": {"value": 1194.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022708}, "meta_inference_completion_cost": {"value": 0.0019104}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:44:25.4412347Z"}
{"ref": "crunchy-turpentine", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.248667}, "meta_inference_prompt_tokens": {"value": 15092.0}, "meta_inference_completion_tokens": {"value": 862.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030184}, "meta_inference_completion_cost": {"value": 0.0013792}, "meta_eval_time": {"value": 15.452}, "meta_eval_prompt_tokens": {"value": 9308.0}, "meta_eval_completion_tokens": {"value": 1418.0}, "meta_eval_prompt_cost": {"value": 0.00297856}, "meta_eval_completion_cost": {"value": 0.00181504}}, "created": "2025-12-10T21:44:25.4678002Z"}
{"ref": "denim-wattage", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.30102999566398}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.0588235294117647}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 43.107434}, "meta_inference_prompt_tokens": {"value": 24068.0}, "meta_inference_completion_tokens": {"value": 1771.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0048136}, "meta_inference_completion_cost": {"value": 0.0028336}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:44:25.5019742Z"}
{"ref": "deafening-surface-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.744821}, "meta_inference_prompt_tokens": {"value": 4635.0}, "meta_inference_completion_tokens": {"value": 484.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.000927}, "meta_inference_completion_cost": {"value": 0.0007744}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:44:25.5402057Z"}
{"ref": "connected-airway", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.52077138005526}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 21.679579}, "meta_inference_prompt_tokens": {"value": 16253.0}, "meta_inference_completion_tokens": {"value": 1047.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032506}, "meta_inference_completion_cost": {"value": 0.0016752}, "meta_eval_time": {"value": 32.989}, "meta_eval_prompt_tokens": {"value": 11815.0}, "meta_eval_completion_tokens": {"value": 2788.0}, "meta_eval_prompt_cost": {"value": 0.0037808}, "meta_eval_completion_cost": {"value": 0.00356864}}, "created": "2025-12-10T21:44:25.9405644Z"}
{"ref": "deafening-surface-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.453965}, "meta_inference_prompt_tokens": {"value": 4633.0}, "meta_inference_completion_tokens": {"value": 492.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009266}, "meta_inference_completion_cost": {"value": 0.0007872}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:44:25.9769292Z"}
{"ref": "denim-wattage", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.142857142857143}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 27.061417}, "meta_inference_prompt_tokens": {"value": 8206.0}, "meta_inference_completion_tokens": {"value": 1404.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0016412}, "meta_inference_completion_cost": {"value": 0.0022464}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:44:26.0144946Z"}
{"ref": "crunchy-turpentine", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.88589}, "meta_inference_prompt_tokens": {"value": 13924.0}, "meta_inference_completion_tokens": {"value": 892.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027848}, "meta_inference_completion_cost": {"value": 0.0014272}, "meta_eval_time": {"value": 14.379}, "meta_eval_prompt_tokens": {"value": 8237.0}, "meta_eval_completion_tokens": {"value": 1298.0}, "meta_eval_prompt_cost": {"value": 0.00263584}, "meta_eval_completion_cost": {"value": 0.00166144}}, "created": "2025-12-10T21:44:28.1148426Z"}
{"ref": "crunchy-turpentine", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.334117}, "meta_inference_prompt_tokens": {"value": 13070.0}, "meta_inference_completion_tokens": {"value": 982.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002614}, "meta_inference_completion_cost": {"value": 0.0015712}, "meta_eval_time": {"value": 17.59}, "meta_eval_prompt_tokens": {"value": 7767.0}, "meta_eval_completion_tokens": {"value": 1685.0}, "meta_eval_prompt_cost": {"value": 0.00248544}, "meta_eval_completion_cost": {"value": 0.0021568}}, "created": "2025-12-10T21:44:28.9689203Z"}
{"ref": "crunchy-turpentine", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.291842}, "meta_inference_prompt_tokens": {"value": 13942.0}, "meta_inference_completion_tokens": {"value": 861.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027884}, "meta_inference_completion_cost": {"value": 0.0013776}, "meta_eval_time": {"value": 15.084}, "meta_eval_prompt_tokens": {"value": 8338.0}, "meta_eval_completion_tokens": {"value": 1481.0}, "meta_eval_prompt_cost": {"value": 0.00266816}, "meta_eval_completion_cost": {"value": 0.00189568}}, "created": "2025-12-10T21:44:29.343148Z"}
{"ref": "cyclic-pond", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.44845911887939}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.441328}, "meta_inference_prompt_tokens": {"value": 12942.0}, "meta_inference_completion_tokens": {"value": 1287.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025884}, "meta_inference_completion_cost": {"value": 0.0020592}, "meta_eval_time": {"value": 19.87}, "meta_eval_prompt_tokens": {"value": 7998.0}, "meta_eval_completion_tokens": {"value": 1982.0}, "meta_eval_prompt_cost": {"value": 0.00255936}, "meta_eval_completion_cost": {"value": 0.00253696}}, "created": "2025-12-10T21:44:33.6161483Z"}
{"ref": "dark-bingo", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.727272727272727}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.712617}, "meta_inference_prompt_tokens": {"value": 10601.0}, "meta_inference_completion_tokens": {"value": 1551.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021202}, "meta_inference_completion_cost": {"value": 0.0024816}, "meta_eval_time": {"value": 14.7}, "meta_eval_prompt_tokens": {"value": 5354.0}, "meta_eval_completion_tokens": {"value": 1442.0}, "meta_eval_prompt_cost": {"value": 0.00171328}, "meta_eval_completion_cost": {"value": 0.00184576}}, "created": "2025-12-10T21:44:33.9143584Z"}
{"ref": "connected-airway", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.67373655241596}, "generation_faithfulness": {"value": 0.931818181818182}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 21.4395}, "meta_inference_prompt_tokens": {"value": 16423.0}, "meta_inference_completion_tokens": {"value": 1146.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032846}, "meta_inference_completion_cost": {"value": 0.0018336}, "meta_eval_time": {"value": 43.264}, "meta_eval_prompt_tokens": {"value": 12762.0}, "meta_eval_completion_tokens": {"value": 4338.0}, "meta_eval_prompt_cost": {"value": 0.00408384}, "meta_eval_completion_cost": {"value": 0.00555264}}, "created": "2025-12-10T21:44:34.5698236Z"}
{"ref": "cool-entropy", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.972222222222222}, "generation_factuality_f1": {"value": 0.625}, "generation_factuality_precision": {"value": 0.454545454545454}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.605579}, "meta_inference_prompt_tokens": {"value": 11442.0}, "meta_inference_completion_tokens": {"value": 1113.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022884}, "meta_inference_completion_cost": {"value": 0.0017808}, "meta_eval_time": {"value": 37.59}, "meta_eval_prompt_tokens": {"value": 7399.0}, "meta_eval_completion_tokens": {"value": 3455.0}, "meta_eval_prompt_cost": {"value": 0.00236768}, "meta_eval_completion_cost": {"value": 0.0044224}}, "created": "2025-12-10T21:44:35.2594359Z"}
{"ref": "crunchy-turpentine", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.751484}, "meta_inference_prompt_tokens": {"value": 13882.0}, "meta_inference_completion_tokens": {"value": 1147.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027764}, "meta_inference_completion_cost": {"value": 0.0018352}, "meta_eval_time": {"value": 18.945}, "meta_eval_prompt_tokens": {"value": 8513.0}, "meta_eval_completion_tokens": {"value": 1746.0}, "meta_eval_prompt_cost": {"value": 0.00272416}, "meta_eval_completion_cost": {"value": 0.00223488}}, "created": "2025-12-10T21:44:36.3008299Z"}
{"ref": "creative-bookcase", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.962962962962963}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 20.716902}, "meta_inference_prompt_tokens": {"value": 11054.0}, "meta_inference_completion_tokens": {"value": 1029.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022108}, "meta_inference_completion_cost": {"value": 0.0016464}, "meta_eval_time": {"value": 30.468}, "meta_eval_prompt_tokens": {"value": 6726.0}, "meta_eval_completion_tokens": {"value": 2770.0}, "meta_eval_prompt_cost": {"value": 0.00215232}, "meta_eval_completion_cost": {"value": 0.0035456}}, "created": "2025-12-10T21:44:36.4033848Z"}
{"ref": "desert-lagoon", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.791706}, "meta_inference_prompt_tokens": {"value": 10465.0}, "meta_inference_completion_tokens": {"value": 1162.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.002093}, "meta_inference_completion_cost": {"value": 0.0018592}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:44:36.441779Z"}
{"ref": "creative-bookcase", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.45061}, "meta_inference_prompt_tokens": {"value": 10388.0}, "meta_inference_completion_tokens": {"value": 1373.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020776}, "meta_inference_completion_cost": {"value": 0.0021968}, "meta_eval_time": {"value": 31.244}, "meta_eval_prompt_tokens": {"value": 6291.0}, "meta_eval_completion_tokens": {"value": 2909.0}, "meta_eval_prompt_cost": {"value": 0.00201312}, "meta_eval_completion_cost": {"value": 0.00372352}}, "created": "2025-12-10T21:44:37.5086386Z"}
{"ref": "critical-wattage", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 0.882352941176471}, "generation_factuality_f1": {"value": 0.307692307692308}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 23.973896}, "meta_inference_prompt_tokens": {"value": 10379.0}, "meta_inference_completion_tokens": {"value": 1352.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020758}, "meta_inference_completion_cost": {"value": 0.0021632}, "meta_eval_time": {"value": 31.502}, "meta_eval_prompt_tokens": {"value": 6055.0}, "meta_eval_completion_tokens": {"value": 3081.0}, "meta_eval_prompt_cost": {"value": 0.0019376}, "meta_eval_completion_cost": {"value": 0.00394368}}, "created": "2025-12-10T21:44:37.5290735Z"}
{"ref": "desert-lagoon", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.373382}, "meta_inference_prompt_tokens": {"value": 6628.0}, "meta_inference_completion_tokens": {"value": 843.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0013256}, "meta_inference_completion_cost": {"value": 0.0013488}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:44:37.5720415Z"}
{"ref": "creative-bookcase", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.225145}, "meta_inference_prompt_tokens": {"value": 10358.0}, "meta_inference_completion_tokens": {"value": 1572.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020716}, "meta_inference_completion_cost": {"value": 0.0025152}, "meta_eval_time": {"value": 31.123}, "meta_eval_prompt_tokens": {"value": 6265.0}, "meta_eval_completion_tokens": {"value": 2820.0}, "meta_eval_prompt_cost": {"value": 0.0020048}, "meta_eval_completion_cost": {"value": 0.0036096}}, "created": "2025-12-10T21:44:37.857242Z"}
{"ref": "dark-bingo", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.485507}, "meta_inference_prompt_tokens": {"value": 10051.0}, "meta_inference_completion_tokens": {"value": 1524.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020102}, "meta_inference_completion_cost": {"value": 0.0024384}, "meta_eval_time": {"value": 18.859}, "meta_eval_prompt_tokens": {"value": 4814.0}, "meta_eval_completion_tokens": {"value": 1558.0}, "meta_eval_prompt_cost": {"value": 0.00154048}, "meta_eval_completion_cost": {"value": 0.00199424}}, "created": "2025-12-10T21:44:38.5091851Z"}
{"ref": "desert-lagoon", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.194046}, "meta_inference_prompt_tokens": {"value": 10387.0}, "meta_inference_completion_tokens": {"value": 743.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020774}, "meta_inference_completion_cost": {"value": 0.0011888}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:44:38.5088554Z"}
{"ref": "cyclic-pond", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 1.94845911887939}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.9}, "generation_factuality_precision": {"value": 0.818181818181818}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.776953}, "meta_inference_prompt_tokens": {"value": 11960.0}, "meta_inference_completion_tokens": {"value": 1189.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002392}, "meta_inference_completion_cost": {"value": 0.0019024}, "meta_eval_time": {"value": 22.987}, "meta_eval_prompt_tokens": {"value": 6869.0}, "meta_eval_completion_tokens": {"value": 2044.0}, "meta_eval_prompt_cost": {"value": 0.00219808}, "meta_eval_completion_cost": {"value": 0.00261632}}, "created": "2025-12-10T21:44:38.5093129Z"}
{"ref": "desert-lagoon", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.962347}, "meta_inference_prompt_tokens": {"value": 9219.0}, "meta_inference_completion_tokens": {"value": 1233.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0018438}, "meta_inference_completion_cost": {"value": 0.0019728}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:44:38.554296Z"}
{"ref": "desert-lagoon", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.099927}, "meta_inference_prompt_tokens": {"value": 10116.0}, "meta_inference_completion_tokens": {"value": 611.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0020232}, "meta_inference_completion_cost": {"value": 0.0009776}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:44:38.5571858Z"}
{"ref": "dark-bingo", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.785714285714286}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.714806}, "meta_inference_prompt_tokens": {"value": 11269.0}, "meta_inference_completion_tokens": {"value": 1437.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022538}, "meta_inference_completion_cost": {"value": 0.0022992}, "meta_eval_time": {"value": 19.029}, "meta_eval_prompt_tokens": {"value": 5941.0}, "meta_eval_completion_tokens": {"value": 1768.0}, "meta_eval_prompt_cost": {"value": 0.00190112}, "meta_eval_completion_cost": {"value": 0.00226304}}, "created": "2025-12-10T21:44:38.6124788Z"}
{"ref": "critical-wattage", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 33.297583}, "meta_inference_prompt_tokens": {"value": 10817.0}, "meta_inference_completion_tokens": {"value": 1354.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021634}, "meta_inference_completion_cost": {"value": 0.0021664}, "meta_eval_time": {"value": 30.87}, "meta_eval_prompt_tokens": {"value": 6107.0}, "meta_eval_completion_tokens": {"value": 2770.0}, "meta_eval_prompt_cost": {"value": 0.00195424}, "meta_eval_completion_cost": {"value": 0.0035456}}, "created": "2025-12-10T21:44:39.3952448Z"}
{"ref": "cyclic-pond", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 1.87398974791402}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.098763}, "meta_inference_prompt_tokens": {"value": 12144.0}, "meta_inference_completion_tokens": {"value": 1442.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024288}, "meta_inference_completion_cost": {"value": 0.0023072}, "meta_eval_time": {"value": 24.41}, "meta_eval_prompt_tokens": {"value": 7247.0}, "meta_eval_completion_tokens": {"value": 2000.0}, "meta_eval_prompt_cost": {"value": 0.00231904}, "meta_eval_completion_cost": {"value": 0.00256}}, "created": "2025-12-10T21:44:40.4972366Z"}
{"ref": "dark-bingo", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.647058823529412}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.75438}, "meta_inference_prompt_tokens": {"value": 11475.0}, "meta_inference_completion_tokens": {"value": 1422.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002295}, "meta_inference_completion_cost": {"value": 0.0022752}, "meta_eval_time": {"value": 22.486}, "meta_eval_prompt_tokens": {"value": 6366.0}, "meta_eval_completion_tokens": {"value": 1958.0}, "meta_eval_prompt_cost": {"value": 0.00203712}, "meta_eval_completion_cost": {"value": 0.00250624}}, "created": "2025-12-10T21:44:40.999187Z"}
{"ref": "cyclic-pond", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.39493964497818}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.941176470588235}, "generation_factuality_precision": {"value": 0.888888888888889}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.976293}, "meta_inference_prompt_tokens": {"value": 13055.0}, "meta_inference_completion_tokens": {"value": 1814.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002611}, "meta_inference_completion_cost": {"value": 0.0029024}, "meta_eval_time": {"value": 26.85}, "meta_eval_prompt_tokens": {"value": 8056.0}, "meta_eval_completion_tokens": {"value": 2210.0}, "meta_eval_prompt_cost": {"value": 0.00257792}, "meta_eval_completion_cost": {"value": 0.0028288}}, "created": "2025-12-10T21:44:42.1165095Z"}
{"ref": "critical-wattage", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.307692307692308}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 35.862189}, "meta_inference_prompt_tokens": {"value": 10302.0}, "meta_inference_completion_tokens": {"value": 1481.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020604}, "meta_inference_completion_cost": {"value": 0.0023696}, "meta_eval_time": {"value": 31.191}, "meta_eval_prompt_tokens": {"value": 6032.0}, "meta_eval_completion_tokens": {"value": 3205.0}, "meta_eval_prompt_cost": {"value": 0.00193024}, "meta_eval_completion_cost": {"value": 0.0041024}}, "created": "2025-12-10T21:44:42.5294567Z"}
{"ref": "denim-wattage", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.533333333333333}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.142857142857143}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.141456}, "meta_inference_prompt_tokens": {"value": 12548.0}, "meta_inference_completion_tokens": {"value": 1860.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0025096}, "meta_inference_completion_cost": {"value": 0.002976}, "meta_eval_time": {"value": 19.762}, "meta_eval_prompt_tokens": {"value": 4186.0}, "meta_eval_completion_tokens": {"value": 1860.0}, "meta_eval_prompt_cost": {"value": 0.00133952}, "meta_eval_completion_cost": {"value": 0.0023808}}, "created": "2025-12-10T21:44:42.9342408Z"}
{"ref": "critical-wattage", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 26.084814}, "meta_inference_prompt_tokens": {"value": 10232.0}, "meta_inference_completion_tokens": {"value": 1257.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020464}, "meta_inference_completion_cost": {"value": 0.0020112}, "meta_eval_time": {"value": 31.504}, "meta_eval_prompt_tokens": {"value": 5949.0}, "meta_eval_completion_tokens": {"value": 2967.0}, "meta_eval_prompt_cost": {"value": 0.00190368}, "meta_eval_completion_cost": {"value": 0.00379776}}, "created": "2025-12-10T21:44:43.0926917Z"}
{"ref": "cool-entropy", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.701754385964912}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 60.671807}, "meta_inference_prompt_tokens": {"value": 11444.0}, "meta_inference_completion_tokens": {"value": 1103.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022888}, "meta_inference_completion_cost": {"value": 0.0017648}, "meta_eval_time": {"value": 45.123}, "meta_eval_prompt_tokens": {"value": 7779.0}, "meta_eval_completion_tokens": {"value": 3817.0}, "meta_eval_prompt_cost": {"value": 0.00248928}, "meta_eval_completion_cost": {"value": 0.00488576}}, "created": "2025-12-10T21:44:43.4012586Z"}
{"ref": "dark-bingo", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.242952}, "meta_inference_prompt_tokens": {"value": 10859.0}, "meta_inference_completion_tokens": {"value": 1163.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021718}, "meta_inference_completion_cost": {"value": 0.0018608}, "meta_eval_time": {"value": 17.992}, "meta_eval_prompt_tokens": {"value": 5541.0}, "meta_eval_completion_tokens": {"value": 1639.0}, "meta_eval_prompt_cost": {"value": 0.00177312}, "meta_eval_completion_cost": {"value": 0.00209792}}, "created": "2025-12-10T21:44:44.075507Z"}
{"ref": "decidable-image", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.44845911887939}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.310342}, "meta_inference_prompt_tokens": {"value": 11249.0}, "meta_inference_completion_tokens": {"value": 1360.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022498}, "meta_inference_completion_cost": {"value": 0.002176}, "meta_eval_time": {"value": 22.546}, "meta_eval_prompt_tokens": {"value": 6594.0}, "meta_eval_completion_tokens": {"value": 2287.0}, "meta_eval_prompt_cost": {"value": 0.00211008}, "meta_eval_completion_cost": {"value": 0.00292736}}, "created": "2025-12-10T21:44:44.0758579Z"}
{"ref": "desert-jetsam", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.6}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.166666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.473649}, "meta_inference_prompt_tokens": {"value": 8388.0}, "meta_inference_completion_tokens": {"value": 752.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0016776}, "meta_inference_completion_cost": {"value": 0.0012032}, "meta_eval_time": {"value": 8.441}, "meta_eval_prompt_tokens": {"value": 3806.0}, "meta_eval_completion_tokens": {"value": 736.0}, "meta_eval_prompt_cost": {"value": 0.00121792}, "meta_eval_completion_cost": {"value": 0.00094208}}, "created": "2025-12-10T21:44:44.780464Z"}
{"ref": "creative-bookcase", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.222222222222222}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.32826}, "meta_inference_prompt_tokens": {"value": 10689.0}, "meta_inference_completion_tokens": {"value": 1415.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021378}, "meta_inference_completion_cost": {"value": 0.002264}, "meta_eval_time": {"value": 39.018}, "meta_eval_prompt_tokens": {"value": 7371.0}, "meta_eval_completion_tokens": {"value": 3982.0}, "meta_eval_prompt_cost": {"value": 0.00235872}, "meta_eval_completion_cost": {"value": 0.00509696}}, "created": "2025-12-10T21:44:45.483089Z"}
{"ref": "decidable-image", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.44845911887939}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.936306}, "meta_inference_prompt_tokens": {"value": 12052.0}, "meta_inference_completion_tokens": {"value": 1226.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024104}, "meta_inference_completion_cost": {"value": 0.0019616}, "meta_eval_time": {"value": 23.949}, "meta_eval_prompt_tokens": {"value": 7384.0}, "meta_eval_completion_tokens": {"value": 2396.0}, "meta_eval_prompt_cost": {"value": 0.00236288}, "meta_eval_completion_cost": {"value": 0.00306688}}, "created": "2025-12-10T21:44:45.5736274Z"}
{"ref": "critical-wattage", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.307692307692308}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 37.995954}, "meta_inference_prompt_tokens": {"value": 10311.0}, "meta_inference_completion_tokens": {"value": 1605.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020622}, "meta_inference_completion_cost": {"value": 0.002568}, "meta_eval_time": {"value": 38.861}, "meta_eval_prompt_tokens": {"value": 6200.0}, "meta_eval_completion_tokens": {"value": 3146.0}, "meta_eval_prompt_cost": {"value": 0.001984}, "meta_eval_completion_cost": {"value": 0.00402688}}, "created": "2025-12-10T21:44:46.0486304Z"}
{"ref": "denim-click", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.941176470588235}, "generation_factuality_precision": {"value": 0.888888888888889}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.650756}, "meta_inference_prompt_tokens": {"value": 10322.0}, "meta_inference_completion_tokens": {"value": 1033.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020644}, "meta_inference_completion_cost": {"value": 0.0016528}, "meta_eval_time": {"value": 24.278}, "meta_eval_prompt_tokens": {"value": 5526.0}, "meta_eval_completion_tokens": {"value": 2186.0}, "meta_eval_prompt_cost": {"value": 0.00176832}, "meta_eval_completion_cost": {"value": 0.00279808}}, "created": "2025-12-10T21:44:46.4179367Z"}
{"ref": "decidable-image", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.517782560806}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 40.119915}, "meta_inference_prompt_tokens": {"value": 12012.0}, "meta_inference_completion_tokens": {"value": 1431.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024024}, "meta_inference_completion_cost": {"value": 0.0022896}, "meta_eval_time": {"value": 26.303}, "meta_eval_prompt_tokens": {"value": 7615.0}, "meta_eval_completion_tokens": {"value": 2414.0}, "meta_eval_prompt_cost": {"value": 0.0024368}, "meta_eval_completion_cost": {"value": 0.00308992}}, "created": "2025-12-10T21:44:46.4799118Z"}
{"ref": "creative-bookcase", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.648648648648649}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 29.12673}, "meta_inference_prompt_tokens": {"value": 10849.0}, "meta_inference_completion_tokens": {"value": 1235.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021698}, "meta_inference_completion_cost": {"value": 0.001976}, "meta_eval_time": {"value": 40.679}, "meta_eval_prompt_tokens": {"value": 7340.0}, "meta_eval_completion_tokens": {"value": 3641.0}, "meta_eval_prompt_cost": {"value": 0.0023488}, "meta_eval_completion_cost": {"value": 0.00466048}}, "created": "2025-12-10T21:44:48.0358015Z"}
{"ref": "cool-entropy", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.366407}, "meta_inference_prompt_tokens": {"value": 12286.0}, "meta_inference_completion_tokens": {"value": 1654.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024572}, "meta_inference_completion_cost": {"value": 0.0026464}, "meta_eval_time": {"value": 52.317}, "meta_eval_prompt_tokens": {"value": 9691.0}, "meta_eval_completion_tokens": {"value": 5343.0}, "meta_eval_prompt_cost": {"value": 0.00310112}, "meta_eval_completion_cost": {"value": 0.00683904}}, "created": "2025-12-10T21:44:48.0986716Z"}
{"ref": "desert-jetsam", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.333333333333333}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.019877}, "meta_inference_prompt_tokens": {"value": 10216.0}, "meta_inference_completion_tokens": {"value": 1245.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020432}, "meta_inference_completion_cost": {"value": 0.001992}, "meta_eval_time": {"value": 12.669}, "meta_eval_prompt_tokens": {"value": 5202.0}, "meta_eval_completion_tokens": {"value": 1180.0}, "meta_eval_prompt_cost": {"value": 0.00166464}, "meta_eval_completion_cost": {"value": 0.0015104}}, "created": "2025-12-10T21:44:49.1472049Z"}
{"ref": "desert-jetsam", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.956201}, "meta_inference_prompt_tokens": {"value": 11290.0}, "meta_inference_completion_tokens": {"value": 1179.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002258}, "meta_inference_completion_cost": {"value": 0.0018864}, "meta_eval_time": {"value": 12.773}, "meta_eval_prompt_tokens": {"value": 5742.0}, "meta_eval_completion_tokens": {"value": 1112.0}, "meta_eval_prompt_cost": {"value": 0.00183744}, "meta_eval_completion_cost": {"value": 0.00142336}}, "created": "2025-12-10T21:44:50.3808334Z"}
{"ref": "decidable-image", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.88685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.69166}, "meta_inference_prompt_tokens": {"value": 11869.0}, "meta_inference_completion_tokens": {"value": 1125.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023738}, "meta_inference_completion_cost": {"value": 0.0018}, "meta_eval_time": {"value": 29.908}, "meta_eval_prompt_tokens": {"value": 7338.0}, "meta_eval_completion_tokens": {"value": 2445.0}, "meta_eval_prompt_cost": {"value": 0.00234816}, "meta_eval_completion_cost": {"value": 0.0031296}}, "created": "2025-12-10T21:44:50.8127118Z"}
{"ref": "desert-jetsam", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.498217}, "meta_inference_prompt_tokens": {"value": 12106.0}, "meta_inference_completion_tokens": {"value": 1399.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024212}, "meta_inference_completion_cost": {"value": 0.0022384}, "meta_eval_time": {"value": 17.184}, "meta_eval_prompt_tokens": {"value": 6657.0}, "meta_eval_completion_tokens": {"value": 1534.0}, "meta_eval_prompt_cost": {"value": 0.00213024}, "meta_eval_completion_cost": {"value": 0.00196352}}, "created": "2025-12-10T21:44:50.8363307Z"}
{"ref": "cool-entropy", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.936170212765958}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 36.254101}, "meta_inference_prompt_tokens": {"value": 12578.0}, "meta_inference_completion_tokens": {"value": 1957.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025156}, "meta_inference_completion_cost": {"value": 0.0031312}, "meta_eval_time": {"value": 50.96}, "meta_eval_prompt_tokens": {"value": 9715.0}, "meta_eval_completion_tokens": {"value": 4614.0}, "meta_eval_prompt_cost": {"value": 0.0031088}, "meta_eval_completion_cost": {"value": 0.00590592}}, "created": "2025-12-10T21:44:51.6480628Z"}
{"ref": "desert-jetsam", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.5}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.437827}, "meta_inference_prompt_tokens": {"value": 7444.0}, "meta_inference_completion_tokens": {"value": 1223.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0014888}, "meta_inference_completion_cost": {"value": 0.0019568}, "meta_eval_time": {"value": 14.035}, "meta_eval_prompt_tokens": {"value": 3611.0}, "meta_eval_completion_tokens": {"value": 1267.0}, "meta_eval_prompt_cost": {"value": 0.00115552}, "meta_eval_completion_cost": {"value": 0.00162176}}, "created": "2025-12-10T21:44:51.6484774Z"}
{"ref": "diachronic-rate", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 19.390865}, "meta_inference_prompt_tokens": {"value": 10573.0}, "meta_inference_completion_tokens": {"value": 669.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021146}, "meta_inference_completion_cost": {"value": 0.0010704}, "meta_eval_time": {"value": 13.306}, "meta_eval_prompt_tokens": {"value": 5184.0}, "meta_eval_completion_tokens": {"value": 1306.0}, "meta_eval_prompt_cost": {"value": 0.00165888}, "meta_eval_completion_cost": {"value": 0.00167168}}, "created": "2025-12-10T21:44:51.8998761Z"}
{"ref": "diachronic-rate", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 17.270103}, "meta_inference_prompt_tokens": {"value": 10572.0}, "meta_inference_completion_tokens": {"value": 692.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021144}, "meta_inference_completion_cost": {"value": 0.0011072}, "meta_eval_time": {"value": 13.414}, "meta_eval_prompt_tokens": {"value": 5127.0}, "meta_eval_completion_tokens": {"value": 1347.0}, "meta_eval_prompt_cost": {"value": 0.00164064}, "meta_eval_completion_cost": {"value": 0.00172416}}, "created": "2025-12-10T21:44:51.9734215Z"}
{"ref": "cyclic-pond", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.28688374518142}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.82692}, "meta_inference_prompt_tokens": {"value": 13914.0}, "meta_inference_completion_tokens": {"value": 1874.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027828}, "meta_inference_completion_cost": {"value": 0.0029984}, "meta_eval_time": {"value": 23.416}, "meta_eval_prompt_tokens": {"value": 8996.0}, "meta_eval_completion_tokens": {"value": 2127.0}, "meta_eval_prompt_cost": {"value": 0.00287872}, "meta_eval_completion_cost": {"value": 0.00272256}}, "created": "2025-12-10T21:44:52.4211024Z"}
{"ref": "denim-click", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 65.633791}, "meta_inference_prompt_tokens": {"value": 10375.0}, "meta_inference_completion_tokens": {"value": 1258.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002075}, "meta_inference_completion_cost": {"value": 0.0020128}, "meta_eval_time": {"value": 27.568}, "meta_eval_prompt_tokens": {"value": 5940.0}, "meta_eval_completion_tokens": {"value": 2896.0}, "meta_eval_prompt_cost": {"value": 0.0019008}, "meta_eval_completion_cost": {"value": 0.00370688}}, "created": "2025-12-10T21:44:52.9804073Z"}
{"ref": "denim-click", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.2}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 35.743619}, "meta_inference_prompt_tokens": {"value": 10300.0}, "meta_inference_completion_tokens": {"value": 1733.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00206}, "meta_inference_completion_cost": {"value": 0.0027728}, "meta_eval_time": {"value": 34.465}, "meta_eval_prompt_tokens": {"value": 6082.0}, "meta_eval_completion_tokens": {"value": 3132.0}, "meta_eval_prompt_cost": {"value": 0.00194624}, "meta_eval_completion_cost": {"value": 0.00400896}}, "created": "2025-12-10T21:44:54.5706481Z"}
{"ref": "dense-octree", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.84}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.166666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.558852}, "meta_inference_prompt_tokens": {"value": 9952.0}, "meta_inference_completion_tokens": {"value": 1028.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019904}, "meta_inference_completion_cost": {"value": 0.0016448}, "meta_eval_time": {"value": 29.31}, "meta_eval_prompt_tokens": {"value": 6267.0}, "meta_eval_completion_tokens": {"value": 2727.0}, "meta_eval_prompt_cost": {"value": 0.00200544}, "meta_eval_completion_cost": {"value": 0.00349056}}, "created": "2025-12-10T21:44:54.8869337Z"}
{"ref": "diachronic-rate", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 17.070019}, "meta_inference_prompt_tokens": {"value": 11807.0}, "meta_inference_completion_tokens": {"value": 667.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023614}, "meta_inference_completion_cost": {"value": 0.0010672}, "meta_eval_time": {"value": 14.475}, "meta_eval_prompt_tokens": {"value": 6368.0}, "meta_eval_completion_tokens": {"value": 1305.0}, "meta_eval_prompt_cost": {"value": 0.00203776}, "meta_eval_completion_cost": {"value": 0.0016704}}, "created": "2025-12-10T21:44:55.0154476Z"}
{"ref": "cool-entropy", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 39.510278}, "meta_inference_prompt_tokens": {"value": 12661.0}, "meta_inference_completion_tokens": {"value": 1599.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025322}, "meta_inference_completion_cost": {"value": 0.0025584}, "meta_eval_time": {"value": 55.723}, "meta_eval_prompt_tokens": {"value": 10169.0}, "meta_eval_completion_tokens": {"value": 5212.0}, "meta_eval_prompt_cost": {"value": 0.00325408}, "meta_eval_completion_cost": {"value": 0.00667136}}, "created": "2025-12-10T21:44:55.0364483Z"}
{"ref": "decidable-image", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.81752936530793}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.850934}, "meta_inference_prompt_tokens": {"value": 11797.0}, "meta_inference_completion_tokens": {"value": 1210.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023594}, "meta_inference_completion_cost": {"value": 0.001936}, "meta_eval_time": {"value": 27.348}, "meta_eval_prompt_tokens": {"value": 7232.0}, "meta_eval_completion_tokens": {"value": 2365.0}, "meta_eval_prompt_cost": {"value": 0.00231424}, "meta_eval_completion_cost": {"value": 0.0030272}}, "created": "2025-12-10T21:44:55.5120606Z"}
{"ref": "diachronic-rate", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 16.287392}, "meta_inference_prompt_tokens": {"value": 10574.0}, "meta_inference_completion_tokens": {"value": 605.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021148}, "meta_inference_completion_cost": {"value": 0.000968}, "meta_eval_time": {"value": 17.754}, "meta_eval_prompt_tokens": {"value": 5209.0}, "meta_eval_completion_tokens": {"value": 1547.0}, "meta_eval_prompt_cost": {"value": 0.00166688}, "meta_eval_completion_cost": {"value": 0.00198016}}, "created": "2025-12-10T21:44:56.3431324Z"}
{"ref": "dense-octree", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.25}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.8658}, "meta_inference_prompt_tokens": {"value": 8724.0}, "meta_inference_completion_tokens": {"value": 1232.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0017448}, "meta_inference_completion_cost": {"value": 0.0019712}, "meta_eval_time": {"value": 21.927}, "meta_eval_prompt_tokens": {"value": 5616.0}, "meta_eval_completion_tokens": {"value": 2252.0}, "meta_eval_prompt_cost": {"value": 0.00179712}, "meta_eval_completion_cost": {"value": 0.00288256}}, "created": "2025-12-10T21:44:57.2241162Z"}
{"ref": "diachronic-rate", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 19.455684}, "meta_inference_prompt_tokens": {"value": 11837.0}, "meta_inference_completion_tokens": {"value": 699.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023674}, "meta_inference_completion_cost": {"value": 0.0011184}, "meta_eval_time": {"value": 18.815}, "meta_eval_prompt_tokens": {"value": 6517.0}, "meta_eval_completion_tokens": {"value": 1731.0}, "meta_eval_prompt_cost": {"value": 0.00208544}, "meta_eval_completion_cost": {"value": 0.00221568}}, "created": "2025-12-10T21:44:57.4636794Z"}
{"ref": "denim-click", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.98713694067948}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.726915}, "meta_inference_prompt_tokens": {"value": 10806.0}, "meta_inference_completion_tokens": {"value": 1397.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021612}, "meta_inference_completion_cost": {"value": 0.0022352}, "meta_eval_time": {"value": 31.734}, "meta_eval_prompt_tokens": {"value": 6138.0}, "meta_eval_completion_tokens": {"value": 2523.0}, "meta_eval_prompt_cost": {"value": 0.00196416}, "meta_eval_completion_cost": {"value": 0.00322944}}, "created": "2025-12-10T21:44:57.7819652Z"}
{"ref": "denim-click", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.98713694067948}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.928467}, "meta_inference_prompt_tokens": {"value": 10635.0}, "meta_inference_completion_tokens": {"value": 1570.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002127}, "meta_inference_completion_cost": {"value": 0.002512}, "meta_eval_time": {"value": 35.675}, "meta_eval_prompt_tokens": {"value": 6284.0}, "meta_eval_completion_tokens": {"value": 3179.0}, "meta_eval_prompt_cost": {"value": 0.00201088}, "meta_eval_completion_cost": {"value": 0.00406912}}, "created": "2025-12-10T21:44:58.8477676Z"}
{"ref": "dense-octree", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.744859}, "meta_inference_prompt_tokens": {"value": 8245.0}, "meta_inference_completion_tokens": {"value": 1515.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001649}, "meta_inference_completion_cost": {"value": 0.002424}, "meta_eval_time": {"value": 26.958}, "meta_eval_prompt_tokens": {"value": 5319.0}, "meta_eval_completion_tokens": {"value": 2110.0}, "meta_eval_prompt_cost": {"value": 0.00170208}, "meta_eval_completion_cost": {"value": 0.0027008}}, "created": "2025-12-10T21:45:01.5679999Z"}
{"ref": "dense-octree", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.818181818181818}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.166666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.187934}, "meta_inference_prompt_tokens": {"value": 10290.0}, "meta_inference_completion_tokens": {"value": 1367.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002058}, "meta_inference_completion_cost": {"value": 0.0021872}, "meta_eval_time": {"value": 32.299}, "meta_eval_prompt_tokens": {"value": 6692.0}, "meta_eval_completion_tokens": {"value": 2559.0}, "meta_eval_prompt_cost": {"value": 0.00214144}, "meta_eval_completion_cost": {"value": 0.00327552}}, "created": "2025-12-10T21:45:01.680653Z"}
{"ref": "dense-octree", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.142857142857143}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.517869}, "meta_inference_prompt_tokens": {"value": 10958.0}, "meta_inference_completion_tokens": {"value": 1166.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021916}, "meta_inference_completion_cost": {"value": 0.0018656}, "meta_eval_time": {"value": 31.617}, "meta_eval_prompt_tokens": {"value": 7064.0}, "meta_eval_completion_tokens": {"value": 3015.0}, "meta_eval_prompt_cost": {"value": 0.00226048}, "meta_eval_completion_cost": {"value": 0.0038592}}, "created": "2025-12-10T21:45:05.5694152Z"}
{"ref": "dichotomic-cliche", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 0.25}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.718188}, "meta_inference_prompt_tokens": {"value": 10765.0}, "meta_inference_completion_tokens": {"value": 1319.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002153}, "meta_inference_completion_cost": {"value": 0.0021104}, "meta_eval_time": {"value": 32.813}, "meta_eval_prompt_tokens": {"value": 6233.0}, "meta_eval_completion_tokens": {"value": 2601.0}, "meta_eval_prompt_cost": {"value": 0.00199456}, "meta_eval_completion_cost": {"value": 0.00332928}}, "created": "2025-12-10T21:45:12.2549523Z"}
{"ref": "distinct-bagging", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 30.806218}, "meta_inference_prompt_tokens": {"value": 11095.0}, "meta_inference_completion_tokens": {"value": 1819.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002219}, "meta_inference_completion_cost": {"value": 0.0029104}, "meta_eval_time": {"value": 29.682}, "meta_eval_prompt_tokens": {"value": 6945.0}, "meta_eval_completion_tokens": {"value": 2580.0}, "meta_eval_prompt_cost": {"value": 0.0022224}, "meta_eval_completion_cost": {"value": 0.0033024}}, "created": "2025-12-10T21:45:13.1362528Z"}
{"ref": "dichotomic-cliche", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 0.25}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.96875}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.118461}, "meta_inference_prompt_tokens": {"value": 11061.0}, "meta_inference_completion_tokens": {"value": 1324.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022122}, "meta_inference_completion_cost": {"value": 0.0021184}, "meta_eval_time": {"value": 31.135}, "meta_eval_prompt_tokens": {"value": 6858.0}, "meta_eval_completion_tokens": {"value": 3201.0}, "meta_eval_prompt_cost": {"value": 0.00219456}, "meta_eval_completion_cost": {"value": 0.00409728}}, "created": "2025-12-10T21:45:13.7041543Z"}
{"ref": "distinct-bagging", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.91304347826087}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 36.775217}, "meta_inference_prompt_tokens": {"value": 11732.0}, "meta_inference_completion_tokens": {"value": 2330.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023464}, "meta_inference_completion_cost": {"value": 0.003728}, "meta_eval_time": {"value": 28.246}, "meta_eval_prompt_tokens": {"value": 7481.0}, "meta_eval_completion_tokens": {"value": 2606.0}, "meta_eval_prompt_cost": {"value": 0.00239392}, "meta_eval_completion_cost": {"value": 0.00333568}}, "created": "2025-12-10T21:45:13.7650757Z"}
{"ref": "dichotomic-cliche", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 0.25}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.043439}, "meta_inference_prompt_tokens": {"value": 10829.0}, "meta_inference_completion_tokens": {"value": 1418.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021658}, "meta_inference_completion_cost": {"value": 0.0022688}, "meta_eval_time": {"value": 29.916}, "meta_eval_prompt_tokens": {"value": 6393.0}, "meta_eval_completion_tokens": {"value": 2588.0}, "meta_eval_prompt_cost": {"value": 0.00204576}, "meta_eval_completion_cost": {"value": 0.00331264}}, "created": "2025-12-10T21:45:14.0360753Z"}
{"ref": "distinct-bagging", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 39.66593}, "meta_inference_prompt_tokens": {"value": 14190.0}, "meta_inference_completion_tokens": {"value": 1618.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002838}, "meta_inference_completion_cost": {"value": 0.0025888}, "meta_eval_time": {"value": 31.318}, "meta_eval_prompt_tokens": {"value": 9479.0}, "meta_eval_completion_tokens": {"value": 2812.0}, "meta_eval_prompt_cost": {"value": 0.00303328}, "meta_eval_completion_cost": {"value": 0.00359936}}, "created": "2025-12-10T21:45:16.1330111Z"}
{"ref": "dichotomic-cliche", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.291666666666667}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 0.96969696969697}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.316148}, "meta_inference_prompt_tokens": {"value": 11394.0}, "meta_inference_completion_tokens": {"value": 1234.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022788}, "meta_inference_completion_cost": {"value": 0.0019744}, "meta_eval_time": {"value": 33.409}, "meta_eval_prompt_tokens": {"value": 7528.0}, "meta_eval_completion_tokens": {"value": 3291.0}, "meta_eval_prompt_cost": {"value": 0.00240896}, "meta_eval_completion_cost": {"value": 0.00421248}}, "created": "2025-12-10T21:45:16.4369218Z"}
{"ref": "district-mallet", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.955321}, "meta_inference_prompt_tokens": {"value": 10812.0}, "meta_inference_completion_tokens": {"value": 1101.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021624}, "meta_inference_completion_cost": {"value": 0.0017616}, "meta_eval_time": {"value": 33.297}, "meta_eval_prompt_tokens": {"value": 6643.0}, "meta_eval_completion_tokens": {"value": 2982.0}, "meta_eval_prompt_cost": {"value": 0.00212576}, "meta_eval_completion_cost": {"value": 0.00381696}}, "created": "2025-12-10T21:45:16.4853771Z"}
{"ref": "distinct-bagging", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.958333333333334}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 75.767892}, "meta_inference_prompt_tokens": {"value": 12758.0}, "meta_inference_completion_tokens": {"value": 1771.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025516}, "meta_inference_completion_cost": {"value": 0.0028336}, "meta_eval_time": {"value": 35.771}, "meta_eval_prompt_tokens": {"value": 8396.0}, "meta_eval_completion_tokens": {"value": 2977.0}, "meta_eval_prompt_cost": {"value": 0.00268672}, "meta_eval_completion_cost": {"value": 0.00381056}}, "created": "2025-12-10T21:45:16.8480217Z"}
{"ref": "dichotomic-cliche", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.291666666666667}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 0.977777777777778}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.471557}, "meta_inference_prompt_tokens": {"value": 11906.0}, "meta_inference_completion_tokens": {"value": 1469.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023812}, "meta_inference_completion_cost": {"value": 0.0023504}, "meta_eval_time": {"value": 36.165}, "meta_eval_prompt_tokens": {"value": 7901.0}, "meta_eval_completion_tokens": {"value": 3714.0}, "meta_eval_prompt_cost": {"value": 0.00252832}, "meta_eval_completion_cost": {"value": 0.00475392}}, "created": "2025-12-10T21:45:18.3418337Z"}
{"ref": "drab-ski", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.541666666666667}, "retrieval_dcg": {"value": 2.39493964497818}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.614462}, "meta_inference_prompt_tokens": {"value": 14263.0}, "meta_inference_completion_tokens": {"value": 1823.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028526}, "meta_inference_completion_cost": {"value": 0.0029168}, "meta_eval_time": {"value": 24.477}, "meta_eval_prompt_tokens": {"value": 9470.0}, "meta_eval_completion_tokens": {"value": 2406.0}, "meta_eval_prompt_cost": {"value": 0.0030304}, "meta_eval_completion_cost": {"value": 0.00307968}}, "created": "2025-12-10T21:45:19.542404Z"}
{"ref": "district-plan", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.78688374518142}, "generation_faithfulness": {"value": 0.958333333333334}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 53.126658}, "meta_inference_prompt_tokens": {"value": 10949.0}, "meta_inference_completion_tokens": {"value": 1302.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021898}, "meta_inference_completion_cost": {"value": 0.0020832}, "meta_eval_time": {"value": 29.748}, "meta_eval_prompt_tokens": {"value": 6616.0}, "meta_eval_completion_tokens": {"value": 2658.0}, "meta_eval_prompt_cost": {"value": 0.00211712}, "meta_eval_completion_cost": {"value": 0.00340224}}, "created": "2025-12-10T21:45:20.1671628Z"}
{"ref": "district-plan", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.88685280723454}, "generation_faithfulness": {"value": 0.935483870967742}, "generation_factuality_f1": {"value": 0.428571428571428}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 31.882599}, "meta_inference_prompt_tokens": {"value": 11517.0}, "meta_inference_completion_tokens": {"value": 1468.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023034}, "meta_inference_completion_cost": {"value": 0.0023488}, "meta_eval_time": {"value": 34.448}, "meta_eval_prompt_tokens": {"value": 7187.0}, "meta_eval_completion_tokens": {"value": 3428.0}, "meta_eval_prompt_cost": {"value": 0.00229984}, "meta_eval_completion_cost": {"value": 0.00438784}}, "created": "2025-12-10T21:45:20.5350466Z"}
{"ref": "ebony-screed", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.636363636363636}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.67968}, "meta_inference_prompt_tokens": {"value": 10709.0}, "meta_inference_completion_tokens": {"value": 672.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021418}, "meta_inference_completion_cost": {"value": 0.0010752}, "meta_eval_time": {"value": 15.377}, "meta_eval_prompt_tokens": {"value": 5356.0}, "meta_eval_completion_tokens": {"value": 1269.0}, "meta_eval_prompt_cost": {"value": 0.00171392}, "meta_eval_completion_cost": {"value": 0.00162432}}, "created": "2025-12-10T21:45:20.9862217Z"}
{"ref": "ebony-screed", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.492219}, "meta_inference_prompt_tokens": {"value": 10706.0}, "meta_inference_completion_tokens": {"value": 758.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021412}, "meta_inference_completion_cost": {"value": 0.0012128}, "meta_eval_time": {"value": 19.468}, "meta_eval_prompt_tokens": {"value": 5626.0}, "meta_eval_completion_tokens": {"value": 1742.0}, "meta_eval_prompt_cost": {"value": 0.00180032}, "meta_eval_completion_cost": {"value": 0.00222976}}, "created": "2025-12-10T21:45:21.0843094Z"}
{"ref": "district-plan", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.17167206389375}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.840948}, "meta_inference_prompt_tokens": {"value": 10754.0}, "meta_inference_completion_tokens": {"value": 1569.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021508}, "meta_inference_completion_cost": {"value": 0.0025104}, "meta_eval_time": {"value": 34.683}, "meta_eval_prompt_tokens": {"value": 6289.0}, "meta_eval_completion_tokens": {"value": 2894.0}, "meta_eval_prompt_cost": {"value": 0.00201248}, "meta_eval_completion_cost": {"value": 0.00370432}}, "created": "2025-12-10T21:45:23.8640332Z"}
{"ref": "district-plan", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.78688374518142}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.742706}, "meta_inference_prompt_tokens": {"value": 11136.0}, "meta_inference_completion_tokens": {"value": 1785.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022272}, "meta_inference_completion_cost": {"value": 0.002856}, "meta_eval_time": {"value": 32.075}, "meta_eval_prompt_tokens": {"value": 6793.0}, "meta_eval_completion_tokens": {"value": 2742.0}, "meta_eval_prompt_cost": {"value": 0.00217376}, "meta_eval_completion_cost": {"value": 0.00350976}}, "created": "2025-12-10T21:45:24.1094185Z"}
{"ref": "district-plan", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.72018614056788}, "generation_faithfulness": {"value": 0.925925925925926}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 32.195346}, "meta_inference_prompt_tokens": {"value": 11561.0}, "meta_inference_completion_tokens": {"value": 1826.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023122}, "meta_inference_completion_cost": {"value": 0.0029216}, "meta_eval_time": {"value": 36.345}, "meta_eval_prompt_tokens": {"value": 7169.0}, "meta_eval_completion_tokens": {"value": 3223.0}, "meta_eval_prompt_cost": {"value": 0.00229408}, "meta_eval_completion_cost": {"value": 0.00412544}}, "created": "2025-12-10T21:45:24.4409495Z"}
{"ref": "ebony-median", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.390119}, "meta_inference_prompt_tokens": {"value": 9867.0}, "meta_inference_completion_tokens": {"value": 775.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019734}, "meta_inference_completion_cost": {"value": 0.00124}, "meta_eval_time": {"value": 28.13}, "meta_eval_prompt_tokens": {"value": 4962.0}, "meta_eval_completion_tokens": {"value": 1970.0}, "meta_eval_prompt_cost": {"value": 0.00158784}, "meta_eval_completion_cost": {"value": 0.0025216}}, "created": "2025-12-10T21:45:24.5120875Z"}
{"ref": "ebony-median", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.596009}, "meta_inference_prompt_tokens": {"value": 9870.0}, "meta_inference_completion_tokens": {"value": 770.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001974}, "meta_inference_completion_cost": {"value": 0.001232}, "meta_eval_time": {"value": 27.488}, "meta_eval_prompt_tokens": {"value": 4925.0}, "meta_eval_completion_tokens": {"value": 1978.0}, "meta_eval_prompt_cost": {"value": 0.001576}, "meta_eval_completion_cost": {"value": 0.00253184}}, "created": "2025-12-10T21:45:24.746986Z"}
{"ref": "drab-ski", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.541666666666667}, "retrieval_dcg": {"value": 2.37707118843058}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.210526315789474}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 32.396127}, "meta_inference_prompt_tokens": {"value": 13176.0}, "meta_inference_completion_tokens": {"value": 2057.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026352}, "meta_inference_completion_cost": {"value": 0.0032912}, "meta_eval_time": {"value": 33.433}, "meta_eval_prompt_tokens": {"value": 9045.0}, "meta_eval_completion_tokens": {"value": 3029.0}, "meta_eval_prompt_cost": {"value": 0.0028944}, "meta_eval_completion_cost": {"value": 0.00387712}}, "created": "2025-12-10T21:45:25.3759199Z"}
{"ref": "district-mallet", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.579710144927536}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 24.189539}, "meta_inference_prompt_tokens": {"value": 11158.0}, "meta_inference_completion_tokens": {"value": 1181.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022316}, "meta_inference_completion_cost": {"value": 0.0018896}, "meta_eval_time": {"value": 37.324}, "meta_eval_prompt_tokens": {"value": 7160.0}, "meta_eval_completion_tokens": {"value": 3320.0}, "meta_eval_prompt_cost": {"value": 0.0022912}, "meta_eval_completion_cost": {"value": 0.0042496}}, "created": "2025-12-10T21:45:25.4627249Z"}
{"ref": "ebony-median", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.355967}, "meta_inference_prompt_tokens": {"value": 11486.0}, "meta_inference_completion_tokens": {"value": 765.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022972}, "meta_inference_completion_cost": {"value": 0.001224}, "meta_eval_time": {"value": 28.275}, "meta_eval_prompt_tokens": {"value": 6815.0}, "meta_eval_completion_tokens": {"value": 2870.0}, "meta_eval_prompt_cost": {"value": 0.0021808}, "meta_eval_completion_cost": {"value": 0.0036736}}, "created": "2025-12-10T21:45:26.0926074Z"}
{"ref": "drab-ski", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.541666666666667}, "retrieval_dcg": {"value": 2.517782560806}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.684816}, "meta_inference_prompt_tokens": {"value": 13677.0}, "meta_inference_completion_tokens": {"value": 1864.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027354}, "meta_inference_completion_cost": {"value": 0.0029824}, "meta_eval_time": {"value": 33.072}, "meta_eval_prompt_tokens": {"value": 9065.0}, "meta_eval_completion_tokens": {"value": 3113.0}, "meta_eval_prompt_cost": {"value": 0.0029008}, "meta_eval_completion_cost": {"value": 0.00398464}}, "created": "2025-12-10T21:45:26.0970594Z"}
{"ref": "drab-ski", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.541666666666667}, "retrieval_dcg": {"value": 2.41781349875287}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.11597}, "meta_inference_prompt_tokens": {"value": 14317.0}, "meta_inference_completion_tokens": {"value": 1792.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028634}, "meta_inference_completion_cost": {"value": 0.0028672}, "meta_eval_time": {"value": 35.465}, "meta_eval_prompt_tokens": {"value": 9383.0}, "meta_eval_completion_tokens": {"value": 2476.0}, "meta_eval_prompt_cost": {"value": 0.00300256}, "meta_eval_completion_cost": {"value": 0.00316928}}, "created": "2025-12-10T21:45:26.3145788Z"}
{"ref": "distinct-bagging", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 31.790192}, "meta_inference_prompt_tokens": {"value": 12881.0}, "meta_inference_completion_tokens": {"value": 2011.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025762}, "meta_inference_completion_cost": {"value": 0.0032176}, "meta_eval_time": {"value": 44.158}, "meta_eval_prompt_tokens": {"value": 8944.0}, "meta_eval_completion_tokens": {"value": 3902.0}, "meta_eval_prompt_cost": {"value": 0.00286208}, "meta_eval_completion_cost": {"value": 0.00499456}}, "created": "2025-12-10T21:45:28.2774518Z"}
{"ref": "dynamic-influencer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.48713694067948}, "generation_faithfulness": {"value": 0.948717948717949}, "generation_factuality_f1": {"value": 0.193548387096774}, "generation_factuality_precision": {"value": 0.111111111111111}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 24.113013}, "meta_inference_prompt_tokens": {"value": 12585.0}, "meta_inference_completion_tokens": {"value": 1504.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002517}, "meta_inference_completion_cost": {"value": 0.0024064}, "meta_eval_time": {"value": 35.069}, "meta_eval_prompt_tokens": {"value": 8473.0}, "meta_eval_completion_tokens": {"value": 3728.0}, "meta_eval_prompt_cost": {"value": 0.00271136}, "meta_eval_completion_cost": {"value": 0.00477184}}, "created": "2025-12-10T21:45:29.678162Z"}
{"ref": "easy-dolce", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.28906482631789}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.585365853658536}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.571428571428571}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.571428571428571}, "meta_inference_time": {"value": 26.784175}, "meta_inference_prompt_tokens": {"value": 13252.0}, "meta_inference_completion_tokens": {"value": 1117.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026504}, "meta_inference_completion_cost": {"value": 0.0017872}, "meta_eval_time": {"value": 35.214}, "meta_eval_prompt_tokens": {"value": 8518.0}, "meta_eval_completion_tokens": {"value": 2857.0}, "meta_eval_prompt_cost": {"value": 0.00272576}, "meta_eval_completion_cost": {"value": 0.00365696}}, "created": "2025-12-10T21:45:30.3183331Z"}
{"ref": "dynamic-influencer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.85620718710802}, "generation_faithfulness": {"value": 0.942857142857143}, "generation_factuality_f1": {"value": 0.222222222222222}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 26.526857}, "meta_inference_prompt_tokens": {"value": 11990.0}, "meta_inference_completion_tokens": {"value": 1368.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002398}, "meta_inference_completion_cost": {"value": 0.0021888}, "meta_eval_time": {"value": 39.145}, "meta_eval_prompt_tokens": {"value": 7954.0}, "meta_eval_completion_tokens": {"value": 3443.0}, "meta_eval_prompt_cost": {"value": 0.00254528}, "meta_eval_completion_cost": {"value": 0.00440704}}, "created": "2025-12-10T21:45:31.6059105Z"}
{"ref": "district-mallet", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.494012}, "meta_inference_prompt_tokens": {"value": 11135.0}, "meta_inference_completion_tokens": {"value": 1268.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002227}, "meta_inference_completion_cost": {"value": 0.0020288}, "meta_eval_time": {"value": 45.471}, "meta_eval_prompt_tokens": {"value": 6798.0}, "meta_eval_completion_tokens": {"value": 2848.0}, "meta_eval_prompt_cost": {"value": 0.00217536}, "meta_eval_completion_cost": {"value": 0.00364544}}, "created": "2025-12-10T21:45:31.9246666Z"}
{"ref": "ebony-screed", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.2867}, "meta_inference_prompt_tokens": {"value": 10710.0}, "meta_inference_completion_tokens": {"value": 1030.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002142}, "meta_inference_completion_cost": {"value": 0.001648}, "meta_eval_time": {"value": 18.829}, "meta_eval_prompt_tokens": {"value": 5733.0}, "meta_eval_completion_tokens": {"value": 1875.0}, "meta_eval_prompt_cost": {"value": 0.00183456}, "meta_eval_completion_cost": {"value": 0.0024}}, "created": "2025-12-10T21:45:32.0013502Z"}
{"ref": "easy-dolce", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.931034482758621}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 30.45378}, "meta_inference_prompt_tokens": {"value": 13191.0}, "meta_inference_completion_tokens": {"value": 1187.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026382}, "meta_inference_completion_cost": {"value": 0.0018992}, "meta_eval_time": {"value": 33.443}, "meta_eval_prompt_tokens": {"value": 8727.0}, "meta_eval_completion_tokens": {"value": 3341.0}, "meta_eval_prompt_cost": {"value": 0.00279264}, "meta_eval_completion_cost": {"value": 0.00427648}}, "created": "2025-12-10T21:45:32.3292687Z"}
{"ref": "easy-dolce", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 24.624655}, "meta_inference_prompt_tokens": {"value": 12178.0}, "meta_inference_completion_tokens": {"value": 1421.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024356}, "meta_inference_completion_cost": {"value": 0.0022736}, "meta_eval_time": {"value": 37.091}, "meta_eval_prompt_tokens": {"value": 7918.0}, "meta_eval_completion_tokens": {"value": 2994.0}, "meta_eval_prompt_cost": {"value": 0.00253376}, "meta_eval_completion_cost": {"value": 0.00383232}}, "created": "2025-12-10T21:45:33.1886711Z"}
{"ref": "dynamic-influencer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.22018614056787}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.127659574468085}, "generation_factuality_precision": {"value": 0.0714285714285714}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 26.171244}, "meta_inference_prompt_tokens": {"value": 12559.0}, "meta_inference_completion_tokens": {"value": 1373.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025118}, "meta_inference_completion_cost": {"value": 0.0021968}, "meta_eval_time": {"value": 41.053}, "meta_eval_prompt_tokens": {"value": 8467.0}, "meta_eval_completion_tokens": {"value": 3685.0}, "meta_eval_prompt_cost": {"value": 0.00270944}, "meta_eval_completion_cost": {"value": 0.0047168}}, "created": "2025-12-10T21:45:33.188947Z"}
{"ref": "drab-ski", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.541666666666667}, "retrieval_dcg": {"value": 2.56160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.2}, "generation_factuality_precision": {"value": 0.111111111111111}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.955103}, "meta_inference_prompt_tokens": {"value": 13855.0}, "meta_inference_completion_tokens": {"value": 2208.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002771}, "meta_inference_completion_cost": {"value": 0.0035328}, "meta_eval_time": {"value": 43.216}, "meta_eval_prompt_tokens": {"value": 9445.0}, "meta_eval_completion_tokens": {"value": 3507.0}, "meta_eval_prompt_cost": {"value": 0.0030224}, "meta_eval_completion_cost": {"value": 0.00448896}}, "created": "2025-12-10T21:45:34.1129608Z"}
{"ref": "ebony-screed", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.282301}, "meta_inference_prompt_tokens": {"value": 10177.0}, "meta_inference_completion_tokens": {"value": 781.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020354}, "meta_inference_completion_cost": {"value": 0.0012496}, "meta_eval_time": {"value": 13.927}, "meta_eval_prompt_tokens": {"value": 4965.0}, "meta_eval_completion_tokens": {"value": 1324.0}, "meta_eval_prompt_cost": {"value": 0.0015888}, "meta_eval_completion_cost": {"value": 0.00169472}}, "created": "2025-12-10T21:45:34.1321469Z"}
{"ref": "district-mallet", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.540540540540541}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 21.238809}, "meta_inference_prompt_tokens": {"value": 11223.0}, "meta_inference_completion_tokens": {"value": 1067.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022446}, "meta_inference_completion_cost": {"value": 0.0017072}, "meta_eval_time": {"value": 49.269}, "meta_eval_prompt_tokens": {"value": 7370.0}, "meta_eval_completion_tokens": {"value": 3838.0}, "meta_eval_prompt_cost": {"value": 0.0023584}, "meta_eval_completion_cost": {"value": 0.00491264}}, "created": "2025-12-10T21:45:35.7849339Z"}
{"ref": "easy-dolce", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.382295}, "meta_inference_prompt_tokens": {"value": 14389.0}, "meta_inference_completion_tokens": {"value": 1029.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028778}, "meta_inference_completion_cost": {"value": 0.0016464}, "meta_eval_time": {"value": 35.095}, "meta_eval_prompt_tokens": {"value": 9817.0}, "meta_eval_completion_tokens": {"value": 3094.0}, "meta_eval_prompt_cost": {"value": 0.00314144}, "meta_eval_completion_cost": {"value": 0.00396032}}, "created": "2025-12-10T21:45:36.8188042Z"}
{"ref": "ebony-median", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.833333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.48084}, "meta_inference_prompt_tokens": {"value": 11138.0}, "meta_inference_completion_tokens": {"value": 1191.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022276}, "meta_inference_completion_cost": {"value": 0.0019056}, "meta_eval_time": {"value": 25.187}, "meta_eval_prompt_tokens": {"value": 6232.0}, "meta_eval_completion_tokens": {"value": 2187.0}, "meta_eval_prompt_cost": {"value": 0.00199424}, "meta_eval_completion_cost": {"value": 0.00279936}}, "created": "2025-12-10T21:45:37.4820178Z"}
{"ref": "easy-dolce", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.882352941176471}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 28.71458}, "meta_inference_prompt_tokens": {"value": 13078.0}, "meta_inference_completion_tokens": {"value": 1594.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026156}, "meta_inference_completion_cost": {"value": 0.0025504}, "meta_eval_time": {"value": 41.148}, "meta_eval_prompt_tokens": {"value": 8688.0}, "meta_eval_completion_tokens": {"value": 3435.0}, "meta_eval_prompt_cost": {"value": 0.00278016}, "meta_eval_completion_cost": {"value": 0.0043968}}, "created": "2025-12-10T21:45:38.6480534Z"}
{"ref": "ebony-median", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.652025}, "meta_inference_prompt_tokens": {"value": 9874.0}, "meta_inference_completion_tokens": {"value": 735.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019748}, "meta_inference_completion_cost": {"value": 0.001176}, "meta_eval_time": {"value": 22.447}, "meta_eval_prompt_tokens": {"value": 4800.0}, "meta_eval_completion_tokens": {"value": 1652.0}, "meta_eval_prompt_cost": {"value": 0.001536}, "meta_eval_completion_cost": {"value": 0.00211456}}, "created": "2025-12-10T21:45:38.966342Z"}
{"ref": "excited-dark", "set": "20251210152915", "metrics": {"generation_should_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 17.4709}, "meta_inference_prompt_tokens": {"value": 4784.0}, "meta_inference_completion_tokens": {"value": 495.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009568}, "meta_inference_completion_cost": {"value": 0.000792}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:45:39.0063443Z"}
{"ref": "excited-dark", "set": "20251210152915", "metrics": {"generation_should_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 16.983859}, "meta_inference_prompt_tokens": {"value": 4791.0}, "meta_inference_completion_tokens": {"value": 777.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009582}, "meta_inference_completion_cost": {"value": 0.0012432}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:45:39.0413188Z"}
{"ref": "excited-dark", "set": "20251210152915", "metrics": {"generation_should_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 26.265255}, "meta_inference_prompt_tokens": {"value": 4796.0}, "meta_inference_completion_tokens": {"value": 849.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009592}, "meta_inference_completion_cost": {"value": 0.0013584}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:45:39.0751381Z"}
{"ref": "dynamic-influencer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.689540520441356}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.230769230769231}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 22.135372}, "meta_inference_prompt_tokens": {"value": 11839.0}, "meta_inference_completion_tokens": {"value": 1344.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023678}, "meta_inference_completion_cost": {"value": 0.0021504}, "meta_eval_time": {"value": 49.18}, "meta_eval_prompt_tokens": {"value": 7483.0}, "meta_eval_completion_tokens": {"value": 4536.0}, "meta_eval_prompt_cost": {"value": 0.00239456}, "meta_eval_completion_cost": {"value": 0.00580608}}, "created": "2025-12-10T21:45:40.8663021Z"}
{"ref": "edible-survey", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 1.93067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.566881}, "meta_inference_prompt_tokens": {"value": 10874.0}, "meta_inference_completion_tokens": {"value": 1405.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021748}, "meta_inference_completion_cost": {"value": 0.002248}, "meta_eval_time": {"value": 27.243}, "meta_eval_prompt_tokens": {"value": 6360.0}, "meta_eval_completion_tokens": {"value": 2579.0}, "meta_eval_prompt_cost": {"value": 0.0020352}, "meta_eval_completion_cost": {"value": 0.00330112}}, "created": "2025-12-10T21:45:41.0436424Z"}
{"ref": "dynamic-influencer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.946394630357186}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 28.585642}, "meta_inference_prompt_tokens": {"value": 12168.0}, "meta_inference_completion_tokens": {"value": 1572.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024336}, "meta_inference_completion_cost": {"value": 0.0025152}, "meta_eval_time": {"value": 46.198}, "meta_eval_prompt_tokens": {"value": 8687.0}, "meta_eval_completion_tokens": {"value": 4258.0}, "meta_eval_prompt_cost": {"value": 0.00277984}, "meta_eval_completion_cost": {"value": 0.00545024}}, "created": "2025-12-10T21:45:41.8482331Z"}
{"ref": "excited-dark", "set": "20251210152915", "metrics": {"generation_should_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 19.514711}, "meta_inference_prompt_tokens": {"value": 4793.0}, "meta_inference_completion_tokens": {"value": 887.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009586}, "meta_inference_completion_cost": {"value": 0.0014192}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:45:41.8683782Z"}
{"ref": "excited-dark", "set": "20251210152915", "metrics": {"generation_should_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 14.511244}, "meta_inference_prompt_tokens": {"value": 4797.0}, "meta_inference_completion_tokens": {"value": 340.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009594}, "meta_inference_completion_cost": {"value": 0.000544}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:45:41.8856818Z"}
{"ref": "ebony-screed", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.777777777777778}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.212903}, "meta_inference_prompt_tokens": {"value": 10173.0}, "meta_inference_completion_tokens": {"value": 646.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020346}, "meta_inference_completion_cost": {"value": 0.0010336}, "meta_eval_time": {"value": 22.471}, "meta_eval_prompt_tokens": {"value": 5060.0}, "meta_eval_completion_tokens": {"value": 1823.0}, "meta_eval_prompt_cost": {"value": 0.0016192}, "meta_eval_completion_cost": {"value": 0.00233344}}, "created": "2025-12-10T21:45:42.0477052Z"}
{"ref": "every-force", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.846153846153846}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.985407}, "meta_inference_prompt_tokens": {"value": 11592.0}, "meta_inference_completion_tokens": {"value": 1159.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023184}, "meta_inference_completion_cost": {"value": 0.0018544}, "meta_eval_time": {"value": 17.59}, "meta_eval_prompt_tokens": {"value": 6490.0}, "meta_eval_completion_tokens": {"value": 1667.0}, "meta_eval_prompt_cost": {"value": 0.0020768}, "meta_eval_completion_cost": {"value": 0.00213376}}, "created": "2025-12-10T21:45:43.9823833Z"}
{"ref": "edible-neutron-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.786883745181415}, "generation_faithfulness": {"value": 0.974358974358974}, "generation_factuality_f1": {"value": 0.88}, "generation_factuality_precision": {"value": 0.785714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.966624}, "meta_inference_prompt_tokens": {"value": 15120.0}, "meta_inference_completion_tokens": {"value": 1134.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003024}, "meta_inference_completion_cost": {"value": 0.0018144}, "meta_eval_time": {"value": 30.329}, "meta_eval_prompt_tokens": {"value": 10295.0}, "meta_eval_completion_tokens": {"value": 3091.0}, "meta_eval_prompt_cost": {"value": 0.0032944}, "meta_eval_completion_cost": {"value": 0.00395648}}, "created": "2025-12-10T21:45:44.4038351Z"}
{"ref": "district-mallet", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.58374}, "meta_inference_prompt_tokens": {"value": 11277.0}, "meta_inference_completion_tokens": {"value": 1629.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022554}, "meta_inference_completion_cost": {"value": 0.0026064}, "meta_eval_time": {"value": 59.291}, "meta_eval_prompt_tokens": {"value": 8314.0}, "meta_eval_completion_tokens": {"value": 5207.0}, "meta_eval_prompt_cost": {"value": 0.00266048}, "meta_eval_completion_cost": {"value": 0.00666496}}, "created": "2025-12-10T21:45:44.9018023Z"}
{"ref": "edible-neutron-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.786883745181415}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.916666666666666}, "generation_factuality_precision": {"value": 0.846153846153846}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.539601}, "meta_inference_prompt_tokens": {"value": 15119.0}, "meta_inference_completion_tokens": {"value": 751.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030238}, "meta_inference_completion_cost": {"value": 0.0012016}, "meta_eval_time": {"value": 31.173}, "meta_eval_prompt_tokens": {"value": 10291.0}, "meta_eval_completion_tokens": {"value": 3165.0}, "meta_eval_prompt_cost": {"value": 0.00329312}, "meta_eval_completion_cost": {"value": 0.0040512}}, "created": "2025-12-10T21:45:44.9122982Z"}
{"ref": "exact-rent", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.93067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.112247}, "meta_inference_prompt_tokens": {"value": 15579.0}, "meta_inference_completion_tokens": {"value": 484.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031158}, "meta_inference_completion_cost": {"value": 0.0007744}, "meta_eval_time": {"value": 11.814}, "meta_eval_prompt_tokens": {"value": 9698.0}, "meta_eval_completion_tokens": {"value": 1040.0}, "meta_eval_prompt_cost": {"value": 0.00310336}, "meta_eval_completion_cost": {"value": 0.0013312}}, "created": "2025-12-10T21:45:45.052643Z"}
{"ref": "edible-neutron-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.786883745181415}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.510069}, "meta_inference_prompt_tokens": {"value": 15123.0}, "meta_inference_completion_tokens": {"value": 897.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030246}, "meta_inference_completion_cost": {"value": 0.0014352}, "meta_eval_time": {"value": 24.61}, "meta_eval_prompt_tokens": {"value": 10014.0}, "meta_eval_completion_tokens": {"value": 2202.0}, "meta_eval_prompt_cost": {"value": 0.00320448}, "meta_eval_completion_cost": {"value": 0.00281856}}, "created": "2025-12-10T21:45:45.1816686Z"}
{"ref": "exact-rent", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.387192}, "meta_inference_prompt_tokens": {"value": 17554.0}, "meta_inference_completion_tokens": {"value": 762.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0035108}, "meta_inference_completion_cost": {"value": 0.0012192}, "meta_eval_time": {"value": 12.632}, "meta_eval_prompt_tokens": {"value": 11687.0}, "meta_eval_completion_tokens": {"value": 1111.0}, "meta_eval_prompt_cost": {"value": 0.00373984}, "meta_eval_completion_cost": {"value": 0.00142208}}, "created": "2025-12-10T21:45:45.8460517Z"}
{"ref": "edible-survey", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 1.44845911887939}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.813582}, "meta_inference_prompt_tokens": {"value": 10328.0}, "meta_inference_completion_tokens": {"value": 1283.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020656}, "meta_inference_completion_cost": {"value": 0.0020528}, "meta_eval_time": {"value": 27.682}, "meta_eval_prompt_tokens": {"value": 6138.0}, "meta_eval_completion_tokens": {"value": 2978.0}, "meta_eval_prompt_cost": {"value": 0.00196416}, "meta_eval_completion_cost": {"value": 0.00381184}}, "created": "2025-12-10T21:45:46.0607772Z"}
{"ref": "edible-survey", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.111996}, "meta_inference_prompt_tokens": {"value": 13202.0}, "meta_inference_completion_tokens": {"value": 912.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026404}, "meta_inference_completion_cost": {"value": 0.0014592}, "meta_eval_time": {"value": 25.448}, "meta_eval_prompt_tokens": {"value": 7997.0}, "meta_eval_completion_tokens": {"value": 2396.0}, "meta_eval_prompt_cost": {"value": 0.00255904}, "meta_eval_completion_cost": {"value": 0.00306688}}, "created": "2025-12-10T21:45:46.4917307Z"}
{"ref": "edible-survey", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.02472}, "meta_inference_prompt_tokens": {"value": 12032.0}, "meta_inference_completion_tokens": {"value": 1100.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024064}, "meta_inference_completion_cost": {"value": 0.00176}, "meta_eval_time": {"value": 30.113}, "meta_eval_prompt_tokens": {"value": 7624.0}, "meta_eval_completion_tokens": {"value": 2969.0}, "meta_eval_prompt_cost": {"value": 0.00243968}, "meta_eval_completion_cost": {"value": 0.00380032}}, "created": "2025-12-10T21:45:46.6091136Z"}
{"ref": "edible-neutron-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.786883745181415}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.846153846153846}, "generation_factuality_precision": {"value": 0.733333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.304606}, "meta_inference_prompt_tokens": {"value": 15125.0}, "meta_inference_completion_tokens": {"value": 1142.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003025}, "meta_inference_completion_cost": {"value": 0.0018272}, "meta_eval_time": {"value": 30.484}, "meta_eval_prompt_tokens": {"value": 10028.0}, "meta_eval_completion_tokens": {"value": 2931.0}, "meta_eval_prompt_cost": {"value": 0.00320896}, "meta_eval_completion_cost": {"value": 0.00375168}}, "created": "2025-12-10T21:45:46.6831743Z"}
{"ref": "every-force", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.073625}, "meta_inference_prompt_tokens": {"value": 11204.0}, "meta_inference_completion_tokens": {"value": 1272.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022408}, "meta_inference_completion_cost": {"value": 0.0020352}, "meta_eval_time": {"value": 18.447}, "meta_eval_prompt_tokens": {"value": 6230.0}, "meta_eval_completion_tokens": {"value": 1639.0}, "meta_eval_prompt_cost": {"value": 0.0019936}, "meta_eval_completion_cost": {"value": 0.00209792}}, "created": "2025-12-10T21:45:46.773952Z"}
{"ref": "exact-rent", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.589523}, "meta_inference_prompt_tokens": {"value": 15855.0}, "meta_inference_completion_tokens": {"value": 738.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003171}, "meta_inference_completion_cost": {"value": 0.0011808}, "meta_eval_time": {"value": 11.211}, "meta_eval_prompt_tokens": {"value": 9757.0}, "meta_eval_completion_tokens": {"value": 1045.0}, "meta_eval_prompt_cost": {"value": 0.00312224}, "meta_eval_completion_cost": {"value": 0.0013376}}, "created": "2025-12-10T21:45:47.0357199Z"}
{"ref": "feldspar-engineer", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.902657}, "meta_inference_prompt_tokens": {"value": 2249.0}, "meta_inference_completion_tokens": {"value": 572.0}, "meta_inference_prompt_cost": {"value": 0.0004498}, "meta_inference_completion_cost": {"value": 0.0009152}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:45:47.0746625Z"}
{"ref": "exact-rent", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.241554}, "meta_inference_prompt_tokens": {"value": 13816.0}, "meta_inference_completion_tokens": {"value": 922.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027632}, "meta_inference_completion_cost": {"value": 0.0014752}, "meta_eval_time": {"value": 10.514}, "meta_eval_prompt_tokens": {"value": 8321.0}, "meta_eval_completion_tokens": {"value": 1011.0}, "meta_eval_prompt_cost": {"value": 0.00266272}, "meta_eval_completion_cost": {"value": 0.00129408}}, "created": "2025-12-10T21:45:47.3671521Z"}
{"ref": "exact-rent", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.77492}, "meta_inference_prompt_tokens": {"value": 15857.0}, "meta_inference_completion_tokens": {"value": 452.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031714}, "meta_inference_completion_cost": {"value": 0.0007232}, "meta_eval_time": {"value": 9.964}, "meta_eval_prompt_tokens": {"value": 9929.0}, "meta_eval_completion_tokens": {"value": 822.0}, "meta_eval_prompt_cost": {"value": 0.00317728}, "meta_eval_completion_cost": {"value": 0.00105216}}, "created": "2025-12-10T21:45:47.4819981Z"}
{"ref": "electrical-tensor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.964285714285714}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.410745}, "meta_inference_prompt_tokens": {"value": 11378.0}, "meta_inference_completion_tokens": {"value": 1038.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022756}, "meta_inference_completion_cost": {"value": 0.0016608}, "meta_eval_time": {"value": 23.983}, "meta_eval_prompt_tokens": {"value": 6982.0}, "meta_eval_completion_tokens": {"value": 2551.0}, "meta_eval_prompt_cost": {"value": 0.00223424}, "meta_eval_completion_cost": {"value": 0.00326528}}, "created": "2025-12-10T21:45:47.884735Z"}
{"ref": "electrical-tensor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.973506}, "meta_inference_prompt_tokens": {"value": 11382.0}, "meta_inference_completion_tokens": {"value": 1028.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022764}, "meta_inference_completion_cost": {"value": 0.0016448}, "meta_eval_time": {"value": 28.519}, "meta_eval_prompt_tokens": {"value": 7014.0}, "meta_eval_completion_tokens": {"value": 2950.0}, "meta_eval_prompt_cost": {"value": 0.00224448}, "meta_eval_completion_cost": {"value": 0.003776}}, "created": "2025-12-10T21:45:49.6397521Z"}
{"ref": "feldspar-engineer", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.502068}, "meta_inference_prompt_tokens": {"value": 2249.0}, "meta_inference_completion_tokens": {"value": 584.0}, "meta_inference_prompt_cost": {"value": 0.0004498}, "meta_inference_completion_cost": {"value": 0.0009344}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:45:49.6987002Z"}
{"ref": "edible-neutron-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.786883745181415}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.143046}, "meta_inference_prompt_tokens": {"value": 15121.0}, "meta_inference_completion_tokens": {"value": 732.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030242}, "meta_inference_completion_cost": {"value": 0.0011712}, "meta_eval_time": {"value": 33.045}, "meta_eval_prompt_tokens": {"value": 10169.0}, "meta_eval_completion_tokens": {"value": 3064.0}, "meta_eval_prompt_cost": {"value": 0.00325408}, "meta_eval_completion_cost": {"value": 0.00392192}}, "created": "2025-12-10T21:45:49.9494194Z"}
{"ref": "energetic-procedure-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.065515}, "meta_inference_prompt_tokens": {"value": 11704.0}, "meta_inference_completion_tokens": {"value": 1411.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023408}, "meta_inference_completion_cost": {"value": 0.0022576}, "meta_eval_time": {"value": 25.592}, "meta_eval_prompt_tokens": {"value": 7446.0}, "meta_eval_completion_tokens": {"value": 2503.0}, "meta_eval_prompt_cost": {"value": 0.00238272}, "meta_eval_completion_cost": {"value": 0.00320384}}, "created": "2025-12-10T21:45:51.0033653Z"}
{"ref": "energetic-procedure-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.43895}, "meta_inference_prompt_tokens": {"value": 11701.0}, "meta_inference_completion_tokens": {"value": 1405.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023402}, "meta_inference_completion_cost": {"value": 0.002248}, "meta_eval_time": {"value": 26.207}, "meta_eval_prompt_tokens": {"value": 7634.0}, "meta_eval_completion_tokens": {"value": 2549.0}, "meta_eval_prompt_cost": {"value": 0.00244288}, "meta_eval_completion_cost": {"value": 0.00326272}}, "created": "2025-12-10T21:45:51.0063086Z"}
{"ref": "feldspar-engineer", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.347526}, "meta_inference_prompt_tokens": {"value": 2249.0}, "meta_inference_completion_tokens": {"value": 584.0}, "meta_inference_prompt_cost": {"value": 0.0004498}, "meta_inference_completion_cost": {"value": 0.0009344}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:45:51.0465753Z"}
{"ref": "feldspar-engineer", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 8.299551}, "meta_inference_prompt_tokens": {"value": 2249.0}, "meta_inference_completion_tokens": {"value": 317.0}, "meta_inference_prompt_cost": {"value": 0.0004498}, "meta_inference_completion_cost": {"value": 0.0005072}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:45:51.0813755Z"}
{"ref": "feldspar-engineer", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 7.960725}, "meta_inference_prompt_tokens": {"value": 2249.0}, "meta_inference_completion_tokens": {"value": 275.0}, "meta_inference_prompt_cost": {"value": 0.0004498}, "meta_inference_completion_cost": {"value": 0.00044}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:45:51.1201185Z"}
{"ref": "every-force", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.049116}, "meta_inference_prompt_tokens": {"value": 11199.0}, "meta_inference_completion_tokens": {"value": 1187.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022398}, "meta_inference_completion_cost": {"value": 0.0018992}, "meta_eval_time": {"value": 18.328}, "meta_eval_prompt_tokens": {"value": 6290.0}, "meta_eval_completion_tokens": {"value": 1845.0}, "meta_eval_prompt_cost": {"value": 0.0020128}, "meta_eval_completion_cost": {"value": 0.0023616}}, "created": "2025-12-10T21:45:53.1407122Z"}
{"ref": "energetic-procedure-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 0.967741935483871}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.812536}, "meta_inference_prompt_tokens": {"value": 11703.0}, "meta_inference_completion_tokens": {"value": 1445.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023406}, "meta_inference_completion_cost": {"value": 0.002312}, "meta_eval_time": {"value": 29.082}, "meta_eval_prompt_tokens": {"value": 7445.0}, "meta_eval_completion_tokens": {"value": 2878.0}, "meta_eval_prompt_cost": {"value": 0.0023824}, "meta_eval_completion_cost": {"value": 0.00368384}}, "created": "2025-12-10T21:45:53.6293467Z"}
{"ref": "electrical-tensor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.094443}, "meta_inference_prompt_tokens": {"value": 11385.0}, "meta_inference_completion_tokens": {"value": 1099.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002277}, "meta_inference_completion_cost": {"value": 0.0017584}, "meta_eval_time": {"value": 28.715}, "meta_eval_prompt_tokens": {"value": 7205.0}, "meta_eval_completion_tokens": {"value": 2783.0}, "meta_eval_prompt_cost": {"value": 0.0023056}, "meta_eval_completion_cost": {"value": 0.00356224}}, "created": "2025-12-10T21:45:54.2130798Z"}
{"ref": "every-force", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.95}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.918615}, "meta_inference_prompt_tokens": {"value": 10083.0}, "meta_inference_completion_tokens": {"value": 1556.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020166}, "meta_inference_completion_cost": {"value": 0.0024896}, "meta_eval_time": {"value": 23.995}, "meta_eval_prompt_tokens": {"value": 5257.0}, "meta_eval_completion_tokens": {"value": 2042.0}, "meta_eval_prompt_cost": {"value": 0.00168224}, "meta_eval_completion_cost": {"value": 0.00261376}}, "created": "2025-12-10T21:45:54.3533122Z"}
{"ref": "electrical-tensor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.964285714285714}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.952633}, "meta_inference_prompt_tokens": {"value": 12253.0}, "meta_inference_completion_tokens": {"value": 1251.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024506}, "meta_inference_completion_cost": {"value": 0.0020016}, "meta_eval_time": {"value": 31.696}, "meta_eval_prompt_tokens": {"value": 7791.0}, "meta_eval_completion_tokens": {"value": 2885.0}, "meta_eval_prompt_cost": {"value": 0.00249312}, "meta_eval_completion_cost": {"value": 0.0036928}}, "created": "2025-12-10T21:45:56.1729533Z"}
{"ref": "energetic-procedure-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.942857142857143}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.618237}, "meta_inference_prompt_tokens": {"value": 13688.0}, "meta_inference_completion_tokens": {"value": 1052.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027376}, "meta_inference_completion_cost": {"value": 0.0016832}, "meta_eval_time": {"value": 31.445}, "meta_eval_prompt_tokens": {"value": 10005.0}, "meta_eval_completion_tokens": {"value": 3384.0}, "meta_eval_prompt_cost": {"value": 0.0032016}, "meta_eval_completion_cost": {"value": 0.00433152}}, "created": "2025-12-10T21:45:57.610842Z"}
{"ref": "energetic-procedure-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.878787878787879}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.02472}, "meta_inference_prompt_tokens": {"value": 13367.0}, "meta_inference_completion_tokens": {"value": 1158.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026734}, "meta_inference_completion_cost": {"value": 0.0018528}, "meta_eval_time": {"value": 31.211}, "meta_eval_prompt_tokens": {"value": 9371.0}, "meta_eval_completion_tokens": {"value": 3227.0}, "meta_eval_prompt_cost": {"value": 0.00299872}, "meta_eval_completion_cost": {"value": 0.00413056}}, "created": "2025-12-10T21:46:00.9290634Z"}
{"ref": "excited-rectangle", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.604462}, "meta_inference_prompt_tokens": {"value": 12025.0}, "meta_inference_completion_tokens": {"value": 683.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002405}, "meta_inference_completion_cost": {"value": 0.0010928}, "meta_eval_time": {"value": 22.319}, "meta_eval_prompt_tokens": {"value": 6972.0}, "meta_eval_completion_tokens": {"value": 1766.0}, "meta_eval_prompt_cost": {"value": 0.00223104}, "meta_eval_completion_cost": {"value": 0.00226048}}, "created": "2025-12-10T21:46:03.2222235Z"}
{"ref": "energetic-procedure-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.490015}, "meta_inference_prompt_tokens": {"value": 13588.0}, "meta_inference_completion_tokens": {"value": 968.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027176}, "meta_inference_completion_cost": {"value": 0.0015488}, "meta_eval_time": {"value": 30.82}, "meta_eval_prompt_tokens": {"value": 9397.0}, "meta_eval_completion_tokens": {"value": 3164.0}, "meta_eval_prompt_cost": {"value": 0.00300704}, "meta_eval_completion_cost": {"value": 0.00404992}}, "created": "2025-12-10T21:46:04.0454422Z"}
{"ref": "energetic-procedure-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.931034482758621}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.702626}, "meta_inference_prompt_tokens": {"value": 16436.0}, "meta_inference_completion_tokens": {"value": 789.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032872}, "meta_inference_completion_cost": {"value": 0.0012624}, "meta_eval_time": {"value": 30.183}, "meta_eval_prompt_tokens": {"value": 12075.0}, "meta_eval_completion_tokens": {"value": 2652.0}, "meta_eval_prompt_cost": {"value": 0.003864}, "meta_eval_completion_cost": {"value": 0.00339456}}, "created": "2025-12-10T21:46:04.3548835Z"}
{"ref": "faded-paprika", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 20.716538}, "meta_inference_prompt_tokens": {"value": 10036.0}, "meta_inference_completion_tokens": {"value": 905.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020072}, "meta_inference_completion_cost": {"value": 0.001448}, "meta_eval_time": {"value": 18.13}, "meta_eval_prompt_tokens": {"value": 4809.0}, "meta_eval_completion_tokens": {"value": 1525.0}, "meta_eval_prompt_cost": {"value": 0.00153888}, "meta_eval_completion_cost": {"value": 0.001952}}, "created": "2025-12-10T21:46:04.8538024Z"}
{"ref": "energetic-procedure-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.973684210526316}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 25.200924}, "meta_inference_prompt_tokens": {"value": 13086.0}, "meta_inference_completion_tokens": {"value": 1289.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026172}, "meta_inference_completion_cost": {"value": 0.0020624}, "meta_eval_time": {"value": 41.384}, "meta_eval_prompt_tokens": {"value": 9529.0}, "meta_eval_completion_tokens": {"value": 3692.0}, "meta_eval_prompt_cost": {"value": 0.00304928}, "meta_eval_completion_cost": {"value": 0.00472576}}, "created": "2025-12-10T21:46:05.5342506Z"}
{"ref": "energetic-procedure-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.911111111111111}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.351882}, "meta_inference_prompt_tokens": {"value": 12208.0}, "meta_inference_completion_tokens": {"value": 1387.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024416}, "meta_inference_completion_cost": {"value": 0.0022192}, "meta_eval_time": {"value": 39.511}, "meta_eval_prompt_tokens": {"value": 8609.0}, "meta_eval_completion_tokens": {"value": 3963.0}, "meta_eval_prompt_cost": {"value": 0.00275488}, "meta_eval_completion_cost": {"value": 0.00507264}}, "created": "2025-12-10T21:46:05.6492394Z"}
{"ref": "flush-cockatoo", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.80676}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 591.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0009456}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:05.6880957Z"}
{"ref": "flush-cockatoo", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.970395}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 399.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0006384}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:06.2435161Z"}
{"ref": "electrical-tensor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.189238}, "meta_inference_prompt_tokens": {"value": 12287.0}, "meta_inference_completion_tokens": {"value": 1052.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024574}, "meta_inference_completion_cost": {"value": 0.0016832}, "meta_eval_time": {"value": 34.219}, "meta_eval_prompt_tokens": {"value": 8044.0}, "meta_eval_completion_tokens": {"value": 3334.0}, "meta_eval_prompt_cost": {"value": 0.00257408}, "meta_eval_completion_cost": {"value": 0.00426752}}, "created": "2025-12-10T21:46:06.2569184Z"}
{"ref": "flush-cockatoo", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.249423}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 514.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0008224}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:06.2789255Z"}
{"ref": "energetic-procedure-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.2}, "generation_factuality_precision": {"value": 0.111111111111111}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.639037}, "meta_inference_prompt_tokens": {"value": 11708.0}, "meta_inference_completion_tokens": {"value": 1401.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023416}, "meta_inference_completion_cost": {"value": 0.0022416}, "meta_eval_time": {"value": 34.847}, "meta_eval_prompt_tokens": {"value": 7698.0}, "meta_eval_completion_tokens": {"value": 3381.0}, "meta_eval_prompt_cost": {"value": 0.00246336}, "meta_eval_completion_cost": {"value": 0.00432768}}, "created": "2025-12-10T21:46:06.4919934Z"}
{"ref": "flush-cockatoo", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.777234}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 521.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0008336}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:06.5379406Z"}
{"ref": "excited-rectangle", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.540540540540541}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 22.783807}, "meta_inference_prompt_tokens": {"value": 11635.0}, "meta_inference_completion_tokens": {"value": 1511.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002327}, "meta_inference_completion_cost": {"value": 0.0024176}, "meta_eval_time": {"value": 29.055}, "meta_eval_prompt_tokens": {"value": 7328.0}, "meta_eval_completion_tokens": {"value": 2988.0}, "meta_eval_prompt_cost": {"value": 0.00234496}, "meta_eval_completion_cost": {"value": 0.00382464}}, "created": "2025-12-10T21:46:08.1662982Z"}
{"ref": "figurative-gofer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.348966}, "meta_inference_prompt_tokens": {"value": 10799.0}, "meta_inference_completion_tokens": {"value": 1127.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021598}, "meta_inference_completion_cost": {"value": 0.0018032}, "meta_eval_time": {"value": 21.915}, "meta_eval_prompt_tokens": {"value": 5762.0}, "meta_eval_completion_tokens": {"value": 1977.0}, "meta_eval_prompt_cost": {"value": 0.00184384}, "meta_eval_completion_cost": {"value": 0.00253056}}, "created": "2025-12-10T21:46:11.9033724Z"}
{"ref": "faded-paprika", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.846153846153846}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.111111111111111}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 23.807707}, "meta_inference_prompt_tokens": {"value": 10748.0}, "meta_inference_completion_tokens": {"value": 1201.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021496}, "meta_inference_completion_cost": {"value": 0.0019216}, "meta_eval_time": {"value": 26.601}, "meta_eval_prompt_tokens": {"value": 5964.0}, "meta_eval_completion_tokens": {"value": 2448.0}, "meta_eval_prompt_cost": {"value": 0.00190848}, "meta_eval_completion_cost": {"value": 0.00313344}}, "created": "2025-12-10T21:46:13.246807Z"}
{"ref": "figurative-gofer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.075542}, "meta_inference_prompt_tokens": {"value": 13409.0}, "meta_inference_completion_tokens": {"value": 1691.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026818}, "meta_inference_completion_cost": {"value": 0.0027056}, "meta_eval_time": {"value": 22.704}, "meta_eval_prompt_tokens": {"value": 7878.0}, "meta_eval_completion_tokens": {"value": 1808.0}, "meta_eval_prompt_cost": {"value": 0.00252096}, "meta_eval_completion_cost": {"value": 0.00231424}}, "created": "2025-12-10T21:46:13.745766Z"}
{"ref": "every-force", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.68}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.061665}, "meta_inference_prompt_tokens": {"value": 12263.0}, "meta_inference_completion_tokens": {"value": 1877.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024526}, "meta_inference_completion_cost": {"value": 0.0030032}, "meta_eval_time": {"value": 42.538}, "meta_eval_prompt_tokens": {"value": 8076.0}, "meta_eval_completion_tokens": {"value": 2906.0}, "meta_eval_prompt_cost": {"value": 0.00258432}, "meta_eval_completion_cost": {"value": 0.00371968}}, "created": "2025-12-10T21:46:14.500223Z"}
{"ref": "fixed-entropy-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.375}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.30260181746521}, "generation_faithfulness": {"value": 0.882352941176471}, "generation_factuality_f1": {"value": 0.392156862745098}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.625}, "retrieval_accuracy": {"value": 0.230769230769231}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.625}, "meta_inference_time": {"value": 15.205566}, "meta_inference_prompt_tokens": {"value": 10556.0}, "meta_inference_completion_tokens": {"value": 630.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021112}, "meta_inference_completion_cost": {"value": 0.001008}, "meta_eval_time": {"value": 19.058}, "meta_eval_prompt_tokens": {"value": 5413.0}, "meta_eval_completion_tokens": {"value": 1920.0}, "meta_eval_prompt_cost": {"value": 0.00173216}, "meta_eval_completion_cost": {"value": 0.0024576}}, "created": "2025-12-10T21:46:15.2732144Z"}
{"ref": "edible-survey", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 1.83333333333333}, "generation_faithfulness": {"value": 0.953488372093023}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.941457}, "meta_inference_prompt_tokens": {"value": 11955.0}, "meta_inference_completion_tokens": {"value": 1431.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002391}, "meta_inference_completion_cost": {"value": 0.0022896}, "meta_eval_time": {"value": 36.683}, "meta_eval_prompt_tokens": {"value": 7462.0}, "meta_eval_completion_tokens": {"value": 3549.0}, "meta_eval_prompt_cost": {"value": 0.00238784}, "meta_eval_completion_cost": {"value": 0.00454272}}, "created": "2025-12-10T21:46:15.367467Z"}
{"ref": "excited-rectangle", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.644436}, "meta_inference_prompt_tokens": {"value": 12215.0}, "meta_inference_completion_tokens": {"value": 1182.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002443}, "meta_inference_completion_cost": {"value": 0.0018912}, "meta_eval_time": {"value": 33.742}, "meta_eval_prompt_tokens": {"value": 7962.0}, "meta_eval_completion_tokens": {"value": 3134.0}, "meta_eval_prompt_cost": {"value": 0.00254784}, "meta_eval_completion_cost": {"value": 0.00401152}}, "created": "2025-12-10T21:46:15.83396Z"}
{"ref": "exothermic-field", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.087285}, "meta_inference_prompt_tokens": {"value": 10204.0}, "meta_inference_completion_tokens": {"value": 1527.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020408}, "meta_inference_completion_cost": {"value": 0.0024432}, "meta_eval_time": {"value": 31.455}, "meta_eval_prompt_tokens": {"value": 6303.0}, "meta_eval_completion_tokens": {"value": 3556.0}, "meta_eval_prompt_cost": {"value": 0.00201696}, "meta_eval_completion_cost": {"value": 0.00455168}}, "created": "2025-12-10T21:46:16.5454917Z"}
{"ref": "faded-paprika", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 0.814814814814815}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.593169}, "meta_inference_prompt_tokens": {"value": 9392.0}, "meta_inference_completion_tokens": {"value": 1244.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018784}, "meta_inference_completion_cost": {"value": 0.0019904}, "meta_eval_time": {"value": 30.742}, "meta_eval_prompt_tokens": {"value": 4907.0}, "meta_eval_completion_tokens": {"value": 2693.0}, "meta_eval_prompt_cost": {"value": 0.00157024}, "meta_eval_completion_cost": {"value": 0.00344704}}, "created": "2025-12-10T21:46:17.2706815Z"}
{"ref": "faded-paprika", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.848484848484848}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 33.044651}, "meta_inference_prompt_tokens": {"value": 10864.0}, "meta_inference_completion_tokens": {"value": 1368.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021728}, "meta_inference_completion_cost": {"value": 0.0021888}, "meta_eval_time": {"value": 31.834}, "meta_eval_prompt_tokens": {"value": 6749.0}, "meta_eval_completion_tokens": {"value": 3116.0}, "meta_eval_prompt_cost": {"value": 0.00215968}, "meta_eval_completion_cost": {"value": 0.00398848}}, "created": "2025-12-10T21:46:17.9334788Z"}
{"ref": "figurative-gofer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.211737}, "meta_inference_prompt_tokens": {"value": 11760.0}, "meta_inference_completion_tokens": {"value": 1756.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002352}, "meta_inference_completion_cost": {"value": 0.0028096}, "meta_eval_time": {"value": 24.121}, "meta_eval_prompt_tokens": {"value": 6696.0}, "meta_eval_completion_tokens": {"value": 2377.0}, "meta_eval_prompt_cost": {"value": 0.00214272}, "meta_eval_completion_cost": {"value": 0.00304256}}, "created": "2025-12-10T21:46:18.5109444Z"}
{"ref": "free-camembert", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.33333333333333}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 16.648119}, "meta_inference_prompt_tokens": {"value": 9989.0}, "meta_inference_completion_tokens": {"value": 798.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019978}, "meta_inference_completion_cost": {"value": 0.0012768}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:18.5477555Z"}
{"ref": "exothermic-field", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.771428571428571}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.013794}, "meta_inference_prompt_tokens": {"value": 10429.0}, "meta_inference_completion_tokens": {"value": 1379.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020858}, "meta_inference_completion_cost": {"value": 0.0022064}, "meta_eval_time": {"value": 33.629}, "meta_eval_prompt_tokens": {"value": 6118.0}, "meta_eval_completion_tokens": {"value": 3119.0}, "meta_eval_prompt_cost": {"value": 0.00195776}, "meta_eval_completion_cost": {"value": 0.00399232}}, "created": "2025-12-10T21:46:18.5777021Z"}
{"ref": "figurative-gofer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.700023}, "meta_inference_prompt_tokens": {"value": 11545.0}, "meta_inference_completion_tokens": {"value": 1333.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002309}, "meta_inference_completion_cost": {"value": 0.0021328}, "meta_eval_time": {"value": 26.388}, "meta_eval_prompt_tokens": {"value": 6274.0}, "meta_eval_completion_tokens": {"value": 2078.0}, "meta_eval_prompt_cost": {"value": 0.00200768}, "meta_eval_completion_cost": {"value": 0.00265984}}, "created": "2025-12-10T21:46:19.5658255Z"}
{"ref": "excited-rectangle", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.415182}, "meta_inference_prompt_tokens": {"value": 12055.0}, "meta_inference_completion_tokens": {"value": 1413.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002411}, "meta_inference_completion_cost": {"value": 0.0022608}, "meta_eval_time": {"value": 37.76}, "meta_eval_prompt_tokens": {"value": 8123.0}, "meta_eval_completion_tokens": {"value": 3566.0}, "meta_eval_prompt_cost": {"value": 0.00259936}, "meta_eval_completion_cost": {"value": 0.00456448}}, "created": "2025-12-10T21:46:19.6676489Z"}
{"ref": "faded-change", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 0.939393939393939}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 43.297049}, "meta_inference_prompt_tokens": {"value": 11821.0}, "meta_inference_completion_tokens": {"value": 2012.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023642}, "meta_inference_completion_cost": {"value": 0.0032192}, "meta_eval_time": {"value": 33.935}, "meta_eval_prompt_tokens": {"value": 7875.0}, "meta_eval_completion_tokens": {"value": 3604.0}, "meta_eval_prompt_cost": {"value": 0.00252}, "meta_eval_completion_cost": {"value": 0.00461312}}, "created": "2025-12-10T21:46:19.8426788Z"}
{"ref": "faded-change", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.481269}, "meta_inference_prompt_tokens": {"value": 11887.0}, "meta_inference_completion_tokens": {"value": 1743.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023774}, "meta_inference_completion_cost": {"value": 0.0027888}, "meta_eval_time": {"value": 34.665}, "meta_eval_prompt_tokens": {"value": 7753.0}, "meta_eval_completion_tokens": {"value": 3222.0}, "meta_eval_prompt_cost": {"value": 0.00248096}, "meta_eval_completion_cost": {"value": 0.00412416}}, "created": "2025-12-10T21:46:19.8813879Z"}
{"ref": "fixed-entropy-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.375}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.30260181746521}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.153846153846154}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 0.142857142857143}, "retrieval_accuracy": {"value": 0.230769230769231}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.142857142857143}, "meta_inference_time": {"value": 21.0908}, "meta_inference_prompt_tokens": {"value": 10557.0}, "meta_inference_completion_tokens": {"value": 939.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021114}, "meta_inference_completion_cost": {"value": 0.0015024}, "meta_eval_time": {"value": 17.069}, "meta_eval_prompt_tokens": {"value": 5361.0}, "meta_eval_completion_tokens": {"value": 1716.0}, "meta_eval_prompt_cost": {"value": 0.00171552}, "meta_eval_completion_cost": {"value": 0.00219648}}, "created": "2025-12-10T21:46:20.3291585Z"}
{"ref": "exothermic-field", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.437415}, "meta_inference_prompt_tokens": {"value": 10075.0}, "meta_inference_completion_tokens": {"value": 1716.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002015}, "meta_inference_completion_cost": {"value": 0.0027456}, "meta_eval_time": {"value": 36.737}, "meta_eval_prompt_tokens": {"value": 5945.0}, "meta_eval_completion_tokens": {"value": 3328.0}, "meta_eval_prompt_cost": {"value": 0.0019024}, "meta_eval_completion_cost": {"value": 0.00425984}}, "created": "2025-12-10T21:46:20.7584344Z"}
{"ref": "faded-change", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.289064826317888}, "generation_faithfulness": {"value": 0.92}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.593268}, "meta_inference_prompt_tokens": {"value": 11103.0}, "meta_inference_completion_tokens": {"value": 1804.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022206}, "meta_inference_completion_cost": {"value": 0.0028864}, "meta_eval_time": {"value": 29.66}, "meta_eval_prompt_tokens": {"value": 6640.0}, "meta_eval_completion_tokens": {"value": 2754.0}, "meta_eval_prompt_cost": {"value": 0.0021248}, "meta_eval_completion_cost": {"value": 0.00352512}}, "created": "2025-12-10T21:46:20.8221662Z"}
{"ref": "faded-paprika", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.774193548387097}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 18.384663}, "meta_inference_prompt_tokens": {"value": 10291.0}, "meta_inference_completion_tokens": {"value": 1055.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020582}, "meta_inference_completion_cost": {"value": 0.001688}, "meta_eval_time": {"value": 35.629}, "meta_eval_prompt_tokens": {"value": 5777.0}, "meta_eval_completion_tokens": {"value": 2855.0}, "meta_eval_prompt_cost": {"value": 0.00184864}, "meta_eval_completion_cost": {"value": 0.0036544}}, "created": "2025-12-10T21:46:22.7452805Z"}
{"ref": "feasible-pole", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.375}, "retrieval_mrr": {"value": 0.25}, "retrieval_dcg": {"value": 1.80102999566398}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.631578947368421}, "generation_factuality_precision": {"value": 0.461538461538462}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.230769230769231}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 36.063346}, "meta_inference_prompt_tokens": {"value": 13649.0}, "meta_inference_completion_tokens": {"value": 1806.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027298}, "meta_inference_completion_cost": {"value": 0.0028896}, "meta_eval_time": {"value": 36.632}, "meta_eval_prompt_tokens": {"value": 9736.0}, "meta_eval_completion_tokens": {"value": 3686.0}, "meta_eval_prompt_cost": {"value": 0.00311552}, "meta_eval_completion_cost": {"value": 0.00471808}}, "created": "2025-12-10T21:46:24.5537257Z"}
{"ref": "exothermic-field", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.682926829268293}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.924326}, "meta_inference_prompt_tokens": {"value": 10199.0}, "meta_inference_completion_tokens": {"value": 1479.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020398}, "meta_inference_completion_cost": {"value": 0.0023664}, "meta_eval_time": {"value": 40.353}, "meta_eval_prompt_tokens": {"value": 5991.0}, "meta_eval_completion_tokens": {"value": 3440.0}, "meta_eval_prompt_cost": {"value": 0.00191712}, "meta_eval_completion_cost": {"value": 0.0044032}}, "created": "2025-12-10T21:46:24.8002935Z"}
{"ref": "fixed-entropy-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.266666666666667}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.222222222222222}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 0.222222222222222}, "meta_inference_time": {"value": 21.983552}, "meta_inference_prompt_tokens": {"value": 12052.0}, "meta_inference_completion_tokens": {"value": 1003.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024104}, "meta_inference_completion_cost": {"value": 0.0016048}, "meta_eval_time": {"value": 27.555}, "meta_eval_prompt_tokens": {"value": 7088.0}, "meta_eval_completion_tokens": {"value": 2477.0}, "meta_eval_prompt_cost": {"value": 0.00226816}, "meta_eval_completion_cost": {"value": 0.00317056}}, "created": "2025-12-10T21:46:25.2040035Z"}
{"ref": "faded-change", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.91304347826087}, "generation_factuality_f1": {"value": 0.266666666666667}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 35.836597}, "meta_inference_prompt_tokens": {"value": 8844.0}, "meta_inference_completion_tokens": {"value": 1796.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0017688}, "meta_inference_completion_cost": {"value": 0.0028736}, "meta_eval_time": {"value": 31.795}, "meta_eval_prompt_tokens": {"value": 5759.0}, "meta_eval_completion_tokens": {"value": 2765.0}, "meta_eval_prompt_cost": {"value": 0.00184288}, "meta_eval_completion_cost": {"value": 0.0035392}}, "created": "2025-12-10T21:46:25.469638Z"}
{"ref": "excited-rectangle", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.67116}, "meta_inference_prompt_tokens": {"value": 11643.0}, "meta_inference_completion_tokens": {"value": 1138.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023286}, "meta_inference_completion_cost": {"value": 0.0018208}, "meta_eval_time": {"value": 44.154}, "meta_eval_prompt_tokens": {"value": 7825.0}, "meta_eval_completion_tokens": {"value": 4284.0}, "meta_eval_prompt_cost": {"value": 0.002504}, "meta_eval_completion_cost": {"value": 0.00548352}}, "created": "2025-12-10T21:46:26.083384Z"}
{"ref": "faded-change", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.815464876785729}, "generation_faithfulness": {"value": 0.966666666666667}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 26.001972}, "meta_inference_prompt_tokens": {"value": 11597.0}, "meta_inference_completion_tokens": {"value": 1729.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023194}, "meta_inference_completion_cost": {"value": 0.0027664}, "meta_eval_time": {"value": 32.255}, "meta_eval_prompt_tokens": {"value": 7313.0}, "meta_eval_completion_tokens": {"value": 3250.0}, "meta_eval_prompt_cost": {"value": 0.00234016}, "meta_eval_completion_cost": {"value": 0.00416}}, "created": "2025-12-10T21:46:26.5055019Z"}
{"ref": "exothermic-field", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.972972972972973}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.25}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.54711}, "meta_inference_prompt_tokens": {"value": 7179.0}, "meta_inference_completion_tokens": {"value": 1576.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0014358}, "meta_inference_completion_cost": {"value": 0.0025216}, "meta_eval_time": {"value": 43.886}, "meta_eval_prompt_tokens": {"value": 5772.0}, "meta_eval_completion_tokens": {"value": 4138.0}, "meta_eval_prompt_cost": {"value": 0.00184704}, "meta_eval_completion_cost": {"value": 0.00529664}}, "created": "2025-12-10T21:46:28.847622Z"}
{"ref": "figurative-gofer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.117647058823529}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.27894294565113}, "generation_faithfulness": {"value": 0.652173913043478}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0625}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.05}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 36.750768}, "meta_inference_prompt_tokens": {"value": 22991.0}, "meta_inference_completion_tokens": {"value": 1993.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0045982}, "meta_inference_completion_cost": {"value": 0.0031888}, "meta_eval_time": {"value": 25.084}, "meta_eval_prompt_tokens": {"value": 7118.0}, "meta_eval_completion_tokens": {"value": 2171.0}, "meta_eval_prompt_cost": {"value": 0.00227776}, "meta_eval_completion_cost": {"value": 0.00277888}}, "created": "2025-12-10T21:46:29.1902885Z"}
{"ref": "frigid-adjuster", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.092192}, "meta_inference_prompt_tokens": {"value": 2253.0}, "meta_inference_completion_tokens": {"value": 636.0}, "meta_inference_prompt_cost": {"value": 0.0004506}, "meta_inference_completion_cost": {"value": 0.0010176}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:29.2323944Z"}
{"ref": "formal-townhouse", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.350726}, "meta_inference_prompt_tokens": {"value": 10848.0}, "meta_inference_completion_tokens": {"value": 1123.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021696}, "meta_inference_completion_cost": {"value": 0.0017968}, "meta_eval_time": {"value": 20.815}, "meta_eval_prompt_tokens": {"value": 5968.0}, "meta_eval_completion_tokens": {"value": 2080.0}, "meta_eval_prompt_cost": {"value": 0.00190976}, "meta_eval_completion_cost": {"value": 0.0026624}}, "created": "2025-12-10T21:46:32.7534841Z"}
{"ref": "frigid-adjuster", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.473213}, "meta_inference_prompt_tokens": {"value": 2253.0}, "meta_inference_completion_tokens": {"value": 513.0}, "meta_inference_prompt_cost": {"value": 0.0004506}, "meta_inference_completion_cost": {"value": 0.0008208}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:32.7881823Z"}
{"ref": "frigid-adjuster", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.978573}, "meta_inference_prompt_tokens": {"value": 2253.0}, "meta_inference_completion_tokens": {"value": 764.0}, "meta_inference_prompt_cost": {"value": 0.0004506}, "meta_inference_completion_cost": {"value": 0.0012224}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:32.821762Z"}
{"ref": "frigid-adjuster", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.04802}, "meta_inference_prompt_tokens": {"value": 4640.0}, "meta_inference_completion_tokens": {"value": 807.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.000928}, "meta_inference_completion_cost": {"value": 0.0012912}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:32.8533921Z"}
{"ref": "frayed-vault", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.789473684210526}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.314362}, "meta_inference_prompt_tokens": {"value": 10995.0}, "meta_inference_completion_tokens": {"value": 753.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002199}, "meta_inference_completion_cost": {"value": 0.0012048}, "meta_eval_time": {"value": 17.688}, "meta_eval_prompt_tokens": {"value": 5874.0}, "meta_eval_completion_tokens": {"value": 1891.0}, "meta_eval_prompt_cost": {"value": 0.00187968}, "meta_eval_completion_cost": {"value": 0.00242048}}, "created": "2025-12-10T21:46:32.9978546Z"}
{"ref": "frayed-vault", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.894736842105263}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.020325}, "meta_inference_prompt_tokens": {"value": 10675.0}, "meta_inference_completion_tokens": {"value": 636.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002135}, "meta_inference_completion_cost": {"value": 0.0010176}, "meta_eval_time": {"value": 19.92}, "meta_eval_prompt_tokens": {"value": 5626.0}, "meta_eval_completion_tokens": {"value": 2078.0}, "meta_eval_prompt_cost": {"value": 0.00180032}, "meta_eval_completion_cost": {"value": 0.00265984}}, "created": "2025-12-10T21:46:33.7106547Z"}
{"ref": "fixed-entropy-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.375}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.62239815965122}, "generation_faithfulness": {"value": 0.96551724137931}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.230769230769231}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 19.251573}, "meta_inference_prompt_tokens": {"value": 11408.0}, "meta_inference_completion_tokens": {"value": 913.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022816}, "meta_inference_completion_cost": {"value": 0.0014608}, "meta_eval_time": {"value": 29.88}, "meta_eval_prompt_tokens": {"value": 6762.0}, "meta_eval_completion_tokens": {"value": 2972.0}, "meta_eval_prompt_cost": {"value": 0.00216384}, "meta_eval_completion_cost": {"value": 0.00380416}}, "created": "2025-12-10T21:46:34.2708254Z"}
{"ref": "formal-townhouse", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.675793}, "meta_inference_prompt_tokens": {"value": 10955.0}, "meta_inference_completion_tokens": {"value": 1379.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002191}, "meta_inference_completion_cost": {"value": 0.0022064}, "meta_eval_time": {"value": 26.714}, "meta_eval_prompt_tokens": {"value": 6076.0}, "meta_eval_completion_tokens": {"value": 2345.0}, "meta_eval_prompt_cost": {"value": 0.00194432}, "meta_eval_completion_cost": {"value": 0.0030016}}, "created": "2025-12-10T21:46:34.9163608Z"}
{"ref": "fixed-entropy-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.597014925373134}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.625}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.625}, "meta_inference_time": {"value": 24.806118}, "meta_inference_prompt_tokens": {"value": 11685.0}, "meta_inference_completion_tokens": {"value": 1119.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002337}, "meta_inference_completion_cost": {"value": 0.0017904}, "meta_eval_time": {"value": 34.448}, "meta_eval_prompt_tokens": {"value": 6968.0}, "meta_eval_completion_tokens": {"value": 2661.0}, "meta_eval_prompt_cost": {"value": 0.00222976}, "meta_eval_completion_cost": {"value": 0.00340608}}, "created": "2025-12-10T21:46:35.4154086Z"}
{"ref": "feasible-pole", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.375}, "retrieval_mrr": {"value": 0.25}, "retrieval_dcg": {"value": 1.80102999566398}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.230769230769231}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.350877}, "meta_inference_prompt_tokens": {"value": 13650.0}, "meta_inference_completion_tokens": {"value": 1766.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00273}, "meta_inference_completion_cost": {"value": 0.0028256}, "meta_eval_time": {"value": 46.139}, "meta_eval_prompt_tokens": {"value": 10178.0}, "meta_eval_completion_tokens": {"value": 4784.0}, "meta_eval_prompt_cost": {"value": 0.00325696}, "meta_eval_completion_cost": {"value": 0.00612352}}, "created": "2025-12-10T21:46:35.8727962Z"}
{"ref": "frigid-adjuster", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.590088}, "meta_inference_prompt_tokens": {"value": 2253.0}, "meta_inference_completion_tokens": {"value": 583.0}, "meta_inference_prompt_cost": {"value": 0.0004506}, "meta_inference_completion_cost": {"value": 0.0009328}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:35.9393598Z"}
{"ref": "frayed-vault", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.992401}, "meta_inference_prompt_tokens": {"value": 10858.0}, "meta_inference_completion_tokens": {"value": 494.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021716}, "meta_inference_completion_cost": {"value": 0.0007904}, "meta_eval_time": {"value": 18.808}, "meta_eval_prompt_tokens": {"value": 5654.0}, "meta_eval_completion_tokens": {"value": 1669.0}, "meta_eval_prompt_cost": {"value": 0.00180928}, "meta_eval_completion_cost": {"value": 0.00213632}}, "created": "2025-12-10T21:46:36.7828626Z"}
{"ref": "flush-cockatoo", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.726576}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 517.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0008272}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:36.8182761Z"}
{"ref": "frayed-vault", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.823529411764706}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.498237}, "meta_inference_prompt_tokens": {"value": 9919.0}, "meta_inference_completion_tokens": {"value": 606.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019838}, "meta_inference_completion_cost": {"value": 0.0009696}, "meta_eval_time": {"value": 21.057}, "meta_eval_prompt_tokens": {"value": 4764.0}, "meta_eval_completion_tokens": {"value": 1860.0}, "meta_eval_prompt_cost": {"value": 0.00152448}, "meta_eval_completion_cost": {"value": 0.0023808}}, "created": "2025-12-10T21:46:37.6384028Z"}
{"ref": "formal-townhouse", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.824542}, "meta_inference_prompt_tokens": {"value": 10730.0}, "meta_inference_completion_tokens": {"value": 1600.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002146}, "meta_inference_completion_cost": {"value": 0.00256}, "meta_eval_time": {"value": 24.414}, "meta_eval_prompt_tokens": {"value": 6080.0}, "meta_eval_completion_tokens": {"value": 2291.0}, "meta_eval_prompt_cost": {"value": 0.0019456}, "meta_eval_completion_cost": {"value": 0.00293248}}, "created": "2025-12-10T21:46:37.7026825Z"}
{"ref": "feasible-pole", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.375}, "retrieval_mrr": {"value": 0.25}, "retrieval_dcg": {"value": 1.93067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.230769230769231}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.560053}, "meta_inference_prompt_tokens": {"value": 15616.0}, "meta_inference_completion_tokens": {"value": 1167.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031232}, "meta_inference_completion_cost": {"value": 0.0018672}, "meta_eval_time": {"value": 51.331}, "meta_eval_prompt_tokens": {"value": 12067.0}, "meta_eval_completion_tokens": {"value": 5090.0}, "meta_eval_prompt_cost": {"value": 0.00386144}, "meta_eval_completion_cost": {"value": 0.0065152}}, "created": "2025-12-10T21:46:38.1550452Z"}
{"ref": "gilded-pole", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.756336}, "meta_inference_prompt_tokens": {"value": 2259.0}, "meta_inference_completion_tokens": {"value": 658.0}, "meta_inference_prompt_cost": {"value": 0.0004518}, "meta_inference_completion_cost": {"value": 0.0010528}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:38.1916346Z"}
{"ref": "frayed-vault", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.861705}, "meta_inference_prompt_tokens": {"value": 11423.0}, "meta_inference_completion_tokens": {"value": 781.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022846}, "meta_inference_completion_cost": {"value": 0.0012496}, "meta_eval_time": {"value": 22.821}, "meta_eval_prompt_tokens": {"value": 6462.0}, "meta_eval_completion_tokens": {"value": 2019.0}, "meta_eval_prompt_cost": {"value": 0.00206784}, "meta_eval_completion_cost": {"value": 0.00258432}}, "created": "2025-12-10T21:46:38.2216018Z"}
{"ref": "gilded-pole", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.981262}, "meta_inference_prompt_tokens": {"value": 4691.0}, "meta_inference_completion_tokens": {"value": 1473.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009382}, "meta_inference_completion_cost": {"value": 0.0023568}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:38.2263776Z"}
{"ref": "gilded-pole", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.462514}, "meta_inference_prompt_tokens": {"value": 2259.0}, "meta_inference_completion_tokens": {"value": 921.0}, "meta_inference_prompt_cost": {"value": 0.0004518}, "meta_inference_completion_cost": {"value": 0.0014736}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:38.2592479Z"}
{"ref": "gilded-pole", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.339933}, "meta_inference_prompt_tokens": {"value": 4675.0}, "meta_inference_completion_tokens": {"value": 1404.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.000935}, "meta_inference_completion_cost": {"value": 0.0022464}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:38.2693201Z"}
{"ref": "gilded-pole", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.556458}, "meta_inference_prompt_tokens": {"value": 4663.0}, "meta_inference_completion_tokens": {"value": 1091.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009326}, "meta_inference_completion_cost": {"value": 0.0017456}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:38.2969195Z"}
{"ref": "flat-total", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.623313}, "meta_inference_prompt_tokens": {"value": 13597.0}, "meta_inference_completion_tokens": {"value": 1157.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027194}, "meta_inference_completion_cost": {"value": 0.0018512}, "meta_eval_time": {"value": 33.404}, "meta_eval_prompt_tokens": {"value": 9937.0}, "meta_eval_completion_tokens": {"value": 3384.0}, "meta_eval_prompt_cost": {"value": 0.00317984}, "meta_eval_completion_cost": {"value": 0.00433152}}, "created": "2025-12-10T21:46:39.9755955Z"}
{"ref": "free-sound", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.842105263157895}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.265973}, "meta_inference_prompt_tokens": {"value": 13128.0}, "meta_inference_completion_tokens": {"value": 1006.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026256}, "meta_inference_completion_cost": {"value": 0.0016096}, "meta_eval_time": {"value": 21.8}, "meta_eval_prompt_tokens": {"value": 8417.0}, "meta_eval_completion_tokens": {"value": 2247.0}, "meta_eval_prompt_cost": {"value": 0.00269344}, "meta_eval_completion_cost": {"value": 0.00287616}}, "created": "2025-12-10T21:46:41.6773298Z"}
{"ref": "frozen-subfloor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 29.012673}, "meta_inference_prompt_tokens": {"value": 14246.0}, "meta_inference_completion_tokens": {"value": 1985.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028492}, "meta_inference_completion_cost": {"value": 0.003176}, "meta_eval_time": {"value": 4.209}, "meta_eval_prompt_tokens": {"value": 7729.0}, "meta_eval_completion_tokens": {"value": 290.0}, "meta_eval_prompt_cost": {"value": 0.00247328}, "meta_eval_completion_cost": {"value": 0.0003712}}, "created": "2025-12-10T21:46:41.881158Z"}
{"ref": "flat-total", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 22.659545}, "meta_inference_prompt_tokens": {"value": 15290.0}, "meta_inference_completion_tokens": {"value": 1058.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003058}, "meta_inference_completion_cost": {"value": 0.0016928}, "meta_eval_time": {"value": 37.13}, "meta_eval_prompt_tokens": {"value": 10789.0}, "meta_eval_completion_tokens": {"value": 3797.0}, "meta_eval_prompt_cost": {"value": 0.00345248}, "meta_eval_completion_cost": {"value": 0.00486016}}, "created": "2025-12-10T21:46:43.4286848Z"}
{"ref": "formal-townhouse", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.962962962962963}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.095463}, "meta_inference_prompt_tokens": {"value": 10923.0}, "meta_inference_completion_tokens": {"value": 1196.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021846}, "meta_inference_completion_cost": {"value": 0.0019136}, "meta_eval_time": {"value": 29.952}, "meta_eval_prompt_tokens": {"value": 6451.0}, "meta_eval_completion_tokens": {"value": 2832.0}, "meta_eval_prompt_cost": {"value": 0.00206432}, "meta_eval_completion_cost": {"value": 0.00362496}}, "created": "2025-12-10T21:46:44.4884226Z"}
{"ref": "free-omelette", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 29.63666}, "meta_inference_prompt_tokens": {"value": 10694.0}, "meta_inference_completion_tokens": {"value": 1227.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021388}, "meta_inference_completion_cost": {"value": 0.0019632}, "meta_eval_time": {"value": 26.381}, "meta_eval_prompt_tokens": {"value": 6229.0}, "meta_eval_completion_tokens": {"value": 2670.0}, "meta_eval_prompt_cost": {"value": 0.00199328}, "meta_eval_completion_cost": {"value": 0.0034176}}, "created": "2025-12-10T21:46:46.1084277Z"}
{"ref": "flat-total", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.436363636363636}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 26.506809}, "meta_inference_prompt_tokens": {"value": 16411.0}, "meta_inference_completion_tokens": {"value": 1145.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032822}, "meta_inference_completion_cost": {"value": 0.001832}, "meta_eval_time": {"value": 40.235}, "meta_eval_prompt_tokens": {"value": 12500.0}, "meta_eval_completion_tokens": {"value": 4161.0}, "meta_eval_prompt_cost": {"value": 0.004}, "meta_eval_completion_cost": {"value": 0.00532608}}, "created": "2025-12-10T21:46:46.5492251Z"}
{"ref": "free-sound", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.789473684210526}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 18.83212}, "meta_inference_prompt_tokens": {"value": 13189.0}, "meta_inference_completion_tokens": {"value": 719.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026378}, "meta_inference_completion_cost": {"value": 0.0011504}, "meta_eval_time": {"value": 21.116}, "meta_eval_prompt_tokens": {"value": 8052.0}, "meta_eval_completion_tokens": {"value": 1806.0}, "meta_eval_prompt_cost": {"value": 0.00257664}, "meta_eval_completion_cost": {"value": 0.00231168}}, "created": "2025-12-10T21:46:47.1091875Z"}
{"ref": "free-sound", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.958333333333334}, "generation_factuality_f1": {"value": 0.441176470588235}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 24.949207}, "meta_inference_prompt_tokens": {"value": 13784.0}, "meta_inference_completion_tokens": {"value": 986.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027568}, "meta_inference_completion_cost": {"value": 0.0015776}, "meta_eval_time": {"value": 24.518}, "meta_eval_prompt_tokens": {"value": 9202.0}, "meta_eval_completion_tokens": {"value": 2637.0}, "meta_eval_prompt_cost": {"value": 0.00294464}, "meta_eval_completion_cost": {"value": 0.00337536}}, "created": "2025-12-10T21:46:47.2988567Z"}
{"ref": "formal-townhouse", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.935483870967742}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.349446}, "meta_inference_prompt_tokens": {"value": 11224.0}, "meta_inference_completion_tokens": {"value": 1199.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022448}, "meta_inference_completion_cost": {"value": 0.0019184}, "meta_eval_time": {"value": 28.536}, "meta_eval_prompt_tokens": {"value": 6150.0}, "meta_eval_completion_tokens": {"value": 2733.0}, "meta_eval_prompt_cost": {"value": 0.001968}, "meta_eval_completion_cost": {"value": 0.00349824}}, "created": "2025-12-10T21:46:48.1403488Z"}
{"ref": "feasible-pole", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.375}, "retrieval_mrr": {"value": 0.25}, "retrieval_dcg": {"value": 1.80102999566398}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.894736842105263}, "generation_factuality_precision": {"value": 0.80952380952381}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.230769230769231}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.531452}, "meta_inference_prompt_tokens": {"value": 13648.0}, "meta_inference_completion_tokens": {"value": 1610.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027296}, "meta_inference_completion_cost": {"value": 0.002576}, "meta_eval_time": {"value": 60.73}, "meta_eval_prompt_tokens": {"value": 10934.0}, "meta_eval_completion_tokens": {"value": 6288.0}, "meta_eval_prompt_cost": {"value": 0.00349888}, "meta_eval_completion_cost": {"value": 0.00804864}}, "created": "2025-12-10T21:46:48.251238Z"}
{"ref": "free-camembert", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.19047619047619}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.8023582360405}, "generation_faithfulness": {"value": 0.791666666666666}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.105263157894737}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0666666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 44.912095}, "meta_inference_prompt_tokens": {"value": 41291.0}, "meta_inference_completion_tokens": {"value": 2251.0}, "meta_inference_tool_call_count": {"value": 3.0}, "meta_inference_prompt_cost": {"value": 0.0082582}, "meta_inference_completion_cost": {"value": 0.0036016}, "meta_eval_time": {"value": 30.299}, "meta_eval_prompt_tokens": {"value": 10266.0}, "meta_eval_completion_tokens": {"value": 2883.0}, "meta_eval_prompt_cost": {"value": 0.00328512}, "meta_eval_completion_cost": {"value": 0.00369024}}, "created": "2025-12-10T21:46:48.9271042Z"}
{"ref": "frigid-siege", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.73461}, "meta_inference_prompt_tokens": {"value": 12515.0}, "meta_inference_completion_tokens": {"value": 925.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002503}, "meta_inference_completion_cost": {"value": 0.00148}, "meta_eval_time": {"value": 22.491}, "meta_eval_prompt_tokens": {"value": 7267.0}, "meta_eval_completion_tokens": {"value": 1752.0}, "meta_eval_prompt_cost": {"value": 0.00232544}, "meta_eval_completion_cost": {"value": 0.00224256}}, "created": "2025-12-10T21:46:49.0315011Z"}
{"ref": "frigid-siege", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.346557}, "meta_inference_prompt_tokens": {"value": 11115.0}, "meta_inference_completion_tokens": {"value": 766.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002223}, "meta_inference_completion_cost": {"value": 0.0012256}, "meta_eval_time": {"value": 15.058}, "meta_eval_prompt_tokens": {"value": 5812.0}, "meta_eval_completion_tokens": {"value": 1280.0}, "meta_eval_prompt_cost": {"value": 0.00185984}, "meta_eval_completion_cost": {"value": 0.0016384}}, "created": "2025-12-10T21:46:50.0120887Z"}
{"ref": "free-camembert", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.772727272727273}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.256231}, "meta_inference_prompt_tokens": {"value": 10247.0}, "meta_inference_completion_tokens": {"value": 1036.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020494}, "meta_inference_completion_cost": {"value": 0.0016576}, "meta_eval_time": {"value": 32.748}, "meta_eval_prompt_tokens": {"value": 5825.0}, "meta_eval_completion_tokens": {"value": 2634.0}, "meta_eval_prompt_cost": {"value": 0.001864}, "meta_eval_completion_cost": {"value": 0.00337152}}, "created": "2025-12-10T21:46:50.0566017Z"}
{"ref": "frigid-siege", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.78927}, "meta_inference_prompt_tokens": {"value": 12082.0}, "meta_inference_completion_tokens": {"value": 593.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024164}, "meta_inference_completion_cost": {"value": 0.0009488}, "meta_eval_time": {"value": 18.237}, "meta_eval_prompt_tokens": {"value": 7040.0}, "meta_eval_completion_tokens": {"value": 1603.0}, "meta_eval_prompt_cost": {"value": 0.0022528}, "meta_eval_completion_cost": {"value": 0.00205184}}, "created": "2025-12-10T21:46:51.1231366Z"}
{"ref": "free-camembert", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 0.918918918918919}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.349944}, "meta_inference_prompt_tokens": {"value": 10485.0}, "meta_inference_completion_tokens": {"value": 1265.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002097}, "meta_inference_completion_cost": {"value": 0.002024}, "meta_eval_time": {"value": 32.17}, "meta_eval_prompt_tokens": {"value": 6488.0}, "meta_eval_completion_tokens": {"value": 3298.0}, "meta_eval_prompt_cost": {"value": 0.00207616}, "meta_eval_completion_cost": {"value": 0.00422144}}, "created": "2025-12-10T21:46:52.1152848Z"}
{"ref": "free-omelette", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.96875}, "generation_factuality_f1": {"value": 0.214285714285714}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 30.446131}, "meta_inference_prompt_tokens": {"value": 10691.0}, "meta_inference_completion_tokens": {"value": 1403.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021382}, "meta_inference_completion_cost": {"value": 0.0022448}, "meta_eval_time": {"value": 33.665}, "meta_eval_prompt_tokens": {"value": 6538.0}, "meta_eval_completion_tokens": {"value": 3333.0}, "meta_eval_prompt_cost": {"value": 0.00209216}, "meta_eval_completion_cost": {"value": 0.00426624}}, "created": "2025-12-10T21:46:52.2539311Z"}
{"ref": "graceful-ambiance", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.386376}, "meta_inference_prompt_tokens": {"value": 4664.0}, "meta_inference_completion_tokens": {"value": 1018.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009328}, "meta_inference_completion_cost": {"value": 0.0016288}, "meta_eval_time": {"value": 0.002}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:52.2966567Z"}
{"ref": "graceful-ambiance", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.346923}, "meta_inference_prompt_tokens": {"value": 4638.0}, "meta_inference_completion_tokens": {"value": 1508.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009276}, "meta_inference_completion_cost": {"value": 0.0024128}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:52.3349175Z"}
{"ref": "frigid-siege", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.350533}, "meta_inference_prompt_tokens": {"value": 11381.0}, "meta_inference_completion_tokens": {"value": 730.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022762}, "meta_inference_completion_cost": {"value": 0.001168}, "meta_eval_time": {"value": 19.329}, "meta_eval_prompt_tokens": {"value": 6152.0}, "meta_eval_completion_tokens": {"value": 1513.0}, "meta_eval_prompt_cost": {"value": 0.00196864}, "meta_eval_completion_cost": {"value": 0.00193664}}, "created": "2025-12-10T21:46:52.3629779Z"}
{"ref": "frigid-siege", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.817072}, "meta_inference_prompt_tokens": {"value": 12187.0}, "meta_inference_completion_tokens": {"value": 744.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024374}, "meta_inference_completion_cost": {"value": 0.0011904}, "meta_eval_time": {"value": 18.11}, "meta_eval_prompt_tokens": {"value": 7004.0}, "meta_eval_completion_tokens": {"value": 1763.0}, "meta_eval_prompt_cost": {"value": 0.00224128}, "meta_eval_completion_cost": {"value": 0.00225664}}, "created": "2025-12-10T21:46:53.1241832Z"}
{"ref": "graceful-ambiance", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.06483}, "meta_inference_prompt_tokens": {"value": 2253.0}, "meta_inference_completion_tokens": {"value": 646.0}, "meta_inference_prompt_cost": {"value": 0.0004506}, "meta_inference_completion_cost": {"value": 0.0010336}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:52.3713973Z"}
{"ref": "free-sound", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.625}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 33.639061}, "meta_inference_prompt_tokens": {"value": 11509.0}, "meta_inference_completion_tokens": {"value": 1574.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023018}, "meta_inference_completion_cost": {"value": 0.0025184}, "meta_eval_time": {"value": 27.854}, "meta_eval_prompt_tokens": {"value": 6898.0}, "meta_eval_completion_tokens": {"value": 2334.0}, "meta_eval_prompt_cost": {"value": 0.00220736}, "meta_eval_completion_cost": {"value": 0.00298752}}, "created": "2025-12-10T21:46:53.1333021Z"}
{"ref": "graceful-ambiance", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.33681}, "meta_inference_prompt_tokens": {"value": 2253.0}, "meta_inference_completion_tokens": {"value": 458.0}, "meta_inference_prompt_cost": {"value": 0.0004506}, "meta_inference_completion_cost": {"value": 0.0007328}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:53.1567197Z"}
{"ref": "free-template", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.935483870967742}, "generation_factuality_f1": {"value": 0.436363636363636}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 32.470415}, "meta_inference_prompt_tokens": {"value": 13913.0}, "meta_inference_completion_tokens": {"value": 1458.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027826}, "meta_inference_completion_cost": {"value": 0.0023328}, "meta_eval_time": {"value": 33.158}, "meta_eval_prompt_tokens": {"value": 9730.0}, "meta_eval_completion_tokens": {"value": 3108.0}, "meta_eval_prompt_cost": {"value": 0.0031136}, "meta_eval_completion_cost": {"value": 0.00397824}}, "created": "2025-12-10T21:46:53.5292437Z"}
{"ref": "free-camembert", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.19047619047619}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.510321158810889}, "generation_faithfulness": {"value": 0.790697674418605}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.105263157894737}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 42.84981}, "meta_inference_prompt_tokens": {"value": 23249.0}, "meta_inference_completion_tokens": {"value": 2409.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0046498}, "meta_inference_completion_cost": {"value": 0.0038544}, "meta_eval_time": {"value": 38.324}, "meta_eval_prompt_tokens": {"value": 9250.0}, "meta_eval_completion_tokens": {"value": 3965.0}, "meta_eval_prompt_cost": {"value": 0.00296}, "meta_eval_completion_cost": {"value": 0.0050752}}, "created": "2025-12-10T21:46:54.195733Z"}
{"ref": "graceful-ambiance", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.653384}, "meta_inference_prompt_tokens": {"value": 4640.0}, "meta_inference_completion_tokens": {"value": 1009.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.000928}, "meta_inference_completion_cost": {"value": 0.0016144}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:46:54.24099Z"}
{"ref": "free-omelette", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.166666666666667}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 20.851561}, "meta_inference_prompt_tokens": {"value": 10693.0}, "meta_inference_completion_tokens": {"value": 912.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021386}, "meta_inference_completion_cost": {"value": 0.0014592}, "meta_eval_time": {"value": 31.486}, "meta_eval_prompt_tokens": {"value": 6252.0}, "meta_eval_completion_tokens": {"value": 3024.0}, "meta_eval_prompt_cost": {"value": 0.00200064}, "meta_eval_completion_cost": {"value": 0.00387072}}, "created": "2025-12-10T21:46:56.0763785Z"}
{"ref": "free-sound", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 21.245151}, "meta_inference_prompt_tokens": {"value": 13153.0}, "meta_inference_completion_tokens": {"value": 1144.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026306}, "meta_inference_completion_cost": {"value": 0.0018304}, "meta_eval_time": {"value": 22.389}, "meta_eval_prompt_tokens": {"value": 8448.0}, "meta_eval_completion_tokens": {"value": 2207.0}, "meta_eval_prompt_cost": {"value": 0.00270336}, "meta_eval_completion_cost": {"value": 0.00282496}}, "created": "2025-12-10T21:46:56.1381314Z"}
{"ref": "free-template", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.962962962962963}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.842106}, "meta_inference_prompt_tokens": {"value": 7372.0}, "meta_inference_completion_tokens": {"value": 1178.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0014744}, "meta_inference_completion_cost": {"value": 0.0018848}, "meta_eval_time": {"value": 27.625}, "meta_eval_prompt_tokens": {"value": 5289.0}, "meta_eval_completion_tokens": {"value": 2769.0}, "meta_eval_prompt_cost": {"value": 0.00169248}, "meta_eval_completion_cost": {"value": 0.00354432}}, "created": "2025-12-10T21:46:56.5110766Z"}
{"ref": "frozen-subfloor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.265884}, "meta_inference_prompt_tokens": {"value": 13024.0}, "meta_inference_completion_tokens": {"value": 1711.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026048}, "meta_inference_completion_cost": {"value": 0.0027376}, "meta_eval_time": {"value": 22.265}, "meta_eval_prompt_tokens": {"value": 7931.0}, "meta_eval_completion_tokens": {"value": 2309.0}, "meta_eval_prompt_cost": {"value": 0.00253792}, "meta_eval_completion_cost": {"value": 0.00295552}}, "created": "2025-12-10T21:46:57.7172326Z"}
{"ref": "free-omelette", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.948717948717949}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 26.66548}, "meta_inference_prompt_tokens": {"value": 10693.0}, "meta_inference_completion_tokens": {"value": 1457.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021386}, "meta_inference_completion_cost": {"value": 0.0023312}, "meta_eval_time": {"value": 37.188}, "meta_eval_prompt_tokens": {"value": 6532.0}, "meta_eval_completion_tokens": {"value": 3570.0}, "meta_eval_prompt_cost": {"value": 0.00209024}, "meta_eval_completion_cost": {"value": 0.0045696}}, "created": "2025-12-10T21:46:58.0466616Z"}
{"ref": "free-template", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.90625}, "generation_factuality_f1": {"value": 0.347826086956522}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 19.45264}, "meta_inference_prompt_tokens": {"value": 11855.0}, "meta_inference_completion_tokens": {"value": 1062.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002371}, "meta_inference_completion_cost": {"value": 0.0016992}, "meta_eval_time": {"value": 33.375}, "meta_eval_prompt_tokens": {"value": 7680.0}, "meta_eval_completion_tokens": {"value": 3246.0}, "meta_eval_prompt_cost": {"value": 0.0024576}, "meta_eval_completion_cost": {"value": 0.00415488}}, "created": "2025-12-10T21:46:58.6160442Z"}
{"ref": "flat-total", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.32}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 39.388927}, "meta_inference_prompt_tokens": {"value": 16316.0}, "meta_inference_completion_tokens": {"value": 1579.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032632}, "meta_inference_completion_cost": {"value": 0.0025264}, "meta_eval_time": {"value": 56.2}, "meta_eval_prompt_tokens": {"value": 13087.0}, "meta_eval_completion_tokens": {"value": 5410.0}, "meta_eval_prompt_cost": {"value": 0.00418784}, "meta_eval_completion_cost": {"value": 0.0069248}}, "created": "2025-12-10T21:47:01.0977057Z"}
{"ref": "free-omelette", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.971428571428571}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 24.278389}, "meta_inference_prompt_tokens": {"value": 11586.0}, "meta_inference_completion_tokens": {"value": 1259.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023172}, "meta_inference_completion_cost": {"value": 0.0020144}, "meta_eval_time": {"value": 41.36}, "meta_eval_prompt_tokens": {"value": 7410.0}, "meta_eval_completion_tokens": {"value": 3495.0}, "meta_eval_prompt_cost": {"value": 0.0023712}, "meta_eval_completion_cost": {"value": 0.0044736}}, "created": "2025-12-10T21:47:02.1537057Z"}
{"ref": "free-template", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.177777777777778}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 25.388357}, "meta_inference_prompt_tokens": {"value": 12566.0}, "meta_inference_completion_tokens": {"value": 1497.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025132}, "meta_inference_completion_cost": {"value": 0.0023952}, "meta_eval_time": {"value": 33.581}, "meta_eval_prompt_tokens": {"value": 8741.0}, "meta_eval_completion_tokens": {"value": 3321.0}, "meta_eval_prompt_cost": {"value": 0.00279712}, "meta_eval_completion_cost": {"value": 0.00425088}}, "created": "2025-12-10T21:47:02.846426Z"}
{"ref": "frozen-subfloor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.958333333333334}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 26.020488}, "meta_inference_prompt_tokens": {"value": 14097.0}, "meta_inference_completion_tokens": {"value": 1625.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028194}, "meta_inference_completion_cost": {"value": 0.0026}, "meta_eval_time": {"value": 27.143}, "meta_eval_prompt_tokens": {"value": 8661.0}, "meta_eval_completion_tokens": {"value": 2424.0}, "meta_eval_prompt_cost": {"value": 0.00277152}, "meta_eval_completion_cost": {"value": 0.00310272}}, "created": "2025-12-10T21:47:03.9940888Z"}
{"ref": "frozen-subfloor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.642857}, "meta_inference_prompt_tokens": {"value": 14473.0}, "meta_inference_completion_tokens": {"value": 1842.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028946}, "meta_inference_completion_cost": {"value": 0.0029472}, "meta_eval_time": {"value": 26.403}, "meta_eval_prompt_tokens": {"value": 9207.0}, "meta_eval_completion_tokens": {"value": 2356.0}, "meta_eval_prompt_cost": {"value": 0.00294624}, "meta_eval_completion_cost": {"value": 0.00301568}}, "created": "2025-12-10T21:47:04.1408431Z"}
{"ref": "frozen-subfloor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 39.770819}, "meta_inference_prompt_tokens": {"value": 12908.0}, "meta_inference_completion_tokens": {"value": 1985.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025816}, "meta_inference_completion_cost": {"value": 0.003176}, "meta_eval_time": {"value": 29.914}, "meta_eval_prompt_tokens": {"value": 7884.0}, "meta_eval_completion_tokens": {"value": 2705.0}, "meta_eval_prompt_cost": {"value": 0.00252288}, "meta_eval_completion_cost": {"value": 0.0034624}}, "created": "2025-12-10T21:47:05.888209Z"}
{"ref": "flat-total", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 29.473169}, "meta_inference_prompt_tokens": {"value": 14760.0}, "meta_inference_completion_tokens": {"value": 1795.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002952}, "meta_inference_completion_cost": {"value": 0.002872}, "meta_eval_time": {"value": 61.52}, "meta_eval_prompt_tokens": {"value": 11779.0}, "meta_eval_completion_tokens": {"value": 5969.0}, "meta_eval_prompt_cost": {"value": 0.00376928}, "meta_eval_completion_cost": {"value": 0.00764032}}, "created": "2025-12-10T21:47:07.0905557Z"}
{"ref": "free-template", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.533333333333333}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 30.505392}, "meta_inference_prompt_tokens": {"value": 12062.0}, "meta_inference_completion_tokens": {"value": 1745.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024124}, "meta_inference_completion_cost": {"value": 0.002792}, "meta_eval_time": {"value": 41.627}, "meta_eval_prompt_tokens": {"value": 8653.0}, "meta_eval_completion_tokens": {"value": 4033.0}, "meta_eval_prompt_cost": {"value": 0.00276896}, "meta_eval_completion_cost": {"value": 0.00516224}}, "created": "2025-12-10T21:47:07.7494307Z"}
{"ref": "feasible-pole", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.375}, "retrieval_mrr": {"value": 0.25}, "retrieval_dcg": {"value": 1.80102999566398}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.230769230769231}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.259068}, "meta_inference_prompt_tokens": {"value": 13651.0}, "meta_inference_completion_tokens": {"value": 1587.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027302}, "meta_inference_completion_cost": {"value": 0.0025392}, "meta_eval_time": {"value": 81.549}, "meta_eval_prompt_tokens": {"value": 21949.0}, "meta_eval_completion_tokens": {"value": 7979.0}, "meta_eval_prompt_cost": {"value": 0.00702368}, "meta_eval_completion_cost": {"value": 0.01021312}}, "created": "2025-12-10T21:47:08.9533078Z"}
{"ref": "glad-dragster", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.347826086956522}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 24.837955}, "meta_inference_prompt_tokens": {"value": 10617.0}, "meta_inference_completion_tokens": {"value": 1434.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021234}, "meta_inference_completion_cost": {"value": 0.0022944}, "meta_eval_time": {"value": 31.109}, "meta_eval_prompt_tokens": {"value": 6045.0}, "meta_eval_completion_tokens": {"value": 2968.0}, "meta_eval_prompt_cost": {"value": 0.0019344}, "meta_eval_completion_cost": {"value": 0.00379904}}, "created": "2025-12-10T21:47:09.4384066Z"}
{"ref": "glad-hip", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.361111111111111}, "retrieval_dcg": {"value": 1.33324743759173}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 36.339475}, "meta_inference_prompt_tokens": {"value": 14138.0}, "meta_inference_completion_tokens": {"value": 1651.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028276}, "meta_inference_completion_cost": {"value": 0.0026416}, "meta_eval_time": {"value": 28.204}, "meta_eval_prompt_tokens": {"value": 9100.0}, "meta_eval_completion_tokens": {"value": 2932.0}, "meta_eval_prompt_cost": {"value": 0.002912}, "meta_eval_completion_cost": {"value": 0.00375296}}, "created": "2025-12-10T21:47:10.1237506Z"}
{"ref": "gourmet-set", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.550787}, "meta_inference_prompt_tokens": {"value": 13914.0}, "meta_inference_completion_tokens": {"value": 1016.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027828}, "meta_inference_completion_cost": {"value": 0.0016256}, "meta_eval_time": {"value": 23.091}, "meta_eval_prompt_tokens": {"value": 8025.0}, "meta_eval_completion_tokens": {"value": 2011.0}, "meta_eval_prompt_cost": {"value": 0.002568}, "meta_eval_completion_cost": {"value": 0.00257408}}, "created": "2025-12-10T21:47:11.3912604Z"}
{"ref": "gourmet-set", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.722222222222222}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.681941}, "meta_inference_prompt_tokens": {"value": 13912.0}, "meta_inference_completion_tokens": {"value": 949.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027824}, "meta_inference_completion_cost": {"value": 0.0015184}, "meta_eval_time": {"value": 21.637}, "meta_eval_prompt_tokens": {"value": 8152.0}, "meta_eval_completion_tokens": {"value": 2154.0}, "meta_eval_prompt_cost": {"value": 0.00260864}, "meta_eval_completion_cost": {"value": 0.00275712}}, "created": "2025-12-10T21:47:11.7343125Z"}
{"ref": "gourmet-set", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.332736}, "meta_inference_prompt_tokens": {"value": 12769.0}, "meta_inference_completion_tokens": {"value": 696.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025538}, "meta_inference_completion_cost": {"value": 0.0011136}, "meta_eval_time": {"value": 19.987}, "meta_eval_prompt_tokens": {"value": 6994.0}, "meta_eval_completion_tokens": {"value": 1992.0}, "meta_eval_prompt_cost": {"value": 0.00223808}, "meta_eval_completion_cost": {"value": 0.00254976}}, "created": "2025-12-10T21:47:12.1514505Z"}
{"ref": "gourmet-set", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.138291}, "meta_inference_prompt_tokens": {"value": 13698.0}, "meta_inference_completion_tokens": {"value": 807.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027396}, "meta_inference_completion_cost": {"value": 0.0012912}, "meta_eval_time": {"value": 24.509}, "meta_eval_prompt_tokens": {"value": 8147.0}, "meta_eval_completion_tokens": {"value": 2287.0}, "meta_eval_prompt_cost": {"value": 0.00260704}, "meta_eval_completion_cost": {"value": 0.00292736}}, "created": "2025-12-10T21:47:12.69002Z"}
{"ref": "greasy-image", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.687466}, "meta_inference_prompt_tokens": {"value": 10720.0}, "meta_inference_completion_tokens": {"value": 1018.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002144}, "meta_inference_completion_cost": {"value": 0.0016288}, "meta_eval_time": {"value": 19.642}, "meta_eval_prompt_tokens": {"value": 5670.0}, "meta_eval_completion_tokens": {"value": 1867.0}, "meta_eval_prompt_cost": {"value": 0.0018144}, "meta_eval_completion_cost": {"value": 0.00238976}}, "created": "2025-12-10T21:47:12.8472034Z"}
{"ref": "gold-trap", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.51063829787234}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 26.492188}, "meta_inference_prompt_tokens": {"value": 12811.0}, "meta_inference_completion_tokens": {"value": 1669.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025622}, "meta_inference_completion_cost": {"value": 0.0026704}, "meta_eval_time": {"value": 26.453}, "meta_eval_prompt_tokens": {"value": 8448.0}, "meta_eval_completion_tokens": {"value": 2859.0}, "meta_eval_prompt_cost": {"value": 0.00270336}, "meta_eval_completion_cost": {"value": 0.00365952}}, "created": "2025-12-10T21:47:13.7932878Z"}
{"ref": "greasy-image", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.77717}, "meta_inference_prompt_tokens": {"value": 10832.0}, "meta_inference_completion_tokens": {"value": 1103.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021664}, "meta_inference_completion_cost": {"value": 0.0017648}, "meta_eval_time": {"value": 18.134}, "meta_eval_prompt_tokens": {"value": 5658.0}, "meta_eval_completion_tokens": {"value": 1716.0}, "meta_eval_prompt_cost": {"value": 0.00181056}, "meta_eval_completion_cost": {"value": 0.00219648}}, "created": "2025-12-10T21:47:14.2597219Z"}
{"ref": "glad-hip", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.32047027401281}, "generation_faithfulness": {"value": 0.948717948717949}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 40.0238}, "meta_inference_prompt_tokens": {"value": 14006.0}, "meta_inference_completion_tokens": {"value": 1847.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028012}, "meta_inference_completion_cost": {"value": 0.0029552}, "meta_eval_time": {"value": 34.568}, "meta_eval_prompt_tokens": {"value": 9295.0}, "meta_eval_completion_tokens": {"value": 3391.0}, "meta_eval_prompt_cost": {"value": 0.0029744}, "meta_eval_completion_cost": {"value": 0.00434048}}, "created": "2025-12-10T21:47:14.5794747Z"}
{"ref": "greasy-image", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.501918}, "meta_inference_prompt_tokens": {"value": 10754.0}, "meta_inference_completion_tokens": {"value": 1780.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021508}, "meta_inference_completion_cost": {"value": 0.002848}, "meta_eval_time": {"value": 25.766}, "meta_eval_prompt_tokens": {"value": 5964.0}, "meta_eval_completion_tokens": {"value": 2245.0}, "meta_eval_prompt_cost": {"value": 0.00190848}, "meta_eval_completion_cost": {"value": 0.0028736}}, "created": "2025-12-10T21:47:14.8358324Z"}
{"ref": "glad-dragster", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.347826086956522}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 20.758895}, "meta_inference_prompt_tokens": {"value": 10589.0}, "meta_inference_completion_tokens": {"value": 1046.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021178}, "meta_inference_completion_cost": {"value": 0.0016736}, "meta_eval_time": {"value": 29.575}, "meta_eval_prompt_tokens": {"value": 6052.0}, "meta_eval_completion_tokens": {"value": 2794.0}, "meta_eval_prompt_cost": {"value": 0.00193664}, "meta_eval_completion_cost": {"value": 0.00357632}}, "created": "2025-12-10T21:47:15.7244359Z"}
{"ref": "glad-hip", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.20231768402027}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.306474}, "meta_inference_prompt_tokens": {"value": 13882.0}, "meta_inference_completion_tokens": {"value": 1900.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027764}, "meta_inference_completion_cost": {"value": 0.00304}, "meta_eval_time": {"value": 30.03}, "meta_eval_prompt_tokens": {"value": 8892.0}, "meta_eval_completion_tokens": {"value": 2886.0}, "meta_eval_prompt_cost": {"value": 0.00284544}, "meta_eval_completion_cost": {"value": 0.00369408}}, "created": "2025-12-10T21:47:17.1867271Z"}
{"ref": "glad-hip", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.31752936530793}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.786926}, "meta_inference_prompt_tokens": {"value": 12883.0}, "meta_inference_completion_tokens": {"value": 1568.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025766}, "meta_inference_completion_cost": {"value": 0.0025088}, "meta_eval_time": {"value": 34.284}, "meta_eval_prompt_tokens": {"value": 8339.0}, "meta_eval_completion_tokens": {"value": 3308.0}, "meta_eval_prompt_cost": {"value": 0.00266848}, "meta_eval_completion_cost": {"value": 0.00423424}}, "created": "2025-12-10T21:47:17.7495618Z"}
{"ref": "gritty-volt", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.695958}, "meta_inference_prompt_tokens": {"value": 13318.0}, "meta_inference_completion_tokens": {"value": 766.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026636}, "meta_inference_completion_cost": {"value": 0.0012256}, "meta_eval_time": {"value": 20.419}, "meta_eval_prompt_tokens": {"value": 8229.0}, "meta_eval_completion_tokens": {"value": 1951.0}, "meta_eval_prompt_cost": {"value": 0.00263328}, "meta_eval_completion_cost": {"value": 0.00249728}}, "created": "2025-12-10T21:47:18.5064588Z"}
{"ref": "greasy-image", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.430739}, "meta_inference_prompt_tokens": {"value": 10794.0}, "meta_inference_completion_tokens": {"value": 1245.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021588}, "meta_inference_completion_cost": {"value": 0.001992}, "meta_eval_time": {"value": 25.176}, "meta_eval_prompt_tokens": {"value": 6209.0}, "meta_eval_completion_tokens": {"value": 2509.0}, "meta_eval_prompt_cost": {"value": 0.00198688}, "meta_eval_completion_cost": {"value": 0.00321152}}, "created": "2025-12-10T21:47:18.7455051Z"}
{"ref": "greasy-image", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.153662}, "meta_inference_prompt_tokens": {"value": 10548.0}, "meta_inference_completion_tokens": {"value": 1567.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021096}, "meta_inference_completion_cost": {"value": 0.0025072}, "meta_eval_time": {"value": 26.622}, "meta_eval_prompt_tokens": {"value": 5926.0}, "meta_eval_completion_tokens": {"value": 2634.0}, "meta_eval_prompt_cost": {"value": 0.00189632}, "meta_eval_completion_cost": {"value": 0.00337152}}, "created": "2025-12-10T21:47:19.8274564Z"}
{"ref": "grizzled-kern", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.3}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 17.635015}, "meta_inference_prompt_tokens": {"value": 11455.0}, "meta_inference_completion_tokens": {"value": 916.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002291}, "meta_inference_completion_cost": {"value": 0.0014656}, "meta_eval_time": {"value": 17.7}, "meta_eval_prompt_tokens": {"value": 6409.0}, "meta_eval_completion_tokens": {"value": 1775.0}, "meta_eval_prompt_cost": {"value": 0.00205088}, "meta_eval_completion_cost": {"value": 0.002272}}, "created": "2025-12-10T21:47:20.5844269Z"}
{"ref": "gritty-ray", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.958333333333334}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 33.824526}, "meta_inference_prompt_tokens": {"value": 10602.0}, "meta_inference_completion_tokens": {"value": 1295.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021204}, "meta_inference_completion_cost": {"value": 0.002072}, "meta_eval_time": {"value": 27.4}, "meta_eval_prompt_tokens": {"value": 6232.0}, "meta_eval_completion_tokens": {"value": 2615.0}, "meta_eval_prompt_cost": {"value": 0.00199424}, "meta_eval_completion_cost": {"value": 0.0033472}}, "created": "2025-12-10T21:47:20.6240093Z"}
{"ref": "gritty-volt", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.391124}, "meta_inference_prompt_tokens": {"value": 13338.0}, "meta_inference_completion_tokens": {"value": 946.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026676}, "meta_inference_completion_cost": {"value": 0.0015136}, "meta_eval_time": {"value": 24.294}, "meta_eval_prompt_tokens": {"value": 8658.0}, "meta_eval_completion_tokens": {"value": 2386.0}, "meta_eval_prompt_cost": {"value": 0.00277056}, "meta_eval_completion_cost": {"value": 0.00305408}}, "created": "2025-12-10T21:47:20.8487918Z"}
{"ref": "glad-hip", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.22018614056787}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.666266}, "meta_inference_prompt_tokens": {"value": 14809.0}, "meta_inference_completion_tokens": {"value": 1493.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029618}, "meta_inference_completion_cost": {"value": 0.0023888}, "meta_eval_time": {"value": 33.729}, "meta_eval_prompt_tokens": {"value": 9794.0}, "meta_eval_completion_tokens": {"value": 3094.0}, "meta_eval_prompt_cost": {"value": 0.00313408}, "meta_eval_completion_cost": {"value": 0.00396032}}, "created": "2025-12-10T21:47:20.8622241Z"}
{"ref": "gold-trap", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.785714285714286}, "generation_factuality_f1": {"value": 0.740740740740741}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 25.100336}, "meta_inference_prompt_tokens": {"value": 12941.0}, "meta_inference_completion_tokens": {"value": 1254.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025882}, "meta_inference_completion_cost": {"value": 0.0020064}, "meta_eval_time": {"value": 31.029}, "meta_eval_prompt_tokens": {"value": 8371.0}, "meta_eval_completion_tokens": {"value": 3110.0}, "meta_eval_prompt_cost": {"value": 0.00267872}, "meta_eval_completion_cost": {"value": 0.0039808}}, "created": "2025-12-10T21:47:21.0808276Z"}
{"ref": "gritty-volt", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.348864}, "meta_inference_prompt_tokens": {"value": 13314.0}, "meta_inference_completion_tokens": {"value": 775.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026628}, "meta_inference_completion_cost": {"value": 0.00124}, "meta_eval_time": {"value": 19.29}, "meta_eval_prompt_tokens": {"value": 8296.0}, "meta_eval_completion_tokens": {"value": 1914.0}, "meta_eval_prompt_cost": {"value": 0.00265472}, "meta_eval_completion_cost": {"value": 0.00244992}}, "created": "2025-12-10T21:47:21.4871884Z"}
{"ref": "glad-dragster", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 27.426939}, "meta_inference_prompt_tokens": {"value": 11016.0}, "meta_inference_completion_tokens": {"value": 1377.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022032}, "meta_inference_completion_cost": {"value": 0.0022032}, "meta_eval_time": {"value": 39.846}, "meta_eval_prompt_tokens": {"value": 7279.0}, "meta_eval_completion_tokens": {"value": 3640.0}, "meta_eval_prompt_cost": {"value": 0.00232928}, "meta_eval_completion_cost": {"value": 0.0046592}}, "created": "2025-12-10T21:47:21.5631395Z"}
{"ref": "glad-dragster", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.32}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 23.573368}, "meta_inference_prompt_tokens": {"value": 11196.0}, "meta_inference_completion_tokens": {"value": 1572.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022392}, "meta_inference_completion_cost": {"value": 0.0025152}, "meta_eval_time": {"value": 37.489}, "meta_eval_prompt_tokens": {"value": 7298.0}, "meta_eval_completion_tokens": {"value": 3528.0}, "meta_eval_prompt_cost": {"value": 0.00233536}, "meta_eval_completion_cost": {"value": 0.00451584}}, "created": "2025-12-10T21:47:22.0161464Z"}
{"ref": "gritty-volt", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.894736842105263}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.60135}, "meta_inference_prompt_tokens": {"value": 13337.0}, "meta_inference_completion_tokens": {"value": 973.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026674}, "meta_inference_completion_cost": {"value": 0.0015568}, "meta_eval_time": {"value": 25.805}, "meta_eval_prompt_tokens": {"value": 8341.0}, "meta_eval_completion_tokens": {"value": 2223.0}, "meta_eval_prompt_cost": {"value": 0.00266912}, "meta_eval_completion_cost": {"value": 0.00284544}}, "created": "2025-12-10T21:47:24.5143495Z"}
{"ref": "gold-trap", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 24.237925}, "meta_inference_prompt_tokens": {"value": 12535.0}, "meta_inference_completion_tokens": {"value": 1166.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002507}, "meta_inference_completion_cost": {"value": 0.0018656}, "meta_eval_time": {"value": 34.026}, "meta_eval_prompt_tokens": {"value": 8247.0}, "meta_eval_completion_tokens": {"value": 3062.0}, "meta_eval_prompt_cost": {"value": 0.00263904}, "meta_eval_completion_cost": {"value": 0.00391936}}, "created": "2025-12-10T21:47:25.1877567Z"}
{"ref": "gold-trap", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.962962962962963}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 21.992787}, "meta_inference_prompt_tokens": {"value": 12791.0}, "meta_inference_completion_tokens": {"value": 1125.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025582}, "meta_inference_completion_cost": {"value": 0.0018}, "meta_eval_time": {"value": 31.239}, "meta_eval_prompt_tokens": {"value": 8412.0}, "meta_eval_completion_tokens": {"value": 2945.0}, "meta_eval_prompt_cost": {"value": 0.00269184}, "meta_eval_completion_cost": {"value": 0.0037696}}, "created": "2025-12-10T21:47:25.5280713Z"}
{"ref": "gold-trap", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.727272727272727}, "generation_factuality_f1": {"value": 0.754716981132076}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 24.865573}, "meta_inference_prompt_tokens": {"value": 12051.0}, "meta_inference_completion_tokens": {"value": 1251.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024102}, "meta_inference_completion_cost": {"value": 0.0020016}, "meta_eval_time": {"value": 36.689}, "meta_eval_prompt_tokens": {"value": 7990.0}, "meta_eval_completion_tokens": {"value": 3589.0}, "meta_eval_prompt_cost": {"value": 0.0025568}, "meta_eval_completion_cost": {"value": 0.00459392}}, "created": "2025-12-10T21:47:25.6777743Z"}
{"ref": "gritty-volt", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.911207}, "meta_inference_prompt_tokens": {"value": 13316.0}, "meta_inference_completion_tokens": {"value": 910.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026632}, "meta_inference_completion_cost": {"value": 0.001456}, "meta_eval_time": {"value": 25.565}, "meta_eval_prompt_tokens": {"value": 8695.0}, "meta_eval_completion_tokens": {"value": 2558.0}, "meta_eval_prompt_cost": {"value": 0.0027824}, "meta_eval_completion_cost": {"value": 0.00327424}}, "created": "2025-12-10T21:47:26.7050749Z"}
{"ref": "humid-candy-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.666913}, "meta_inference_prompt_tokens": {"value": 2252.0}, "meta_inference_completion_tokens": {"value": 1182.0}, "meta_inference_prompt_cost": {"value": 0.0004504}, "meta_inference_completion_cost": {"value": 0.0018912}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:47:26.7436169Z"}
{"ref": "humid-candy-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.010448}, "meta_inference_prompt_tokens": {"value": 11445.0}, "meta_inference_completion_tokens": {"value": 1270.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002289}, "meta_inference_completion_cost": {"value": 0.002032}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:47:26.7776514Z"}
{"ref": "gourmet-set", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.869565217391304}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.609449}, "meta_inference_prompt_tokens": {"value": 13693.0}, "meta_inference_completion_tokens": {"value": 903.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027386}, "meta_inference_completion_cost": {"value": 0.0014448}, "meta_eval_time": {"value": 30.625}, "meta_eval_prompt_tokens": {"value": 8100.0}, "meta_eval_completion_tokens": {"value": 2443.0}, "meta_eval_prompt_cost": {"value": 0.002592}, "meta_eval_completion_cost": {"value": 0.00312704}}, "created": "2025-12-10T21:47:26.8157887Z"}
{"ref": "humid-candy-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.605165}, "meta_inference_prompt_tokens": {"value": 2252.0}, "meta_inference_completion_tokens": {"value": 582.0}, "meta_inference_prompt_cost": {"value": 0.0004504}, "meta_inference_completion_cost": {"value": 0.0009312}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:47:26.8198847Z"}
{"ref": "gritty-ray", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 25.819158}, "meta_inference_prompt_tokens": {"value": 10274.0}, "meta_inference_completion_tokens": {"value": 1244.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020548}, "meta_inference_completion_cost": {"value": 0.0019904}, "meta_eval_time": {"value": 34.453}, "meta_eval_prompt_tokens": {"value": 6284.0}, "meta_eval_completion_tokens": {"value": 3245.0}, "meta_eval_prompt_cost": {"value": 0.00201088}, "meta_eval_completion_cost": {"value": 0.0041536}}, "created": "2025-12-10T21:47:27.7133813Z"}
{"ref": "humid-candy-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.730342}, "meta_inference_prompt_tokens": {"value": 11445.0}, "meta_inference_completion_tokens": {"value": 1800.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002289}, "meta_inference_completion_cost": {"value": 0.00288}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:47:27.7482672Z"}
{"ref": "glad-dragster", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 26.77585}, "meta_inference_prompt_tokens": {"value": 11142.0}, "meta_inference_completion_tokens": {"value": 1531.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022284}, "meta_inference_completion_cost": {"value": 0.0024496}, "meta_eval_time": {"value": 49.899}, "meta_eval_prompt_tokens": {"value": 7208.0}, "meta_eval_completion_tokens": {"value": 3734.0}, "meta_eval_prompt_cost": {"value": 0.00230656}, "meta_eval_completion_cost": {"value": 0.00477952}}, "created": "2025-12-10T21:47:28.2048024Z"}
{"ref": "grizzled-kern", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.785714285714286}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.897686}, "meta_inference_prompt_tokens": {"value": 10947.0}, "meta_inference_completion_tokens": {"value": 955.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021894}, "meta_inference_completion_cost": {"value": 0.001528}, "meta_eval_time": {"value": 19.611}, "meta_eval_prompt_tokens": {"value": 5728.0}, "meta_eval_completion_tokens": {"value": 1577.0}, "meta_eval_prompt_cost": {"value": 0.00183296}, "meta_eval_completion_cost": {"value": 0.00201856}}, "created": "2025-12-10T21:47:31.8024216Z"}
{"ref": "gritty-ray", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.766666666666667}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 27.694459}, "meta_inference_prompt_tokens": {"value": 9926.0}, "meta_inference_completion_tokens": {"value": 1387.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019852}, "meta_inference_completion_cost": {"value": 0.0022192}, "meta_eval_time": {"value": 31.435}, "meta_eval_prompt_tokens": {"value": 5852.0}, "meta_eval_completion_tokens": {"value": 3096.0}, "meta_eval_prompt_cost": {"value": 0.00187264}, "meta_eval_completion_cost": {"value": 0.00396288}}, "created": "2025-12-10T21:47:35.4747602Z"}
{"ref": "humane-taping", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.789473684210526}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.730851}, "meta_inference_prompt_tokens": {"value": 11504.0}, "meta_inference_completion_tokens": {"value": 1011.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023008}, "meta_inference_completion_cost": {"value": 0.0016176}, "meta_eval_time": {"value": 20.836}, "meta_eval_prompt_tokens": {"value": 6340.0}, "meta_eval_completion_tokens": {"value": 1988.0}, "meta_eval_prompt_cost": {"value": 0.0020288}, "meta_eval_completion_cost": {"value": 0.00254464}}, "created": "2025-12-10T21:47:36.6007513Z"}
{"ref": "grizzled-kern", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.931034482758621}, "generation_factuality_f1": {"value": 0.171428571428571}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 21.182248}, "meta_inference_prompt_tokens": {"value": 10405.0}, "meta_inference_completion_tokens": {"value": 1235.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002081}, "meta_inference_completion_cost": {"value": 0.001976}, "meta_eval_time": {"value": 30.252}, "meta_eval_prompt_tokens": {"value": 6114.0}, "meta_eval_completion_tokens": {"value": 3009.0}, "meta_eval_prompt_cost": {"value": 0.00195648}, "meta_eval_completion_cost": {"value": 0.00385152}}, "created": "2025-12-10T21:47:37.3819664Z"}
{"ref": "humane-taping", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.575355}, "meta_inference_prompt_tokens": {"value": 11515.0}, "meta_inference_completion_tokens": {"value": 815.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002303}, "meta_inference_completion_cost": {"value": 0.001304}, "meta_eval_time": {"value": 16.766}, "meta_eval_prompt_tokens": {"value": 6203.0}, "meta_eval_completion_tokens": {"value": 1411.0}, "meta_eval_prompt_cost": {"value": 0.00198496}, "meta_eval_completion_cost": {"value": 0.00180608}}, "created": "2025-12-10T21:47:37.7179499Z"}
{"ref": "gritty-ray", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.72972972972973}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 30.479325}, "meta_inference_prompt_tokens": {"value": 10194.0}, "meta_inference_completion_tokens": {"value": 1453.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020388}, "meta_inference_completion_cost": {"value": 0.0023248}, "meta_eval_time": {"value": 39.983}, "meta_eval_prompt_tokens": {"value": 6625.0}, "meta_eval_completion_tokens": {"value": 3770.0}, "meta_eval_prompt_cost": {"value": 0.00212}, "meta_eval_completion_cost": {"value": 0.0048256}}, "created": "2025-12-10T21:47:37.7385288Z"}
{"ref": "gritty-ray", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 25.807416}, "meta_inference_prompt_tokens": {"value": 9775.0}, "meta_inference_completion_tokens": {"value": 1554.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001955}, "meta_inference_completion_cost": {"value": 0.0024864}, "meta_eval_time": {"value": 29.425}, "meta_eval_prompt_tokens": {"value": 5688.0}, "meta_eval_completion_tokens": {"value": 2740.0}, "meta_eval_prompt_cost": {"value": 0.00182016}, "meta_eval_completion_cost": {"value": 0.0035072}}, "created": "2025-12-10T21:47:38.908792Z"}
{"ref": "humane-taping", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.818181818181818}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.62889}, "meta_inference_prompt_tokens": {"value": 10381.0}, "meta_inference_completion_tokens": {"value": 789.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020762}, "meta_inference_completion_cost": {"value": 0.0012624}, "meta_eval_time": {"value": 13.704}, "meta_eval_prompt_tokens": {"value": 5020.0}, "meta_eval_completion_tokens": {"value": 1232.0}, "meta_eval_prompt_cost": {"value": 0.0016064}, "meta_eval_completion_cost": {"value": 0.00157696}}, "created": "2025-12-10T21:47:39.4184464Z"}
{"ref": "humid-candy-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.8981}, "meta_inference_prompt_tokens": {"value": 2252.0}, "meta_inference_completion_tokens": {"value": 653.0}, "meta_inference_prompt_cost": {"value": 0.0004504}, "meta_inference_completion_cost": {"value": 0.0010448}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:47:39.4575117Z"}
{"ref": "heartless-circuit", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.266666666666667}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 23.593128}, "meta_inference_prompt_tokens": {"value": 10141.0}, "meta_inference_completion_tokens": {"value": 1395.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020282}, "meta_inference_completion_cost": {"value": 0.002232}, "meta_eval_time": {"value": 30.187}, "meta_eval_prompt_tokens": {"value": 6170.0}, "meta_eval_completion_tokens": {"value": 3118.0}, "meta_eval_prompt_cost": {"value": 0.0019744}, "meta_eval_completion_cost": {"value": 0.00399104}}, "created": "2025-12-10T21:47:40.3571226Z"}
{"ref": "humane-taping", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.818181818181818}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.410833}, "meta_inference_prompt_tokens": {"value": 11317.0}, "meta_inference_completion_tokens": {"value": 898.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022634}, "meta_inference_completion_cost": {"value": 0.0014368}, "meta_eval_time": {"value": 15.088}, "meta_eval_prompt_tokens": {"value": 5997.0}, "meta_eval_completion_tokens": {"value": 1401.0}, "meta_eval_prompt_cost": {"value": 0.00191904}, "meta_eval_completion_cost": {"value": 0.00179328}}, "created": "2025-12-10T21:47:40.6551254Z"}
{"ref": "humane-taping", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.705696}, "meta_inference_prompt_tokens": {"value": 10563.0}, "meta_inference_completion_tokens": {"value": 1348.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021126}, "meta_inference_completion_cost": {"value": 0.0021568}, "meta_eval_time": {"value": 16.117}, "meta_eval_prompt_tokens": {"value": 5327.0}, "meta_eval_completion_tokens": {"value": 1495.0}, "meta_eval_prompt_cost": {"value": 0.00170464}, "meta_eval_completion_cost": {"value": 0.0019136}}, "created": "2025-12-10T21:47:42.9729355Z"}
{"ref": "grizzled-razorbill", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.32}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 26.166626}, "meta_inference_prompt_tokens": {"value": 12325.0}, "meta_inference_completion_tokens": {"value": 1411.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002465}, "meta_inference_completion_cost": {"value": 0.0022576}, "meta_eval_time": {"value": 38.9}, "meta_eval_prompt_tokens": {"value": 8713.0}, "meta_eval_completion_tokens": {"value": 3654.0}, "meta_eval_prompt_cost": {"value": 0.00278816}, "meta_eval_completion_cost": {"value": 0.00467712}}, "created": "2025-12-10T21:47:43.0814574Z"}
{"ref": "hoary-travel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.622398159651221}, "generation_faithfulness": {"value": 0.954545454545454}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.552919}, "meta_inference_prompt_tokens": {"value": 13776.0}, "meta_inference_completion_tokens": {"value": 1308.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027552}, "meta_inference_completion_cost": {"value": 0.0020928}, "meta_eval_time": {"value": 28.803}, "meta_eval_prompt_tokens": {"value": 9379.0}, "meta_eval_completion_tokens": {"value": 2602.0}, "meta_eval_prompt_cost": {"value": 0.00300128}, "meta_eval_completion_cost": {"value": 0.00333056}}, "created": "2025-12-10T21:47:43.0996708Z"}
{"ref": "hoary-travel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.801029995663981}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.10361}, "meta_inference_prompt_tokens": {"value": 12218.0}, "meta_inference_completion_tokens": {"value": 950.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024436}, "meta_inference_completion_cost": {"value": 0.00152}, "meta_eval_time": {"value": 28.604}, "meta_eval_prompt_tokens": {"value": 7359.0}, "meta_eval_completion_tokens": {"value": 2504.0}, "meta_eval_prompt_cost": {"value": 0.00235488}, "meta_eval_completion_cost": {"value": 0.00320512}}, "created": "2025-12-10T21:47:43.4756378Z"}
{"ref": "hoary-travel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.746141434859122}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.857937}, "meta_inference_prompt_tokens": {"value": 11395.0}, "meta_inference_completion_tokens": {"value": 856.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002279}, "meta_inference_completion_cost": {"value": 0.0013696}, "meta_eval_time": {"value": 26.004}, "meta_eval_prompt_tokens": {"value": 6856.0}, "meta_eval_completion_tokens": {"value": 2616.0}, "meta_eval_prompt_cost": {"value": 0.00219392}, "meta_eval_completion_cost": {"value": 0.00334848}}, "created": "2025-12-10T21:47:44.5439738Z"}
{"ref": "heartless-circuit", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.935483870967742}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 25.022369}, "meta_inference_prompt_tokens": {"value": 10348.0}, "meta_inference_completion_tokens": {"value": 1468.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020696}, "meta_inference_completion_cost": {"value": 0.0023488}, "meta_eval_time": {"value": 32.053}, "meta_eval_prompt_tokens": {"value": 6410.0}, "meta_eval_completion_tokens": {"value": 3130.0}, "meta_eval_prompt_cost": {"value": 0.0020512}, "meta_eval_completion_cost": {"value": 0.0040064}}, "created": "2025-12-10T21:47:44.7860538Z"}
{"ref": "heartless-circuit", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 26.328941}, "meta_inference_prompt_tokens": {"value": 10026.0}, "meta_inference_completion_tokens": {"value": 1561.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020052}, "meta_inference_completion_cost": {"value": 0.0024976}, "meta_eval_time": {"value": 39.344}, "meta_eval_prompt_tokens": {"value": 6504.0}, "meta_eval_completion_tokens": {"value": 3756.0}, "meta_eval_prompt_cost": {"value": 0.00208128}, "meta_eval_completion_cost": {"value": 0.00480768}}, "created": "2025-12-10T21:47:45.2790187Z"}
{"ref": "grizzled-kern", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.387096774193548}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.111111111111111}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 22.952441}, "meta_inference_prompt_tokens": {"value": 9691.0}, "meta_inference_completion_tokens": {"value": 1444.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019382}, "meta_inference_completion_cost": {"value": 0.0023104}, "meta_eval_time": {"value": 31.441}, "meta_eval_prompt_tokens": {"value": 5578.0}, "meta_eval_completion_tokens": {"value": 2885.0}, "meta_eval_prompt_cost": {"value": 0.00178496}, "meta_eval_completion_cost": {"value": 0.0036928}}, "created": "2025-12-10T21:47:45.2821178Z"}
{"ref": "grizzled-kern", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.846153846153846}, "generation_factuality_f1": {"value": 0.3}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.111111111111111}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 23.357352}, "meta_inference_prompt_tokens": {"value": 10404.0}, "meta_inference_completion_tokens": {"value": 1295.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020808}, "meta_inference_completion_cost": {"value": 0.002072}, "meta_eval_time": {"value": 26.579}, "meta_eval_prompt_tokens": {"value": 6075.0}, "meta_eval_completion_tokens": {"value": 2462.0}, "meta_eval_prompt_cost": {"value": 0.001944}, "meta_eval_completion_cost": {"value": 0.00315136}}, "created": "2025-12-10T21:47:45.3606969Z"}
{"ref": "grizzled-razorbill", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454546}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 26.105579}, "meta_inference_prompt_tokens": {"value": 12758.0}, "meta_inference_completion_tokens": {"value": 1266.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025516}, "meta_inference_completion_cost": {"value": 0.0020256}, "meta_eval_time": {"value": 37.2}, "meta_eval_prompt_tokens": {"value": 8841.0}, "meta_eval_completion_tokens": {"value": 3780.0}, "meta_eval_prompt_cost": {"value": 0.00282912}, "meta_eval_completion_cost": {"value": 0.0048384}}, "created": "2025-12-10T21:47:46.1969294Z"}
{"ref": "hoary-travel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.67591763355243}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.297142}, "meta_inference_prompt_tokens": {"value": 13224.0}, "meta_inference_completion_tokens": {"value": 932.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026448}, "meta_inference_completion_cost": {"value": 0.0014912}, "meta_eval_time": {"value": 31.896}, "meta_eval_prompt_tokens": {"value": 8680.0}, "meta_eval_completion_tokens": {"value": 3046.0}, "meta_eval_prompt_cost": {"value": 0.0027776}, "meta_eval_completion_cost": {"value": 0.00389888}}, "created": "2025-12-10T21:47:46.51737Z"}
{"ref": "grizzled-razorbill", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.708333333333334}, "retrieval_dcg": {"value": 2.37707118843058}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.707070707070707}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 0.714285714285714}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.714285714285714}, "meta_inference_time": {"value": 25.006657}, "meta_inference_prompt_tokens": {"value": 13618.0}, "meta_inference_completion_tokens": {"value": 1281.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027236}, "meta_inference_completion_cost": {"value": 0.0020496}, "meta_eval_time": {"value": 34.483}, "meta_eval_prompt_tokens": {"value": 9667.0}, "meta_eval_completion_tokens": {"value": 3435.0}, "meta_eval_prompt_cost": {"value": 0.00309344}, "meta_eval_completion_cost": {"value": 0.0043968}}, "created": "2025-12-10T21:47:47.373733Z"}
{"ref": "grizzled-razorbill", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.631578947368421}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 23.988777}, "meta_inference_prompt_tokens": {"value": 13542.0}, "meta_inference_completion_tokens": {"value": 1075.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027084}, "meta_inference_completion_cost": {"value": 0.00172}, "meta_eval_time": {"value": 36.681}, "meta_eval_prompt_tokens": {"value": 9474.0}, "meta_eval_completion_tokens": {"value": 3235.0}, "meta_eval_prompt_cost": {"value": 0.00303168}, "meta_eval_completion_cost": {"value": 0.0041408}}, "created": "2025-12-10T21:47:48.4537631Z"}
{"ref": "hot-cougar", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 0.964285714285714}, "generation_factuality_f1": {"value": 0.2}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 34.243003}, "meta_inference_prompt_tokens": {"value": 9942.0}, "meta_inference_completion_tokens": {"value": 1547.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019884}, "meta_inference_completion_cost": {"value": 0.0024752}, "meta_eval_time": {"value": 30.668}, "meta_eval_prompt_tokens": {"value": 5849.0}, "meta_eval_completion_tokens": {"value": 2995.0}, "meta_eval_prompt_cost": {"value": 0.00187168}, "meta_eval_completion_cost": {"value": 0.0038336}}, "created": "2025-12-10T21:47:48.4558017Z"}
{"ref": "hoary-travel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.801029995663981}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 19.3376}, "meta_inference_prompt_tokens": {"value": 12215.0}, "meta_inference_completion_tokens": {"value": 807.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002443}, "meta_inference_completion_cost": {"value": 0.0012912}, "meta_eval_time": {"value": 28.681}, "meta_eval_prompt_tokens": {"value": 7364.0}, "meta_eval_completion_tokens": {"value": 2836.0}, "meta_eval_prompt_cost": {"value": 0.00235648}, "meta_eval_completion_cost": {"value": 0.00363008}}, "created": "2025-12-10T21:47:49.3442346Z"}
{"ref": "hot-cougar", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.727272727272727}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 30.188173}, "meta_inference_prompt_tokens": {"value": 12350.0}, "meta_inference_completion_tokens": {"value": 1435.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00247}, "meta_inference_completion_cost": {"value": 0.002296}, "meta_eval_time": {"value": 25.418}, "meta_eval_prompt_tokens": {"value": 8026.0}, "meta_eval_completion_tokens": {"value": 2706.0}, "meta_eval_prompt_cost": {"value": 0.00256832}, "meta_eval_completion_cost": {"value": 0.00346368}}, "created": "2025-12-10T21:47:50.7262566Z"}
{"ref": "hot-cougar", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 31.632402}, "meta_inference_prompt_tokens": {"value": 10996.0}, "meta_inference_completion_tokens": {"value": 1875.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021992}, "meta_inference_completion_cost": {"value": 0.003}, "meta_eval_time": {"value": 30.585}, "meta_eval_prompt_tokens": {"value": 6688.0}, "meta_eval_completion_tokens": {"value": 2810.0}, "meta_eval_prompt_cost": {"value": 0.00214016}, "meta_eval_completion_cost": {"value": 0.0035968}}, "created": "2025-12-10T21:47:52.6416304Z"}
{"ref": "grizzled-razorbill", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 0.926829268292683}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.659297}, "meta_inference_prompt_tokens": {"value": 13051.0}, "meta_inference_completion_tokens": {"value": 1359.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026102}, "meta_inference_completion_cost": {"value": 0.0021744}, "meta_eval_time": {"value": 42.553}, "meta_eval_prompt_tokens": {"value": 9375.0}, "meta_eval_completion_tokens": {"value": 4200.0}, "meta_eval_prompt_cost": {"value": 0.003}, "meta_eval_completion_cost": {"value": 0.005376}}, "created": "2025-12-10T21:47:53.98521Z"}
{"ref": "huge-frequency", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 0.333333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.166666666666667}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 33.16003}, "meta_inference_prompt_tokens": {"value": 15494.0}, "meta_inference_completion_tokens": {"value": 1506.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030988}, "meta_inference_completion_cost": {"value": 0.0024096}, "meta_eval_time": {"value": 36.805}, "meta_eval_prompt_tokens": {"value": 11095.0}, "meta_eval_completion_tokens": {"value": 3699.0}, "meta_eval_prompt_cost": {"value": 0.0035504}, "meta_eval_completion_cost": {"value": 0.00473472}}, "created": "2025-12-10T21:47:54.0349264Z"}
{"ref": "immature-plateau", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.722222222222222}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.837503}, "meta_inference_prompt_tokens": {"value": 9473.0}, "meta_inference_completion_tokens": {"value": 1365.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018946}, "meta_inference_completion_cost": {"value": 0.002184}, "meta_eval_time": {"value": 22.23}, "meta_eval_prompt_tokens": {"value": 4738.0}, "meta_eval_completion_tokens": {"value": 2222.0}, "meta_eval_prompt_cost": {"value": 0.00151616}, "meta_eval_completion_cost": {"value": 0.00284416}}, "created": "2025-12-10T21:47:54.0805747Z"}
{"ref": "hot-cougar", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 28.397702}, "meta_inference_prompt_tokens": {"value": 11090.0}, "meta_inference_completion_tokens": {"value": 1526.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002218}, "meta_inference_completion_cost": {"value": 0.0024416}, "meta_eval_time": {"value": 32.992}, "meta_eval_prompt_tokens": {"value": 6714.0}, "meta_eval_completion_tokens": {"value": 2895.0}, "meta_eval_prompt_cost": {"value": 0.00214848}, "meta_eval_completion_cost": {"value": 0.0037056}}, "created": "2025-12-10T21:47:54.5158975Z"}
{"ref": "heartless-circuit", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 26.512323}, "meta_inference_prompt_tokens": {"value": 10305.0}, "meta_inference_completion_tokens": {"value": 1425.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002061}, "meta_inference_completion_cost": {"value": 0.00228}, "meta_eval_time": {"value": 46.863}, "meta_eval_prompt_tokens": {"value": 6715.0}, "meta_eval_completion_tokens": {"value": 4013.0}, "meta_eval_prompt_cost": {"value": 0.0021488}, "meta_eval_completion_cost": {"value": 0.00513664}}, "created": "2025-12-10T21:47:54.656677Z"}
{"ref": "heartless-circuit", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 0.935483870967742}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 31.494856}, "meta_inference_prompt_tokens": {"value": 10345.0}, "meta_inference_completion_tokens": {"value": 1439.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002069}, "meta_inference_completion_cost": {"value": 0.0023024}, "meta_eval_time": {"value": 33.75}, "meta_eval_prompt_tokens": {"value": 6282.0}, "meta_eval_completion_tokens": {"value": 3026.0}, "meta_eval_prompt_cost": {"value": 0.00201024}, "meta_eval_completion_cost": {"value": 0.00387328}}, "created": "2025-12-10T21:47:55.3508583Z"}
{"ref": "huge-frequency", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.944444444444444}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 28.696216}, "meta_inference_prompt_tokens": {"value": 12947.0}, "meta_inference_completion_tokens": {"value": 1548.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025894}, "meta_inference_completion_cost": {"value": 0.0024768}, "meta_eval_time": {"value": 34.287}, "meta_eval_prompt_tokens": {"value": 8588.0}, "meta_eval_completion_tokens": {"value": 3604.0}, "meta_eval_prompt_cost": {"value": 0.00274816}, "meta_eval_completion_cost": {"value": 0.00461312}}, "created": "2025-12-10T21:47:55.4069839Z"}
{"ref": "hot-cougar", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.2}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 26.137541}, "meta_inference_prompt_tokens": {"value": 9727.0}, "meta_inference_completion_tokens": {"value": 1543.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019454}, "meta_inference_completion_cost": {"value": 0.0024688}, "meta_eval_time": {"value": 31.971}, "meta_eval_prompt_tokens": {"value": 5649.0}, "meta_eval_completion_tokens": {"value": 3238.0}, "meta_eval_prompt_cost": {"value": 0.00180768}, "meta_eval_completion_cost": {"value": 0.00414464}}, "created": "2025-12-10T21:47:56.5277502Z"}
{"ref": "inflammable-radian", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.118615}, "meta_inference_prompt_tokens": {"value": 12292.0}, "meta_inference_completion_tokens": {"value": 775.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024584}, "meta_inference_completion_cost": {"value": 0.00124}, "meta_eval_time": {"value": 11.533}, "meta_eval_prompt_tokens": {"value": 6386.0}, "meta_eval_completion_tokens": {"value": 1206.0}, "meta_eval_prompt_cost": {"value": 0.00204352}, "meta_eval_completion_cost": {"value": 0.00154368}}, "created": "2025-12-10T21:47:56.8640944Z"}
{"ref": "immature-plateau", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.336474}, "meta_inference_prompt_tokens": {"value": 11399.0}, "meta_inference_completion_tokens": {"value": 983.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022798}, "meta_inference_completion_cost": {"value": 0.0015728}, "meta_eval_time": {"value": 19.213}, "meta_eval_prompt_tokens": {"value": 6346.0}, "meta_eval_completion_tokens": {"value": 1831.0}, "meta_eval_prompt_cost": {"value": 0.00203072}, "meta_eval_completion_cost": {"value": 0.00234368}}, "created": "2025-12-10T21:47:56.9702641Z"}
{"ref": "huge-frequency", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.972972972972973}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 24.854673}, "meta_inference_prompt_tokens": {"value": 12547.0}, "meta_inference_completion_tokens": {"value": 1324.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025094}, "meta_inference_completion_cost": {"value": 0.0021184}, "meta_eval_time": {"value": 37.103}, "meta_eval_prompt_tokens": {"value": 8604.0}, "meta_eval_completion_tokens": {"value": 3898.0}, "meta_eval_prompt_cost": {"value": 0.00275328}, "meta_eval_completion_cost": {"value": 0.00498944}}, "created": "2025-12-10T21:47:57.9894626Z"}
{"ref": "hushed-pitch", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.96551724137931}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.826521}, "meta_inference_prompt_tokens": {"value": 13596.0}, "meta_inference_completion_tokens": {"value": 2223.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027192}, "meta_inference_completion_cost": {"value": 0.0035568}, "meta_eval_time": {"value": 31.923}, "meta_eval_prompt_tokens": {"value": 9618.0}, "meta_eval_completion_tokens": {"value": 3232.0}, "meta_eval_prompt_cost": {"value": 0.00307776}, "meta_eval_completion_cost": {"value": 0.00413696}}, "created": "2025-12-10T21:47:58.7762745Z"}
{"ref": "inflammable-radian", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 18.941893}, "meta_inference_prompt_tokens": {"value": 14080.0}, "meta_inference_completion_tokens": {"value": 745.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002816}, "meta_inference_completion_cost": {"value": 0.001192}, "meta_eval_time": {"value": 14.322}, "meta_eval_prompt_tokens": {"value": 8340.0}, "meta_eval_completion_tokens": {"value": 1382.0}, "meta_eval_prompt_cost": {"value": 0.0026688}, "meta_eval_completion_cost": {"value": 0.00176896}}, "created": "2025-12-10T21:48:00.5575677Z"}
{"ref": "immature-plateau", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.330784}, "meta_inference_prompt_tokens": {"value": 10576.0}, "meta_inference_completion_tokens": {"value": 1271.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021152}, "meta_inference_completion_cost": {"value": 0.0020336}, "meta_eval_time": {"value": 21.354}, "meta_eval_prompt_tokens": {"value": 5639.0}, "meta_eval_completion_tokens": {"value": 2077.0}, "meta_eval_prompt_cost": {"value": 0.00180448}, "meta_eval_completion_cost": {"value": 0.00265856}}, "created": "2025-12-10T21:48:00.8450699Z"}
{"ref": "inflammable-radian", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 16.207873}, "meta_inference_prompt_tokens": {"value": 14075.0}, "meta_inference_completion_tokens": {"value": 524.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002815}, "meta_inference_completion_cost": {"value": 0.0008384}, "meta_eval_time": {"value": 16.19}, "meta_eval_prompt_tokens": {"value": 8266.0}, "meta_eval_completion_tokens": {"value": 1344.0}, "meta_eval_prompt_cost": {"value": 0.00264512}, "meta_eval_completion_cost": {"value": 0.00172032}}, "created": "2025-12-10T21:48:01.0135564Z"}
{"ref": "immature-plateau", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.722222222222222}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.957264}, "meta_inference_prompt_tokens": {"value": 9594.0}, "meta_inference_completion_tokens": {"value": 1519.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019188}, "meta_inference_completion_cost": {"value": 0.0024304}, "meta_eval_time": {"value": 23.892}, "meta_eval_prompt_tokens": {"value": 4695.0}, "meta_eval_completion_tokens": {"value": 2192.0}, "meta_eval_prompt_cost": {"value": 0.0015024}, "meta_eval_completion_cost": {"value": 0.00280576}}, "created": "2025-12-10T21:48:01.3090736Z"}
{"ref": "huge-frequency", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 32.645287}, "meta_inference_prompt_tokens": {"value": 10945.0}, "meta_inference_completion_tokens": {"value": 1710.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002189}, "meta_inference_completion_cost": {"value": 0.002736}, "meta_eval_time": {"value": 41.144}, "meta_eval_prompt_tokens": {"value": 7109.0}, "meta_eval_completion_tokens": {"value": 3896.0}, "meta_eval_prompt_cost": {"value": 0.00227488}, "meta_eval_completion_cost": {"value": 0.00498688}}, "created": "2025-12-10T21:48:01.7677446Z"}
{"ref": "huge-frequency", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.978260869565217}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 21.549222}, "meta_inference_prompt_tokens": {"value": 11068.0}, "meta_inference_completion_tokens": {"value": 1408.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022136}, "meta_inference_completion_cost": {"value": 0.0022528}, "meta_eval_time": {"value": 43.087}, "meta_eval_prompt_tokens": {"value": 7967.0}, "meta_eval_completion_tokens": {"value": 4416.0}, "meta_eval_prompt_cost": {"value": 0.00254944}, "meta_eval_completion_cost": {"value": 0.00565248}}, "created": "2025-12-10T21:48:02.9579569Z"}
{"ref": "inflammable-radian", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.52923}, "meta_inference_prompt_tokens": {"value": 14075.0}, "meta_inference_completion_tokens": {"value": 671.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002815}, "meta_inference_completion_cost": {"value": 0.0010736}, "meta_eval_time": {"value": 21.327}, "meta_eval_prompt_tokens": {"value": 8331.0}, "meta_eval_completion_tokens": {"value": 1575.0}, "meta_eval_prompt_cost": {"value": 0.00266592}, "meta_eval_completion_cost": {"value": 0.002016}}, "created": "2025-12-10T21:48:04.4621247Z"}
{"ref": "immature-plateau", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.631578947368421}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.525265}, "meta_inference_prompt_tokens": {"value": 9512.0}, "meta_inference_completion_tokens": {"value": 1487.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019024}, "meta_inference_completion_cost": {"value": 0.0023792}, "meta_eval_time": {"value": 26.9}, "meta_eval_prompt_tokens": {"value": 4809.0}, "meta_eval_completion_tokens": {"value": 2403.0}, "meta_eval_prompt_cost": {"value": 0.00153888}, "meta_eval_completion_cost": {"value": 0.00307584}}, "created": "2025-12-10T21:48:04.6760342Z"}
{"ref": "hushed-pitch", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.90625}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.996152}, "meta_inference_prompt_tokens": {"value": 13787.0}, "meta_inference_completion_tokens": {"value": 1766.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027574}, "meta_inference_completion_cost": {"value": 0.0028256}, "meta_eval_time": {"value": 37.272}, "meta_eval_prompt_tokens": {"value": 9734.0}, "meta_eval_completion_tokens": {"value": 3402.0}, "meta_eval_prompt_cost": {"value": 0.00311488}, "meta_eval_completion_cost": {"value": 0.00435456}}, "created": "2025-12-10T21:48:05.059018Z"}
{"ref": "indulgent-dope", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.216209}, "meta_inference_prompt_tokens": {"value": 9569.0}, "meta_inference_completion_tokens": {"value": 1287.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019138}, "meta_inference_completion_cost": {"value": 0.0020592}, "meta_eval_time": {"value": 26.073}, "meta_eval_prompt_tokens": {"value": 4830.0}, "meta_eval_completion_tokens": {"value": 2320.0}, "meta_eval_prompt_cost": {"value": 0.0015456}, "meta_eval_completion_cost": {"value": 0.0029696}}, "created": "2025-12-10T21:48:06.7628724Z"}
{"ref": "intense-configuration", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.094991}, "meta_inference_prompt_tokens": {"value": 10795.0}, "meta_inference_completion_tokens": {"value": 1014.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002159}, "meta_inference_completion_cost": {"value": 0.0016224}, "meta_eval_time": {"value": 20.248}, "meta_eval_prompt_tokens": {"value": 5860.0}, "meta_eval_completion_tokens": {"value": 1982.0}, "meta_eval_prompt_cost": {"value": 0.0018752}, "meta_eval_completion_cost": {"value": 0.00253696}}, "created": "2025-12-10T21:48:06.8029153Z"}
{"ref": "inflammable-radian", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.16076}, "meta_inference_prompt_tokens": {"value": 14079.0}, "meta_inference_completion_tokens": {"value": 781.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028158}, "meta_inference_completion_cost": {"value": 0.0012496}, "meta_eval_time": {"value": 16.585}, "meta_eval_prompt_tokens": {"value": 8434.0}, "meta_eval_completion_tokens": {"value": 1455.0}, "meta_eval_prompt_cost": {"value": 0.00269888}, "meta_eval_completion_cost": {"value": 0.0018624}}, "created": "2025-12-10T21:48:07.3476896Z"}
{"ref": "immediate-monastery", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 0.954545454545454}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.509068}, "meta_inference_prompt_tokens": {"value": 12945.0}, "meta_inference_completion_tokens": {"value": 1161.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002589}, "meta_inference_completion_cost": {"value": 0.0018576}, "meta_eval_time": {"value": 24.482}, "meta_eval_prompt_tokens": {"value": 8448.0}, "meta_eval_completion_tokens": {"value": 2592.0}, "meta_eval_prompt_cost": {"value": 0.00270336}, "meta_eval_completion_cost": {"value": 0.00331776}}, "created": "2025-12-10T21:48:08.2643466Z"}
{"ref": "indulgent-dope", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.88}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.358429}, "meta_inference_prompt_tokens": {"value": 10899.0}, "meta_inference_completion_tokens": {"value": 1483.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021798}, "meta_inference_completion_cost": {"value": 0.0023728}, "meta_eval_time": {"value": 27.241}, "meta_eval_prompt_tokens": {"value": 6634.0}, "meta_eval_completion_tokens": {"value": 2760.0}, "meta_eval_prompt_cost": {"value": 0.00212288}, "meta_eval_completion_cost": {"value": 0.0035328}}, "created": "2025-12-10T21:48:10.753122Z"}
{"ref": "indulgent-dope", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.955267}, "meta_inference_prompt_tokens": {"value": 11176.0}, "meta_inference_completion_tokens": {"value": 1415.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022352}, "meta_inference_completion_cost": {"value": 0.002264}, "meta_eval_time": {"value": 29.074}, "meta_eval_prompt_tokens": {"value": 6555.0}, "meta_eval_completion_tokens": {"value": 2724.0}, "meta_eval_prompt_cost": {"value": 0.0020976}, "meta_eval_completion_cost": {"value": 0.00348672}}, "created": "2025-12-10T21:48:12.1927857Z"}
{"ref": "inverted-vinegar", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.375}, "retrieval_mrr": {"value": 0.555555555555556}, "retrieval_dcg": {"value": 1.35067113796274}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.230769230769231}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 21.039796}, "meta_inference_prompt_tokens": {"value": 13219.0}, "meta_inference_completion_tokens": {"value": 1064.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026438}, "meta_inference_completion_cost": {"value": 0.0017024}, "meta_eval_time": {"value": 14.396}, "meta_eval_prompt_tokens": {"value": 7450.0}, "meta_eval_completion_tokens": {"value": 1225.0}, "meta_eval_prompt_cost": {"value": 0.002384}, "meta_eval_completion_cost": {"value": 0.001568}}, "created": "2025-12-10T21:48:12.4239702Z"}
{"ref": "iron-amortization", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.930676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.268385}, "meta_inference_prompt_tokens": {"value": 9741.0}, "meta_inference_completion_tokens": {"value": 626.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019482}, "meta_inference_completion_cost": {"value": 0.0010016}, "meta_eval_time": {"value": 13.003}, "meta_eval_prompt_tokens": {"value": 4353.0}, "meta_eval_completion_tokens": {"value": 1135.0}, "meta_eval_prompt_cost": {"value": 0.00139296}, "meta_eval_completion_cost": {"value": 0.0014528}}, "created": "2025-12-10T21:48:14.3688004Z"}
{"ref": "immediate-monastery", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 0.962962962962963}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.824055}, "meta_inference_prompt_tokens": {"value": 12951.0}, "meta_inference_completion_tokens": {"value": 1628.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025902}, "meta_inference_completion_cost": {"value": 0.0026048}, "meta_eval_time": {"value": 28.987}, "meta_eval_prompt_tokens": {"value": 8590.0}, "meta_eval_completion_tokens": {"value": 2920.0}, "meta_eval_prompt_cost": {"value": 0.0027488}, "meta_eval_completion_cost": {"value": 0.0037376}}, "created": "2025-12-10T21:48:14.3834861Z"}
{"ref": "immediate-monastery", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.544459}, "meta_inference_prompt_tokens": {"value": 12950.0}, "meta_inference_completion_tokens": {"value": 1726.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00259}, "meta_inference_completion_cost": {"value": 0.0027616}, "meta_eval_time": {"value": 36.19}, "meta_eval_prompt_tokens": {"value": 8843.0}, "meta_eval_completion_tokens": {"value": 3226.0}, "meta_eval_prompt_cost": {"value": 0.00282976}, "meta_eval_completion_cost": {"value": 0.00412928}}, "created": "2025-12-10T21:48:15.1394177Z"}
{"ref": "intense-configuration", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.283504}, "meta_inference_prompt_tokens": {"value": 10697.0}, "meta_inference_completion_tokens": {"value": 1351.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021394}, "meta_inference_completion_cost": {"value": 0.0021616}, "meta_eval_time": {"value": 22.46}, "meta_eval_prompt_tokens": {"value": 6021.0}, "meta_eval_completion_tokens": {"value": 2149.0}, "meta_eval_prompt_cost": {"value": 0.00192672}, "meta_eval_completion_cost": {"value": 0.00275072}}, "created": "2025-12-10T21:48:15.1398648Z"}
{"ref": "iron-amortization", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.930676558073393}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.930196}, "meta_inference_prompt_tokens": {"value": 9743.0}, "meta_inference_completion_tokens": {"value": 700.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019486}, "meta_inference_completion_cost": {"value": 0.00112}, "meta_eval_time": {"value": 13.43}, "meta_eval_prompt_tokens": {"value": 4366.0}, "meta_eval_completion_tokens": {"value": 1114.0}, "meta_eval_prompt_cost": {"value": 0.00139712}, "meta_eval_completion_cost": {"value": 0.00142592}}, "created": "2025-12-10T21:48:16.4264135Z"}
{"ref": "iron-amortization", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.930676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.438028}, "meta_inference_prompt_tokens": {"value": 9744.0}, "meta_inference_completion_tokens": {"value": 774.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019488}, "meta_inference_completion_cost": {"value": 0.0012384}, "meta_eval_time": {"value": 19.968}, "meta_eval_prompt_tokens": {"value": 4651.0}, "meta_eval_completion_tokens": {"value": 1786.0}, "meta_eval_prompt_cost": {"value": 0.00148832}, "meta_eval_completion_cost": {"value": 0.00228608}}, "created": "2025-12-10T21:48:16.868248Z"}
{"ref": "intense-configuration", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.862068965517241}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.940218}, "meta_inference_prompt_tokens": {"value": 10982.0}, "meta_inference_completion_tokens": {"value": 1044.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021964}, "meta_inference_completion_cost": {"value": 0.0016704}, "meta_eval_time": {"value": 29.972}, "meta_eval_prompt_tokens": {"value": 6597.0}, "meta_eval_completion_tokens": {"value": 2864.0}, "meta_eval_prompt_cost": {"value": 0.00211104}, "meta_eval_completion_cost": {"value": 0.00366592}}, "created": "2025-12-10T21:48:17.3894057Z"}
{"ref": "hushed-pitch", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.975}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 37.717429}, "meta_inference_prompt_tokens": {"value": 13769.0}, "meta_inference_completion_tokens": {"value": 2374.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027538}, "meta_inference_completion_cost": {"value": 0.0037984}, "meta_eval_time": {"value": 41.178}, "meta_eval_prompt_tokens": {"value": 10485.0}, "meta_eval_completion_tokens": {"value": 4350.0}, "meta_eval_prompt_cost": {"value": 0.0033552}, "meta_eval_completion_cost": {"value": 0.005568}}, "created": "2025-12-10T21:48:17.8163757Z"}
{"ref": "hushed-pitch", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 26.563355}, "meta_inference_prompt_tokens": {"value": 13832.0}, "meta_inference_completion_tokens": {"value": 1800.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027664}, "meta_inference_completion_cost": {"value": 0.00288}, "meta_eval_time": {"value": 42.333}, "meta_eval_prompt_tokens": {"value": 10258.0}, "meta_eval_completion_tokens": {"value": 4221.0}, "meta_eval_prompt_cost": {"value": 0.00328256}, "meta_eval_completion_cost": {"value": 0.00540288}}, "created": "2025-12-10T21:48:17.8439723Z"}
{"ref": "intense-configuration", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.878787878787879}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.489759}, "meta_inference_prompt_tokens": {"value": 10792.0}, "meta_inference_completion_tokens": {"value": 1634.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021584}, "meta_inference_completion_cost": {"value": 0.0026144}, "meta_eval_time": {"value": 30.39}, "meta_eval_prompt_tokens": {"value": 6704.0}, "meta_eval_completion_tokens": {"value": 2936.0}, "meta_eval_prompt_cost": {"value": 0.00214528}, "meta_eval_completion_cost": {"value": 0.00375808}}, "created": "2025-12-10T21:48:18.905666Z"}
{"ref": "inverted-vinegar", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.466666666666667}, "retrieval_dcg": {"value": 2.28816693634346}, "generation_faithfulness": {"value": 0.882352941176471}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 22.505898}, "meta_inference_prompt_tokens": {"value": 12152.0}, "meta_inference_completion_tokens": {"value": 1326.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024304}, "meta_inference_completion_cost": {"value": 0.0021216}, "meta_eval_time": {"value": 22.918}, "meta_eval_prompt_tokens": {"value": 6854.0}, "meta_eval_completion_tokens": {"value": 2033.0}, "meta_eval_prompt_cost": {"value": 0.00219328}, "meta_eval_completion_cost": {"value": 0.00260224}}, "created": "2025-12-10T21:48:19.491235Z"}
{"ref": "inverted-vinegar", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.625}, "retrieval_mrr": {"value": 0.423333333333333}, "retrieval_dcg": {"value": 2.87398974791402}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.454545454545454}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 0.833333333333334}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 25.973417}, "meta_inference_prompt_tokens": {"value": 11094.0}, "meta_inference_completion_tokens": {"value": 1256.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022188}, "meta_inference_completion_cost": {"value": 0.0020096}, "meta_eval_time": {"value": 21.321}, "meta_eval_prompt_tokens": {"value": 6249.0}, "meta_eval_completion_tokens": {"value": 2177.0}, "meta_eval_prompt_cost": {"value": 0.00199968}, "meta_eval_completion_cost": {"value": 0.00278656}}, "created": "2025-12-10T21:48:20.1358668Z"}
{"ref": "immediate-monastery", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.06160631164485}, "generation_faithfulness": {"value": 0.838709677419355}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.466111}, "meta_inference_prompt_tokens": {"value": 12871.0}, "meta_inference_completion_tokens": {"value": 1540.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025742}, "meta_inference_completion_cost": {"value": 0.002464}, "meta_eval_time": {"value": 35.588}, "meta_eval_prompt_tokens": {"value": 8587.0}, "meta_eval_completion_tokens": {"value": 3304.0}, "meta_eval_prompt_cost": {"value": 0.00274784}, "meta_eval_completion_cost": {"value": 0.00422912}}, "created": "2025-12-10T21:48:20.1677882Z"}
{"ref": "indulgent-dope", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 24.220012}, "meta_inference_prompt_tokens": {"value": 10494.0}, "meta_inference_completion_tokens": {"value": 1454.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020988}, "meta_inference_completion_cost": {"value": 0.0023264}, "meta_eval_time": {"value": 31.842}, "meta_eval_prompt_tokens": {"value": 6348.0}, "meta_eval_completion_tokens": {"value": 2936.0}, "meta_eval_prompt_cost": {"value": 0.00203136}, "meta_eval_completion_cost": {"value": 0.00375808}}, "created": "2025-12-10T21:48:20.3574289Z"}
{"ref": "indulgent-dope", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 22.805029}, "meta_inference_prompt_tokens": {"value": 11251.0}, "meta_inference_completion_tokens": {"value": 1219.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022502}, "meta_inference_completion_cost": {"value": 0.0019504}, "meta_eval_time": {"value": 35.394}, "meta_eval_prompt_tokens": {"value": 7382.0}, "meta_eval_completion_tokens": {"value": 3081.0}, "meta_eval_prompt_cost": {"value": 0.00236224}, "meta_eval_completion_cost": {"value": 0.00394368}}, "created": "2025-12-10T21:48:20.7253455Z"}
{"ref": "intense-configuration", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.493222}, "meta_inference_prompt_tokens": {"value": 10852.0}, "meta_inference_completion_tokens": {"value": 1384.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021704}, "meta_inference_completion_cost": {"value": 0.0022144}, "meta_eval_time": {"value": 31.662}, "meta_eval_prompt_tokens": {"value": 6688.0}, "meta_eval_completion_tokens": {"value": 2880.0}, "meta_eval_prompt_cost": {"value": 0.00214016}, "meta_eval_completion_cost": {"value": 0.0036864}}, "created": "2025-12-10T21:48:21.0432641Z"}
{"ref": "hushed-pitch", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.947368421052632}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.262025}, "meta_inference_prompt_tokens": {"value": 15142.0}, "meta_inference_completion_tokens": {"value": 2096.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030284}, "meta_inference_completion_cost": {"value": 0.0033536}, "meta_eval_time": {"value": 54.371}, "meta_eval_prompt_tokens": {"value": 12055.0}, "meta_eval_completion_tokens": {"value": 5032.0}, "meta_eval_prompt_cost": {"value": 0.0038576}, "meta_eval_completion_cost": {"value": 0.00644096}}, "created": "2025-12-10T21:48:22.6095735Z"}
{"ref": "immediate-monastery", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.972222222222222}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.208459}, "meta_inference_prompt_tokens": {"value": 12856.0}, "meta_inference_completion_tokens": {"value": 1852.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025712}, "meta_inference_completion_cost": {"value": 0.0029632}, "meta_eval_time": {"value": 45.511}, "meta_eval_prompt_tokens": {"value": 9645.0}, "meta_eval_completion_tokens": {"value": 4083.0}, "meta_eval_prompt_cost": {"value": 0.0030864}, "meta_eval_completion_cost": {"value": 0.00522624}}, "created": "2025-12-10T21:48:25.9033947Z"}
{"ref": "inverted-vinegar", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.75}, "retrieval_mrr": {"value": 0.408333333333333}, "retrieval_dcg": {"value": 3.20732308124736}, "generation_faithfulness": {"value": 0.935483870967742}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.6}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.6}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 35.087095}, "meta_inference_prompt_tokens": {"value": 11927.0}, "meta_inference_completion_tokens": {"value": 1890.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023854}, "meta_inference_completion_cost": {"value": 0.003024}, "meta_eval_time": {"value": 32.762}, "meta_eval_prompt_tokens": {"value": 7288.0}, "meta_eval_completion_tokens": {"value": 3061.0}, "meta_eval_prompt_cost": {"value": 0.00233216}, "meta_eval_completion_cost": {"value": 0.00391808}}, "created": "2025-12-10T21:48:33.6477887Z"}
{"ref": "iron-program", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.521739130434783}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 26.33472}, "meta_inference_prompt_tokens": {"value": 12358.0}, "meta_inference_completion_tokens": {"value": 1529.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024716}, "meta_inference_completion_cost": {"value": 0.0024464}, "meta_eval_time": {"value": 36.81}, "meta_eval_prompt_tokens": {"value": 7856.0}, "meta_eval_completion_tokens": {"value": 3020.0}, "meta_eval_prompt_cost": {"value": 0.00251392}, "meta_eval_completion_cost": {"value": 0.0038656}}, "created": "2025-12-10T21:48:33.818385Z"}
{"ref": "inverted-rack", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.83324743759173}, "generation_faithfulness": {"value": 0.862068965517241}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.556383}, "meta_inference_prompt_tokens": {"value": 11404.0}, "meta_inference_completion_tokens": {"value": 1475.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022808}, "meta_inference_completion_cost": {"value": 0.00236}, "meta_eval_time": {"value": 38.8}, "meta_eval_prompt_tokens": {"value": 7408.0}, "meta_eval_completion_tokens": {"value": 3096.0}, "meta_eval_prompt_cost": {"value": 0.00237056}, "meta_eval_completion_cost": {"value": 0.00396288}}, "created": "2025-12-10T21:48:34.1874473Z"}
{"ref": "jovial-winch", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 31.930209}, "meta_inference_prompt_tokens": {"value": 11194.0}, "meta_inference_completion_tokens": {"value": 1346.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022388}, "meta_inference_completion_cost": {"value": 0.0021536}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:48:34.2314799Z"}
{"ref": "inventive-architect", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.594059405940594}, "generation_factuality_precision": {"value": 0.454545454545454}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 21.514383}, "meta_inference_prompt_tokens": {"value": 14389.0}, "meta_inference_completion_tokens": {"value": 1063.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028778}, "meta_inference_completion_cost": {"value": 0.0017008}, "meta_eval_time": {"value": 30.429}, "meta_eval_prompt_tokens": {"value": 9844.0}, "meta_eval_completion_tokens": {"value": 3366.0}, "meta_eval_prompt_cost": {"value": 0.00315008}, "meta_eval_completion_cost": {"value": 0.00430848}}, "created": "2025-12-10T21:48:35.1418844Z"}
{"ref": "inverted-rack", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.316666666666667}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.27906976744186}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.222222222222222}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 0.222222222222222}, "meta_inference_time": {"value": 25.97914}, "meta_inference_prompt_tokens": {"value": 12499.0}, "meta_inference_completion_tokens": {"value": 1402.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024998}, "meta_inference_completion_cost": {"value": 0.0022432}, "meta_eval_time": {"value": 40.559}, "meta_eval_prompt_tokens": {"value": 8240.0}, "meta_eval_completion_tokens": {"value": 3552.0}, "meta_eval_prompt_cost": {"value": 0.0026368}, "meta_eval_completion_cost": {"value": 0.00454656}}, "created": "2025-12-10T21:48:36.0062993Z"}
{"ref": "inverted-vinegar", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.625}, "retrieval_mrr": {"value": 0.423333333333333}, "retrieval_dcg": {"value": 2.71040452176391}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.454545454545454}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 0.833333333333334}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.188688}, "meta_inference_prompt_tokens": {"value": 12130.0}, "meta_inference_completion_tokens": {"value": 1383.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002426}, "meta_inference_completion_cost": {"value": 0.0022128}, "meta_eval_time": {"value": 35.101}, "meta_eval_prompt_tokens": {"value": 7277.0}, "meta_eval_completion_tokens": {"value": 2548.0}, "meta_eval_prompt_cost": {"value": 0.00232864}, "meta_eval_completion_cost": {"value": 0.00326144}}, "created": "2025-12-10T21:48:36.9118504Z"}
{"ref": "iron-amortization", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.93067655807339}, "generation_faithfulness": {"value": 0.96969696969697}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.212463}, "meta_inference_prompt_tokens": {"value": 11412.0}, "meta_inference_completion_tokens": {"value": 872.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022824}, "meta_inference_completion_cost": {"value": 0.0013952}, "meta_eval_time": {"value": 32.877}, "meta_eval_prompt_tokens": {"value": 6623.0}, "meta_eval_completion_tokens": {"value": 2901.0}, "meta_eval_prompt_cost": {"value": 0.00211936}, "meta_eval_completion_cost": {"value": 0.00371328}}, "created": "2025-12-10T21:48:37.3921356Z"}
{"ref": "inverted-rack", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.4875}, "retrieval_dcg": {"value": 2.44845911887939}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.042115}, "meta_inference_prompt_tokens": {"value": 11773.0}, "meta_inference_completion_tokens": {"value": 1497.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023546}, "meta_inference_completion_cost": {"value": 0.0023952}, "meta_eval_time": {"value": 43.048}, "meta_eval_prompt_tokens": {"value": 7613.0}, "meta_eval_completion_tokens": {"value": 4069.0}, "meta_eval_prompt_cost": {"value": 0.00243616}, "meta_eval_completion_cost": {"value": 0.00520832}}, "created": "2025-12-10T21:48:37.600131Z"}
{"ref": "isochoric-goose", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 0.85}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.93561}, "meta_inference_prompt_tokens": {"value": 14985.0}, "meta_inference_completion_tokens": {"value": 960.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002997}, "meta_inference_completion_cost": {"value": 0.001536}, "meta_eval_time": {"value": 23.551}, "meta_eval_prompt_tokens": {"value": 9713.0}, "meta_eval_completion_tokens": {"value": 2096.0}, "meta_eval_prompt_cost": {"value": 0.00310816}, "meta_eval_completion_cost": {"value": 0.00268288}}, "created": "2025-12-10T21:48:37.9808039Z"}
{"ref": "iron-amortization", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.98713694067948}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.21403}, "meta_inference_prompt_tokens": {"value": 11364.0}, "meta_inference_completion_tokens": {"value": 873.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022728}, "meta_inference_completion_cost": {"value": 0.0013968}, "meta_eval_time": {"value": 37.577}, "meta_eval_prompt_tokens": {"value": 6549.0}, "meta_eval_completion_tokens": {"value": 3415.0}, "meta_eval_prompt_cost": {"value": 0.00209568}, "meta_eval_completion_cost": {"value": 0.0043712}}, "created": "2025-12-10T21:48:38.1752682Z"}
{"ref": "iron-program", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.135688}, "meta_inference_prompt_tokens": {"value": 10592.0}, "meta_inference_completion_tokens": {"value": 1462.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021184}, "meta_inference_completion_cost": {"value": 0.0023392}, "meta_eval_time": {"value": 37.555}, "meta_eval_prompt_tokens": {"value": 6862.0}, "meta_eval_completion_tokens": {"value": 3854.0}, "meta_eval_prompt_cost": {"value": 0.00219584}, "meta_eval_completion_cost": {"value": 0.00493312}}, "created": "2025-12-10T21:48:38.6147454Z"}
{"ref": "inventive-architect", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.526315789473684}, "generation_factuality_precision": {"value": 0.384615384615385}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 27.838027}, "meta_inference_prompt_tokens": {"value": 13199.0}, "meta_inference_completion_tokens": {"value": 1722.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026398}, "meta_inference_completion_cost": {"value": 0.0027552}, "meta_eval_time": {"value": 44.64}, "meta_eval_prompt_tokens": {"value": 9129.0}, "meta_eval_completion_tokens": {"value": 4069.0}, "meta_eval_prompt_cost": {"value": 0.00292128}, "meta_eval_completion_cost": {"value": 0.00520832}}, "created": "2025-12-10T21:48:38.6608859Z"}
{"ref": "isochoric-goose", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.954545454545454}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.2397}, "meta_inference_prompt_tokens": {"value": 12367.0}, "meta_inference_completion_tokens": {"value": 1327.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024734}, "meta_inference_completion_cost": {"value": 0.0021232}, "meta_eval_time": {"value": 28.295}, "meta_eval_prompt_tokens": {"value": 7406.0}, "meta_eval_completion_tokens": {"value": 2362.0}, "meta_eval_prompt_cost": {"value": 0.00236992}, "meta_eval_completion_cost": {"value": 0.00302336}}, "created": "2025-12-10T21:48:39.0891143Z"}
{"ref": "jellied-tritone", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.624179}, "meta_inference_prompt_tokens": {"value": 10109.0}, "meta_inference_completion_tokens": {"value": 1052.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020218}, "meta_inference_completion_cost": {"value": 0.0016832}, "meta_eval_time": {"value": 19.419}, "meta_eval_prompt_tokens": {"value": 5302.0}, "meta_eval_completion_tokens": {"value": 1956.0}, "meta_eval_prompt_cost": {"value": 0.00169664}, "meta_eval_completion_cost": {"value": 0.00250368}}, "created": "2025-12-10T21:48:39.6403191Z"}
{"ref": "inventive-architect", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.555555555555556}, "generation_factuality_precision": {"value": 0.454545454545454}, "generation_factuality_recall": {"value": 0.714285714285714}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.714285714285714}, "meta_inference_time": {"value": 27.340008}, "meta_inference_prompt_tokens": {"value": 14391.0}, "meta_inference_completion_tokens": {"value": 1429.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028782}, "meta_inference_completion_cost": {"value": 0.0022864}, "meta_eval_time": {"value": 45.083}, "meta_eval_prompt_tokens": {"value": 10404.0}, "meta_eval_completion_tokens": {"value": 3952.0}, "meta_eval_prompt_cost": {"value": 0.00332928}, "meta_eval_completion_cost": {"value": 0.00505856}}, "created": "2025-12-10T21:48:39.7755658Z"}
{"ref": "laminated-ohm-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.35466}, "meta_inference_prompt_tokens": {"value": 2253.0}, "meta_inference_completion_tokens": {"value": 461.0}, "meta_inference_prompt_cost": {"value": 0.0004506}, "meta_inference_completion_cost": {"value": 0.0007376}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:48:39.8163855Z"}
{"ref": "jellied-chenille", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.94639463035719}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.587779}, "meta_inference_prompt_tokens": {"value": 13650.0}, "meta_inference_completion_tokens": {"value": 1634.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00273}, "meta_inference_completion_cost": {"value": 0.0026144}, "meta_eval_time": {"value": 29.0}, "meta_eval_prompt_tokens": {"value": 8642.0}, "meta_eval_completion_tokens": {"value": 2750.0}, "meta_eval_prompt_cost": {"value": 0.00276544}, "meta_eval_completion_cost": {"value": 0.00352}}, "created": "2025-12-10T21:48:41.4590846Z"}
{"ref": "laminated-ohm-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.433247}, "meta_inference_prompt_tokens": {"value": 2253.0}, "meta_inference_completion_tokens": {"value": 710.0}, "meta_inference_prompt_cost": {"value": 0.0004506}, "meta_inference_completion_cost": {"value": 0.001136}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:48:41.4999615Z"}
{"ref": "laminated-ohm-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.722798}, "meta_inference_prompt_tokens": {"value": 11621.0}, "meta_inference_completion_tokens": {"value": 1292.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0023242}, "meta_inference_completion_cost": {"value": 0.0020672}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:48:41.5362334Z"}
{"ref": "laminated-ohm-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.522357}, "meta_inference_prompt_tokens": {"value": 8185.0}, "meta_inference_completion_tokens": {"value": 1012.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001637}, "meta_inference_completion_cost": {"value": 0.0016192}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:48:41.575239Z"}
{"ref": "jellied-chenille", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.88685280723454}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.708022}, "meta_inference_prompt_tokens": {"value": 15724.0}, "meta_inference_completion_tokens": {"value": 1773.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031448}, "meta_inference_completion_cost": {"value": 0.0028368}, "meta_eval_time": {"value": 22.847}, "meta_eval_prompt_tokens": {"value": 9884.0}, "meta_eval_completion_tokens": {"value": 2258.0}, "meta_eval_prompt_cost": {"value": 0.00316288}, "meta_eval_completion_cost": {"value": 0.00289024}}, "created": "2025-12-10T21:48:42.3936133Z"}
{"ref": "inverted-rack", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.86263630730883}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.947368421052632}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.052016}, "meta_inference_prompt_tokens": {"value": 10825.0}, "meta_inference_completion_tokens": {"value": 1470.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002165}, "meta_inference_completion_cost": {"value": 0.002352}, "meta_eval_time": {"value": 50.038}, "meta_eval_prompt_tokens": {"value": 7043.0}, "meta_eval_completion_tokens": {"value": 4071.0}, "meta_eval_prompt_cost": {"value": 0.00225376}, "meta_eval_completion_cost": {"value": 0.00521088}}, "created": "2025-12-10T21:48:44.1112237Z"}
{"ref": "jellied-tritone", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.956521739130435}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.159317}, "meta_inference_prompt_tokens": {"value": 10612.0}, "meta_inference_completion_tokens": {"value": 1274.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021224}, "meta_inference_completion_cost": {"value": 0.0020384}, "meta_eval_time": {"value": 28.645}, "meta_eval_prompt_tokens": {"value": 6455.0}, "meta_eval_completion_tokens": {"value": 2817.0}, "meta_eval_prompt_cost": {"value": 0.0020656}, "meta_eval_completion_cost": {"value": 0.00360576}}, "created": "2025-12-10T21:48:45.553305Z"}
{"ref": "inventive-architect", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 0.981818181818182}, "generation_factuality_f1": {"value": 0.770642201834862}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 22.832902}, "meta_inference_prompt_tokens": {"value": 14388.0}, "meta_inference_completion_tokens": {"value": 1077.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028776}, "meta_inference_completion_cost": {"value": 0.0017232}, "meta_eval_time": {"value": 51.966}, "meta_eval_prompt_tokens": {"value": 10531.0}, "meta_eval_completion_tokens": {"value": 4824.0}, "meta_eval_prompt_cost": {"value": 0.00336992}, "meta_eval_completion_cost": {"value": 0.00617472}}, "created": "2025-12-10T21:48:46.0855247Z"}
{"ref": "isochoric-goose", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.986753}, "meta_inference_prompt_tokens": {"value": 14749.0}, "meta_inference_completion_tokens": {"value": 1136.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029498}, "meta_inference_completion_cost": {"value": 0.0018176}, "meta_eval_time": {"value": 33.889}, "meta_eval_prompt_tokens": {"value": 9444.0}, "meta_eval_completion_tokens": {"value": 2482.0}, "meta_eval_prompt_cost": {"value": 0.00302208}, "meta_eval_completion_cost": {"value": 0.00317696}}, "created": "2025-12-10T21:48:46.1168661Z"}
{"ref": "kinetic-function", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.825024}, "meta_inference_prompt_tokens": {"value": 13369.0}, "meta_inference_completion_tokens": {"value": 1241.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026738}, "meta_inference_completion_cost": {"value": 0.0019856}, "meta_eval_time": {"value": 11.275}, "meta_eval_prompt_tokens": {"value": 7553.0}, "meta_eval_completion_tokens": {"value": 1064.0}, "meta_eval_prompt_cost": {"value": 0.00241696}, "meta_eval_completion_cost": {"value": 0.00136192}}, "created": "2025-12-10T21:48:47.3200849Z"}
{"ref": "jellied-tritone", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8125}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.535104}, "meta_inference_prompt_tokens": {"value": 10111.0}, "meta_inference_completion_tokens": {"value": 1074.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020222}, "meta_inference_completion_cost": {"value": 0.0017184}, "meta_eval_time": {"value": 21.798}, "meta_eval_prompt_tokens": {"value": 5308.0}, "meta_eval_completion_tokens": {"value": 1831.0}, "meta_eval_prompt_cost": {"value": 0.00169856}, "meta_eval_completion_cost": {"value": 0.00234368}}, "created": "2025-12-10T21:48:47.7985331Z"}
{"ref": "iron-program", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.133979}, "meta_inference_prompt_tokens": {"value": 11863.0}, "meta_inference_completion_tokens": {"value": 1478.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023726}, "meta_inference_completion_cost": {"value": 0.0023648}, "meta_eval_time": {"value": 40.348}, "meta_eval_prompt_tokens": {"value": 8026.0}, "meta_eval_completion_tokens": {"value": 3861.0}, "meta_eval_prompt_cost": {"value": 0.00256832}, "meta_eval_completion_cost": {"value": 0.00494208}}, "created": "2025-12-10T21:48:48.6488332Z"}
{"ref": "isometric-asadero", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.483333333333333}, "retrieval_dcg": {"value": 1.41781349875287}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.735635}, "meta_inference_prompt_tokens": {"value": 12439.0}, "meta_inference_completion_tokens": {"value": 1579.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024878}, "meta_inference_completion_cost": {"value": 0.0025264}, "meta_eval_time": {"value": 33.44}, "meta_eval_prompt_tokens": {"value": 7645.0}, "meta_eval_completion_tokens": {"value": 2896.0}, "meta_eval_prompt_cost": {"value": 0.0024464}, "meta_eval_completion_cost": {"value": 0.00370688}}, "created": "2025-12-10T21:48:48.6794029Z"}
{"ref": "iron-program", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 0.914285714285714}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.862462}, "meta_inference_prompt_tokens": {"value": 12015.0}, "meta_inference_completion_tokens": {"value": 1807.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002403}, "meta_inference_completion_cost": {"value": 0.0028912}, "meta_eval_time": {"value": 41.865}, "meta_eval_prompt_tokens": {"value": 7913.0}, "meta_eval_completion_tokens": {"value": 3735.0}, "meta_eval_prompt_cost": {"value": 0.00253216}, "meta_eval_completion_cost": {"value": 0.0047808}}, "created": "2025-12-10T21:48:48.7048539Z"}
{"ref": "isochoric-goose", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 0.289064826317888}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.37163}, "meta_inference_prompt_tokens": {"value": 12033.0}, "meta_inference_completion_tokens": {"value": 1341.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024066}, "meta_inference_completion_cost": {"value": 0.0021456}, "meta_eval_time": {"value": 33.215}, "meta_eval_prompt_tokens": {"value": 7066.0}, "meta_eval_completion_tokens": {"value": 2745.0}, "meta_eval_prompt_cost": {"value": 0.00226112}, "meta_eval_completion_cost": {"value": 0.0035136}}, "created": "2025-12-10T21:48:49.6809677Z"}
{"ref": "khaki-sprite", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.16}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 0.673726329362866}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.0869565217391304}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0666666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 32.258435}, "meta_inference_prompt_tokens": {"value": 89030.0}, "meta_inference_completion_tokens": {"value": 1287.0}, "meta_inference_tool_call_count": {"value": 3.0}, "meta_inference_prompt_cost": {"value": 0.017806}, "meta_inference_completion_cost": {"value": 0.0020592}, "meta_eval_time": {"value": 30.603}, "meta_eval_prompt_tokens": {"value": 30270.0}, "meta_eval_completion_tokens": {"value": 2492.0}, "meta_eval_prompt_cost": {"value": 0.0096864}, "meta_eval_completion_cost": {"value": 0.00318976}}, "created": "2025-12-10T21:48:51.3771689Z"}
{"ref": "jolly-stunt", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 2.22018614056788}, "generation_faithfulness": {"value": 0.625}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.285714285714286}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.558133}, "meta_inference_prompt_tokens": {"value": 13545.0}, "meta_inference_completion_tokens": {"value": 1598.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.002709}, "meta_inference_completion_cost": {"value": 0.0025568}, "meta_eval_time": {"value": 28.755}, "meta_eval_prompt_tokens": {"value": 4977.0}, "meta_eval_completion_tokens": {"value": 2517.0}, "meta_eval_prompt_cost": {"value": 0.00159264}, "meta_eval_completion_cost": {"value": 0.00322176}}, "created": "2025-12-10T21:48:51.4046244Z"}
{"ref": "laminated-ohm-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.402398}, "meta_inference_prompt_tokens": {"value": 5935.0}, "meta_inference_completion_tokens": {"value": 1026.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001187}, "meta_inference_completion_cost": {"value": 0.0016416}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:48:51.4194032Z"}
{"ref": "isochoric-goose", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.805606}, "meta_inference_prompt_tokens": {"value": 11919.0}, "meta_inference_completion_tokens": {"value": 1372.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023838}, "meta_inference_completion_cost": {"value": 0.0021952}, "meta_eval_time": {"value": 43.912}, "meta_eval_prompt_tokens": {"value": 7440.0}, "meta_eval_completion_tokens": {"value": 3591.0}, "meta_eval_prompt_cost": {"value": 0.0023808}, "meta_eval_completion_cost": {"value": 0.00459648}}, "created": "2025-12-10T21:48:52.1949377Z"}
{"ref": "kinetic-function", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.307713}, "meta_inference_prompt_tokens": {"value": 10833.0}, "meta_inference_completion_tokens": {"value": 1102.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021666}, "meta_inference_completion_cost": {"value": 0.0017632}, "meta_eval_time": {"value": 10.709}, "meta_eval_prompt_tokens": {"value": 5223.0}, "meta_eval_completion_tokens": {"value": 893.0}, "meta_eval_prompt_cost": {"value": 0.00167136}, "meta_eval_completion_cost": {"value": 0.00114304}}, "created": "2025-12-10T21:48:52.3264866Z"}
{"ref": "inverted-rack", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.4875}, "retrieval_dcg": {"value": 2.56160631164485}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.087786}, "meta_inference_prompt_tokens": {"value": 12520.0}, "meta_inference_completion_tokens": {"value": 1684.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002504}, "meta_inference_completion_cost": {"value": 0.0026944}, "meta_eval_time": {"value": 45.551}, "meta_eval_prompt_tokens": {"value": 8723.0}, "meta_eval_completion_tokens": {"value": 4255.0}, "meta_eval_prompt_cost": {"value": 0.00279136}, "meta_eval_completion_cost": {"value": 0.0054464}}, "created": "2025-12-10T21:48:52.3505661Z"}
{"ref": "jellied-chenille", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.84}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.66462}, "meta_inference_prompt_tokens": {"value": 13221.0}, "meta_inference_completion_tokens": {"value": 1724.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026442}, "meta_inference_completion_cost": {"value": 0.0027584}, "meta_eval_time": {"value": 35.762}, "meta_eval_prompt_tokens": {"value": 8234.0}, "meta_eval_completion_tokens": {"value": 2719.0}, "meta_eval_prompt_cost": {"value": 0.00263488}, "meta_eval_completion_cost": {"value": 0.00348032}}, "created": "2025-12-10T21:48:53.6497314Z"}
{"ref": "jovial-winch", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.882756}, "meta_inference_prompt_tokens": {"value": 10734.0}, "meta_inference_completion_tokens": {"value": 993.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021468}, "meta_inference_completion_cost": {"value": 0.0015888}, "meta_eval_time": {"value": 15.509}, "meta_eval_prompt_tokens": {"value": 5364.0}, "meta_eval_completion_tokens": {"value": 1496.0}, "meta_eval_prompt_cost": {"value": 0.00171648}, "meta_eval_completion_cost": {"value": 0.00191488}}, "created": "2025-12-10T21:48:55.1921184Z"}
{"ref": "jolly-stunt", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.945945945945946}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.350755}, "meta_inference_prompt_tokens": {"value": 12007.0}, "meta_inference_completion_tokens": {"value": 1889.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024014}, "meta_inference_completion_cost": {"value": 0.0030224}, "meta_eval_time": {"value": 37.553}, "meta_eval_prompt_tokens": {"value": 7924.0}, "meta_eval_completion_tokens": {"value": 3512.0}, "meta_eval_prompt_cost": {"value": 0.00253568}, "meta_eval_completion_cost": {"value": 0.00449536}}, "created": "2025-12-10T21:48:55.4163671Z"}
{"ref": "linear-volume", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.500026}, "meta_inference_prompt_tokens": {"value": 6494.0}, "meta_inference_completion_tokens": {"value": 1798.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0012988}, "meta_inference_completion_cost": {"value": 0.0028768}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:48:55.4543594Z"}
{"ref": "inventive-architect", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.705882352941176}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 34.844556}, "meta_inference_prompt_tokens": {"value": 13647.0}, "meta_inference_completion_tokens": {"value": 1413.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027294}, "meta_inference_completion_cost": {"value": 0.0022608}, "meta_eval_time": {"value": 51.571}, "meta_eval_prompt_tokens": {"value": 10325.0}, "meta_eval_completion_tokens": {"value": 5051.0}, "meta_eval_prompt_cost": {"value": 0.003304}, "meta_eval_completion_cost": {"value": 0.00646528}}, "created": "2025-12-10T21:48:56.6708535Z"}
{"ref": "khaki-sprite", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.966666666666667}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 23.700994}, "meta_inference_prompt_tokens": {"value": 20173.0}, "meta_inference_completion_tokens": {"value": 1135.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0040346}, "meta_inference_completion_cost": {"value": 0.001816}, "meta_eval_time": {"value": 36.45}, "meta_eval_prompt_tokens": {"value": 16277.0}, "meta_eval_completion_tokens": {"value": 2973.0}, "meta_eval_prompt_cost": {"value": 0.00520864}, "meta_eval_completion_cost": {"value": 0.00380544}}, "created": "2025-12-10T21:48:56.8480841Z"}
{"ref": "jolly-stunt", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.146003}, "meta_inference_prompt_tokens": {"value": 12142.0}, "meta_inference_completion_tokens": {"value": 1622.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024284}, "meta_inference_completion_cost": {"value": 0.0025952}, "meta_eval_time": {"value": 35.754}, "meta_eval_prompt_tokens": {"value": 7410.0}, "meta_eval_completion_tokens": {"value": 3234.0}, "meta_eval_prompt_cost": {"value": 0.0023712}, "meta_eval_completion_cost": {"value": 0.00413952}}, "created": "2025-12-10T21:48:56.845081Z"}
{"ref": "khaki-sprite", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.671672063893751}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 18.60093}, "meta_inference_prompt_tokens": {"value": 16022.0}, "meta_inference_completion_tokens": {"value": 728.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032044}, "meta_inference_completion_cost": {"value": 0.0011648}, "meta_eval_time": {"value": 19.548}, "meta_eval_prompt_tokens": {"value": 11040.0}, "meta_eval_completion_tokens": {"value": 1673.0}, "meta_eval_prompt_cost": {"value": 0.0035328}, "meta_eval_completion_cost": {"value": 0.00214144}}, "created": "2025-12-10T21:48:57.6936625Z"}
{"ref": "jovial-winch", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.799405}, "meta_inference_prompt_tokens": {"value": 10780.0}, "meta_inference_completion_tokens": {"value": 1046.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002156}, "meta_inference_completion_cost": {"value": 0.0016736}, "meta_eval_time": {"value": 19.501}, "meta_eval_prompt_tokens": {"value": 5442.0}, "meta_eval_completion_tokens": {"value": 1719.0}, "meta_eval_prompt_cost": {"value": 0.00174144}, "meta_eval_completion_cost": {"value": 0.00220032}}, "created": "2025-12-10T21:48:57.7060927Z"}
{"ref": "jellied-tritone", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.846153846153846}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.40874}, "meta_inference_prompt_tokens": {"value": 10108.0}, "meta_inference_completion_tokens": {"value": 1230.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020216}, "meta_inference_completion_cost": {"value": 0.001968}, "meta_eval_time": {"value": 19.024}, "meta_eval_prompt_tokens": {"value": 5377.0}, "meta_eval_completion_tokens": {"value": 1785.0}, "meta_eval_prompt_cost": {"value": 0.00172064}, "meta_eval_completion_cost": {"value": 0.0022848}}, "created": "2025-12-10T21:48:57.7263142Z"}
{"ref": "linear-volume", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.86102}, "meta_inference_prompt_tokens": {"value": 7539.0}, "meta_inference_completion_tokens": {"value": 2271.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0015078}, "meta_inference_completion_cost": {"value": 0.0036336}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:48:57.7501248Z"}
{"ref": "linear-volume", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.651768}, "meta_inference_prompt_tokens": {"value": 2256.0}, "meta_inference_completion_tokens": {"value": 730.0}, "meta_inference_prompt_cost": {"value": 0.0004512}, "meta_inference_completion_cost": {"value": 0.001168}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:48:57.7927282Z"}
{"ref": "linear-volume", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.754158}, "meta_inference_prompt_tokens": {"value": 2256.0}, "meta_inference_completion_tokens": {"value": 721.0}, "meta_inference_prompt_cost": {"value": 0.0004512}, "meta_inference_completion_cost": {"value": 0.0011536}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:48:57.8325348Z"}
{"ref": "jellied-chenille", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.8}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.789473684210526}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.666666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.255657}, "meta_inference_prompt_tokens": {"value": 7564.0}, "meta_inference_completion_tokens": {"value": 1126.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0015128}, "meta_inference_completion_cost": {"value": 0.0018016}, "meta_eval_time": {"value": 25.158}, "meta_eval_prompt_tokens": {"value": 4558.0}, "meta_eval_completion_tokens": {"value": 2228.0}, "meta_eval_prompt_cost": {"value": 0.00145856}, "meta_eval_completion_cost": {"value": 0.00285184}}, "created": "2025-12-10T21:48:58.8579853Z"}
{"ref": "isometric-asadero", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.483333333333333}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 0.972972972972973}, "generation_factuality_f1": {"value": 0.436363636363636}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 23.661701}, "meta_inference_prompt_tokens": {"value": 12575.0}, "meta_inference_completion_tokens": {"value": 1189.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002515}, "meta_inference_completion_cost": {"value": 0.0019024}, "meta_eval_time": {"value": 40.64}, "meta_eval_prompt_tokens": {"value": 7979.0}, "meta_eval_completion_tokens": {"value": 3678.0}, "meta_eval_prompt_cost": {"value": 0.00255328}, "meta_eval_completion_cost": {"value": 0.00470784}}, "created": "2025-12-10T21:48:59.5852986Z"}
{"ref": "jellied-tritone", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.851921}, "meta_inference_prompt_tokens": {"value": 9636.0}, "meta_inference_completion_tokens": {"value": 1059.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019272}, "meta_inference_completion_cost": {"value": 0.0016944}, "meta_eval_time": {"value": 20.69}, "meta_eval_prompt_tokens": {"value": 4826.0}, "meta_eval_completion_tokens": {"value": 1871.0}, "meta_eval_prompt_cost": {"value": 0.00154432}, "meta_eval_completion_cost": {"value": 0.00239488}}, "created": "2025-12-10T21:48:59.8254305Z"}
{"ref": "jovial-winch", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 28.384429}, "meta_inference_prompt_tokens": {"value": 10954.0}, "meta_inference_completion_tokens": {"value": 1598.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021908}, "meta_inference_completion_cost": {"value": 0.0025568}, "meta_eval_time": {"value": 26.051}, "meta_eval_prompt_tokens": {"value": 5991.0}, "meta_eval_completion_tokens": {"value": 2350.0}, "meta_eval_prompt_cost": {"value": 0.00191712}, "meta_eval_completion_cost": {"value": 0.003008}}, "created": "2025-12-10T21:49:00.3245031Z"}
{"ref": "jovial-winch", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.289064826317888}, "generation_faithfulness": {"value": 0.777777777777778}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.858474}, "meta_inference_prompt_tokens": {"value": 10608.0}, "meta_inference_completion_tokens": {"value": 933.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021216}, "meta_inference_completion_cost": {"value": 0.0014928}, "meta_eval_time": {"value": 22.34}, "meta_eval_prompt_tokens": {"value": 5526.0}, "meta_eval_completion_tokens": {"value": 2031.0}, "meta_eval_prompt_cost": {"value": 0.00176832}, "meta_eval_completion_cost": {"value": 0.00259968}}, "created": "2025-12-10T21:49:00.3740035Z"}
{"ref": "iron-program", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.075605}, "meta_inference_prompt_tokens": {"value": 11786.0}, "meta_inference_completion_tokens": {"value": 1842.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023572}, "meta_inference_completion_cost": {"value": 0.0029472}, "meta_eval_time": {"value": 46.303}, "meta_eval_prompt_tokens": {"value": 8063.0}, "meta_eval_completion_tokens": {"value": 4139.0}, "meta_eval_prompt_cost": {"value": 0.00258016}, "meta_eval_completion_cost": {"value": 0.00529792}}, "created": "2025-12-10T21:49:00.7086138Z"}
{"ref": "isometric-asadero", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.483333333333333}, "retrieval_dcg": {"value": 1.44639463035719}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 0.32}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 27.073981}, "meta_inference_prompt_tokens": {"value": 13388.0}, "meta_inference_completion_tokens": {"value": 1334.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026776}, "meta_inference_completion_cost": {"value": 0.0021344}, "meta_eval_time": {"value": 44.977}, "meta_eval_prompt_tokens": {"value": 9491.0}, "meta_eval_completion_tokens": {"value": 3539.0}, "meta_eval_prompt_cost": {"value": 0.00303712}, "meta_eval_completion_cost": {"value": 0.00452992}}, "created": "2025-12-10T21:49:02.4085294Z"}
{"ref": "jellied-chenille", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 2.017782560806}, "generation_faithfulness": {"value": 0.708333333333334}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.59007}, "meta_inference_prompt_tokens": {"value": 15291.0}, "meta_inference_completion_tokens": {"value": 1670.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030582}, "meta_inference_completion_cost": {"value": 0.002672}, "meta_eval_time": {"value": 28.707}, "meta_eval_prompt_tokens": {"value": 9692.0}, "meta_eval_completion_tokens": {"value": 2504.0}, "meta_eval_prompt_cost": {"value": 0.00310144}, "meta_eval_completion_cost": {"value": 0.00320512}}, "created": "2025-12-10T21:49:02.5699094Z"}
{"ref": "lime-forest", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.520908}, "meta_inference_prompt_tokens": {"value": 12993.0}, "meta_inference_completion_tokens": {"value": 511.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025986}, "meta_inference_completion_cost": {"value": 0.0008176}, "meta_eval_time": {"value": 10.625}, "meta_eval_prompt_tokens": {"value": 7152.0}, "meta_eval_completion_tokens": {"value": 645.0}, "meta_eval_prompt_cost": {"value": 0.00228864}, "meta_eval_completion_cost": {"value": 0.0008256}}, "created": "2025-12-10T21:49:02.8564893Z"}
{"ref": "lime-forest", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.250252}, "meta_inference_prompt_tokens": {"value": 13825.0}, "meta_inference_completion_tokens": {"value": 545.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002765}, "meta_inference_completion_cost": {"value": 0.000872}, "meta_eval_time": {"value": 11.495}, "meta_eval_prompt_tokens": {"value": 7876.0}, "meta_eval_completion_tokens": {"value": 893.0}, "meta_eval_prompt_cost": {"value": 0.00252032}, "meta_eval_completion_cost": {"value": 0.00114304}}, "created": "2025-12-10T21:49:02.9455137Z"}
{"ref": "lazy-grade", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.235294117647059}, "retrieval_mrr": {"value": 0.225}, "retrieval_dcg": {"value": 0.657237182772003}, "generation_faithfulness": {"value": 0.526315789473684}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.133333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.285714285714286}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.3524}, "meta_inference_prompt_tokens": {"value": 9563.0}, "meta_inference_completion_tokens": {"value": 1611.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019126}, "meta_inference_completion_cost": {"value": 0.0025776}, "meta_eval_time": {"value": 17.621}, "meta_eval_prompt_tokens": {"value": 4643.0}, "meta_eval_completion_tokens": {"value": 2153.0}, "meta_eval_prompt_cost": {"value": 0.00148576}, "meta_eval_completion_cost": {"value": 0.00275584}}, "created": "2025-12-10T21:49:03.7457656Z"}
{"ref": "kinetic-function", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.578947368421053}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.507014}, "meta_inference_prompt_tokens": {"value": 12010.0}, "meta_inference_completion_tokens": {"value": 1524.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002402}, "meta_inference_completion_cost": {"value": 0.0024384}, "meta_eval_time": {"value": 25.154}, "meta_eval_prompt_tokens": {"value": 6907.0}, "meta_eval_completion_tokens": {"value": 2070.0}, "meta_eval_prompt_cost": {"value": 0.00221024}, "meta_eval_completion_cost": {"value": 0.0026496}}, "created": "2025-12-10T21:49:05.0068243Z"}
{"ref": "lower-accelerator", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.845577}, "meta_inference_prompt_tokens": {"value": 14200.0}, "meta_inference_completion_tokens": {"value": 1372.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00284}, "meta_inference_completion_cost": {"value": 0.0021952}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:49:05.0791621Z"}
{"ref": "lime-forest", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.221015}, "meta_inference_prompt_tokens": {"value": 12777.0}, "meta_inference_completion_tokens": {"value": 579.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025554}, "meta_inference_completion_cost": {"value": 0.0009264}, "meta_eval_time": {"value": 12.686}, "meta_eval_prompt_tokens": {"value": 6942.0}, "meta_eval_completion_tokens": {"value": 832.0}, "meta_eval_prompt_cost": {"value": 0.00222144}, "meta_eval_completion_cost": {"value": 0.00106496}}, "created": "2025-12-10T21:49:05.0726492Z"}
{"ref": "lower-accelerator", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.423566}, "meta_inference_prompt_tokens": {"value": 17881.0}, "meta_inference_completion_tokens": {"value": 1267.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0035762}, "meta_inference_completion_cost": {"value": 0.0020272}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:49:05.1168397Z"}
{"ref": "kinetic-function", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.895982}, "meta_inference_prompt_tokens": {"value": 11340.0}, "meta_inference_completion_tokens": {"value": 877.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002268}, "meta_inference_completion_cost": {"value": 0.0014032}, "meta_eval_time": {"value": 10.363}, "meta_eval_prompt_tokens": {"value": 5621.0}, "meta_eval_completion_tokens": {"value": 839.0}, "meta_eval_prompt_cost": {"value": 0.00179872}, "meta_eval_completion_cost": {"value": 0.00107392}}, "created": "2025-12-10T21:49:05.5928144Z"}
{"ref": "linear-volume", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.2}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 32.443613}, "meta_inference_prompt_tokens": {"value": 11561.0}, "meta_inference_completion_tokens": {"value": 1626.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023122}, "meta_inference_completion_cost": {"value": 0.0026016}, "meta_eval_time": {"value": 10.632}, "meta_eval_prompt_tokens": {"value": 6297.0}, "meta_eval_completion_tokens": {"value": 768.0}, "meta_eval_prompt_cost": {"value": 0.00201504}, "meta_eval_completion_cost": {"value": 0.00098304}}, "created": "2025-12-10T21:49:06.1399297Z"}
{"ref": "isometric-asadero", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 0.86046511627907}, "generation_factuality_f1": {"value": 0.216216216216216}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.4}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 27.082522}, "meta_inference_prompt_tokens": {"value": 13180.0}, "meta_inference_completion_tokens": {"value": 1531.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002636}, "meta_inference_completion_cost": {"value": 0.0024496}, "meta_eval_time": {"value": 51.176}, "meta_eval_prompt_tokens": {"value": 9096.0}, "meta_eval_completion_tokens": {"value": 4336.0}, "meta_eval_prompt_cost": {"value": 0.00291072}, "meta_eval_completion_cost": {"value": 0.00555008}}, "created": "2025-12-10T21:49:06.3538922Z"}
{"ref": "kinetic-function", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.92}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.638533}, "meta_inference_prompt_tokens": {"value": 11640.0}, "meta_inference_completion_tokens": {"value": 1512.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002328}, "meta_inference_completion_cost": {"value": 0.0024192}, "meta_eval_time": {"value": 25.795}, "meta_eval_prompt_tokens": {"value": 6518.0}, "meta_eval_completion_tokens": {"value": 2284.0}, "meta_eval_prompt_cost": {"value": 0.00208576}, "meta_eval_completion_cost": {"value": 0.00292352}}, "created": "2025-12-10T21:49:08.2376802Z"}
{"ref": "khaki-sprite", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.785714285714286}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 23.984903}, "meta_inference_prompt_tokens": {"value": 20167.0}, "meta_inference_completion_tokens": {"value": 1061.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0040334}, "meta_inference_completion_cost": {"value": 0.0016976}, "meta_eval_time": {"value": 30.181}, "meta_eval_prompt_tokens": {"value": 15976.0}, "meta_eval_completion_tokens": {"value": 2802.0}, "meta_eval_prompt_cost": {"value": 0.00511232}, "meta_eval_completion_cost": {"value": 0.00358656}}, "created": "2025-12-10T21:49:08.8372298Z"}
{"ref": "isometric-asadero", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.483333333333333}, "retrieval_dcg": {"value": 1.74614143485912}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.436363636363636}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 26.940981}, "meta_inference_prompt_tokens": {"value": 13069.0}, "meta_inference_completion_tokens": {"value": 1760.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026138}, "meta_inference_completion_cost": {"value": 0.002816}, "meta_eval_time": {"value": 50.707}, "meta_eval_prompt_tokens": {"value": 9066.0}, "meta_eval_completion_tokens": {"value": 4031.0}, "meta_eval_prompt_cost": {"value": 0.00290112}, "meta_eval_completion_cost": {"value": 0.00515968}}, "created": "2025-12-10T21:49:10.9162489Z"}
{"ref": "jolly-stunt", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.944444444444444}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.842526}, "meta_inference_prompt_tokens": {"value": 12717.0}, "meta_inference_completion_tokens": {"value": 2001.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025434}, "meta_inference_completion_cost": {"value": 0.0032016}, "meta_eval_time": {"value": 36.376}, "meta_eval_prompt_tokens": {"value": 8209.0}, "meta_eval_completion_tokens": {"value": 3255.0}, "meta_eval_prompt_cost": {"value": 0.00262688}, "meta_eval_completion_cost": {"value": 0.0041664}}, "created": "2025-12-10T21:49:11.5585942Z"}
{"ref": "level-ambient", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.236347}, "meta_inference_prompt_tokens": {"value": 12310.0}, "meta_inference_completion_tokens": {"value": 977.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002462}, "meta_inference_completion_cost": {"value": 0.0015632}, "meta_eval_time": {"value": 28.886}, "meta_eval_prompt_tokens": {"value": 7986.0}, "meta_eval_completion_tokens": {"value": 2875.0}, "meta_eval_prompt_cost": {"value": 0.00255552}, "meta_eval_completion_cost": {"value": 0.00368}}, "created": "2025-12-10T21:49:13.0394616Z"}
{"ref": "lower-accelerator", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 36.031057}, "meta_inference_prompt_tokens": {"value": 23578.0}, "meta_inference_completion_tokens": {"value": 1503.0}, "meta_inference_tool_call_count": {"value": 3.0}, "meta_inference_prompt_cost": {"value": 0.0047156}, "meta_inference_completion_cost": {"value": 0.0024048}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:49:13.085659Z"}
{"ref": "lime-forest", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.156848}, "meta_inference_prompt_tokens": {"value": 12000.0}, "meta_inference_completion_tokens": {"value": 608.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024}, "meta_inference_completion_cost": {"value": 0.0009728}, "meta_eval_time": {"value": 15.744}, "meta_eval_prompt_tokens": {"value": 6574.0}, "meta_eval_completion_tokens": {"value": 1270.0}, "meta_eval_prompt_cost": {"value": 0.00210368}, "meta_eval_completion_cost": {"value": 0.0016256}}, "created": "2025-12-10T21:49:13.6172285Z"}
{"ref": "lazy-grade", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.235294117647059}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 0.719741384391281}, "generation_faithfulness": {"value": 0.6}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.133333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.285714285714286}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.739866}, "meta_inference_prompt_tokens": {"value": 10175.0}, "meta_inference_completion_tokens": {"value": 1702.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002035}, "meta_inference_completion_cost": {"value": 0.0027232}, "meta_eval_time": {"value": 25.099}, "meta_eval_prompt_tokens": {"value": 5298.0}, "meta_eval_completion_tokens": {"value": 2143.0}, "meta_eval_prompt_cost": {"value": 0.00169536}, "meta_eval_completion_cost": {"value": 0.00274304}}, "created": "2025-12-10T21:49:13.8431949Z"}
{"ref": "jolly-stunt", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.689655172413793}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.731011}, "meta_inference_prompt_tokens": {"value": 11757.0}, "meta_inference_completion_tokens": {"value": 1632.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023514}, "meta_inference_completion_cost": {"value": 0.0026112}, "meta_eval_time": {"value": 37.075}, "meta_eval_prompt_tokens": {"value": 7565.0}, "meta_eval_completion_tokens": {"value": 3274.0}, "meta_eval_prompt_cost": {"value": 0.0024208}, "meta_eval_completion_cost": {"value": 0.00419072}}, "created": "2025-12-10T21:49:14.0286445Z"}
{"ref": "many-goose", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 8.704994}, "meta_inference_prompt_tokens": {"value": 2252.0}, "meta_inference_completion_tokens": {"value": 444.0}, "meta_inference_prompt_cost": {"value": 0.0004504}, "meta_inference_completion_cost": {"value": 0.0007104}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:49:14.0733814Z"}
{"ref": "lazy-grade", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.235294117647059}, "retrieval_mrr": {"value": 0.225}, "retrieval_dcg": {"value": 0.689540520441356}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.133333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.285714285714286}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.986147}, "meta_inference_prompt_tokens": {"value": 10307.0}, "meta_inference_completion_tokens": {"value": 1586.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020614}, "meta_inference_completion_cost": {"value": 0.0025376}, "meta_eval_time": {"value": 27.206}, "meta_eval_prompt_tokens": {"value": 5643.0}, "meta_eval_completion_tokens": {"value": 2554.0}, "meta_eval_prompt_cost": {"value": 0.00180576}, "meta_eval_completion_cost": {"value": 0.00326912}}, "created": "2025-12-10T21:49:16.9276776Z"}
{"ref": "many-goose", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.585183}, "meta_inference_prompt_tokens": {"value": 4680.0}, "meta_inference_completion_tokens": {"value": 705.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.000936}, "meta_inference_completion_cost": {"value": 0.001128}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:49:16.9741774Z"}
{"ref": "lime-forest", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.85899}, "meta_inference_prompt_tokens": {"value": 14718.0}, "meta_inference_completion_tokens": {"value": 901.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029436}, "meta_inference_completion_cost": {"value": 0.0014416}, "meta_eval_time": {"value": 18.604}, "meta_eval_prompt_tokens": {"value": 9004.0}, "meta_eval_completion_tokens": {"value": 1550.0}, "meta_eval_prompt_cost": {"value": 0.00288128}, "meta_eval_completion_cost": {"value": 0.001984}}, "created": "2025-12-10T21:49:17.502606Z"}
{"ref": "level-ambient", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.931034482758621}, "generation_factuality_f1": {"value": 0.941176470588235}, "generation_factuality_precision": {"value": 0.888888888888889}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.923765}, "meta_inference_prompt_tokens": {"value": 12310.0}, "meta_inference_completion_tokens": {"value": 1136.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002462}, "meta_inference_completion_cost": {"value": 0.0018176}, "meta_eval_time": {"value": 28.982}, "meta_eval_prompt_tokens": {"value": 7932.0}, "meta_eval_completion_tokens": {"value": 2978.0}, "meta_eval_prompt_cost": {"value": 0.00253824}, "meta_eval_completion_cost": {"value": 0.00381184}}, "created": "2025-12-10T21:49:17.7051265Z"}
{"ref": "many-goose", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.068585}, "meta_inference_prompt_tokens": {"value": 2252.0}, "meta_inference_completion_tokens": {"value": 729.0}, "meta_inference_prompt_cost": {"value": 0.0004504}, "meta_inference_completion_cost": {"value": 0.0011664}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:49:17.7461324Z"}
{"ref": "many-goose", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.922967}, "meta_inference_prompt_tokens": {"value": 4682.0}, "meta_inference_completion_tokens": {"value": 1095.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009364}, "meta_inference_completion_cost": {"value": 0.001752}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:49:17.7867238Z"}
{"ref": "lazy-grade", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.470588235294118}, "retrieval_mrr": {"value": 0.4875}, "retrieval_dcg": {"value": 2.25332791322268}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.307692307692308}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.571428571428571}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.244155}, "meta_inference_prompt_tokens": {"value": 11109.0}, "meta_inference_completion_tokens": {"value": 1584.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022218}, "meta_inference_completion_cost": {"value": 0.0025344}, "meta_eval_time": {"value": 31.685}, "meta_eval_prompt_tokens": {"value": 6292.0}, "meta_eval_completion_tokens": {"value": 2331.0}, "meta_eval_prompt_cost": {"value": 0.00201344}, "meta_eval_completion_cost": {"value": 0.00298368}}, "created": "2025-12-10T21:49:17.8429565Z"}
{"ref": "khaki-sprite", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 22.744419}, "meta_inference_prompt_tokens": {"value": 20170.0}, "meta_inference_completion_tokens": {"value": 1123.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.004034}, "meta_inference_completion_cost": {"value": 0.0017968}, "meta_eval_time": {"value": 40.889}, "meta_eval_prompt_tokens": {"value": 16407.0}, "meta_eval_completion_tokens": {"value": 3001.0}, "meta_eval_prompt_cost": {"value": 0.00525024}, "meta_eval_completion_cost": {"value": 0.00384128}}, "created": "2025-12-10T21:49:19.1348511Z"}
{"ref": "level-ambient", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.902057}, "meta_inference_prompt_tokens": {"value": 12310.0}, "meta_inference_completion_tokens": {"value": 895.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002462}, "meta_inference_completion_cost": {"value": 0.001432}, "meta_eval_time": {"value": 33.943}, "meta_eval_prompt_tokens": {"value": 7860.0}, "meta_eval_completion_tokens": {"value": 2937.0}, "meta_eval_prompt_cost": {"value": 0.0025152}, "meta_eval_completion_cost": {"value": 0.00375936}}, "created": "2025-12-10T21:49:21.3020836Z"}
{"ref": "lazy-grade", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.470588235294118}, "retrieval_mrr": {"value": 0.4875}, "retrieval_dcg": {"value": 2.04408999000654}, "generation_faithfulness": {"value": 0.962962962962963}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.307692307692308}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.571428571428571}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.812889}, "meta_inference_prompt_tokens": {"value": 10887.0}, "meta_inference_completion_tokens": {"value": 1978.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021774}, "meta_inference_completion_cost": {"value": 0.0031648}, "meta_eval_time": {"value": 32.679}, "meta_eval_prompt_tokens": {"value": 6840.0}, "meta_eval_completion_tokens": {"value": 3063.0}, "meta_eval_prompt_cost": {"value": 0.0021888}, "meta_eval_completion_cost": {"value": 0.00392064}}, "created": "2025-12-10T21:49:21.3741544Z"}
{"ref": "lower-accelerator", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.9}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 20.178957}, "meta_inference_prompt_tokens": {"value": 7328.0}, "meta_inference_completion_tokens": {"value": 1406.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0014656}, "meta_inference_completion_cost": {"value": 0.0022496}, "meta_eval_time": {"value": 21.694}, "meta_eval_prompt_tokens": {"value": 3987.0}, "meta_eval_completion_tokens": {"value": 2279.0}, "meta_eval_prompt_cost": {"value": 0.00127584}, "meta_eval_completion_cost": {"value": 0.00291712}}, "created": "2025-12-10T21:49:22.109868Z"}
{"ref": "level-ambient", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.925925925925926}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.85506}, "meta_inference_prompt_tokens": {"value": 12311.0}, "meta_inference_completion_tokens": {"value": 1165.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024622}, "meta_inference_completion_cost": {"value": 0.001864}, "meta_eval_time": {"value": 34.979}, "meta_eval_prompt_tokens": {"value": 7939.0}, "meta_eval_completion_tokens": {"value": 2788.0}, "meta_eval_prompt_cost": {"value": 0.00254048}, "meta_eval_completion_cost": {"value": 0.00356864}}, "created": "2025-12-10T21:49:22.8226149Z"}
{"ref": "lime-sparrow", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.964263086904791}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 34.644173}, "meta_inference_prompt_tokens": {"value": 10141.0}, "meta_inference_completion_tokens": {"value": 1676.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020282}, "meta_inference_completion_cost": {"value": 0.0026816}, "meta_eval_time": {"value": 27.648}, "meta_eval_prompt_tokens": {"value": 5734.0}, "meta_eval_completion_tokens": {"value": 2366.0}, "meta_eval_prompt_cost": {"value": 0.00183488}, "meta_eval_completion_cost": {"value": 0.00302848}}, "created": "2025-12-10T21:49:24.3609817Z"}
{"ref": "many-goose", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.050864}, "meta_inference_prompt_tokens": {"value": 2252.0}, "meta_inference_completion_tokens": {"value": 772.0}, "meta_inference_prompt_cost": {"value": 0.0004504}, "meta_inference_completion_cost": {"value": 0.0012352}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:49:24.4019014Z"}
{"ref": "level-ambient", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.945945945945946}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.624229}, "meta_inference_prompt_tokens": {"value": 12578.0}, "meta_inference_completion_tokens": {"value": 1314.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025156}, "meta_inference_completion_cost": {"value": 0.0021024}, "meta_eval_time": {"value": 40.569}, "meta_eval_prompt_tokens": {"value": 8593.0}, "meta_eval_completion_tokens": {"value": 3546.0}, "meta_eval_prompt_cost": {"value": 0.00274976}, "meta_eval_completion_cost": {"value": 0.00453888}}, "created": "2025-12-10T21:49:26.1719453Z"}
{"ref": "lime-sparrow", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 1.55852487112829}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 25.245056}, "meta_inference_prompt_tokens": {"value": 10728.0}, "meta_inference_completion_tokens": {"value": 1562.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021456}, "meta_inference_completion_cost": {"value": 0.0024992}, "meta_eval_time": {"value": 37.574}, "meta_eval_prompt_tokens": {"value": 6575.0}, "meta_eval_completion_tokens": {"value": 3344.0}, "meta_eval_prompt_cost": {"value": 0.002104}, "meta_eval_completion_cost": {"value": 0.00428032}}, "created": "2025-12-10T21:49:29.9398523Z"}
{"ref": "lower-accelerator", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.68}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 27.538448}, "meta_inference_prompt_tokens": {"value": 9343.0}, "meta_inference_completion_tokens": {"value": 1537.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018686}, "meta_inference_completion_cost": {"value": 0.0024592}, "meta_eval_time": {"value": 30.547}, "meta_eval_prompt_tokens": {"value": 5480.0}, "meta_eval_completion_tokens": {"value": 2423.0}, "meta_eval_prompt_cost": {"value": 0.0017536}, "meta_eval_completion_cost": {"value": 0.00310144}}, "created": "2025-12-10T21:49:30.9124728Z"}
{"ref": "lime-sparrow", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.22323}, "meta_inference_prompt_tokens": {"value": 9763.0}, "meta_inference_completion_tokens": {"value": 1264.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019526}, "meta_inference_completion_cost": {"value": 0.0020224}, "meta_eval_time": {"value": 40.118}, "meta_eval_prompt_tokens": {"value": 5533.0}, "meta_eval_completion_tokens": {"value": 2817.0}, "meta_eval_prompt_cost": {"value": 0.00177056}, "meta_eval_completion_cost": {"value": 0.00360576}}, "created": "2025-12-10T21:49:31.5754949Z"}
{"ref": "lime-sparrow", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.361111111111111}, "retrieval_dcg": {"value": 1.10659419162582}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.350877192982456}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 27.346412}, "meta_inference_prompt_tokens": {"value": 12619.0}, "meta_inference_completion_tokens": {"value": 1399.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025238}, "meta_inference_completion_cost": {"value": 0.0022384}, "meta_eval_time": {"value": 35.155}, "meta_eval_prompt_tokens": {"value": 8200.0}, "meta_eval_completion_tokens": {"value": 3315.0}, "meta_eval_prompt_cost": {"value": 0.002624}, "meta_eval_completion_cost": {"value": 0.0042432}}, "created": "2025-12-10T21:49:32.8913459Z"}
{"ref": "loud-catch", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.784884}, "meta_inference_prompt_tokens": {"value": 12562.0}, "meta_inference_completion_tokens": {"value": 1986.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025124}, "meta_inference_completion_cost": {"value": 0.0031776}, "meta_eval_time": {"value": 34.444}, "meta_eval_prompt_tokens": {"value": 8632.0}, "meta_eval_completion_tokens": {"value": 3092.0}, "meta_eval_prompt_cost": {"value": 0.00276224}, "meta_eval_completion_cost": {"value": 0.00395776}}, "created": "2025-12-10T21:49:37.0699824Z"}
{"ref": "metal-cymbal-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 28.757997}, "meta_inference_prompt_tokens": {"value": 47263.0}, "meta_inference_completion_tokens": {"value": 1189.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0094526}, "meta_inference_completion_cost": {"value": 0.0019024}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:49:37.1148981Z"}
{"ref": "loud-catch", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428571}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 31.429653}, "meta_inference_prompt_tokens": {"value": 14023.0}, "meta_inference_completion_tokens": {"value": 2103.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028046}, "meta_inference_completion_cost": {"value": 0.0033648}, "meta_eval_time": {"value": 36.629}, "meta_eval_prompt_tokens": {"value": 9476.0}, "meta_eval_completion_tokens": {"value": 3065.0}, "meta_eval_prompt_cost": {"value": 0.00303232}, "meta_eval_completion_cost": {"value": 0.0039232}}, "created": "2025-12-10T21:49:37.3787204Z"}
{"ref": "lower-keel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.375}, "retrieval_mrr": {"value": 0.566666666666667}, "retrieval_dcg": {"value": 1.94639463035719}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.875}, "generation_factuality_precision": {"value": 0.777777777777778}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.230769230769231}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.355407}, "meta_inference_prompt_tokens": {"value": 11507.0}, "meta_inference_completion_tokens": {"value": 1211.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023014}, "meta_inference_completion_cost": {"value": 0.0019376}, "meta_eval_time": {"value": 37.017}, "meta_eval_prompt_tokens": {"value": 7442.0}, "meta_eval_completion_tokens": {"value": 2972.0}, "meta_eval_prompt_cost": {"value": 0.00238144}, "meta_eval_completion_cost": {"value": 0.00380416}}, "created": "2025-12-10T21:49:40.0039798Z"}
{"ref": "lime-sparrow", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 1.60234862196714}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.470588235294118}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 30.8253}, "meta_inference_prompt_tokens": {"value": 11643.0}, "meta_inference_completion_tokens": {"value": 1343.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023286}, "meta_inference_completion_cost": {"value": 0.0021488}, "meta_eval_time": {"value": 42.264}, "meta_eval_prompt_tokens": {"value": 7594.0}, "meta_eval_completion_tokens": {"value": 3593.0}, "meta_eval_prompt_cost": {"value": 0.00243008}, "meta_eval_completion_cost": {"value": 0.00459904}}, "created": "2025-12-10T21:49:40.057938Z"}
{"ref": "local-manager", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.972222222222222}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.13362}, "meta_inference_prompt_tokens": {"value": 13251.0}, "meta_inference_completion_tokens": {"value": 1146.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026502}, "meta_inference_completion_cost": {"value": 0.0018336}, "meta_eval_time": {"value": 46.374}, "meta_eval_prompt_tokens": {"value": 9303.0}, "meta_eval_completion_tokens": {"value": 3710.0}, "meta_eval_prompt_cost": {"value": 0.00297696}, "meta_eval_completion_cost": {"value": 0.0047488}}, "created": "2025-12-10T21:49:40.0613773Z"}
{"ref": "lower-keel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.301022}, "meta_inference_prompt_tokens": {"value": 11331.0}, "meta_inference_completion_tokens": {"value": 1317.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022662}, "meta_inference_completion_cost": {"value": 0.0021072}, "meta_eval_time": {"value": 37.2}, "meta_eval_prompt_tokens": {"value": 7510.0}, "meta_eval_completion_tokens": {"value": 3490.0}, "meta_eval_prompt_cost": {"value": 0.0024032}, "meta_eval_completion_cost": {"value": 0.0044672}}, "created": "2025-12-10T21:49:40.9888384Z"}
{"ref": "magnetic-rotor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 0.85}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.384498}, "meta_inference_prompt_tokens": {"value": 11004.0}, "meta_inference_completion_tokens": {"value": 1232.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022008}, "meta_inference_completion_cost": {"value": 0.0019712}, "meta_eval_time": {"value": 28.53}, "meta_eval_prompt_tokens": {"value": 6825.0}, "meta_eval_completion_tokens": {"value": 2632.0}, "meta_eval_prompt_cost": {"value": 0.002184}, "meta_eval_completion_cost": {"value": 0.00336896}}, "created": "2025-12-10T21:49:42.4110167Z"}
{"ref": "lower-keel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.645279}, "meta_inference_prompt_tokens": {"value": 12282.0}, "meta_inference_completion_tokens": {"value": 1482.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024564}, "meta_inference_completion_cost": {"value": 0.0023712}, "meta_eval_time": {"value": 34.194}, "meta_eval_prompt_tokens": {"value": 8482.0}, "meta_eval_completion_tokens": {"value": 3460.0}, "meta_eval_prompt_cost": {"value": 0.00271424}, "meta_eval_completion_cost": {"value": 0.0044288}}, "created": "2025-12-10T21:49:42.4740163Z"}
{"ref": "local-manager", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.894927}, "meta_inference_prompt_tokens": {"value": 13680.0}, "meta_inference_completion_tokens": {"value": 1358.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002736}, "meta_inference_completion_cost": {"value": 0.0021728}, "meta_eval_time": {"value": 48.297}, "meta_eval_prompt_tokens": {"value": 9736.0}, "meta_eval_completion_tokens": {"value": 3814.0}, "meta_eval_prompt_cost": {"value": 0.00311552}, "meta_eval_completion_cost": {"value": 0.00488192}}, "created": "2025-12-10T21:49:46.0339167Z"}
{"ref": "local-manager", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.853674}, "meta_inference_prompt_tokens": {"value": 13684.0}, "meta_inference_completion_tokens": {"value": 1828.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027368}, "meta_inference_completion_cost": {"value": 0.0029248}, "meta_eval_time": {"value": 49.746}, "meta_eval_prompt_tokens": {"value": 10488.0}, "meta_eval_completion_tokens": {"value": 4711.0}, "meta_eval_prompt_cost": {"value": 0.00335616}, "meta_eval_completion_cost": {"value": 0.00603008}}, "created": "2025-12-10T21:49:47.5009012Z"}
{"ref": "loud-catch", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.685714285714286}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 32.353028}, "meta_inference_prompt_tokens": {"value": 13423.0}, "meta_inference_completion_tokens": {"value": 1832.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026846}, "meta_inference_completion_cost": {"value": 0.0029312}, "meta_eval_time": {"value": 46.582}, "meta_eval_prompt_tokens": {"value": 10133.0}, "meta_eval_completion_tokens": {"value": 4397.0}, "meta_eval_prompt_cost": {"value": 0.00324256}, "meta_eval_completion_cost": {"value": 0.00562816}}, "created": "2025-12-10T21:49:49.0325287Z"}
{"ref": "mild-compression", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.208003}, "meta_inference_prompt_tokens": {"value": 4659.0}, "meta_inference_completion_tokens": {"value": 1026.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009318}, "meta_inference_completion_cost": {"value": 0.0016416}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:49:49.0773584Z"}
{"ref": "mild-compression", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.613211}, "meta_inference_prompt_tokens": {"value": 4652.0}, "meta_inference_completion_tokens": {"value": 1153.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009304}, "meta_inference_completion_cost": {"value": 0.0018448}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:49:49.1281018Z"}
{"ref": "mild-compression", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.150278}, "meta_inference_prompt_tokens": {"value": 4653.0}, "meta_inference_completion_tokens": {"value": 1022.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009306}, "meta_inference_completion_cost": {"value": 0.0016352}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:49:49.1677284Z"}
{"ref": "mild-compression", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.488952}, "meta_inference_prompt_tokens": {"value": 4652.0}, "meta_inference_completion_tokens": {"value": 1079.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009304}, "meta_inference_completion_cost": {"value": 0.0017264}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:49:49.217222Z"}
{"ref": "mild-compression", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.440474}, "meta_inference_prompt_tokens": {"value": 2256.0}, "meta_inference_completion_tokens": {"value": 434.0}, "meta_inference_prompt_cost": {"value": 0.0004512}, "meta_inference_completion_cost": {"value": 0.0006944}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:49:49.25591Z"}
{"ref": "loud-catch", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.894736842105263}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.120274}, "meta_inference_prompt_tokens": {"value": 14074.0}, "meta_inference_completion_tokens": {"value": 1869.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028148}, "meta_inference_completion_cost": {"value": 0.0029904}, "meta_eval_time": {"value": 40.609}, "meta_eval_prompt_tokens": {"value": 9785.0}, "meta_eval_completion_tokens": {"value": 3527.0}, "meta_eval_prompt_cost": {"value": 0.0031312}, "meta_eval_completion_cost": {"value": 0.00451456}}, "created": "2025-12-10T21:49:49.4926778Z"}
{"ref": "lower-keel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.96875}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.423671}, "meta_inference_prompt_tokens": {"value": 11651.0}, "meta_inference_completion_tokens": {"value": 1494.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023302}, "meta_inference_completion_cost": {"value": 0.0023904}, "meta_eval_time": {"value": 46.888}, "meta_eval_prompt_tokens": {"value": 7801.0}, "meta_eval_completion_tokens": {"value": 3088.0}, "meta_eval_prompt_cost": {"value": 0.00249632}, "meta_eval_completion_cost": {"value": 0.00395264}}, "created": "2025-12-10T21:49:49.7989839Z"}
{"ref": "many-muenster", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 31.943503}, "meta_inference_prompt_tokens": {"value": 13971.0}, "meta_inference_completion_tokens": {"value": 1749.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027942}, "meta_inference_completion_cost": {"value": 0.0027984}, "meta_eval_time": {"value": 25.597}, "meta_eval_prompt_tokens": {"value": 9115.0}, "meta_eval_completion_tokens": {"value": 2456.0}, "meta_eval_prompt_cost": {"value": 0.0029168}, "meta_eval_completion_cost": {"value": 0.00314368}}, "created": "2025-12-10T21:49:50.0387648Z"}
{"ref": "magenta-cockatoo", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.835820895522388}, "generation_factuality_precision": {"value": 0.875}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 24.660061}, "meta_inference_prompt_tokens": {"value": 10236.0}, "meta_inference_completion_tokens": {"value": 1122.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020472}, "meta_inference_completion_cost": {"value": 0.0017952}, "meta_eval_time": {"value": 45.269}, "meta_eval_prompt_tokens": {"value": 6477.0}, "meta_eval_completion_tokens": {"value": 4002.0}, "meta_eval_prompt_cost": {"value": 0.00207264}, "meta_eval_completion_cost": {"value": 0.00512256}}, "created": "2025-12-10T21:49:50.4248712Z"}
{"ref": "magnetic-rotor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.71342}, "meta_inference_prompt_tokens": {"value": 10930.0}, "meta_inference_completion_tokens": {"value": 1077.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002186}, "meta_inference_completion_cost": {"value": 0.0017232}, "meta_eval_time": {"value": 46.184}, "meta_eval_prompt_tokens": {"value": 6822.0}, "meta_eval_completion_tokens": {"value": 3274.0}, "meta_eval_prompt_cost": {"value": 0.00218304}, "meta_eval_completion_cost": {"value": 0.00419072}}, "created": "2025-12-10T21:49:51.3054249Z"}
{"ref": "local-manager", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.93195974923544}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.982121}, "meta_inference_prompt_tokens": {"value": 13560.0}, "meta_inference_completion_tokens": {"value": 1567.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002712}, "meta_inference_completion_cost": {"value": 0.0025072}, "meta_eval_time": {"value": 51.482}, "meta_eval_prompt_tokens": {"value": 10152.0}, "meta_eval_completion_tokens": {"value": 4057.0}, "meta_eval_prompt_cost": {"value": 0.00324864}, "meta_eval_completion_cost": {"value": 0.00519296}}, "created": "2025-12-10T21:49:51.343838Z"}
{"ref": "magenta-cockatoo", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.872340425531915}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.57988}, "meta_inference_prompt_tokens": {"value": 10536.0}, "meta_inference_completion_tokens": {"value": 1172.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021072}, "meta_inference_completion_cost": {"value": 0.0018752}, "meta_eval_time": {"value": 45.673}, "meta_eval_prompt_tokens": {"value": 6996.0}, "meta_eval_completion_tokens": {"value": 4164.0}, "meta_eval_prompt_cost": {"value": 0.00223872}, "meta_eval_completion_cost": {"value": 0.00532992}}, "created": "2025-12-10T21:49:51.851668Z"}
{"ref": "metal-cymbal-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 22.426316}, "meta_inference_prompt_tokens": {"value": 17830.0}, "meta_inference_completion_tokens": {"value": 1509.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003566}, "meta_inference_completion_cost": {"value": 0.0024144}, "meta_eval_time": {"value": 11.764}, "meta_eval_prompt_tokens": {"value": 11295.0}, "meta_eval_completion_tokens": {"value": 1075.0}, "meta_eval_prompt_cost": {"value": 0.0036144}, "meta_eval_completion_cost": {"value": 0.001376}}, "created": "2025-12-10T21:49:51.8734433Z"}
{"ref": "local-manager", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.96426308690479}, "generation_faithfulness": {"value": 0.955555555555556}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.315842}, "meta_inference_prompt_tokens": {"value": 13348.0}, "meta_inference_completion_tokens": {"value": 1310.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026696}, "meta_inference_completion_cost": {"value": 0.002096}, "meta_eval_time": {"value": 52.585}, "meta_eval_prompt_tokens": {"value": 9492.0}, "meta_eval_completion_tokens": {"value": 4273.0}, "meta_eval_prompt_cost": {"value": 0.00303744}, "meta_eval_completion_cost": {"value": 0.00546944}}, "created": "2025-12-10T21:49:52.2326516Z"}
{"ref": "magenta-cockatoo", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.948717948717949}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.99958}, "meta_inference_prompt_tokens": {"value": 10513.0}, "meta_inference_completion_tokens": {"value": 1221.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021026}, "meta_inference_completion_cost": {"value": 0.0019536}, "meta_eval_time": {"value": 39.847}, "meta_eval_prompt_tokens": {"value": 6853.0}, "meta_eval_completion_tokens": {"value": 3726.0}, "meta_eval_prompt_cost": {"value": 0.00219296}, "meta_eval_completion_cost": {"value": 0.00476928}}, "created": "2025-12-10T21:49:52.9826716Z"}
{"ref": "magenta-cockatoo", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.933333333333333}, "generation_factuality_precision": {"value": 0.875}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.05693}, "meta_inference_prompt_tokens": {"value": 10749.0}, "meta_inference_completion_tokens": {"value": 1331.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021498}, "meta_inference_completion_cost": {"value": 0.0021296}, "meta_eval_time": {"value": 46.906}, "meta_eval_prompt_tokens": {"value": 7048.0}, "meta_eval_completion_tokens": {"value": 3635.0}, "meta_eval_prompt_cost": {"value": 0.00225536}, "meta_eval_completion_cost": {"value": 0.0046528}}, "created": "2025-12-10T21:49:53.2995109Z"}
{"ref": "metal-cymbal-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 24.150691}, "meta_inference_prompt_tokens": {"value": 16756.0}, "meta_inference_completion_tokens": {"value": 1345.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0033512}, "meta_inference_completion_cost": {"value": 0.002152}, "meta_eval_time": {"value": 12.006}, "meta_eval_prompt_tokens": {"value": 10132.0}, "meta_eval_completion_tokens": {"value": 966.0}, "meta_eval_prompt_cost": {"value": 0.00324224}, "meta_eval_completion_cost": {"value": 0.00123648}}, "created": "2025-12-10T21:49:53.5395862Z"}
{"ref": "metal-cymbal-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 24.271183}, "meta_inference_prompt_tokens": {"value": 17900.0}, "meta_inference_completion_tokens": {"value": 1280.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00358}, "meta_inference_completion_cost": {"value": 0.002048}, "meta_eval_time": {"value": 16.589}, "meta_eval_prompt_tokens": {"value": 11296.0}, "meta_eval_completion_tokens": {"value": 1250.0}, "meta_eval_prompt_cost": {"value": 0.00361472}, "meta_eval_completion_cost": {"value": 0.0016}}, "created": "2025-12-10T21:49:53.7441186Z"}
{"ref": "lower-keel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.375}, "retrieval_mrr": {"value": 0.566666666666667}, "retrieval_dcg": {"value": 1.93195974923544}, "generation_faithfulness": {"value": 0.977777777777778}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.230769230769231}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.664478}, "meta_inference_prompt_tokens": {"value": 11468.0}, "meta_inference_completion_tokens": {"value": 1682.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022936}, "meta_inference_completion_cost": {"value": 0.0026912}, "meta_eval_time": {"value": 48.853}, "meta_eval_prompt_tokens": {"value": 8038.0}, "meta_eval_completion_tokens": {"value": 4123.0}, "meta_eval_prompt_cost": {"value": 0.00257216}, "meta_eval_completion_cost": {"value": 0.00527744}}, "created": "2025-12-10T21:49:54.485051Z"}
{"ref": "magnetic-rotor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.209889}, "meta_inference_prompt_tokens": {"value": 10049.0}, "meta_inference_completion_tokens": {"value": 1125.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020098}, "meta_inference_completion_cost": {"value": 0.0018}, "meta_eval_time": {"value": 41.624}, "meta_eval_prompt_tokens": {"value": 5803.0}, "meta_eval_completion_tokens": {"value": 2696.0}, "meta_eval_prompt_cost": {"value": 0.00185696}, "meta_eval_completion_cost": {"value": 0.00345088}}, "created": "2025-12-10T21:49:55.7393603Z"}
{"ref": "many-muenster", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.701754385964912}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 24.588827}, "meta_inference_prompt_tokens": {"value": 11757.0}, "meta_inference_completion_tokens": {"value": 1313.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023514}, "meta_inference_completion_cost": {"value": 0.0021008}, "meta_eval_time": {"value": 38.354}, "meta_eval_prompt_tokens": {"value": 7666.0}, "meta_eval_completion_tokens": {"value": 3279.0}, "meta_eval_prompt_cost": {"value": 0.00245312}, "meta_eval_completion_cost": {"value": 0.00419712}}, "created": "2025-12-10T21:49:56.1807468Z"}
{"ref": "magnetic-rotor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.614809}, "meta_inference_prompt_tokens": {"value": 10291.0}, "meta_inference_completion_tokens": {"value": 1716.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020582}, "meta_inference_completion_cost": {"value": 0.0027456}, "meta_eval_time": {"value": 44.683}, "meta_eval_prompt_tokens": {"value": 6791.0}, "meta_eval_completion_tokens": {"value": 3684.0}, "meta_eval_prompt_cost": {"value": 0.00217312}, "meta_eval_completion_cost": {"value": 0.00471552}}, "created": "2025-12-10T21:49:58.3430499Z"}
{"ref": "many-muenster", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 18.594209}, "meta_inference_prompt_tokens": {"value": 13653.0}, "meta_inference_completion_tokens": {"value": 1142.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027306}, "meta_inference_completion_cost": {"value": 0.0018272}, "meta_eval_time": {"value": 36.925}, "meta_eval_prompt_tokens": {"value": 8916.0}, "meta_eval_completion_tokens": {"value": 3131.0}, "meta_eval_prompt_cost": {"value": 0.00285312}, "meta_eval_completion_cost": {"value": 0.00400768}}, "created": "2025-12-10T21:49:58.3525728Z"}
{"ref": "metal-cymbal-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.411413}, "meta_inference_prompt_tokens": {"value": 17661.0}, "meta_inference_completion_tokens": {"value": 1832.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0035322}, "meta_inference_completion_cost": {"value": 0.0029312}, "meta_eval_time": {"value": 19.85}, "meta_eval_prompt_tokens": {"value": 11397.0}, "meta_eval_completion_tokens": {"value": 1827.0}, "meta_eval_prompt_cost": {"value": 0.00364704}, "meta_eval_completion_cost": {"value": 0.00233856}}, "created": "2025-12-10T21:49:59.9624823Z"}
{"ref": "magenta-cockatoo", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.976744186046512}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.938397}, "meta_inference_prompt_tokens": {"value": 10472.0}, "meta_inference_completion_tokens": {"value": 1300.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020944}, "meta_inference_completion_cost": {"value": 0.00208}, "meta_eval_time": {"value": 49.19}, "meta_eval_prompt_tokens": {"value": 7014.0}, "meta_eval_completion_tokens": {"value": 3977.0}, "meta_eval_prompt_cost": {"value": 0.00224448}, "meta_eval_completion_cost": {"value": 0.00509056}}, "created": "2025-12-10T21:50:00.1523538Z"}
{"ref": "many-henry", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.972222222222222}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 23.318979}, "meta_inference_prompt_tokens": {"value": 11114.0}, "meta_inference_completion_tokens": {"value": 1571.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022228}, "meta_inference_completion_cost": {"value": 0.0025136}, "meta_eval_time": {"value": 42.608}, "meta_eval_prompt_tokens": {"value": 7452.0}, "meta_eval_completion_tokens": {"value": 3550.0}, "meta_eval_prompt_cost": {"value": 0.00238464}, "meta_eval_completion_cost": {"value": 0.004544}}, "created": "2025-12-10T21:50:00.1531777Z"}
{"ref": "magnetic-rotor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.07087}, "meta_inference_prompt_tokens": {"value": 10883.0}, "meta_inference_completion_tokens": {"value": 1431.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021766}, "meta_inference_completion_cost": {"value": 0.0022896}, "meta_eval_time": {"value": 43.816}, "meta_eval_prompt_tokens": {"value": 7067.0}, "meta_eval_completion_tokens": {"value": 3682.0}, "meta_eval_prompt_cost": {"value": 0.00226144}, "meta_eval_completion_cost": {"value": 0.00471296}}, "created": "2025-12-10T21:50:00.8305914Z"}
{"ref": "mild-flashing", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.905753}, "meta_inference_prompt_tokens": {"value": 10840.0}, "meta_inference_completion_tokens": {"value": 1048.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002168}, "meta_inference_completion_cost": {"value": 0.0016768}, "meta_eval_time": {"value": 11.715}, "meta_eval_prompt_tokens": {"value": 5402.0}, "meta_eval_completion_tokens": {"value": 950.0}, "meta_eval_prompt_cost": {"value": 0.00172864}, "meta_eval_completion_cost": {"value": 0.001216}}, "created": "2025-12-10T21:50:01.7956374Z"}
{"ref": "mild-flashing", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.419414}, "meta_inference_prompt_tokens": {"value": 10621.0}, "meta_inference_completion_tokens": {"value": 894.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021242}, "meta_inference_completion_cost": {"value": 0.0014304}, "meta_eval_time": {"value": 12.716}, "meta_eval_prompt_tokens": {"value": 5124.0}, "meta_eval_completion_tokens": {"value": 1142.0}, "meta_eval_prompt_cost": {"value": 0.00163968}, "meta_eval_completion_cost": {"value": 0.00146176}}, "created": "2025-12-10T21:50:02.0470659Z"}
{"ref": "many-henry", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 26.998431}, "meta_inference_prompt_tokens": {"value": 11112.0}, "meta_inference_completion_tokens": {"value": 1536.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022224}, "meta_inference_completion_cost": {"value": 0.0024576}, "meta_eval_time": {"value": 44.437}, "meta_eval_prompt_tokens": {"value": 7486.0}, "meta_eval_completion_tokens": {"value": 3737.0}, "meta_eval_prompt_cost": {"value": 0.00239552}, "meta_eval_completion_cost": {"value": 0.00478336}}, "created": "2025-12-10T21:50:02.322008Z"}
{"ref": "mashed-boom", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.919994579889346}, "generation_faithfulness": {"value": 0.975609756097561}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 38.22441}, "meta_inference_prompt_tokens": {"value": 11606.0}, "meta_inference_completion_tokens": {"value": 2286.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023212}, "meta_inference_completion_cost": {"value": 0.0036576}, "meta_eval_time": {"value": 40.736}, "meta_eval_prompt_tokens": {"value": 7802.0}, "meta_eval_completion_tokens": {"value": 3999.0}, "meta_eval_prompt_cost": {"value": 0.00249664}, "meta_eval_completion_cost": {"value": 0.00511872}}, "created": "2025-12-10T21:50:02.886012Z"}
{"ref": "many-muenster", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 24.833373}, "meta_inference_prompt_tokens": {"value": 13958.0}, "meta_inference_completion_tokens": {"value": 1232.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027916}, "meta_inference_completion_cost": {"value": 0.0019712}, "meta_eval_time": {"value": 36.889}, "meta_eval_prompt_tokens": {"value": 9515.0}, "meta_eval_completion_tokens": {"value": 3274.0}, "meta_eval_prompt_cost": {"value": 0.0030448}, "meta_eval_completion_cost": {"value": 0.00419072}}, "created": "2025-12-10T21:50:03.1029096Z"}
{"ref": "mild-flashing", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.111111111111111}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.057391}, "meta_inference_prompt_tokens": {"value": 10946.0}, "meta_inference_completion_tokens": {"value": 856.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021892}, "meta_inference_completion_cost": {"value": 0.0013696}, "meta_eval_time": {"value": 11.473}, "meta_eval_prompt_tokens": {"value": 5643.0}, "meta_eval_completion_tokens": {"value": 931.0}, "meta_eval_prompt_cost": {"value": 0.00180576}, "meta_eval_completion_cost": {"value": 0.00119168}}, "created": "2025-12-10T21:50:05.2580393Z"}
{"ref": "navy-chimpanzee-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.283602}, "meta_inference_prompt_tokens": {"value": 4645.0}, "meta_inference_completion_tokens": {"value": 506.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.000929}, "meta_inference_completion_cost": {"value": 0.0008096}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:50:05.3339755Z"}
{"ref": "navy-chimpanzee-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.809661}, "meta_inference_prompt_tokens": {"value": 4649.0}, "meta_inference_completion_tokens": {"value": 358.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009298}, "meta_inference_completion_cost": {"value": 0.0005728}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:50:05.3745693Z"}
{"ref": "mild-flashing", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.900397}, "meta_inference_prompt_tokens": {"value": 11058.0}, "meta_inference_completion_tokens": {"value": 903.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022116}, "meta_inference_completion_cost": {"value": 0.0014448}, "meta_eval_time": {"value": 15.625}, "meta_eval_prompt_tokens": {"value": 5592.0}, "meta_eval_completion_tokens": {"value": 984.0}, "meta_eval_prompt_cost": {"value": 0.00178944}, "meta_eval_completion_cost": {"value": 0.00125952}}, "created": "2025-12-10T21:50:05.461881Z"}
{"ref": "loud-catch", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.951219512195122}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.352069}, "meta_inference_prompt_tokens": {"value": 14945.0}, "meta_inference_completion_tokens": {"value": 1719.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002989}, "meta_inference_completion_cost": {"value": 0.0027504}, "meta_eval_time": {"value": 56.156}, "meta_eval_prompt_tokens": {"value": 10920.0}, "meta_eval_completion_tokens": {"value": 3897.0}, "meta_eval_prompt_cost": {"value": 0.0034944}, "meta_eval_completion_cost": {"value": 0.00498816}}, "created": "2025-12-10T21:50:07.7883508Z"}
{"ref": "mashed-boom", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.98713694067948}, "generation_faithfulness": {"value": 0.490196078431372}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.005522}, "meta_inference_prompt_tokens": {"value": 11209.0}, "meta_inference_completion_tokens": {"value": 2203.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022418}, "meta_inference_completion_cost": {"value": 0.0035248}, "meta_eval_time": {"value": 48.962}, "meta_eval_prompt_tokens": {"value": 7618.0}, "meta_eval_completion_tokens": {"value": 4403.0}, "meta_eval_prompt_cost": {"value": 0.00243776}, "meta_eval_completion_cost": {"value": 0.00563584}}, "created": "2025-12-10T21:50:08.1322148Z"}
{"ref": "modern-zipper", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.818181818181818}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.463521}, "meta_inference_prompt_tokens": {"value": 10089.0}, "meta_inference_completion_tokens": {"value": 541.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020178}, "meta_inference_completion_cost": {"value": 0.0008656}, "meta_eval_time": {"value": 16.0}, "meta_eval_prompt_tokens": {"value": 4762.0}, "meta_eval_completion_tokens": {"value": 1263.0}, "meta_eval_prompt_cost": {"value": 0.00152384}, "meta_eval_completion_cost": {"value": 0.00161664}}, "created": "2025-12-10T21:50:09.340992Z"}
{"ref": "navy-chimpanzee-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.830519}, "meta_inference_prompt_tokens": {"value": 4647.0}, "meta_inference_completion_tokens": {"value": 711.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009294}, "meta_inference_completion_cost": {"value": 0.0011376}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:50:09.382454Z"}
{"ref": "modern-zipper", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.062431}, "meta_inference_prompt_tokens": {"value": 9668.0}, "meta_inference_completion_tokens": {"value": 588.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019336}, "meta_inference_completion_cost": {"value": 0.0009408}, "meta_eval_time": {"value": 18.25}, "meta_eval_prompt_tokens": {"value": 4545.0}, "meta_eval_completion_tokens": {"value": 1652.0}, "meta_eval_prompt_cost": {"value": 0.0014544}, "meta_eval_completion_cost": {"value": 0.00211456}}, "created": "2025-12-10T21:50:10.1409768Z"}
{"ref": "navy-chimpanzee-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.50009}, "meta_inference_prompt_tokens": {"value": 4651.0}, "meta_inference_completion_tokens": {"value": 707.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009302}, "meta_inference_completion_cost": {"value": 0.0011312}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:50:10.1906569Z"}
{"ref": "modern-zipper", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.830556}, "meta_inference_prompt_tokens": {"value": 9912.0}, "meta_inference_completion_tokens": {"value": 533.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019824}, "meta_inference_completion_cost": {"value": 0.0008528}, "meta_eval_time": {"value": 19.158}, "meta_eval_prompt_tokens": {"value": 4566.0}, "meta_eval_completion_tokens": {"value": 1336.0}, "meta_eval_prompt_cost": {"value": 0.00146112}, "meta_eval_completion_cost": {"value": 0.00171008}}, "created": "2025-12-10T21:50:10.5008267Z"}
{"ref": "many-muenster", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.685714285714286}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 27.142295}, "meta_inference_prompt_tokens": {"value": 12060.0}, "meta_inference_completion_tokens": {"value": 1453.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002412}, "meta_inference_completion_cost": {"value": 0.0023248}, "meta_eval_time": {"value": 41.066}, "meta_eval_prompt_tokens": {"value": 7677.0}, "meta_eval_completion_tokens": {"value": 3232.0}, "meta_eval_prompt_cost": {"value": 0.00245664}, "meta_eval_completion_cost": {"value": 0.00413696}}, "created": "2025-12-10T21:50:12.0462226Z"}
{"ref": "navy-chimpanzee-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.577125}, "meta_inference_prompt_tokens": {"value": 4648.0}, "meta_inference_completion_tokens": {"value": 567.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009296}, "meta_inference_completion_cost": {"value": 0.0009072}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:50:12.089436Z"}
{"ref": "mashed-boom", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.98713694067948}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 38.310738}, "meta_inference_prompt_tokens": {"value": 10824.0}, "meta_inference_completion_tokens": {"value": 2169.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021648}, "meta_inference_completion_cost": {"value": 0.0034704}, "meta_eval_time": {"value": 39.303}, "meta_eval_prompt_tokens": {"value": 7263.0}, "meta_eval_completion_tokens": {"value": 3371.0}, "meta_eval_prompt_cost": {"value": 0.00232416}, "meta_eval_completion_cost": {"value": 0.00431488}}, "created": "2025-12-10T21:50:12.2421985Z"}
{"ref": "modern-zipper", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.613973}, "meta_inference_prompt_tokens": {"value": 10212.0}, "meta_inference_completion_tokens": {"value": 662.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020424}, "meta_inference_completion_cost": {"value": 0.0010592}, "meta_eval_time": {"value": 16.895}, "meta_eval_prompt_tokens": {"value": 4914.0}, "meta_eval_completion_tokens": {"value": 1438.0}, "meta_eval_prompt_cost": {"value": 0.00157248}, "meta_eval_completion_cost": {"value": 0.00184064}}, "created": "2025-12-10T21:50:12.6768984Z"}
{"ref": "many-henry", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.153846153846154}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 31.181878}, "meta_inference_prompt_tokens": {"value": 11355.0}, "meta_inference_completion_tokens": {"value": 1805.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002271}, "meta_inference_completion_cost": {"value": 0.002888}, "meta_eval_time": {"value": 51.543}, "meta_eval_prompt_tokens": {"value": 8045.0}, "meta_eval_completion_tokens": {"value": 4351.0}, "meta_eval_prompt_cost": {"value": 0.0025744}, "meta_eval_completion_cost": {"value": 0.00556928}}, "created": "2025-12-10T21:50:12.8898399Z"}
{"ref": "mashed-funding", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.883720930232558}, "generation_factuality_f1": {"value": 0.540540540540541}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 22.277979}, "meta_inference_prompt_tokens": {"value": 13709.0}, "meta_inference_completion_tokens": {"value": 1106.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027418}, "meta_inference_completion_cost": {"value": 0.0017696}, "meta_eval_time": {"value": 42.003}, "meta_eval_prompt_tokens": {"value": 9444.0}, "meta_eval_completion_tokens": {"value": 3920.0}, "meta_eval_prompt_cost": {"value": 0.00302208}, "meta_eval_completion_cost": {"value": 0.0050176}}, "created": "2025-12-10T21:50:13.618245Z"}
{"ref": "mild-flashing", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.187888}, "meta_inference_prompt_tokens": {"value": 11216.0}, "meta_inference_completion_tokens": {"value": 911.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022432}, "meta_inference_completion_cost": {"value": 0.0014576}, "meta_eval_time": {"value": 16.367}, "meta_eval_prompt_tokens": {"value": 5659.0}, "meta_eval_completion_tokens": {"value": 1283.0}, "meta_eval_prompt_cost": {"value": 0.00181088}, "meta_eval_completion_cost": {"value": 0.00164224}}, "created": "2025-12-10T21:50:17.2882547Z"}
{"ref": "modern-zipper", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.351911}, "meta_inference_prompt_tokens": {"value": 9907.0}, "meta_inference_completion_tokens": {"value": 616.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019814}, "meta_inference_completion_cost": {"value": 0.0009856}, "meta_eval_time": {"value": 15.342}, "meta_eval_prompt_tokens": {"value": 4597.0}, "meta_eval_completion_tokens": {"value": 1334.0}, "meta_eval_prompt_cost": {"value": 0.00147104}, "meta_eval_completion_cost": {"value": 0.00170752}}, "created": "2025-12-10T21:50:17.730196Z"}
{"ref": "many-henry", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.972222222222222}, "generation_factuality_f1": {"value": 0.413793103448276}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 27.759297}, "meta_inference_prompt_tokens": {"value": 11011.0}, "meta_inference_completion_tokens": {"value": 1702.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022022}, "meta_inference_completion_cost": {"value": 0.0027232}, "meta_eval_time": {"value": 49.734}, "meta_eval_prompt_tokens": {"value": 7502.0}, "meta_eval_completion_tokens": {"value": 3958.0}, "meta_eval_prompt_cost": {"value": 0.00240064}, "meta_eval_completion_cost": {"value": 0.00506624}}, "created": "2025-12-10T21:50:19.7176371Z"}
{"ref": "mashed-funding", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.896551724137931}, "generation_factuality_f1": {"value": 0.625}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 28.96681}, "meta_inference_prompt_tokens": {"value": 14661.0}, "meta_inference_completion_tokens": {"value": 1486.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029322}, "meta_inference_completion_cost": {"value": 0.0023776}, "meta_eval_time": {"value": 56.882}, "meta_eval_prompt_tokens": {"value": 10585.0}, "meta_eval_completion_tokens": {"value": 4629.0}, "meta_eval_prompt_cost": {"value": 0.0033872}, "meta_eval_completion_cost": {"value": 0.00592512}}, "created": "2025-12-10T21:50:19.7426231Z"}
{"ref": "mashed-funding", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.96969696969697}, "generation_factuality_f1": {"value": 0.740740740740741}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 23.66448}, "meta_inference_prompt_tokens": {"value": 12887.0}, "meta_inference_completion_tokens": {"value": 1213.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025774}, "meta_inference_completion_cost": {"value": 0.0019408}, "meta_eval_time": {"value": 41.65}, "meta_eval_prompt_tokens": {"value": 8965.0}, "meta_eval_completion_tokens": {"value": 3659.0}, "meta_eval_prompt_cost": {"value": 0.0028688}, "meta_eval_completion_cost": {"value": 0.00468352}}, "created": "2025-12-10T21:50:24.1629562Z"}
{"ref": "mashed-funding", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.978260869565217}, "generation_factuality_f1": {"value": 0.677966101694915}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 29.531747}, "meta_inference_prompt_tokens": {"value": 12535.0}, "meta_inference_completion_tokens": {"value": 1716.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002507}, "meta_inference_completion_cost": {"value": 0.0027456}, "meta_eval_time": {"value": 45.167}, "meta_eval_prompt_tokens": {"value": 8441.0}, "meta_eval_completion_tokens": {"value": 3951.0}, "meta_eval_prompt_cost": {"value": 0.00270112}, "meta_eval_completion_cost": {"value": 0.00505728}}, "created": "2025-12-10T21:50:27.6182239Z"}
{"ref": "mashed-funding", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.441176470588235}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 25.699116}, "meta_inference_prompt_tokens": {"value": 13295.0}, "meta_inference_completion_tokens": {"value": 1496.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002659}, "meta_inference_completion_cost": {"value": 0.0023936}, "meta_eval_time": {"value": 47.583}, "meta_eval_prompt_tokens": {"value": 9655.0}, "meta_eval_completion_tokens": {"value": 4633.0}, "meta_eval_prompt_cost": {"value": 0.0030896}, "meta_eval_completion_cost": {"value": 0.00593024}}, "created": "2025-12-10T21:50:27.6291719Z"}
{"ref": "novel-luge", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.448925}, "meta_inference_prompt_tokens": {"value": 4654.0}, "meta_inference_completion_tokens": {"value": 872.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009308}, "meta_inference_completion_cost": {"value": 0.0013952}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:50:27.6703332Z"}
{"ref": "miniature-riser", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.88685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 31.562715}, "meta_inference_prompt_tokens": {"value": 13776.0}, "meta_inference_completion_tokens": {"value": 1711.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027552}, "meta_inference_completion_cost": {"value": 0.0027376}, "meta_eval_time": {"value": 36.389}, "meta_eval_prompt_tokens": {"value": 10345.0}, "meta_eval_completion_tokens": {"value": 3878.0}, "meta_eval_prompt_cost": {"value": 0.0033104}, "meta_eval_completion_cost": {"value": 0.00496384}}, "created": "2025-12-10T21:50:28.2985018Z"}
{"ref": "novel-luge", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.81775}, "meta_inference_prompt_tokens": {"value": 4652.0}, "meta_inference_completion_tokens": {"value": 1137.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009304}, "meta_inference_completion_cost": {"value": 0.0018192}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:50:28.3373368Z"}
{"ref": "mashed-boom", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.931959749235439}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 39.374804}, "meta_inference_prompt_tokens": {"value": 11389.0}, "meta_inference_completion_tokens": {"value": 2431.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022778}, "meta_inference_completion_cost": {"value": 0.0038896}, "meta_eval_time": {"value": 40.869}, "meta_eval_prompt_tokens": {"value": 7559.0}, "meta_eval_completion_tokens": {"value": 3681.0}, "meta_eval_prompt_cost": {"value": 0.00241888}, "meta_eval_completion_cost": {"value": 0.00471168}}, "created": "2025-12-10T21:50:28.4369161Z"}
{"ref": "mashed-boom", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.964263086904791}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.405605}, "meta_inference_prompt_tokens": {"value": 11537.0}, "meta_inference_completion_tokens": {"value": 2116.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023074}, "meta_inference_completion_cost": {"value": 0.0033856}, "meta_eval_time": {"value": 51.529}, "meta_eval_prompt_tokens": {"value": 8527.0}, "meta_eval_completion_tokens": {"value": 4756.0}, "meta_eval_prompt_cost": {"value": 0.00272864}, "meta_eval_completion_cost": {"value": 0.00608768}}, "created": "2025-12-10T21:50:28.9519999Z"}
{"ref": "moist-humvee", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.905791}, "meta_inference_prompt_tokens": {"value": 12250.0}, "meta_inference_completion_tokens": {"value": 1046.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00245}, "meta_inference_completion_cost": {"value": 0.0016736}, "meta_eval_time": {"value": 35.255}, "meta_eval_prompt_tokens": {"value": 7841.0}, "meta_eval_completion_tokens": {"value": 3061.0}, "meta_eval_prompt_cost": {"value": 0.00250912}, "meta_eval_completion_cost": {"value": 0.00391808}}, "created": "2025-12-10T21:50:31.4789203Z"}
{"ref": "narrow-sofa", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.662125}, "meta_inference_prompt_tokens": {"value": 12269.0}, "meta_inference_completion_tokens": {"value": 1153.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024538}, "meta_inference_completion_cost": {"value": 0.0018448}, "meta_eval_time": {"value": 34.431}, "meta_eval_prompt_tokens": {"value": 7898.0}, "meta_eval_completion_tokens": {"value": 2820.0}, "meta_eval_prompt_cost": {"value": 0.00252736}, "meta_eval_completion_cost": {"value": 0.0036096}}, "created": "2025-12-10T21:50:32.8286413Z"}
{"ref": "narrow-sofa", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.774193548387097}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.504863}, "meta_inference_prompt_tokens": {"value": 11935.0}, "meta_inference_completion_tokens": {"value": 950.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002387}, "meta_inference_completion_cost": {"value": 0.00152}, "meta_eval_time": {"value": 31.486}, "meta_eval_prompt_tokens": {"value": 7361.0}, "meta_eval_completion_tokens": {"value": 2876.0}, "meta_eval_prompt_cost": {"value": 0.00235552}, "meta_eval_completion_cost": {"value": 0.00368128}}, "created": "2025-12-10T21:50:34.413062Z"}
{"ref": "miniature-riser", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.41999457988935}, "generation_faithfulness": {"value": 0.977777777777778}, "generation_factuality_f1": {"value": 0.173913043478261}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 41.709932}, "meta_inference_prompt_tokens": {"value": 14167.0}, "meta_inference_completion_tokens": {"value": 2299.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028334}, "meta_inference_completion_cost": {"value": 0.0036784}, "meta_eval_time": {"value": 43.2}, "meta_eval_prompt_tokens": {"value": 10649.0}, "meta_eval_completion_tokens": {"value": 4104.0}, "meta_eval_prompt_cost": {"value": 0.00340768}, "meta_eval_completion_cost": {"value": 0.00525312}}, "created": "2025-12-10T21:50:34.5995883Z"}
{"ref": "moist-humvee", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.890139}, "meta_inference_prompt_tokens": {"value": 12267.0}, "meta_inference_completion_tokens": {"value": 1579.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024534}, "meta_inference_completion_cost": {"value": 0.0025264}, "meta_eval_time": {"value": 42.545}, "meta_eval_prompt_tokens": {"value": 7824.0}, "meta_eval_completion_tokens": {"value": 2878.0}, "meta_eval_prompt_cost": {"value": 0.00250368}, "meta_eval_completion_cost": {"value": 0.00368384}}, "created": "2025-12-10T21:50:34.8371645Z"}
{"ref": "nimble-armament", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.98713694067948}, "generation_faithfulness": {"value": 0.769230769230769}, "generation_factuality_f1": {"value": 0.222222222222222}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 18.318574}, "meta_inference_prompt_tokens": {"value": 12029.0}, "meta_inference_completion_tokens": {"value": 780.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024058}, "meta_inference_completion_cost": {"value": 0.001248}, "meta_eval_time": {"value": 21.88}, "meta_eval_prompt_tokens": {"value": 6576.0}, "meta_eval_completion_tokens": {"value": 1752.0}, "meta_eval_prompt_cost": {"value": 0.00210432}, "meta_eval_completion_cost": {"value": 0.00224256}}, "created": "2025-12-10T21:50:35.5409956Z"}
{"ref": "novel-luge", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.646981}, "meta_inference_prompt_tokens": {"value": 4652.0}, "meta_inference_completion_tokens": {"value": 1060.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009304}, "meta_inference_completion_cost": {"value": 0.001696}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:50:35.5793057Z"}
{"ref": "novel-luge", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.119462}, "meta_inference_prompt_tokens": {"value": 2256.0}, "meta_inference_completion_tokens": {"value": 651.0}, "meta_inference_prompt_cost": {"value": 0.0004512}, "meta_inference_completion_cost": {"value": 0.0010416}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:50:35.6137773Z"}
{"ref": "moist-humvee", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.807692307692308}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.304826}, "meta_inference_prompt_tokens": {"value": 12119.0}, "meta_inference_completion_tokens": {"value": 1002.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024238}, "meta_inference_completion_cost": {"value": 0.0016032}, "meta_eval_time": {"value": 34.42}, "meta_eval_prompt_tokens": {"value": 7463.0}, "meta_eval_completion_tokens": {"value": 2712.0}, "meta_eval_prompt_cost": {"value": 0.00238816}, "meta_eval_completion_cost": {"value": 0.00347136}}, "created": "2025-12-10T21:50:36.5762363Z"}
{"ref": "nearest-tuba-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.941176470588235}, "generation_factuality_precision": {"value": 0.888888888888889}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.499991}, "meta_inference_prompt_tokens": {"value": 17332.0}, "meta_inference_completion_tokens": {"value": 722.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0034664}, "meta_inference_completion_cost": {"value": 0.0011552}, "meta_eval_time": {"value": 24.134}, "meta_eval_prompt_tokens": {"value": 11696.0}, "meta_eval_completion_tokens": {"value": 2142.0}, "meta_eval_prompt_cost": {"value": 0.00374272}, "meta_eval_completion_cost": {"value": 0.00274176}}, "created": "2025-12-10T21:50:36.8530331Z"}
{"ref": "novel-luge", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.127088}, "meta_inference_prompt_tokens": {"value": 2256.0}, "meta_inference_completion_tokens": {"value": 477.0}, "meta_inference_prompt_cost": {"value": 0.0004512}, "meta_inference_completion_cost": {"value": 0.0007632}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:50:36.8996322Z"}
{"ref": "navy-veneer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.930676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.774193548387097}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 28.504304}, "meta_inference_prompt_tokens": {"value": 9885.0}, "meta_inference_completion_tokens": {"value": 1571.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001977}, "meta_inference_completion_cost": {"value": 0.0025136}, "meta_eval_time": {"value": 26.382}, "meta_eval_prompt_tokens": {"value": 5499.0}, "meta_eval_completion_tokens": {"value": 2495.0}, "meta_eval_prompt_cost": {"value": 0.00175968}, "meta_eval_completion_cost": {"value": 0.0031936}}, "created": "2025-12-10T21:50:38.5106996Z"}
{"ref": "nearest-tuba-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.941176470588235}, "generation_factuality_precision": {"value": 0.888888888888889}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.4871}, "meta_inference_prompt_tokens": {"value": 17335.0}, "meta_inference_completion_tokens": {"value": 717.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003467}, "meta_inference_completion_cost": {"value": 0.0011472}, "meta_eval_time": {"value": 25.77}, "meta_eval_prompt_tokens": {"value": 11648.0}, "meta_eval_completion_tokens": {"value": 2012.0}, "meta_eval_prompt_cost": {"value": 0.00372736}, "meta_eval_completion_cost": {"value": 0.00257536}}, "created": "2025-12-10T21:50:38.7015355Z"}
{"ref": "narrow-sofa", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.476766}, "meta_inference_prompt_tokens": {"value": 11931.0}, "meta_inference_completion_tokens": {"value": 1022.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023862}, "meta_inference_completion_cost": {"value": 0.0016352}, "meta_eval_time": {"value": 35.954}, "meta_eval_prompt_tokens": {"value": 7561.0}, "meta_eval_completion_tokens": {"value": 2928.0}, "meta_eval_prompt_cost": {"value": 0.00241952}, "meta_eval_completion_cost": {"value": 0.00374784}}, "created": "2025-12-10T21:50:39.0972931Z"}
{"ref": "narrow-sofa", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.325573}, "meta_inference_prompt_tokens": {"value": 11925.0}, "meta_inference_completion_tokens": {"value": 1029.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002385}, "meta_inference_completion_cost": {"value": 0.0016464}, "meta_eval_time": {"value": 31.26}, "meta_eval_prompt_tokens": {"value": 7359.0}, "meta_eval_completion_tokens": {"value": 2627.0}, "meta_eval_prompt_cost": {"value": 0.00235488}, "meta_eval_completion_cost": {"value": 0.00336256}}, "created": "2025-12-10T21:50:39.1342882Z"}
{"ref": "nimble-armament", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.98713694067948}, "generation_faithfulness": {"value": 0.769230769230769}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 20.09034}, "meta_inference_prompt_tokens": {"value": 12026.0}, "meta_inference_completion_tokens": {"value": 993.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024052}, "meta_inference_completion_cost": {"value": 0.0015888}, "meta_eval_time": {"value": 19.989}, "meta_eval_prompt_tokens": {"value": 6630.0}, "meta_eval_completion_tokens": {"value": 1603.0}, "meta_eval_prompt_cost": {"value": 0.0021216}, "meta_eval_completion_cost": {"value": 0.00205184}}, "created": "2025-12-10T21:50:39.7473393Z"}
{"ref": "nimble-armament", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.98713694067948}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.2}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 16.640081}, "meta_inference_prompt_tokens": {"value": 12024.0}, "meta_inference_completion_tokens": {"value": 939.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024048}, "meta_inference_completion_cost": {"value": 0.0015024}, "meta_eval_time": {"value": 22.001}, "meta_eval_prompt_tokens": {"value": 6682.0}, "meta_eval_completion_tokens": {"value": 1835.0}, "meta_eval_prompt_cost": {"value": 0.00213824}, "meta_eval_completion_cost": {"value": 0.0023488}}, "created": "2025-12-10T21:50:39.7756784Z"}
{"ref": "numerous-database", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.475738}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 648.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0010368}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:50:39.8140371Z"}
{"ref": "narrow-conduction", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.22102457555333}, "generation_faithfulness": {"value": 0.838709677419355}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.653507}, "meta_inference_prompt_tokens": {"value": 13001.0}, "meta_inference_completion_tokens": {"value": 1645.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026002}, "meta_inference_completion_cost": {"value": 0.002632}, "meta_eval_time": {"value": 34.596}, "meta_eval_prompt_tokens": {"value": 9240.0}, "meta_eval_completion_tokens": {"value": 3172.0}, "meta_eval_prompt_cost": {"value": 0.0029568}, "meta_eval_completion_cost": {"value": 0.00406016}}, "created": "2025-12-10T21:50:40.0098194Z"}
{"ref": "numerous-database", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 8.838861}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 398.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0006368}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:50:40.047637Z"}
{"ref": "moist-humvee", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 0.96}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.840592}, "meta_inference_prompt_tokens": {"value": 11676.0}, "meta_inference_completion_tokens": {"value": 1155.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023352}, "meta_inference_completion_cost": {"value": 0.001848}, "meta_eval_time": {"value": 32.94}, "meta_eval_prompt_tokens": {"value": 7292.0}, "meta_eval_completion_tokens": {"value": 2712.0}, "meta_eval_prompt_cost": {"value": 0.00233344}, "meta_eval_completion_cost": {"value": 0.00347136}}, "created": "2025-12-10T21:50:43.1805879Z"}
{"ref": "narrow-conduction", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.59009482198187}, "generation_faithfulness": {"value": 0.822222222222222}, "generation_factuality_f1": {"value": 0.51063829787234}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 45.99771}, "meta_inference_prompt_tokens": {"value": 12393.0}, "meta_inference_completion_tokens": {"value": 1871.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024786}, "meta_inference_completion_cost": {"value": 0.0029936}, "meta_eval_time": {"value": 43.766}, "meta_eval_prompt_tokens": {"value": 9771.0}, "meta_eval_completion_tokens": {"value": 4744.0}, "meta_eval_prompt_cost": {"value": 0.00312672}, "meta_eval_completion_cost": {"value": 0.00607232}}, "created": "2025-12-10T21:50:44.6350632Z"}
{"ref": "moist-humvee", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.75287}, "meta_inference_prompt_tokens": {"value": 12395.0}, "meta_inference_completion_tokens": {"value": 1597.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002479}, "meta_inference_completion_cost": {"value": 0.0025552}, "meta_eval_time": {"value": 34.518}, "meta_eval_prompt_tokens": {"value": 7973.0}, "meta_eval_completion_tokens": {"value": 3201.0}, "meta_eval_prompt_cost": {"value": 0.00255136}, "meta_eval_completion_cost": {"value": 0.00409728}}, "created": "2025-12-10T21:50:45.0644844Z"}
{"ref": "miniature-riser", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.56160631164485}, "generation_faithfulness": {"value": 0.977777777777778}, "generation_factuality_f1": {"value": 0.375}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 32.719292}, "meta_inference_prompt_tokens": {"value": 13694.0}, "meta_inference_completion_tokens": {"value": 2200.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027388}, "meta_inference_completion_cost": {"value": 0.00352}, "meta_eval_time": {"value": 55.425}, "meta_eval_prompt_tokens": {"value": 10626.0}, "meta_eval_completion_tokens": {"value": 4533.0}, "meta_eval_prompt_cost": {"value": 0.00340032}, "meta_eval_completion_cost": {"value": 0.00580224}}, "created": "2025-12-10T21:50:45.8940294Z"}
{"ref": "numerous-database", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.880569}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 648.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0010368}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:50:45.9339983Z"}
{"ref": "nimble-batter", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 28.311144}, "meta_inference_prompt_tokens": {"value": 10540.0}, "meta_inference_completion_tokens": {"value": 1803.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002108}, "meta_inference_completion_cost": {"value": 0.0028848}, "meta_eval_time": {"value": 28.876}, "meta_eval_prompt_tokens": {"value": 5677.0}, "meta_eval_completion_tokens": {"value": 2632.0}, "meta_eval_prompt_cost": {"value": 0.00181664}, "meta_eval_completion_cost": {"value": 0.00336896}}, "created": "2025-12-10T21:50:46.2050217Z"}
{"ref": "many-henry", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 28.898048}, "meta_inference_prompt_tokens": {"value": 10812.0}, "meta_inference_completion_tokens": {"value": 1674.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021624}, "meta_inference_completion_cost": {"value": 0.0026784}, "meta_eval_time": {"value": 60.584}, "meta_eval_prompt_tokens": {"value": 7263.0}, "meta_eval_completion_tokens": {"value": 3829.0}, "meta_eval_prompt_cost": {"value": 0.00232416}, "meta_eval_completion_cost": {"value": 0.00490112}}, "created": "2025-12-10T21:50:46.6593919Z"}
{"ref": "numerous-database", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 10.384987}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 483.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0007728}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:50:46.6993345Z"}
{"ref": "narrow-sofa", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.818181818181818}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.912893}, "meta_inference_prompt_tokens": {"value": 12922.0}, "meta_inference_completion_tokens": {"value": 1663.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025844}, "meta_inference_completion_cost": {"value": 0.0026608}, "meta_eval_time": {"value": 46.601}, "meta_eval_prompt_tokens": {"value": 9242.0}, "meta_eval_completion_tokens": {"value": 4010.0}, "meta_eval_prompt_cost": {"value": 0.00295744}, "meta_eval_completion_cost": {"value": 0.0051328}}, "created": "2025-12-10T21:50:46.796038Z"}
{"ref": "nimble-batter", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.426632}, "meta_inference_prompt_tokens": {"value": 9811.0}, "meta_inference_completion_tokens": {"value": 2159.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019622}, "meta_inference_completion_cost": {"value": 0.0034544}, "meta_eval_time": {"value": 27.774}, "meta_eval_prompt_tokens": {"value": 5326.0}, "meta_eval_completion_tokens": {"value": 2526.0}, "meta_eval_prompt_cost": {"value": 0.00170432}, "meta_eval_completion_cost": {"value": 0.00323328}}, "created": "2025-12-10T21:50:47.5551815Z"}
{"ref": "narrow-conduction", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.25332791322268}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.436363636363636}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 22.868638}, "meta_inference_prompt_tokens": {"value": 12406.0}, "meta_inference_completion_tokens": {"value": 1290.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024812}, "meta_inference_completion_cost": {"value": 0.002064}, "meta_eval_time": {"value": 46.443}, "meta_eval_prompt_tokens": {"value": 8733.0}, "meta_eval_completion_tokens": {"value": 3716.0}, "meta_eval_prompt_cost": {"value": 0.00279456}, "meta_eval_completion_cost": {"value": 0.00475648}}, "created": "2025-12-10T21:50:48.2813412Z"}
{"ref": "nearest-tuba-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.941176470588235}, "generation_factuality_precision": {"value": 0.888888888888889}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.688196}, "meta_inference_prompt_tokens": {"value": 17329.0}, "meta_inference_completion_tokens": {"value": 585.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0034658}, "meta_inference_completion_cost": {"value": 0.000936}, "meta_eval_time": {"value": 24.169}, "meta_eval_prompt_tokens": {"value": 11661.0}, "meta_eval_completion_tokens": {"value": 2020.0}, "meta_eval_prompt_cost": {"value": 0.00373152}, "meta_eval_completion_cost": {"value": 0.0025856}}, "created": "2025-12-10T21:50:48.3738936Z"}
{"ref": "numerous-database", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 8.77052}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 479.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0007664}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:50:48.4101478Z"}
{"ref": "navy-veneer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.966666666666667}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 37.317342}, "meta_inference_prompt_tokens": {"value": 11035.0}, "meta_inference_completion_tokens": {"value": 2065.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002207}, "meta_inference_completion_cost": {"value": 0.003304}, "meta_eval_time": {"value": 37.104}, "meta_eval_prompt_tokens": {"value": 7436.0}, "meta_eval_completion_tokens": {"value": 3379.0}, "meta_eval_prompt_cost": {"value": 0.00237952}, "meta_eval_completion_cost": {"value": 0.00432512}}, "created": "2025-12-10T21:50:49.3884025Z"}
{"ref": "nimble-batter", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.78399}, "meta_inference_prompt_tokens": {"value": 10720.0}, "meta_inference_completion_tokens": {"value": 1549.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002144}, "meta_inference_completion_cost": {"value": 0.0024784}, "meta_eval_time": {"value": 20.472}, "meta_eval_prompt_tokens": {"value": 5578.0}, "meta_eval_completion_tokens": {"value": 1742.0}, "meta_eval_prompt_cost": {"value": 0.00178496}, "meta_eval_completion_cost": {"value": 0.00222976}}, "created": "2025-12-10T21:50:49.4609856Z"}
{"ref": "miniature-riser", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.93067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.789473684210526}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 29.68926}, "meta_inference_prompt_tokens": {"value": 13737.0}, "meta_inference_completion_tokens": {"value": 1872.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027474}, "meta_inference_completion_cost": {"value": 0.0029952}, "meta_eval_time": {"value": 40.72}, "meta_eval_prompt_tokens": {"value": 10610.0}, "meta_eval_completion_tokens": {"value": 4066.0}, "meta_eval_prompt_cost": {"value": 0.0033952}, "meta_eval_completion_cost": {"value": 0.00520448}}, "created": "2025-12-10T21:50:50.1416149Z"}
{"ref": "nimble-batter", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.355214}, "meta_inference_prompt_tokens": {"value": 10741.0}, "meta_inference_completion_tokens": {"value": 1994.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021482}, "meta_inference_completion_cost": {"value": 0.0031904}, "meta_eval_time": {"value": 17.761}, "meta_eval_prompt_tokens": {"value": 5555.0}, "meta_eval_completion_tokens": {"value": 1537.0}, "meta_eval_prompt_cost": {"value": 0.0017776}, "meta_eval_completion_cost": {"value": 0.00196736}}, "created": "2025-12-10T21:50:50.6282589Z"}
{"ref": "nimble-armament", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.98713694067948}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 21.197201}, "meta_inference_prompt_tokens": {"value": 12026.0}, "meta_inference_completion_tokens": {"value": 1090.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024052}, "meta_inference_completion_cost": {"value": 0.001744}, "meta_eval_time": {"value": 24.049}, "meta_eval_prompt_tokens": {"value": 6737.0}, "meta_eval_completion_tokens": {"value": 1846.0}, "meta_eval_prompt_cost": {"value": 0.00215584}, "meta_eval_completion_cost": {"value": 0.00236288}}, "created": "2025-12-10T21:50:51.711693Z"}
{"ref": "narrow-conduction", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 0.931959749235439}, "generation_faithfulness": {"value": 0.926829268292683}, "generation_factuality_f1": {"value": 0.655737704918033}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 26.776566}, "meta_inference_prompt_tokens": {"value": 12580.0}, "meta_inference_completion_tokens": {"value": 1598.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002516}, "meta_inference_completion_cost": {"value": 0.0025568}, "meta_eval_time": {"value": 45.78}, "meta_eval_prompt_tokens": {"value": 9152.0}, "meta_eval_completion_tokens": {"value": 3858.0}, "meta_eval_prompt_cost": {"value": 0.00292864}, "meta_eval_completion_cost": {"value": 0.00493824}}, "created": "2025-12-10T21:50:52.0574681Z"}
{"ref": "nearest-tuba-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.941176470588235}, "generation_factuality_precision": {"value": 0.888888888888889}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.806701}, "meta_inference_prompt_tokens": {"value": 17332.0}, "meta_inference_completion_tokens": {"value": 510.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0034664}, "meta_inference_completion_cost": {"value": 0.000816}, "meta_eval_time": {"value": 23.795}, "meta_eval_prompt_tokens": {"value": 11628.0}, "meta_eval_completion_tokens": {"value": 2061.0}, "meta_eval_prompt_cost": {"value": 0.00372096}, "meta_eval_completion_cost": {"value": 0.00263808}}, "created": "2025-12-10T21:50:52.2713058Z"}
{"ref": "nimble-batter", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 27.077347}, "meta_inference_prompt_tokens": {"value": 10878.0}, "meta_inference_completion_tokens": {"value": 2058.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021756}, "meta_inference_completion_cost": {"value": 0.0032928}, "meta_eval_time": {"value": 21.575}, "meta_eval_prompt_tokens": {"value": 5875.0}, "meta_eval_completion_tokens": {"value": 1862.0}, "meta_eval_prompt_cost": {"value": 0.00188}, "meta_eval_completion_cost": {"value": 0.00238336}}, "created": "2025-12-10T21:50:53.0924736Z"}
{"ref": "nimble-armament", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.98713694067948}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 26.509104}, "meta_inference_prompt_tokens": {"value": 12022.0}, "meta_inference_completion_tokens": {"value": 1074.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024044}, "meta_inference_completion_cost": {"value": 0.0017184}, "meta_eval_time": {"value": 24.903}, "meta_eval_prompt_tokens": {"value": 6891.0}, "meta_eval_completion_tokens": {"value": 1972.0}, "meta_eval_prompt_cost": {"value": 0.00220512}, "meta_eval_completion_cost": {"value": 0.00252416}}, "created": "2025-12-10T21:50:53.2774132Z"}
{"ref": "milky-lepton", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.44845911887939}, "generation_faithfulness": {"value": 0.905660377358491}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 58.821928}, "meta_inference_prompt_tokens": {"value": 15536.0}, "meta_inference_completion_tokens": {"value": 3829.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031072}, "meta_inference_completion_cost": {"value": 0.0061264}, "meta_eval_time": {"value": 64.1}, "meta_eval_prompt_tokens": {"value": 13975.0}, "meta_eval_completion_tokens": {"value": 6041.0}, "meta_eval_prompt_cost": {"value": 0.004472}, "meta_eval_completion_cost": {"value": 0.00773248}}, "created": "2025-12-10T21:50:53.630715Z"}
{"ref": "milky-lepton", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.6875}, "retrieval_dcg": {"value": 1.33824592639634}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.15}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 46.730035}, "meta_inference_prompt_tokens": {"value": 34005.0}, "meta_inference_completion_tokens": {"value": 3428.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.006801}, "meta_inference_completion_cost": {"value": 0.0054848}, "meta_eval_time": {"value": 59.652}, "meta_eval_prompt_tokens": {"value": 17323.0}, "meta_eval_completion_tokens": {"value": 6096.0}, "meta_eval_prompt_cost": {"value": 0.00554336}, "meta_eval_completion_cost": {"value": 0.00780288}}, "created": "2025-12-10T21:50:54.1873803Z"}
{"ref": "nearest-tuba-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.833333333333334}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.941176470588235}, "generation_factuality_precision": {"value": 0.888888888888889}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.682243}, "meta_inference_prompt_tokens": {"value": 17331.0}, "meta_inference_completion_tokens": {"value": 723.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0034662}, "meta_inference_completion_cost": {"value": 0.0011568}, "meta_eval_time": {"value": 20.301}, "meta_eval_prompt_tokens": {"value": 11657.0}, "meta_eval_completion_tokens": {"value": 1882.0}, "meta_eval_prompt_cost": {"value": 0.00373024}, "meta_eval_completion_cost": {"value": 0.00240896}}, "created": "2025-12-10T21:50:55.1760066Z"}
{"ref": "miniature-riser", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.946394630357186}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 35.056022}, "meta_inference_prompt_tokens": {"value": 11901.0}, "meta_inference_completion_tokens": {"value": 2098.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023802}, "meta_inference_completion_cost": {"value": 0.0033568}, "meta_eval_time": {"value": 56.921}, "meta_eval_prompt_tokens": {"value": 8430.0}, "meta_eval_completion_tokens": {"value": 4605.0}, "meta_eval_prompt_cost": {"value": 0.0026976}, "meta_eval_completion_cost": {"value": 0.0058944}}, "created": "2025-12-10T21:50:55.3083001Z"}
{"ref": "navy-veneer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.96}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.396317}, "meta_inference_prompt_tokens": {"value": 9903.0}, "meta_inference_completion_tokens": {"value": 1540.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019806}, "meta_inference_completion_cost": {"value": 0.002464}, "meta_eval_time": {"value": 30.848}, "meta_eval_prompt_tokens": {"value": 5690.0}, "meta_eval_completion_tokens": {"value": 2883.0}, "meta_eval_prompt_cost": {"value": 0.0018208}, "meta_eval_completion_cost": {"value": 0.00369024}}, "created": "2025-12-10T21:50:58.5552458Z"}
{"ref": "nuclear-pointer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 42.347713}, "meta_inference_prompt_tokens": {"value": 10837.0}, "meta_inference_completion_tokens": {"value": 1157.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021674}, "meta_inference_completion_cost": {"value": 0.0018512}, "meta_eval_time": {"value": 18.839}, "meta_eval_prompt_tokens": {"value": 5671.0}, "meta_eval_completion_tokens": {"value": 1629.0}, "meta_eval_prompt_cost": {"value": 0.00181472}, "meta_eval_completion_cost": {"value": 0.00208512}}, "created": "2025-12-10T21:50:58.9250665Z"}
{"ref": "nuclear-pointer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 28.215921}, "meta_inference_prompt_tokens": {"value": 11275.0}, "meta_inference_completion_tokens": {"value": 1691.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002255}, "meta_inference_completion_cost": {"value": 0.0027056}, "meta_eval_time": {"value": 26.971}, "meta_eval_prompt_tokens": {"value": 6715.0}, "meta_eval_completion_tokens": {"value": 2400.0}, "meta_eval_prompt_cost": {"value": 0.0021488}, "meta_eval_completion_cost": {"value": 0.003072}}, "created": "2025-12-10T21:51:03.9064636Z"}
{"ref": "nutty-platform", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.257589}, "meta_inference_prompt_tokens": {"value": 11945.0}, "meta_inference_completion_tokens": {"value": 1034.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002389}, "meta_inference_completion_cost": {"value": 0.0016544}, "meta_eval_time": {"value": 24.316}, "meta_eval_prompt_tokens": {"value": 7222.0}, "meta_eval_completion_tokens": {"value": 2047.0}, "meta_eval_prompt_cost": {"value": 0.00231104}, "meta_eval_completion_cost": {"value": 0.00262016}}, "created": "2025-12-10T21:51:04.1662338Z"}
{"ref": "nuclear-pointer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 26.479403}, "meta_inference_prompt_tokens": {"value": 11348.0}, "meta_inference_completion_tokens": {"value": 1595.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022696}, "meta_inference_completion_cost": {"value": 0.002552}, "meta_eval_time": {"value": 26.168}, "meta_eval_prompt_tokens": {"value": 6761.0}, "meta_eval_completion_tokens": {"value": 2493.0}, "meta_eval_prompt_cost": {"value": 0.00216352}, "meta_eval_completion_cost": {"value": 0.00319104}}, "created": "2025-12-10T21:51:04.7248441Z"}
{"ref": "optical-team", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.453439}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 634.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0010144}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:04.7638653Z"}
{"ref": "optical-team", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.278713}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 514.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0008224}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:04.8021156Z"}
{"ref": "navy-veneer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.533333333333333}, "retrieval_dcg": {"value": 1.90929150399595}, "generation_faithfulness": {"value": 0.846153846153846}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.15}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 38.86688}, "meta_inference_prompt_tokens": {"value": 25704.0}, "meta_inference_completion_tokens": {"value": 2028.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0051408}, "meta_inference_completion_cost": {"value": 0.0032448}, "meta_eval_time": {"value": 32.488}, "meta_eval_prompt_tokens": {"value": 9630.0}, "meta_eval_completion_tokens": {"value": 3094.0}, "meta_eval_prompt_cost": {"value": 0.0030816}, "meta_eval_completion_cost": {"value": 0.00396032}}, "created": "2025-12-10T21:51:06.9381695Z"}
{"ref": "nuclear-pointer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.72}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 25.25414}, "meta_inference_prompt_tokens": {"value": 11409.0}, "meta_inference_completion_tokens": {"value": 1368.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022818}, "meta_inference_completion_cost": {"value": 0.0021888}, "meta_eval_time": {"value": 28.866}, "meta_eval_prompt_tokens": {"value": 6912.0}, "meta_eval_completion_tokens": {"value": 2458.0}, "meta_eval_prompt_cost": {"value": 0.00221184}, "meta_eval_completion_cost": {"value": 0.00314624}}, "created": "2025-12-10T21:51:07.6063374Z"}
{"ref": "obnoxious-shark", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.375}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 23.197011}, "meta_inference_prompt_tokens": {"value": 11822.0}, "meta_inference_completion_tokens": {"value": 1074.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023644}, "meta_inference_completion_cost": {"value": 0.0017184}, "meta_eval_time": {"value": 20.829}, "meta_eval_prompt_tokens": {"value": 6867.0}, "meta_eval_completion_tokens": {"value": 1966.0}, "meta_eval_prompt_cost": {"value": 0.00219744}, "meta_eval_completion_cost": {"value": 0.00251648}}, "created": "2025-12-10T21:51:07.6908783Z"}
{"ref": "optical-team", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.958882}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 449.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0007184}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:07.7325741Z"}
{"ref": "optical-team", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.916556}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 507.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0008112}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:07.7706899Z"}
{"ref": "obsolete-tent-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.657237182772}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 19.060446}, "meta_inference_prompt_tokens": {"value": 10022.0}, "meta_inference_completion_tokens": {"value": 973.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020044}, "meta_inference_completion_cost": {"value": 0.0015568}, "meta_eval_time": {"value": 15.766}, "meta_eval_prompt_tokens": {"value": 5001.0}, "meta_eval_completion_tokens": {"value": 1384.0}, "meta_eval_prompt_cost": {"value": 0.00160032}, "meta_eval_completion_cost": {"value": 0.00177152}}, "created": "2025-12-10T21:51:08.0783092Z"}
{"ref": "obsolete-tent-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.657237182772}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 23.727774}, "meta_inference_prompt_tokens": {"value": 10023.0}, "meta_inference_completion_tokens": {"value": 1349.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020046}, "meta_inference_completion_cost": {"value": 0.0021584}, "meta_eval_time": {"value": 18.699}, "meta_eval_prompt_tokens": {"value": 4962.0}, "meta_eval_completion_tokens": {"value": 1471.0}, "meta_eval_prompt_cost": {"value": 0.00158784}, "meta_eval_completion_cost": {"value": 0.00188288}}, "created": "2025-12-10T21:51:08.1949989Z"}
{"ref": "nutty-platform", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.48897}, "meta_inference_prompt_tokens": {"value": 14382.0}, "meta_inference_completion_tokens": {"value": 1168.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028764}, "meta_inference_completion_cost": {"value": 0.0018688}, "meta_eval_time": {"value": 28.533}, "meta_eval_prompt_tokens": {"value": 9564.0}, "meta_eval_completion_tokens": {"value": 2596.0}, "meta_eval_prompt_cost": {"value": 0.00306048}, "meta_eval_completion_cost": {"value": 0.00332288}}, "created": "2025-12-10T21:51:08.3156862Z"}
{"ref": "milky-lepton", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.6875}, "retrieval_dcg": {"value": 1.41992332021804}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.15}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 51.578639}, "meta_inference_prompt_tokens": {"value": 30468.0}, "meta_inference_completion_tokens": {"value": 3335.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0060936}, "meta_inference_completion_cost": {"value": 0.005336}, "meta_eval_time": {"value": 75.799}, "meta_eval_prompt_tokens": {"value": 17562.0}, "meta_eval_completion_tokens": {"value": 7009.0}, "meta_eval_prompt_cost": {"value": 0.00561984}, "meta_eval_completion_cost": {"value": 0.00897152}}, "created": "2025-12-10T21:51:08.8239102Z"}
{"ref": "narrow-conduction", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 0.719741384391281}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428571}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 26.336006}, "meta_inference_prompt_tokens": {"value": 12399.0}, "meta_inference_completion_tokens": {"value": 1618.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024798}, "meta_inference_completion_cost": {"value": 0.0025888}, "meta_eval_time": {"value": 60.652}, "meta_eval_prompt_tokens": {"value": 9350.0}, "meta_eval_completion_tokens": {"value": 5239.0}, "meta_eval_prompt_cost": {"value": 0.002992}, "meta_eval_completion_cost": {"value": 0.00670592}}, "created": "2025-12-10T21:51:08.83069Z"}
{"ref": "obsolete-tent-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.856207187108022}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.25}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 18.619996}, "meta_inference_prompt_tokens": {"value": 9415.0}, "meta_inference_completion_tokens": {"value": 996.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001883}, "meta_inference_completion_cost": {"value": 0.0015936}, "meta_eval_time": {"value": 19.776}, "meta_eval_prompt_tokens": {"value": 5254.0}, "meta_eval_completion_tokens": {"value": 1839.0}, "meta_eval_prompt_cost": {"value": 0.00168128}, "meta_eval_completion_cost": {"value": 0.00235392}}, "created": "2025-12-10T21:51:11.5273261Z"}
{"ref": "obsolete-tent-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.657237182772}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 22.088809}, "meta_inference_prompt_tokens": {"value": 10023.0}, "meta_inference_completion_tokens": {"value": 840.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020046}, "meta_inference_completion_cost": {"value": 0.001344}, "meta_eval_time": {"value": 18.799}, "meta_eval_prompt_tokens": {"value": 4996.0}, "meta_eval_completion_tokens": {"value": 1570.0}, "meta_eval_prompt_cost": {"value": 0.00159872}, "meta_eval_completion_cost": {"value": 0.0020096}}, "created": "2025-12-10T21:51:12.1144284Z"}
{"ref": "obnoxious-shark", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.375}, "retrieval_dcg": {"value": 1.017782560806}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.428571428571429}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 21.672097}, "meta_inference_prompt_tokens": {"value": 11684.0}, "meta_inference_completion_tokens": {"value": 943.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023368}, "meta_inference_completion_cost": {"value": 0.0015088}, "meta_eval_time": {"value": 27.328}, "meta_eval_prompt_tokens": {"value": 6696.0}, "meta_eval_completion_tokens": {"value": 2028.0}, "meta_eval_prompt_cost": {"value": 0.00214272}, "meta_eval_completion_cost": {"value": 0.00259584}}, "created": "2025-12-10T21:51:12.4328375Z"}
{"ref": "nutty-platform", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.559157}, "meta_inference_prompt_tokens": {"value": 14383.0}, "meta_inference_completion_tokens": {"value": 1018.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028766}, "meta_inference_completion_cost": {"value": 0.0016288}, "meta_eval_time": {"value": 29.704}, "meta_eval_prompt_tokens": {"value": 9650.0}, "meta_eval_completion_tokens": {"value": 2593.0}, "meta_eval_prompt_cost": {"value": 0.003088}, "meta_eval_completion_cost": {"value": 0.00331904}}, "created": "2025-12-10T21:51:12.9246232Z"}
{"ref": "optical-team", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.162465}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 639.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0010224}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:12.9912089Z"}
{"ref": "overcast-diameter-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.54258}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 718.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0011488}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:13.0300522Z"}
{"ref": "overcast-diameter-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 8.307445}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 386.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0006176}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:13.07722Z"}
{"ref": "overcast-diameter-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.895168}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 589.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0009424}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:13.1190922Z"}
{"ref": "nuclear-plisse", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.655737704918033}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 37.999843}, "meta_inference_prompt_tokens": {"value": 13727.0}, "meta_inference_completion_tokens": {"value": 1916.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027454}, "meta_inference_completion_cost": {"value": 0.0030656}, "meta_eval_time": {"value": 37.842}, "meta_eval_prompt_tokens": {"value": 9658.0}, "meta_eval_completion_tokens": {"value": 3091.0}, "meta_eval_prompt_cost": {"value": 0.00309056}, "meta_eval_completion_cost": {"value": 0.00395648}}, "created": "2025-12-10T21:51:14.4808499Z"}
{"ref": "overcast-diameter-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.127636}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 641.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0010256}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:14.5276141Z"}
{"ref": "nuclear-plisse", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.51063829787234}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 22.45396}, "meta_inference_prompt_tokens": {"value": 13745.0}, "meta_inference_completion_tokens": {"value": 1282.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002749}, "meta_inference_completion_cost": {"value": 0.0020512}, "meta_eval_time": {"value": 35.432}, "meta_eval_prompt_tokens": {"value": 9534.0}, "meta_eval_completion_tokens": {"value": 3212.0}, "meta_eval_prompt_cost": {"value": 0.00305088}, "meta_eval_completion_cost": {"value": 0.00411136}}, "created": "2025-12-10T21:51:14.5662069Z"}
{"ref": "overcast-diameter-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.049058}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 640.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.001024}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:14.5674522Z"}
{"ref": "obnoxious-shark", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.375}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.428571428571429}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 17.142177}, "meta_inference_prompt_tokens": {"value": 11829.0}, "meta_inference_completion_tokens": {"value": 937.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023658}, "meta_inference_completion_cost": {"value": 0.0014992}, "meta_eval_time": {"value": 25.429}, "meta_eval_prompt_tokens": {"value": 6704.0}, "meta_eval_completion_tokens": {"value": 1984.0}, "meta_eval_prompt_cost": {"value": 0.00214528}, "meta_eval_completion_cost": {"value": 0.00253952}}, "created": "2025-12-10T21:51:14.8546406Z"}
{"ref": "obsolete-tent-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.886852807234542}, "generation_faithfulness": {"value": 0.894736842105263}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 19.539771}, "meta_inference_prompt_tokens": {"value": 10428.0}, "meta_inference_completion_tokens": {"value": 875.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020856}, "meta_inference_completion_cost": {"value": 0.0014}, "meta_eval_time": {"value": 26.515}, "meta_eval_prompt_tokens": {"value": 5925.0}, "meta_eval_completion_tokens": {"value": 2258.0}, "meta_eval_prompt_cost": {"value": 0.001896}, "meta_eval_completion_cost": {"value": 0.00289024}}, "created": "2025-12-10T21:51:14.9610513Z"}
{"ref": "milky-lepton", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.517782560806}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 44.076698}, "meta_inference_prompt_tokens": {"value": 15506.0}, "meta_inference_completion_tokens": {"value": 3192.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031012}, "meta_inference_completion_cost": {"value": 0.0051072}, "meta_eval_time": {"value": 75.084}, "meta_eval_prompt_tokens": {"value": 14033.0}, "meta_eval_completion_tokens": {"value": 6753.0}, "meta_eval_prompt_cost": {"value": 0.00449056}, "meta_eval_completion_cost": {"value": 0.00864384}}, "created": "2025-12-10T21:51:15.0881482Z"}
{"ref": "nutty-platform", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.904761904761905}, "generation_factuality_f1": {"value": 0.697674418604651}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 20.79959}, "meta_inference_prompt_tokens": {"value": 11945.0}, "meta_inference_completion_tokens": {"value": 1073.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002389}, "meta_inference_completion_cost": {"value": 0.0017168}, "meta_eval_time": {"value": 27.051}, "meta_eval_prompt_tokens": {"value": 7357.0}, "meta_eval_completion_tokens": {"value": 2334.0}, "meta_eval_prompt_cost": {"value": 0.00235424}, "meta_eval_completion_cost": {"value": 0.00298752}}, "created": "2025-12-10T21:51:15.3703413Z"}
{"ref": "obsolete-tent-B", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.821428571428571}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "generation_should_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.450813}, "meta_inference_prompt_tokens": {"value": 10094.0}, "meta_inference_completion_tokens": {"value": 1077.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020188}, "meta_inference_completion_cost": {"value": 0.0017232}, "meta_eval_time": {"value": 25.034}, "meta_eval_prompt_tokens": {"value": 5637.0}, "meta_eval_completion_tokens": {"value": 2573.0}, "meta_eval_prompt_cost": {"value": 0.00180384}, "meta_eval_completion_cost": {"value": 0.00329344}}, "created": "2025-12-10T21:51:15.7009753Z"}
{"ref": "obnoxious-shark", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.74305999434256}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 24.302462}, "meta_inference_prompt_tokens": {"value": 11551.0}, "meta_inference_completion_tokens": {"value": 1082.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023102}, "meta_inference_completion_cost": {"value": 0.0017312}, "meta_eval_time": {"value": 25.752}, "meta_eval_prompt_tokens": {"value": 6741.0}, "meta_eval_completion_tokens": {"value": 2340.0}, "meta_eval_prompt_cost": {"value": 0.00215712}, "meta_eval_completion_cost": {"value": 0.0029952}}, "created": "2025-12-10T21:51:15.9309631Z"}
{"ref": "obsolete-tent-B", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.933333333333333}, "generation_factuality_precision": {"value": 0.875}, "generation_factuality_recall": {"value": 1.0}, "generation_should_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.580127}, "meta_inference_prompt_tokens": {"value": 10657.0}, "meta_inference_completion_tokens": {"value": 1089.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021314}, "meta_inference_completion_cost": {"value": 0.0017424}, "meta_eval_time": {"value": 30.034}, "meta_eval_prompt_tokens": {"value": 6082.0}, "meta_eval_completion_tokens": {"value": 2677.0}, "meta_eval_prompt_cost": {"value": 0.00194624}, "meta_eval_completion_cost": {"value": 0.00342656}}, "created": "2025-12-10T21:51:16.0071583Z"}
{"ref": "obsolete-tent-B", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.925925925925926}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "generation_should_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.781722}, "meta_inference_prompt_tokens": {"value": 10657.0}, "meta_inference_completion_tokens": {"value": 965.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021314}, "meta_inference_completion_cost": {"value": 0.001544}, "meta_eval_time": {"value": 30.357}, "meta_eval_prompt_tokens": {"value": 6206.0}, "meta_eval_completion_tokens": {"value": 2523.0}, "meta_eval_prompt_cost": {"value": 0.00198592}, "meta_eval_completion_cost": {"value": 0.00322944}}, "created": "2025-12-10T21:51:16.6001699Z"}
{"ref": "navy-veneer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 1.3476851923511}, "generation_faithfulness": {"value": 0.96969696969697}, "generation_factuality_f1": {"value": 0.51063829787234}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 38.212487}, "meta_inference_prompt_tokens": {"value": 23103.0}, "meta_inference_completion_tokens": {"value": 2124.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0046206}, "meta_inference_completion_cost": {"value": 0.0033984}, "meta_eval_time": {"value": 41.973}, "meta_eval_prompt_tokens": {"value": 8643.0}, "meta_eval_completion_tokens": {"value": 3357.0}, "meta_eval_prompt_cost": {"value": 0.00276576}, "meta_eval_completion_cost": {"value": 0.00429696}}, "created": "2025-12-10T21:51:16.611014Z"}
{"ref": "patient-bow", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 9.53007}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 349.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0005584}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:16.6545205Z"}
{"ref": "patient-bow", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.026809}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 836.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0013376}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:16.6971679Z"}
{"ref": "parallel-race", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.05213}, "meta_inference_prompt_tokens": {"value": 2257.0}, "meta_inference_completion_tokens": {"value": 465.0}, "meta_inference_prompt_cost": {"value": 0.0004514}, "meta_inference_completion_cost": {"value": 0.000744}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:16.7388364Z"}
{"ref": "patient-bow", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.276628}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 585.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.000936}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:16.7768846Z"}
{"ref": "parallel-race", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.836347}, "meta_inference_prompt_tokens": {"value": 2257.0}, "meta_inference_completion_tokens": {"value": 602.0}, "meta_inference_prompt_cost": {"value": 0.0004514}, "meta_inference_completion_cost": {"value": 0.0009632}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:16.8207247Z"}
{"ref": "milky-lepton", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.517782560806}, "generation_faithfulness": {"value": 0.971428571428571}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 55.577345}, "meta_inference_prompt_tokens": {"value": 14902.0}, "meta_inference_completion_tokens": {"value": 3484.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029804}, "meta_inference_completion_cost": {"value": 0.0055744}, "meta_eval_time": {"value": 83.603}, "meta_eval_prompt_tokens": {"value": 14513.0}, "meta_eval_completion_tokens": {"value": 7345.0}, "meta_eval_prompt_cost": {"value": 0.00464416}, "meta_eval_completion_cost": {"value": 0.0094016}}, "created": "2025-12-10T21:51:17.1843858Z"}
{"ref": "patient-bow", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.931726}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 530.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.000848}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:17.2546878Z"}
{"ref": "nuclear-plisse", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.550363}, "meta_inference_prompt_tokens": {"value": 13726.0}, "meta_inference_completion_tokens": {"value": 1823.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027452}, "meta_inference_completion_cost": {"value": 0.0029168}, "meta_eval_time": {"value": 33.171}, "meta_eval_prompt_tokens": {"value": 9333.0}, "meta_eval_completion_tokens": {"value": 2682.0}, "meta_eval_prompt_cost": {"value": 0.00298656}, "meta_eval_completion_cost": {"value": 0.00343296}}, "created": "2025-12-10T21:51:17.844914Z"}
{"ref": "nuclear-plisse", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.021681}, "meta_inference_prompt_tokens": {"value": 12351.0}, "meta_inference_completion_tokens": {"value": 2155.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024702}, "meta_inference_completion_cost": {"value": 0.003448}, "meta_eval_time": {"value": 42.966}, "meta_eval_prompt_tokens": {"value": 8552.0}, "meta_eval_completion_tokens": {"value": 3597.0}, "meta_eval_prompt_cost": {"value": 0.00273664}, "meta_eval_completion_cost": {"value": 0.00460416}}, "created": "2025-12-10T21:51:18.6127049Z"}
{"ref": "nuclear-pointer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 52.841232}, "meta_inference_prompt_tokens": {"value": 49761.0}, "meta_inference_completion_tokens": {"value": 2571.0}, "meta_inference_tool_call_count": {"value": 3.0}, "meta_inference_prompt_cost": {"value": 0.0099522}, "meta_inference_completion_cost": {"value": 0.0041136}, "meta_eval_time": {"value": 28.315}, "meta_eval_prompt_tokens": {"value": 15816.0}, "meta_eval_completion_tokens": {"value": 2389.0}, "meta_eval_prompt_cost": {"value": 0.00506112}, "meta_eval_completion_cost": {"value": 0.00305792}}, "created": "2025-12-10T21:51:21.4495828Z"}
{"ref": "obsolete-tent-B", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.96551724137931}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "generation_should_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.281496}, "meta_inference_prompt_tokens": {"value": 10747.0}, "meta_inference_completion_tokens": {"value": 1129.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021494}, "meta_inference_completion_cost": {"value": 0.0018064}, "meta_eval_time": {"value": 31.104}, "meta_eval_prompt_tokens": {"value": 6304.0}, "meta_eval_completion_tokens": {"value": 2678.0}, "meta_eval_prompt_cost": {"value": 0.00201728}, "meta_eval_completion_cost": {"value": 0.00342784}}, "created": "2025-12-10T21:51:23.2052737Z"}
{"ref": "obnoxious-shark", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.375}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.521739130434783}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 23.158453}, "meta_inference_prompt_tokens": {"value": 11566.0}, "meta_inference_completion_tokens": {"value": 1232.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023132}, "meta_inference_completion_cost": {"value": 0.0019712}, "meta_eval_time": {"value": 36.025}, "meta_eval_prompt_tokens": {"value": 6988.0}, "meta_eval_completion_tokens": {"value": 2779.0}, "meta_eval_prompt_cost": {"value": 0.00223616}, "meta_eval_completion_cost": {"value": 0.00355712}}, "created": "2025-12-10T21:51:23.6197102Z"}
{"ref": "parallel-race", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.619045}, "meta_inference_prompt_tokens": {"value": 4685.0}, "meta_inference_completion_tokens": {"value": 1027.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.000937}, "meta_inference_completion_cost": {"value": 0.0016432}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:23.6628519Z"}
{"ref": "organic-cost", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.647145}, "meta_inference_prompt_tokens": {"value": 10314.0}, "meta_inference_completion_tokens": {"value": 820.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020628}, "meta_inference_completion_cost": {"value": 0.001312}, "meta_eval_time": {"value": 15.701}, "meta_eval_prompt_tokens": {"value": 4759.0}, "meta_eval_completion_tokens": {"value": 1253.0}, "meta_eval_prompt_cost": {"value": 0.00152288}, "meta_eval_completion_cost": {"value": 0.00160384}}, "created": "2025-12-10T21:51:24.574851Z"}
{"ref": "nutty-platform", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.533576}, "meta_inference_prompt_tokens": {"value": 14383.0}, "meta_inference_completion_tokens": {"value": 1043.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028766}, "meta_inference_completion_cost": {"value": 0.0016688}, "meta_eval_time": {"value": 39.546}, "meta_eval_prompt_tokens": {"value": 9575.0}, "meta_eval_completion_tokens": {"value": 2586.0}, "meta_eval_prompt_cost": {"value": 0.003064}, "meta_eval_completion_cost": {"value": 0.00331008}}, "created": "2025-12-10T21:51:27.2807712Z"}
{"ref": "obsolete-tent-B", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "generation_should_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.878057}, "meta_inference_prompt_tokens": {"value": 10938.0}, "meta_inference_completion_tokens": {"value": 989.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021876}, "meta_inference_completion_cost": {"value": 0.0015824}, "meta_eval_time": {"value": 32.366}, "meta_eval_prompt_tokens": {"value": 6447.0}, "meta_eval_completion_tokens": {"value": 2663.0}, "meta_eval_prompt_cost": {"value": 0.00206304}, "meta_eval_completion_cost": {"value": 0.00340864}}, "created": "2025-12-10T21:51:27.2810555Z"}
{"ref": "organic-cost", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.220628}, "meta_inference_prompt_tokens": {"value": 10314.0}, "meta_inference_completion_tokens": {"value": 766.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020628}, "meta_inference_completion_cost": {"value": 0.0012256}, "meta_eval_time": {"value": 15.62}, "meta_eval_prompt_tokens": {"value": 4765.0}, "meta_eval_completion_tokens": {"value": 1221.0}, "meta_eval_prompt_cost": {"value": 0.0015248}, "meta_eval_completion_cost": {"value": 0.00156288}}, "created": "2025-12-10T21:51:27.2811678Z"}
{"ref": "patient-bow", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 11.15705}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 417.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0006672}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:27.3445271Z"}
{"ref": "optimal-gaffer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.416666666666667}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 37.060881}, "meta_inference_prompt_tokens": {"value": 10721.0}, "meta_inference_completion_tokens": {"value": 2093.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021442}, "meta_inference_completion_cost": {"value": 0.0033488}, "meta_eval_time": {"value": 21.062}, "meta_eval_prompt_tokens": {"value": 5767.0}, "meta_eval_completion_tokens": {"value": 1931.0}, "meta_eval_prompt_cost": {"value": 0.00184544}, "meta_eval_completion_cost": {"value": 0.00247168}}, "created": "2025-12-10T21:51:28.0408547Z"}
{"ref": "one-tuple", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.126722}, "meta_inference_prompt_tokens": {"value": 11319.0}, "meta_inference_completion_tokens": {"value": 1993.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022638}, "meta_inference_completion_cost": {"value": 0.0031888}, "meta_eval_time": {"value": 34.462}, "meta_eval_prompt_tokens": {"value": 7637.0}, "meta_eval_completion_tokens": {"value": 3317.0}, "meta_eval_prompt_cost": {"value": 0.00244384}, "meta_eval_completion_cost": {"value": 0.00424576}}, "created": "2025-12-10T21:51:28.131257Z"}
{"ref": "parallel-race", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.044492}, "meta_inference_prompt_tokens": {"value": 2257.0}, "meta_inference_completion_tokens": {"value": 775.0}, "meta_inference_prompt_cost": {"value": 0.0004514}, "meta_inference_completion_cost": {"value": 0.00124}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:28.1687735Z"}
{"ref": "parallel-race", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.303275}, "meta_inference_prompt_tokens": {"value": 2257.0}, "meta_inference_completion_tokens": {"value": 584.0}, "meta_inference_prompt_cost": {"value": 0.0004514}, "meta_inference_completion_cost": {"value": 0.0009344}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:28.2040455Z"}
{"ref": "organic-cost", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.113586}, "meta_inference_prompt_tokens": {"value": 9943.0}, "meta_inference_completion_tokens": {"value": 976.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019886}, "meta_inference_completion_cost": {"value": 0.0015616}, "meta_eval_time": {"value": 15.939}, "meta_eval_prompt_tokens": {"value": 4656.0}, "meta_eval_completion_tokens": {"value": 1270.0}, "meta_eval_prompt_cost": {"value": 0.00148992}, "meta_eval_completion_cost": {"value": 0.0016256}}, "created": "2025-12-10T21:51:28.4122845Z"}
{"ref": "organic-cost", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 18.287664}, "meta_inference_prompt_tokens": {"value": 10316.0}, "meta_inference_completion_tokens": {"value": 785.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020632}, "meta_inference_completion_cost": {"value": 0.001256}, "meta_eval_time": {"value": 17.42}, "meta_eval_prompt_tokens": {"value": 4837.0}, "meta_eval_completion_tokens": {"value": 1435.0}, "meta_eval_prompt_cost": {"value": 0.00154784}, "meta_eval_completion_cost": {"value": 0.0018368}}, "created": "2025-12-10T21:51:29.6257419Z"}
{"ref": "one-tuple", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.470954}, "meta_inference_prompt_tokens": {"value": 10275.0}, "meta_inference_completion_tokens": {"value": 1715.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002055}, "meta_inference_completion_cost": {"value": 0.002744}, "meta_eval_time": {"value": 34.333}, "meta_eval_prompt_tokens": {"value": 6047.0}, "meta_eval_completion_tokens": {"value": 2815.0}, "meta_eval_prompt_cost": {"value": 0.00193504}, "meta_eval_completion_cost": {"value": 0.0036032}}, "created": "2025-12-10T21:51:29.6853538Z"}
{"ref": "organic-cost", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 21.6303}, "meta_inference_prompt_tokens": {"value": 10314.0}, "meta_inference_completion_tokens": {"value": 955.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020628}, "meta_inference_completion_cost": {"value": 0.001528}, "meta_eval_time": {"value": 14.288}, "meta_eval_prompt_tokens": {"value": 4749.0}, "meta_eval_completion_tokens": {"value": 1160.0}, "meta_eval_prompt_cost": {"value": 0.00151968}, "meta_eval_completion_cost": {"value": 0.0014848}}, "created": "2025-12-10T21:51:30.9284806Z"}
{"ref": "one-tuple", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.766666666666667}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.930053}, "meta_inference_prompt_tokens": {"value": 10484.0}, "meta_inference_completion_tokens": {"value": 1680.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020968}, "meta_inference_completion_cost": {"value": 0.002688}, "meta_eval_time": {"value": 36.714}, "meta_eval_prompt_tokens": {"value": 6489.0}, "meta_eval_completion_tokens": {"value": 3073.0}, "meta_eval_prompt_cost": {"value": 0.00207648}, "meta_eval_completion_cost": {"value": 0.00393344}}, "created": "2025-12-10T21:51:31.9268841Z"}
{"ref": "optimal-gaffer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.270876}, "meta_inference_prompt_tokens": {"value": 12126.0}, "meta_inference_completion_tokens": {"value": 1877.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024252}, "meta_inference_completion_cost": {"value": 0.0030032}, "meta_eval_time": {"value": 27.015}, "meta_eval_prompt_tokens": {"value": 7479.0}, "meta_eval_completion_tokens": {"value": 2403.0}, "meta_eval_prompt_cost": {"value": 0.00239328}, "meta_eval_completion_cost": {"value": 0.00307584}}, "created": "2025-12-10T21:51:35.2478717Z"}
{"ref": "optimal-gaffer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.812092}, "meta_inference_prompt_tokens": {"value": 11340.0}, "meta_inference_completion_tokens": {"value": 2047.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002268}, "meta_inference_completion_cost": {"value": 0.0032752}, "meta_eval_time": {"value": 28.822}, "meta_eval_prompt_tokens": {"value": 6658.0}, "meta_eval_completion_tokens": {"value": 2531.0}, "meta_eval_prompt_cost": {"value": 0.00213056}, "meta_eval_completion_cost": {"value": 0.00323968}}, "created": "2025-12-10T21:51:36.9384031Z"}
{"ref": "nuclear-plisse", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 30.127876}, "meta_inference_prompt_tokens": {"value": 12728.0}, "meta_inference_completion_tokens": {"value": 1625.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025456}, "meta_inference_completion_cost": {"value": 0.0026}, "meta_eval_time": {"value": 58.364}, "meta_eval_prompt_tokens": {"value": 8889.0}, "meta_eval_completion_tokens": {"value": 3708.0}, "meta_eval_prompt_cost": {"value": 0.00284448}, "meta_eval_completion_cost": {"value": 0.00474624}}, "created": "2025-12-10T21:51:37.5367472Z"}
{"ref": "one-tuple", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.532397}, "meta_inference_prompt_tokens": {"value": 11558.0}, "meta_inference_completion_tokens": {"value": 1832.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023116}, "meta_inference_completion_cost": {"value": 0.0029312}, "meta_eval_time": {"value": 33.471}, "meta_eval_prompt_tokens": {"value": 7590.0}, "meta_eval_completion_tokens": {"value": 3186.0}, "meta_eval_prompt_cost": {"value": 0.0024288}, "meta_eval_completion_cost": {"value": 0.00407808}}, "created": "2025-12-10T21:51:37.6755376Z"}
{"ref": "optimal-gaffer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.727272727272727}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 36.038591}, "meta_inference_prompt_tokens": {"value": 11606.0}, "meta_inference_completion_tokens": {"value": 1773.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023212}, "meta_inference_completion_cost": {"value": 0.0028368}, "meta_eval_time": {"value": 31.241}, "meta_eval_prompt_tokens": {"value": 6916.0}, "meta_eval_completion_tokens": {"value": 2375.0}, "meta_eval_prompt_cost": {"value": 0.00221312}, "meta_eval_completion_cost": {"value": 0.00304}}, "created": "2025-12-10T21:51:38.9228291Z"}
{"ref": "optimal-gaffer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 46.201975}, "meta_inference_prompt_tokens": {"value": 11003.0}, "meta_inference_completion_tokens": {"value": 2381.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022006}, "meta_inference_completion_cost": {"value": 0.0038096}, "meta_eval_time": {"value": 34.521}, "meta_eval_prompt_tokens": {"value": 6734.0}, "meta_eval_completion_tokens": {"value": 2869.0}, "meta_eval_prompt_cost": {"value": 0.00215488}, "meta_eval_completion_cost": {"value": 0.00367232}}, "created": "2025-12-10T21:51:39.3614916Z"}
{"ref": "perfect-butte", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.783216783216783}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 0.888888888888889}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.888888888888889}, "meta_inference_time": {"value": 17.244148}, "meta_inference_prompt_tokens": {"value": 13067.0}, "meta_inference_completion_tokens": {"value": 764.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026134}, "meta_inference_completion_cost": {"value": 0.0012224}, "meta_eval_time": {"value": 22.246}, "meta_eval_prompt_tokens": {"value": 7969.0}, "meta_eval_completion_tokens": {"value": 2032.0}, "meta_eval_prompt_cost": {"value": 0.00255008}, "meta_eval_completion_cost": {"value": 0.00260096}}, "created": "2025-12-10T21:51:40.9021726Z"}
{"ref": "plain-embed-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.814312}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 576.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0009216}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:40.9382867Z"}
{"ref": "optical-rotor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.511111111111111}, "retrieval_dcg": {"value": 1.70231768402027}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.705473}, "meta_inference_prompt_tokens": {"value": 13217.0}, "meta_inference_completion_tokens": {"value": 1327.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026434}, "meta_inference_completion_cost": {"value": 0.0021232}, "meta_eval_time": {"value": 42.801}, "meta_eval_prompt_tokens": {"value": 8714.0}, "meta_eval_completion_tokens": {"value": 3660.0}, "meta_eval_prompt_cost": {"value": 0.00278848}, "meta_eval_completion_cost": {"value": 0.0046848}}, "created": "2025-12-10T21:51:41.7667599Z"}
{"ref": "perfect-butte", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.842105263157895}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 0.888888888888889}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.888888888888889}, "meta_inference_time": {"value": 16.52779}, "meta_inference_prompt_tokens": {"value": 13063.0}, "meta_inference_completion_tokens": {"value": 651.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026126}, "meta_inference_completion_cost": {"value": 0.0010416}, "meta_eval_time": {"value": 24.637}, "meta_eval_prompt_tokens": {"value": 8017.0}, "meta_eval_completion_tokens": {"value": 2196.0}, "meta_eval_prompt_cost": {"value": 0.00256544}, "meta_eval_completion_cost": {"value": 0.00281088}}, "created": "2025-12-10T21:51:42.5224965Z"}
{"ref": "plain-embed-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 7.955787}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 475.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.00076}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:42.5586202Z"}
{"ref": "optical-rotor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.566666666666667}, "retrieval_dcg": {"value": 1.33324743759173}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.42097}, "meta_inference_prompt_tokens": {"value": 12249.0}, "meta_inference_completion_tokens": {"value": 1030.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024498}, "meta_inference_completion_cost": {"value": 0.001648}, "meta_eval_time": {"value": 44.909}, "meta_eval_prompt_tokens": {"value": 7887.0}, "meta_eval_completion_tokens": {"value": 3629.0}, "meta_eval_prompt_cost": {"value": 0.00252384}, "meta_eval_completion_cost": {"value": 0.00464512}}, "created": "2025-12-10T21:51:43.5054398Z"}
{"ref": "plain-embed-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.200415}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 641.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0010256}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:43.5512541Z"}
{"ref": "optical-rotor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.445833333333333}, "retrieval_dcg": {"value": 1.87707118843058}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.266369}, "meta_inference_prompt_tokens": {"value": 13566.0}, "meta_inference_completion_tokens": {"value": 1439.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027132}, "meta_inference_completion_cost": {"value": 0.0023024}, "meta_eval_time": {"value": 41.533}, "meta_eval_prompt_tokens": {"value": 8981.0}, "meta_eval_completion_tokens": {"value": 3572.0}, "meta_eval_prompt_cost": {"value": 0.00287392}, "meta_eval_completion_cost": {"value": 0.00457216}}, "created": "2025-12-10T21:51:45.4863832Z"}
{"ref": "plain-embed-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.952753}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 579.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0009264}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:45.5230518Z"}
{"ref": "one-tuple", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.914285714285714}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.874485}, "meta_inference_prompt_tokens": {"value": 10846.0}, "meta_inference_completion_tokens": {"value": 1236.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021692}, "meta_inference_completion_cost": {"value": 0.0019776}, "meta_eval_time": {"value": 37.473}, "meta_eval_prompt_tokens": {"value": 6834.0}, "meta_eval_completion_tokens": {"value": 3402.0}, "meta_eval_prompt_cost": {"value": 0.00218688}, "meta_eval_completion_cost": {"value": 0.00435456}}, "created": "2025-12-10T21:51:45.8282592Z"}
{"ref": "plain-embed-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.006334}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 583.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0009328}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:45.8643036Z"}
{"ref": "piercing-halite", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.71535}, "meta_inference_prompt_tokens": {"value": 12997.0}, "meta_inference_completion_tokens": {"value": 804.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025994}, "meta_inference_completion_cost": {"value": 0.0012864}, "meta_eval_time": {"value": 17.996}, "meta_eval_prompt_tokens": {"value": 7467.0}, "meta_eval_completion_tokens": {"value": 1607.0}, "meta_eval_prompt_cost": {"value": 0.00238944}, "meta_eval_completion_cost": {"value": 0.00205696}}, "created": "2025-12-10T21:51:46.4651061Z"}
{"ref": "perpendicular-stick-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 1.017782560806}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.625}, "generation_factuality_precision": {"value": 0.454545454545454}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.676582}, "meta_inference_prompt_tokens": {"value": 19450.0}, "meta_inference_completion_tokens": {"value": 676.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00389}, "meta_inference_completion_cost": {"value": 0.0010816}, "meta_eval_time": {"value": 18.543}, "meta_eval_prompt_tokens": {"value": 13672.0}, "meta_eval_completion_tokens": {"value": 1683.0}, "meta_eval_prompt_cost": {"value": 0.00437504}, "meta_eval_completion_cost": {"value": 0.00215424}}, "created": "2025-12-10T21:51:46.7815301Z"}
{"ref": "plastic-bean", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.141159}, "meta_inference_prompt_tokens": {"value": 2259.0}, "meta_inference_completion_tokens": {"value": 401.0}, "meta_inference_prompt_cost": {"value": 0.0004518}, "meta_inference_completion_cost": {"value": 0.0006416}, "meta_eval_time": {"value": 0.002}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:46.8209616Z"}
{"ref": "overcast-travel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.933333333333333}, "generation_factuality_precision": {"value": 0.875}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.959508}, "meta_inference_prompt_tokens": {"value": 10217.0}, "meta_inference_completion_tokens": {"value": 1097.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020434}, "meta_inference_completion_cost": {"value": 0.0017552}, "meta_eval_time": {"value": 31.823}, "meta_eval_prompt_tokens": {"value": 5829.0}, "meta_eval_completion_tokens": {"value": 2514.0}, "meta_eval_prompt_cost": {"value": 0.00186528}, "meta_eval_completion_cost": {"value": 0.00321792}}, "created": "2025-12-10T21:51:47.2339269Z"}
{"ref": "piercing-halite", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.226549}, "meta_inference_prompt_tokens": {"value": 11318.0}, "meta_inference_completion_tokens": {"value": 906.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022636}, "meta_inference_completion_cost": {"value": 0.0014496}, "meta_eval_time": {"value": 19.625}, "meta_eval_prompt_tokens": {"value": 6300.0}, "meta_eval_completion_tokens": {"value": 1813.0}, "meta_eval_prompt_cost": {"value": 0.002016}, "meta_eval_completion_cost": {"value": 0.00232064}}, "created": "2025-12-10T21:51:49.2863117Z"}
{"ref": "piercing-halite", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.776232}, "meta_inference_prompt_tokens": {"value": 10607.0}, "meta_inference_completion_tokens": {"value": 779.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021214}, "meta_inference_completion_cost": {"value": 0.0012464}, "meta_eval_time": {"value": 17.361}, "meta_eval_prompt_tokens": {"value": 5243.0}, "meta_eval_completion_tokens": {"value": 1438.0}, "meta_eval_prompt_cost": {"value": 0.00167776}, "meta_eval_completion_cost": {"value": 0.00184064}}, "created": "2025-12-10T21:51:49.3236278Z"}
{"ref": "plastic-bean", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.083429}, "meta_inference_prompt_tokens": {"value": 2259.0}, "meta_inference_completion_tokens": {"value": 594.0}, "meta_inference_prompt_cost": {"value": 0.0004518}, "meta_inference_completion_cost": {"value": 0.0009504}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:49.3571306Z"}
{"ref": "optical-rotor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.6}, "retrieval_dcg": {"value": 1.06160631164485}, "generation_faithfulness": {"value": 0.930232558139535}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.4}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.633502}, "meta_inference_prompt_tokens": {"value": 12409.0}, "meta_inference_completion_tokens": {"value": 1006.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024818}, "meta_inference_completion_cost": {"value": 0.0016096}, "meta_eval_time": {"value": 42.072}, "meta_eval_prompt_tokens": {"value": 7889.0}, "meta_eval_completion_tokens": {"value": 3591.0}, "meta_eval_prompt_cost": {"value": 0.00252448}, "meta_eval_completion_cost": {"value": 0.00459648}}, "created": "2025-12-10T21:51:49.8810122Z"}
{"ref": "perfect-butte", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.788732394366197}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 0.777777777777778}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.777777777777778}, "meta_inference_time": {"value": 17.142111}, "meta_inference_prompt_tokens": {"value": 13065.0}, "meta_inference_completion_tokens": {"value": 790.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002613}, "meta_inference_completion_cost": {"value": 0.001264}, "meta_eval_time": {"value": 23.304}, "meta_eval_prompt_tokens": {"value": 8030.0}, "meta_eval_completion_tokens": {"value": 2076.0}, "meta_eval_prompt_cost": {"value": 0.0025696}, "meta_eval_completion_cost": {"value": 0.00265728}}, "created": "2025-12-10T21:51:50.6443239Z"}
{"ref": "plastic-bean", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.616656}, "meta_inference_prompt_tokens": {"value": 2259.0}, "meta_inference_completion_tokens": {"value": 396.0}, "meta_inference_prompt_cost": {"value": 0.0004518}, "meta_inference_completion_cost": {"value": 0.0006336}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:50.6767391Z"}
{"ref": "perpendicular-stick-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 0.25}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.042169}, "meta_inference_prompt_tokens": {"value": 17405.0}, "meta_inference_completion_tokens": {"value": 660.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003481}, "meta_inference_completion_cost": {"value": 0.001056}, "meta_eval_time": {"value": 24.035}, "meta_eval_prompt_tokens": {"value": 11823.0}, "meta_eval_completion_tokens": {"value": 2334.0}, "meta_eval_prompt_cost": {"value": 0.00378336}, "meta_eval_completion_cost": {"value": 0.00298752}}, "created": "2025-12-10T21:51:51.4148611Z"}
{"ref": "perpendicular-stick-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 0.856207187108022}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.441176470588235}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 17.866093}, "meta_inference_prompt_tokens": {"value": 20146.0}, "meta_inference_completion_tokens": {"value": 747.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0040292}, "meta_inference_completion_cost": {"value": 0.0011952}, "meta_eval_time": {"value": 24.299}, "meta_eval_prompt_tokens": {"value": 14293.0}, "meta_eval_completion_tokens": {"value": 2220.0}, "meta_eval_prompt_cost": {"value": 0.00457376}, "meta_eval_completion_cost": {"value": 0.0028416}}, "created": "2025-12-10T21:51:51.6369972Z"}
{"ref": "patient-radio", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.079976}, "meta_inference_prompt_tokens": {"value": 12209.0}, "meta_inference_completion_tokens": {"value": 1337.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024418}, "meta_inference_completion_cost": {"value": 0.0021392}, "meta_eval_time": {"value": 35.38}, "meta_eval_prompt_tokens": {"value": 8455.0}, "meta_eval_completion_tokens": {"value": 3588.0}, "meta_eval_prompt_cost": {"value": 0.0027056}, "meta_eval_completion_cost": {"value": 0.00459264}}, "created": "2025-12-10T21:51:52.2419816Z"}
{"ref": "perpendicular-stick-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.80102999566398}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.517241379310345}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 15.762615}, "meta_inference_prompt_tokens": {"value": 20293.0}, "meta_inference_completion_tokens": {"value": 620.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0040586}, "meta_inference_completion_cost": {"value": 0.000992}, "meta_eval_time": {"value": 22.881}, "meta_eval_prompt_tokens": {"value": 14357.0}, "meta_eval_completion_tokens": {"value": 1745.0}, "meta_eval_prompt_cost": {"value": 0.00459424}, "meta_eval_completion_cost": {"value": 0.0022336}}, "created": "2025-12-10T21:51:52.601583Z"}
{"ref": "optical-rotor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.6}, "retrieval_dcg": {"value": 1.06160631164485}, "generation_faithfulness": {"value": 0.974358974358974}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.4}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.129659}, "meta_inference_prompt_tokens": {"value": 12413.0}, "meta_inference_completion_tokens": {"value": 1344.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024826}, "meta_inference_completion_cost": {"value": 0.0021504}, "meta_eval_time": {"value": 45.421}, "meta_eval_prompt_tokens": {"value": 7702.0}, "meta_eval_completion_tokens": {"value": 3203.0}, "meta_eval_prompt_cost": {"value": 0.00246464}, "meta_eval_completion_cost": {"value": 0.00409984}}, "created": "2025-12-10T21:51:54.2817784Z"}
{"ref": "overcast-travel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.862068965517241}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.598978}, "meta_inference_prompt_tokens": {"value": 10026.0}, "meta_inference_completion_tokens": {"value": 935.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020052}, "meta_inference_completion_cost": {"value": 0.001496}, "meta_eval_time": {"value": 39.403}, "meta_eval_prompt_tokens": {"value": 5671.0}, "meta_eval_completion_tokens": {"value": 2925.0}, "meta_eval_prompt_cost": {"value": 0.00181472}, "meta_eval_completion_cost": {"value": 0.003744}}, "created": "2025-12-10T21:51:54.406922Z"}
{"ref": "piercing-halite", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.944444444444444}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.126484}, "meta_inference_prompt_tokens": {"value": 11239.0}, "meta_inference_completion_tokens": {"value": 775.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022478}, "meta_inference_completion_cost": {"value": 0.00124}, "meta_eval_time": {"value": 18.175}, "meta_eval_prompt_tokens": {"value": 6017.0}, "meta_eval_completion_tokens": {"value": 1769.0}, "meta_eval_prompt_cost": {"value": 0.00192544}, "meta_eval_completion_cost": {"value": 0.00226432}}, "created": "2025-12-10T21:51:55.8859053Z"}
{"ref": "overcast-travel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.415475}, "meta_inference_prompt_tokens": {"value": 10609.0}, "meta_inference_completion_tokens": {"value": 1407.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021218}, "meta_inference_completion_cost": {"value": 0.0022512}, "meta_eval_time": {"value": 42.223}, "meta_eval_prompt_tokens": {"value": 7118.0}, "meta_eval_completion_tokens": {"value": 3705.0}, "meta_eval_prompt_cost": {"value": 0.00227776}, "meta_eval_completion_cost": {"value": 0.0047424}}, "created": "2025-12-10T21:51:56.8317282Z"}
{"ref": "plastic-bean", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.038511}, "meta_inference_prompt_tokens": {"value": 2259.0}, "meta_inference_completion_tokens": {"value": 721.0}, "meta_inference_prompt_cost": {"value": 0.0004518}, "meta_inference_completion_cost": {"value": 0.0011536}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:56.8650161Z"}
{"ref": "patient-radio", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.570335}, "meta_inference_prompt_tokens": {"value": 11547.0}, "meta_inference_completion_tokens": {"value": 1320.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023094}, "meta_inference_completion_cost": {"value": 0.002112}, "meta_eval_time": {"value": 35.388}, "meta_eval_prompt_tokens": {"value": 7504.0}, "meta_eval_completion_tokens": {"value": 3292.0}, "meta_eval_prompt_cost": {"value": 0.00240128}, "meta_eval_completion_cost": {"value": 0.00421376}}, "created": "2025-12-10T21:51:56.8804176Z"}
{"ref": "parallel-director", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.634363328997314}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.004719}, "meta_inference_prompt_tokens": {"value": 11662.0}, "meta_inference_completion_tokens": {"value": 2065.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023324}, "meta_inference_completion_cost": {"value": 0.003304}, "meta_eval_time": {"value": 43.38}, "meta_eval_prompt_tokens": {"value": 8003.0}, "meta_eval_completion_tokens": {"value": 3856.0}, "meta_eval_prompt_cost": {"value": 0.00256096}, "meta_eval_completion_cost": {"value": 0.00493568}}, "created": "2025-12-10T21:51:57.9938479Z"}
{"ref": "parallel-director", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 0.333333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.648757}, "meta_inference_prompt_tokens": {"value": 11325.0}, "meta_inference_completion_tokens": {"value": 1938.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002265}, "meta_inference_completion_cost": {"value": 0.0031008}, "meta_eval_time": {"value": 42.873}, "meta_eval_prompt_tokens": {"value": 7526.0}, "meta_eval_completion_tokens": {"value": 3609.0}, "meta_eval_prompt_cost": {"value": 0.00240832}, "meta_eval_completion_cost": {"value": 0.00461952}}, "created": "2025-12-10T21:51:58.0070348Z"}
{"ref": "patient-radio", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.264404}, "meta_inference_prompt_tokens": {"value": 11872.0}, "meta_inference_completion_tokens": {"value": 1327.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023744}, "meta_inference_completion_cost": {"value": 0.0021232}, "meta_eval_time": {"value": 40.965}, "meta_eval_prompt_tokens": {"value": 8153.0}, "meta_eval_completion_tokens": {"value": 4130.0}, "meta_eval_prompt_cost": {"value": 0.00260896}, "meta_eval_completion_cost": {"value": 0.0052864}}, "created": "2025-12-10T21:51:58.2607825Z"}
{"ref": "perfect-butte", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.842105263157895}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 0.888888888888889}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.888888888888889}, "meta_inference_time": {"value": 24.829273}, "meta_inference_prompt_tokens": {"value": 14926.0}, "meta_inference_completion_tokens": {"value": 926.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029852}, "meta_inference_completion_cost": {"value": 0.0014816}, "meta_eval_time": {"value": 30.969}, "meta_eval_prompt_tokens": {"value": 10310.0}, "meta_eval_completion_tokens": {"value": 2837.0}, "meta_eval_prompt_cost": {"value": 0.0032992}, "meta_eval_completion_cost": {"value": 0.00363136}}, "created": "2025-12-10T21:51:59.0527143Z"}
{"ref": "quadratic-factor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.680676558073393}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.05}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 41.277174}, "meta_inference_prompt_tokens": {"value": 26073.0}, "meta_inference_completion_tokens": {"value": 2698.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0052146}, "meta_inference_completion_cost": {"value": 0.0043168}, "meta_eval_time": {"value": 0.003}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:59.0900662Z"}
{"ref": "plastic-bean", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.528432}, "meta_inference_prompt_tokens": {"value": 2259.0}, "meta_inference_completion_tokens": {"value": 418.0}, "meta_inference_prompt_cost": {"value": 0.0004518}, "meta_inference_completion_cost": {"value": 0.0006688}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:51:59.1255305Z"}
{"ref": "overcast-travel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.670649}, "meta_inference_prompt_tokens": {"value": 10478.0}, "meta_inference_completion_tokens": {"value": 1519.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020956}, "meta_inference_completion_cost": {"value": 0.0024304}, "meta_eval_time": {"value": 43.667}, "meta_eval_prompt_tokens": {"value": 6805.0}, "meta_eval_completion_tokens": {"value": 4061.0}, "meta_eval_prompt_cost": {"value": 0.0021776}, "meta_eval_completion_cost": {"value": 0.00519808}}, "created": "2025-12-10T21:51:59.7154104Z"}
{"ref": "patient-radio", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.868445}, "meta_inference_prompt_tokens": {"value": 13854.0}, "meta_inference_completion_tokens": {"value": 1478.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027708}, "meta_inference_completion_cost": {"value": 0.0023648}, "meta_eval_time": {"value": 36.382}, "meta_eval_prompt_tokens": {"value": 9932.0}, "meta_eval_completion_tokens": {"value": 3262.0}, "meta_eval_prompt_cost": {"value": 0.00317824}, "meta_eval_completion_cost": {"value": 0.00417536}}, "created": "2025-12-10T21:52:00.0851779Z"}
{"ref": "parallel-director", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.840984}, "meta_inference_prompt_tokens": {"value": 11087.0}, "meta_inference_completion_tokens": {"value": 1815.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022174}, "meta_inference_completion_cost": {"value": 0.002904}, "meta_eval_time": {"value": 45.568}, "meta_eval_prompt_tokens": {"value": 7219.0}, "meta_eval_completion_tokens": {"value": 3683.0}, "meta_eval_prompt_cost": {"value": 0.00231008}, "meta_eval_completion_cost": {"value": 0.00471424}}, "created": "2025-12-10T21:52:00.4696039Z"}
{"ref": "parallel-director", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.70231768402027}, "generation_faithfulness": {"value": 0.86046511627907}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.360356}, "meta_inference_prompt_tokens": {"value": 12268.0}, "meta_inference_completion_tokens": {"value": 2234.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024536}, "meta_inference_completion_cost": {"value": 0.0035744}, "meta_eval_time": {"value": 47.95}, "meta_eval_prompt_tokens": {"value": 9026.0}, "meta_eval_completion_tokens": {"value": 4464.0}, "meta_eval_prompt_cost": {"value": 0.00288832}, "meta_eval_completion_cost": {"value": 0.00571392}}, "created": "2025-12-10T21:52:03.9192321Z"}
{"ref": "parallel-director", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.743059994342564}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 51.840184}, "meta_inference_prompt_tokens": {"value": 11677.0}, "meta_inference_completion_tokens": {"value": 2243.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023354}, "meta_inference_completion_cost": {"value": 0.0035888}, "meta_eval_time": {"value": 49.009}, "meta_eval_prompt_tokens": {"value": 8617.0}, "meta_eval_completion_tokens": {"value": 4596.0}, "meta_eval_prompt_cost": {"value": 0.00275744}, "meta_eval_completion_cost": {"value": 0.00588288}}, "created": "2025-12-10T21:52:04.7474122Z"}
{"ref": "overcast-travel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.785618}, "meta_inference_prompt_tokens": {"value": 10031.0}, "meta_inference_completion_tokens": {"value": 1581.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020062}, "meta_inference_completion_cost": {"value": 0.0025296}, "meta_eval_time": {"value": 51.688}, "meta_eval_prompt_tokens": {"value": 6766.0}, "meta_eval_completion_tokens": {"value": 4560.0}, "meta_eval_prompt_cost": {"value": 0.00216512}, "meta_eval_completion_cost": {"value": 0.0058368}}, "created": "2025-12-10T21:52:04.8604831Z"}
{"ref": "perfect-butte", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.612244897959184}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.625}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.625}, "meta_inference_time": {"value": 25.006952}, "meta_inference_prompt_tokens": {"value": 14698.0}, "meta_inference_completion_tokens": {"value": 1324.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029396}, "meta_inference_completion_cost": {"value": 0.0021184}, "meta_eval_time": {"value": 42.007}, "meta_eval_prompt_tokens": {"value": 10211.0}, "meta_eval_completion_tokens": {"value": 3690.0}, "meta_eval_prompt_cost": {"value": 0.00326752}, "meta_eval_completion_cost": {"value": 0.0047232}}, "created": "2025-12-10T21:52:05.2618381Z"}
{"ref": "patient-radio", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.939393939393939}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.84898}, "meta_inference_prompt_tokens": {"value": 11437.0}, "meta_inference_completion_tokens": {"value": 1432.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022874}, "meta_inference_completion_cost": {"value": 0.0022912}, "meta_eval_time": {"value": 41.013}, "meta_eval_prompt_tokens": {"value": 7510.0}, "meta_eval_completion_tokens": {"value": 3570.0}, "meta_eval_prompt_cost": {"value": 0.0024032}, "meta_eval_completion_cost": {"value": 0.0045696}}, "created": "2025-12-10T21:52:05.635277Z"}
{"ref": "piercing-halite", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.826086956521739}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.665171}, "meta_inference_prompt_tokens": {"value": 10556.0}, "meta_inference_completion_tokens": {"value": 691.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021112}, "meta_inference_completion_cost": {"value": 0.0011056}, "meta_eval_time": {"value": 25.726}, "meta_eval_prompt_tokens": {"value": 5411.0}, "meta_eval_completion_tokens": {"value": 2215.0}, "meta_eval_prompt_cost": {"value": 0.00173152}, "meta_eval_completion_cost": {"value": 0.0028352}}, "created": "2025-12-10T21:52:06.6990284Z"}
{"ref": "pleasant-geometry", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.162105}, "meta_inference_prompt_tokens": {"value": 9294.0}, "meta_inference_completion_tokens": {"value": 970.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018588}, "meta_inference_completion_cost": {"value": 0.001552}, "meta_eval_time": {"value": 17.029}, "meta_eval_prompt_tokens": {"value": 4137.0}, "meta_eval_completion_tokens": {"value": 1643.0}, "meta_eval_prompt_cost": {"value": 0.00132384}, "meta_eval_completion_cost": {"value": 0.00210304}}, "created": "2025-12-10T21:52:06.946231Z"}
{"ref": "proper-binary", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.333333333333333}, "generation_faithfulness": {"value": 0.533333333333333}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.606649}, "meta_inference_prompt_tokens": {"value": 11347.0}, "meta_inference_completion_tokens": {"value": 1176.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022694}, "meta_inference_completion_cost": {"value": 0.0018816}, "meta_eval_time": {"value": 15.635}, "meta_eval_prompt_tokens": {"value": 6129.0}, "meta_eval_completion_tokens": {"value": 1549.0}, "meta_eval_prompt_cost": {"value": 0.00196128}, "meta_eval_completion_cost": {"value": 0.00198272}}, "created": "2025-12-10T21:52:07.3085867Z"}
{"ref": "proper-binary", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.7}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.493379}, "meta_inference_prompt_tokens": {"value": 13321.0}, "meta_inference_completion_tokens": {"value": 1066.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026642}, "meta_inference_completion_cost": {"value": 0.0017056}, "meta_eval_time": {"value": 13.342}, "meta_eval_prompt_tokens": {"value": 7710.0}, "meta_eval_completion_tokens": {"value": 1391.0}, "meta_eval_prompt_cost": {"value": 0.0024672}, "meta_eval_completion_cost": {"value": 0.00178048}}, "created": "2025-12-10T21:52:07.662505Z"}
{"ref": "pleasant-geometry", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.668312}, "meta_inference_prompt_tokens": {"value": 11076.0}, "meta_inference_completion_tokens": {"value": 1247.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022152}, "meta_inference_completion_cost": {"value": 0.0019952}, "meta_eval_time": {"value": 16.867}, "meta_eval_prompt_tokens": {"value": 5674.0}, "meta_eval_completion_tokens": {"value": 1686.0}, "meta_eval_prompt_cost": {"value": 0.00181568}, "meta_eval_completion_cost": {"value": 0.00215808}}, "created": "2025-12-10T21:52:08.3173823Z"}
{"ref": "planar-dome", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.842105263157895}, "generation_factuality_f1": {"value": 0.648648648648649}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 23.587422}, "meta_inference_prompt_tokens": {"value": 7010.0}, "meta_inference_completion_tokens": {"value": 1332.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001402}, "meta_inference_completion_cost": {"value": 0.0021312}, "meta_eval_time": {"value": 23.561}, "meta_eval_prompt_tokens": {"value": 4441.0}, "meta_eval_completion_tokens": {"value": 2184.0}, "meta_eval_prompt_cost": {"value": 0.00142112}, "meta_eval_completion_cost": {"value": 0.00279552}}, "created": "2025-12-10T21:52:09.4588565Z"}
{"ref": "proper-binary", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.6}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.673186}, "meta_inference_prompt_tokens": {"value": 12325.0}, "meta_inference_completion_tokens": {"value": 1262.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002465}, "meta_inference_completion_cost": {"value": 0.0020192}, "meta_eval_time": {"value": 13.691}, "meta_eval_prompt_tokens": {"value": 6557.0}, "meta_eval_completion_tokens": {"value": 1173.0}, "meta_eval_prompt_cost": {"value": 0.00209824}, "meta_eval_completion_cost": {"value": 0.00150144}}, "created": "2025-12-10T21:52:10.6213246Z"}
{"ref": "planar-dome", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 21.039167}, "meta_inference_prompt_tokens": {"value": 8806.0}, "meta_inference_completion_tokens": {"value": 1162.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0017612}, "meta_inference_completion_cost": {"value": 0.0018592}, "meta_eval_time": {"value": 23.556}, "meta_eval_prompt_tokens": {"value": 5468.0}, "meta_eval_completion_tokens": {"value": 2067.0}, "meta_eval_prompt_cost": {"value": 0.00174976}, "meta_eval_completion_cost": {"value": 0.00264576}}, "created": "2025-12-10T21:52:10.8260325Z"}
{"ref": "quiet-symphony", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.852097}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 445.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.000712}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:10.8686518Z"}
{"ref": "quiet-symphony", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.833856}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 595.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.000952}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:10.9079485Z"}
{"ref": "planar-dome", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 24.348563}, "meta_inference_prompt_tokens": {"value": 8779.0}, "meta_inference_completion_tokens": {"value": 1344.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0017558}, "meta_inference_completion_cost": {"value": 0.0021504}, "meta_eval_time": {"value": 25.053}, "meta_eval_prompt_tokens": {"value": 5714.0}, "meta_eval_completion_tokens": {"value": 2297.0}, "meta_eval_prompt_cost": {"value": 0.00182848}, "meta_eval_completion_cost": {"value": 0.00294016}}, "created": "2025-12-10T21:52:11.5543573Z"}
{"ref": "pink-mythology-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.105263157894737}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.971428571428571}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 0.714285714285714}, "retrieval_accuracy": {"value": 0.0555555555555556}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.111111111111111}, "generation_correctness": {"value": 0.714285714285714}, "meta_inference_time": {"value": 30.493017}, "meta_inference_prompt_tokens": {"value": 9996.0}, "meta_inference_completion_tokens": {"value": 1506.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019992}, "meta_inference_completion_cost": {"value": 0.0024096}, "meta_eval_time": {"value": 40.746}, "meta_eval_prompt_tokens": {"value": 7119.0}, "meta_eval_completion_tokens": {"value": 3795.0}, "meta_eval_prompt_cost": {"value": 0.00227808}, "meta_eval_completion_cost": {"value": 0.0048576}}, "created": "2025-12-10T21:52:11.7120261Z"}
{"ref": "pink-mythology-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.934782608695652}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 27.166974}, "meta_inference_prompt_tokens": {"value": 10998.0}, "meta_inference_completion_tokens": {"value": 1573.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021996}, "meta_inference_completion_cost": {"value": 0.0025168}, "meta_eval_time": {"value": 35.529}, "meta_eval_prompt_tokens": {"value": 6303.0}, "meta_eval_completion_tokens": {"value": 3783.0}, "meta_eval_prompt_cost": {"value": 0.00201696}, "meta_eval_completion_cost": {"value": 0.00484224}}, "created": "2025-12-10T21:52:12.5025233Z"}
{"ref": "proper-binary", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.322931}, "meta_inference_prompt_tokens": {"value": 12945.0}, "meta_inference_completion_tokens": {"value": 1181.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002589}, "meta_inference_completion_cost": {"value": 0.0018896}, "meta_eval_time": {"value": 20.415}, "meta_eval_prompt_tokens": {"value": 7570.0}, "meta_eval_completion_tokens": {"value": 1848.0}, "meta_eval_prompt_cost": {"value": 0.0024224}, "meta_eval_completion_cost": {"value": 0.00236544}}, "created": "2025-12-10T21:52:12.6906993Z"}
{"ref": "planar-dome", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.85}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 23.909984}, "meta_inference_prompt_tokens": {"value": 9485.0}, "meta_inference_completion_tokens": {"value": 1188.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001897}, "meta_inference_completion_cost": {"value": 0.0019008}, "meta_eval_time": {"value": 23.654}, "meta_eval_prompt_tokens": {"value": 6047.0}, "meta_eval_completion_tokens": {"value": 2224.0}, "meta_eval_prompt_cost": {"value": 0.00193504}, "meta_eval_completion_cost": {"value": 0.00284672}}, "created": "2025-12-10T21:52:12.9859404Z"}
{"ref": "quiet-symphony", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.34726}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 333.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0005328}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:13.0234771Z"}
{"ref": "quiet-symphony", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.367519}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 591.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0009456}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:13.0575312Z"}
{"ref": "pink-mythology-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.105263157894737}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.966666666666667}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0555555555555556}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.111111111111111}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.813447}, "meta_inference_prompt_tokens": {"value": 10564.0}, "meta_inference_completion_tokens": {"value": 1048.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021128}, "meta_inference_completion_cost": {"value": 0.0016768}, "meta_eval_time": {"value": 34.174}, "meta_eval_prompt_tokens": {"value": 6686.0}, "meta_eval_completion_tokens": {"value": 2898.0}, "meta_eval_prompt_cost": {"value": 0.00213952}, "meta_eval_completion_cost": {"value": 0.00370944}}, "created": "2025-12-10T21:52:13.1335721Z"}
{"ref": "planar-dome", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.904761904761905}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.444357}, "meta_inference_prompt_tokens": {"value": 8817.0}, "meta_inference_completion_tokens": {"value": 1299.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0017634}, "meta_inference_completion_cost": {"value": 0.0020784}, "meta_eval_time": {"value": 26.439}, "meta_eval_prompt_tokens": {"value": 5999.0}, "meta_eval_completion_tokens": {"value": 2544.0}, "meta_eval_prompt_cost": {"value": 0.00191968}, "meta_eval_completion_cost": {"value": 0.00325632}}, "created": "2025-12-10T21:52:13.295213Z"}
{"ref": "quiet-symphony", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.670481}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 717.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0011472}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:13.3297615Z"}
{"ref": "perpendicular-stick-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 0.919994579889346}, "generation_faithfulness": {"value": 0.958333333333334}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.311942}, "meta_inference_prompt_tokens": {"value": 17511.0}, "meta_inference_completion_tokens": {"value": 1093.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0035022}, "meta_inference_completion_cost": {"value": 0.0017488}, "meta_eval_time": {"value": 24.992}, "meta_eval_prompt_tokens": {"value": 12157.0}, "meta_eval_completion_tokens": {"value": 2392.0}, "meta_eval_prompt_cost": {"value": 0.00389024}, "meta_eval_completion_cost": {"value": 0.00306176}}, "created": "2025-12-10T21:52:14.3823567Z"}
{"ref": "pleasant-geometry", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.842105263157895}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.250392}, "meta_inference_prompt_tokens": {"value": 10067.0}, "meta_inference_completion_tokens": {"value": 948.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020134}, "meta_inference_completion_cost": {"value": 0.0015168}, "meta_eval_time": {"value": 23.924}, "meta_eval_prompt_tokens": {"value": 5149.0}, "meta_eval_completion_tokens": {"value": 2021.0}, "meta_eval_prompt_cost": {"value": 0.00164768}, "meta_eval_completion_cost": {"value": 0.00258688}}, "created": "2025-12-10T21:52:14.637197Z"}
{"ref": "radioactive-developer", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 6.625972}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 268.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0004288}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:14.6929519Z"}
{"ref": "pleasant-geometry", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.295664}, "meta_inference_prompt_tokens": {"value": 9205.0}, "meta_inference_completion_tokens": {"value": 926.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001841}, "meta_inference_completion_cost": {"value": 0.0014816}, "meta_eval_time": {"value": 18.169}, "meta_eval_prompt_tokens": {"value": 4294.0}, "meta_eval_completion_tokens": {"value": 1739.0}, "meta_eval_prompt_cost": {"value": 0.00137408}, "meta_eval_completion_cost": {"value": 0.00222592}}, "created": "2025-12-10T21:52:15.0692449Z"}
{"ref": "radioactive-developer", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 5.861998}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 218.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0003488}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:15.1194132Z"}
{"ref": "pink-mythology-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.1}, "retrieval_mrr": {"value": 0.125}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0526315789473684}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.1}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 24.167098}, "meta_inference_prompt_tokens": {"value": 11095.0}, "meta_inference_completion_tokens": {"value": 1453.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002219}, "meta_inference_completion_cost": {"value": 0.0023248}, "meta_eval_time": {"value": 35.049}, "meta_eval_prompt_tokens": {"value": 6517.0}, "meta_eval_completion_tokens": {"value": 3308.0}, "meta_eval_prompt_cost": {"value": 0.00208544}, "meta_eval_completion_cost": {"value": 0.00423424}}, "created": "2025-12-10T21:52:17.6462487Z"}
{"ref": "radioactive-developer", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 6.593615}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 268.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0004288}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:17.7120647Z"}
{"ref": "proper-binary", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.142857142857143}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.198585}, "meta_inference_prompt_tokens": {"value": 9095.0}, "meta_inference_completion_tokens": {"value": 1546.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001819}, "meta_inference_completion_cost": {"value": 0.0024736}, "meta_eval_time": {"value": 13.866}, "meta_eval_prompt_tokens": {"value": 4499.0}, "meta_eval_completion_tokens": {"value": 1293.0}, "meta_eval_prompt_cost": {"value": 0.00143968}, "meta_eval_completion_cost": {"value": 0.00165504}}, "created": "2025-12-10T21:52:17.842193Z"}
{"ref": "pink-mythology-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.1}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.976190476190476}, "generation_factuality_f1": {"value": 0.307692307692308}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.285714285714286}, "retrieval_accuracy": {"value": 0.0526315789473684}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.1}, "generation_correctness": {"value": 0.285714285714286}, "meta_inference_time": {"value": 25.377175}, "meta_inference_prompt_tokens": {"value": 11596.0}, "meta_inference_completion_tokens": {"value": 1298.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023192}, "meta_inference_completion_cost": {"value": 0.0020768}, "meta_eval_time": {"value": 42.902}, "meta_eval_prompt_tokens": {"value": 6945.0}, "meta_eval_completion_tokens": {"value": 4055.0}, "meta_eval_prompt_cost": {"value": 0.0022224}, "meta_eval_completion_cost": {"value": 0.0051904}}, "created": "2025-12-10T21:52:20.475405Z"}
{"ref": "pink-mythology-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.105263157894737}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.95}, "generation_factuality_f1": {"value": 0.588235294117647}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.714285714285714}, "retrieval_accuracy": {"value": 0.0555555555555556}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.111111111111111}, "generation_correctness": {"value": 0.714285714285714}, "meta_inference_time": {"value": 23.047016}, "meta_inference_prompt_tokens": {"value": 10551.0}, "meta_inference_completion_tokens": {"value": 1380.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021102}, "meta_inference_completion_cost": {"value": 0.002208}, "meta_eval_time": {"value": 45.398}, "meta_eval_prompt_tokens": {"value": 7614.0}, "meta_eval_completion_tokens": {"value": 4210.0}, "meta_eval_prompt_cost": {"value": 0.00243648}, "meta_eval_completion_cost": {"value": 0.0053888}}, "created": "2025-12-10T21:52:20.6830594Z"}
{"ref": "pink-mythology-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 0.3125}, "retrieval_dcg": {"value": 0.919994579889346}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.452830188679245}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.571428571428571}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.2}, "generation_correctness": {"value": 0.571428571428571}, "meta_inference_time": {"value": 29.318102}, "meta_inference_prompt_tokens": {"value": 11480.0}, "meta_inference_completion_tokens": {"value": 1281.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002296}, "meta_inference_completion_cost": {"value": 0.0020496}, "meta_eval_time": {"value": 42.23}, "meta_eval_prompt_tokens": {"value": 6701.0}, "meta_eval_completion_tokens": {"value": 3578.0}, "meta_eval_prompt_cost": {"value": 0.00214432}, "meta_eval_completion_cost": {"value": 0.00457984}}, "created": "2025-12-10T21:52:21.6268271Z"}
{"ref": "radioactive-developer", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 7.36243}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 268.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0004288}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:21.6620786Z"}
{"ref": "purple-bastion-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428571}, "retrieval_mrr": {"value": 0.446666666666667}, "retrieval_dcg": {"value": 2.73752394519728}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.592466}, "meta_inference_prompt_tokens": {"value": 13803.0}, "meta_inference_completion_tokens": {"value": 738.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027606}, "meta_inference_completion_cost": {"value": 0.0011808}, "meta_eval_time": {"value": 28.175}, "meta_eval_prompt_tokens": {"value": 9047.0}, "meta_eval_completion_tokens": {"value": 2521.0}, "meta_eval_prompt_cost": {"value": 0.00289504}, "meta_eval_completion_cost": {"value": 0.00322688}}, "created": "2025-12-10T21:52:22.6164091Z"}
{"ref": "quantum-row", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.200175}, "meta_inference_prompt_tokens": {"value": 10321.0}, "meta_inference_completion_tokens": {"value": 1044.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020642}, "meta_inference_completion_cost": {"value": 0.0016704}, "meta_eval_time": {"value": 22.204}, "meta_eval_prompt_tokens": {"value": 5487.0}, "meta_eval_completion_tokens": {"value": 1878.0}, "meta_eval_prompt_cost": {"value": 0.00175584}, "meta_eval_completion_cost": {"value": 0.00240384}}, "created": "2025-12-10T21:52:22.7093145Z"}
{"ref": "quantum-row", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.648834}, "meta_inference_prompt_tokens": {"value": 14674.0}, "meta_inference_completion_tokens": {"value": 1327.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029348}, "meta_inference_completion_cost": {"value": 0.0021232}, "meta_eval_time": {"value": 25.019}, "meta_eval_prompt_tokens": {"value": 9520.0}, "meta_eval_completion_tokens": {"value": 2225.0}, "meta_eval_prompt_cost": {"value": 0.0030464}, "meta_eval_completion_cost": {"value": 0.002848}}, "created": "2025-12-10T21:52:23.3190689Z"}
{"ref": "rancid-root", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.517992}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 580.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.000928}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:23.3552562Z"}
{"ref": "quadratic-factor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.25}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 37.139922}, "meta_inference_prompt_tokens": {"value": 7712.0}, "meta_inference_completion_tokens": {"value": 2258.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0015424}, "meta_inference_completion_cost": {"value": 0.0036128}, "meta_eval_time": {"value": 24.056}, "meta_eval_prompt_tokens": {"value": 4463.0}, "meta_eval_completion_tokens": {"value": 1789.0}, "meta_eval_prompt_cost": {"value": 0.00142816}, "meta_eval_completion_cost": {"value": 0.00228992}}, "created": "2025-12-10T21:52:23.8068931Z"}
{"ref": "quantum-row", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.512754}, "meta_inference_prompt_tokens": {"value": 10299.0}, "meta_inference_completion_tokens": {"value": 1046.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020598}, "meta_inference_completion_cost": {"value": 0.0016736}, "meta_eval_time": {"value": 19.18}, "meta_eval_prompt_tokens": {"value": 5301.0}, "meta_eval_completion_tokens": {"value": 1672.0}, "meta_eval_prompt_cost": {"value": 0.00169632}, "meta_eval_completion_cost": {"value": 0.00214016}}, "created": "2025-12-10T21:52:24.8523968Z"}
{"ref": "radioactive-developer", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 5.947515}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 217.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0003472}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:24.890796Z"}
{"ref": "pleasant-geometry", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.65173}, "meta_inference_prompt_tokens": {"value": 10100.0}, "meta_inference_completion_tokens": {"value": 1191.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00202}, "meta_inference_completion_cost": {"value": 0.0019056}, "meta_eval_time": {"value": 20.253}, "meta_eval_prompt_tokens": {"value": 4985.0}, "meta_eval_completion_tokens": {"value": 1980.0}, "meta_eval_prompt_cost": {"value": 0.0015952}, "meta_eval_completion_cost": {"value": 0.0025344}}, "created": "2025-12-10T21:52:25.1487037Z"}
{"ref": "quadratic-factor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.266666666666667}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.25}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 34.953541}, "meta_inference_prompt_tokens": {"value": 7662.0}, "meta_inference_completion_tokens": {"value": 1917.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0015324}, "meta_inference_completion_cost": {"value": 0.0030672}, "meta_eval_time": {"value": 19.967}, "meta_eval_prompt_tokens": {"value": 4473.0}, "meta_eval_completion_tokens": {"value": 1692.0}, "meta_eval_prompt_cost": {"value": 0.00143136}, "meta_eval_completion_cost": {"value": 0.00216576}}, "created": "2025-12-10T21:52:25.2786188Z"}
{"ref": "pink-mythology-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.105263157894737}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.540540540540541}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.0555555555555556}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.111111111111111}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 22.107432}, "meta_inference_prompt_tokens": {"value": 11206.0}, "meta_inference_completion_tokens": {"value": 1205.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022412}, "meta_inference_completion_cost": {"value": 0.001928}, "meta_eval_time": {"value": 40.921}, "meta_eval_prompt_tokens": {"value": 8037.0}, "meta_eval_completion_tokens": {"value": 3785.0}, "meta_eval_prompt_cost": {"value": 0.00257184}, "meta_eval_completion_cost": {"value": 0.0048448}}, "created": "2025-12-10T21:52:26.4792871Z"}
{"ref": "ragged-filet", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.827245}, "meta_inference_prompt_tokens": {"value": 6116.0}, "meta_inference_completion_tokens": {"value": 602.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0012232}, "meta_inference_completion_cost": {"value": 0.0009632}, "meta_eval_time": {"value": 11.858}, "meta_eval_prompt_tokens": {"value": 2954.0}, "meta_eval_completion_tokens": {"value": 1102.0}, "meta_eval_prompt_cost": {"value": 0.00094528}, "meta_eval_completion_cost": {"value": 0.00141056}}, "created": "2025-12-10T21:52:26.5841965Z"}
{"ref": "rancid-root", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.395385}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 513.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0008208}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:26.6197264Z"}
{"ref": "random-exception", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 7.636015}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 425.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.00068}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:26.6602102Z"}
{"ref": "rancid-root", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.245804}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 449.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0007184}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:26.6930207Z"}
{"ref": "rancid-root", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.201027}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 321.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0005136}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:26.7258852Z"}
{"ref": "random-exception", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 10.499653}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 414.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0006624}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:26.7588436Z"}
{"ref": "random-exception", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 8.16433}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 350.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.00056}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:26.7962577Z"}
{"ref": "random-exception", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 6.913062}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 222.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0003552}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:26.8281924Z"}
{"ref": "rancid-root", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.053421}, "meta_inference_prompt_tokens": {"value": 4645.0}, "meta_inference_completion_tokens": {"value": 945.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.000929}, "meta_inference_completion_cost": {"value": 0.001512}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:26.8607302Z"}
{"ref": "random-zipper", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.920055}, "meta_inference_prompt_tokens": {"value": 2252.0}, "meta_inference_completion_tokens": {"value": 512.0}, "meta_inference_prompt_cost": {"value": 0.0004504}, "meta_inference_completion_cost": {"value": 0.0008192}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:26.8935232Z"}
{"ref": "random-zipper", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.395486}, "meta_inference_prompt_tokens": {"value": 4676.0}, "meta_inference_completion_tokens": {"value": 1014.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009352}, "meta_inference_completion_cost": {"value": 0.0016224}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:26.9277529Z"}
{"ref": "random-zipper", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 8.050968}, "meta_inference_prompt_tokens": {"value": 2252.0}, "meta_inference_completion_tokens": {"value": 383.0}, "meta_inference_prompt_cost": {"value": 0.0004504}, "meta_inference_completion_cost": {"value": 0.0006128}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:26.9601804Z"}
{"ref": "random-zipper", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.878498}, "meta_inference_prompt_tokens": {"value": 2252.0}, "meta_inference_completion_tokens": {"value": 436.0}, "meta_inference_prompt_cost": {"value": 0.0004504}, "meta_inference_completion_cost": {"value": 0.0006976}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:26.9924817Z"}
{"ref": "random-exception", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.083904}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 392.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0006272}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:27.0288033Z"}
{"ref": "quantum-row", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.558139534883721}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 21.526541}, "meta_inference_prompt_tokens": {"value": 13426.0}, "meta_inference_completion_tokens": {"value": 1363.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026852}, "meta_inference_completion_cost": {"value": 0.0021808}, "meta_eval_time": {"value": 18.729}, "meta_eval_prompt_tokens": {"value": 8223.0}, "meta_eval_completion_tokens": {"value": 1800.0}, "meta_eval_prompt_cost": {"value": 0.00263136}, "meta_eval_completion_cost": {"value": 0.002304}}, "created": "2025-12-10T21:52:28.2338166Z"}
{"ref": "ragged-filet", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.497354}, "meta_inference_prompt_tokens": {"value": 6121.0}, "meta_inference_completion_tokens": {"value": 651.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0012242}, "meta_inference_completion_cost": {"value": 0.0010416}, "meta_eval_time": {"value": 15.346}, "meta_eval_prompt_tokens": {"value": 2926.0}, "meta_eval_completion_tokens": {"value": 1293.0}, "meta_eval_prompt_cost": {"value": 0.00093632}, "meta_eval_completion_cost": {"value": 0.00165504}}, "created": "2025-12-10T21:52:30.4981293Z"}
{"ref": "purple-bastion-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.714285714285714}, "retrieval_mrr": {"value": 0.413888888888889}, "retrieval_dcg": {"value": 3.13799963932075}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.555555555555556}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.942038}, "meta_inference_prompt_tokens": {"value": 13922.0}, "meta_inference_completion_tokens": {"value": 764.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027844}, "meta_inference_completion_cost": {"value": 0.0012224}, "meta_eval_time": {"value": 32.057}, "meta_eval_prompt_tokens": {"value": 9301.0}, "meta_eval_completion_tokens": {"value": 2989.0}, "meta_eval_prompt_cost": {"value": 0.00297632}, "meta_eval_completion_cost": {"value": 0.00382592}}, "created": "2025-12-10T21:52:32.1848507Z"}
{"ref": "prompt-poset", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.41999457988935}, "generation_faithfulness": {"value": 0.911764705882353}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 21.837326}, "meta_inference_prompt_tokens": {"value": 11821.0}, "meta_inference_completion_tokens": {"value": 1282.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023642}, "meta_inference_completion_cost": {"value": 0.0020512}, "meta_eval_time": {"value": 34.622}, "meta_eval_prompt_tokens": {"value": 7757.0}, "meta_eval_completion_tokens": {"value": 3488.0}, "meta_eval_prompt_cost": {"value": 0.00248224}, "meta_eval_completion_cost": {"value": 0.00446464}}, "created": "2025-12-10T21:52:32.6617112Z"}
{"ref": "quiet-steel-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.4}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.86644}, "meta_inference_prompt_tokens": {"value": 9859.0}, "meta_inference_completion_tokens": {"value": 688.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019718}, "meta_inference_completion_cost": {"value": 0.0011008}, "meta_eval_time": {"value": 20.845}, "meta_eval_prompt_tokens": {"value": 5109.0}, "meta_eval_completion_tokens": {"value": 1929.0}, "meta_eval_prompt_cost": {"value": 0.00163488}, "meta_eval_completion_cost": {"value": 0.00246912}}, "created": "2025-12-10T21:52:32.7122853Z"}
{"ref": "quiet-steel-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.827586206896552}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.4}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 18.602259}, "meta_inference_prompt_tokens": {"value": 9862.0}, "meta_inference_completion_tokens": {"value": 604.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019724}, "meta_inference_completion_cost": {"value": 0.0009664}, "meta_eval_time": {"value": 18.454}, "meta_eval_prompt_tokens": {"value": 5034.0}, "meta_eval_completion_tokens": {"value": 1822.0}, "meta_eval_prompt_cost": {"value": 0.00161088}, "meta_eval_completion_cost": {"value": 0.00233216}}, "created": "2025-12-10T21:52:32.8720311Z"}
{"ref": "pink-mythology-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.1}, "retrieval_mrr": {"value": 0.125}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.907407407407408}, "generation_factuality_f1": {"value": 0.483870967741935}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 0.428571428571429}, "retrieval_accuracy": {"value": 0.0526315789473684}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.1}, "generation_correctness": {"value": 0.428571428571429}, "meta_inference_time": {"value": 27.059834}, "meta_inference_prompt_tokens": {"value": 11354.0}, "meta_inference_completion_tokens": {"value": 1524.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022708}, "meta_inference_completion_cost": {"value": 0.0024384}, "meta_eval_time": {"value": 49.738}, "meta_eval_prompt_tokens": {"value": 7764.0}, "meta_eval_completion_tokens": {"value": 4962.0}, "meta_eval_prompt_cost": {"value": 0.00248448}, "meta_eval_completion_cost": {"value": 0.00635136}}, "created": "2025-12-10T21:52:33.3239701Z"}
{"ref": "quadratic-factor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.117647058823529}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.77023815442732}, "generation_faithfulness": {"value": 0.6}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0625}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0454545454545455}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 52.113337}, "meta_inference_prompt_tokens": {"value": 48755.0}, "meta_inference_completion_tokens": {"value": 3303.0}, "meta_inference_tool_call_count": {"value": 3.0}, "meta_inference_prompt_cost": {"value": 0.009751}, "meta_inference_completion_cost": {"value": 0.0052848}, "meta_eval_time": {"value": 26.85}, "meta_eval_prompt_tokens": {"value": 12507.0}, "meta_eval_completion_tokens": {"value": 2351.0}, "meta_eval_prompt_cost": {"value": 0.00400224}, "meta_eval_completion_cost": {"value": 0.00300928}}, "created": "2025-12-10T21:52:33.8468248Z"}
{"ref": "quadratic-factor", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.719741384391281}, "generation_faithfulness": {"value": 0.68}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0625}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 58.563467}, "meta_inference_prompt_tokens": {"value": 24627.0}, "meta_inference_completion_tokens": {"value": 3913.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0049254}, "meta_inference_completion_cost": {"value": 0.0062608}, "meta_eval_time": {"value": 29.087}, "meta_eval_prompt_tokens": {"value": 11427.0}, "meta_eval_completion_tokens": {"value": 2856.0}, "meta_eval_prompt_cost": {"value": 0.00365664}, "meta_eval_completion_cost": {"value": 0.00365568}}, "created": "2025-12-10T21:52:33.8764397Z"}
{"ref": "pink-mythology-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.105263157894737}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.682926829268293}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0555555555555556}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.111111111111111}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 26.019251}, "meta_inference_prompt_tokens": {"value": 10438.0}, "meta_inference_completion_tokens": {"value": 1502.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020876}, "meta_inference_completion_cost": {"value": 0.0024032}, "meta_eval_time": {"value": 52.756}, "meta_eval_prompt_tokens": {"value": 7756.0}, "meta_eval_completion_tokens": {"value": 4711.0}, "meta_eval_prompt_cost": {"value": 0.00248192}, "meta_eval_completion_cost": {"value": 0.00603008}}, "created": "2025-12-10T21:52:34.555759Z"}
{"ref": "quantum-row", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.855305}, "meta_inference_prompt_tokens": {"value": 12464.0}, "meta_inference_completion_tokens": {"value": 1475.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024928}, "meta_inference_completion_cost": {"value": 0.00236}, "meta_eval_time": {"value": 27.02}, "meta_eval_prompt_tokens": {"value": 7650.0}, "meta_eval_completion_tokens": {"value": 2234.0}, "meta_eval_prompt_cost": {"value": 0.002448}, "meta_eval_completion_cost": {"value": 0.00285952}}, "created": "2025-12-10T21:52:34.7191203Z"}
{"ref": "quiet-steel-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.904761904761905}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.4}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.646439}, "meta_inference_prompt_tokens": {"value": 10084.0}, "meta_inference_completion_tokens": {"value": 801.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020168}, "meta_inference_completion_cost": {"value": 0.0012816}, "meta_eval_time": {"value": 23.824}, "meta_eval_prompt_tokens": {"value": 5464.0}, "meta_eval_completion_tokens": {"value": 1987.0}, "meta_eval_prompt_cost": {"value": 0.00174848}, "meta_eval_completion_cost": {"value": 0.00254336}}, "created": "2025-12-10T21:52:34.7763663Z"}
{"ref": "prompt-poset", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.80102999566398}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.878048780487805}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 28.387783}, "meta_inference_prompt_tokens": {"value": 11218.0}, "meta_inference_completion_tokens": {"value": 1542.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022436}, "meta_inference_completion_cost": {"value": 0.0024672}, "meta_eval_time": {"value": 42.597}, "meta_eval_prompt_tokens": {"value": 8349.0}, "meta_eval_completion_tokens": {"value": 4156.0}, "meta_eval_prompt_cost": {"value": 0.00267168}, "meta_eval_completion_cost": {"value": 0.00531968}}, "created": "2025-12-10T21:52:35.2338232Z"}
{"ref": "ragged-filet", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.837776}, "meta_inference_prompt_tokens": {"value": 6118.0}, "meta_inference_completion_tokens": {"value": 623.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0012236}, "meta_inference_completion_cost": {"value": 0.0009968}, "meta_eval_time": {"value": 10.594}, "meta_eval_prompt_tokens": {"value": 2817.0}, "meta_eval_completion_tokens": {"value": 904.0}, "meta_eval_prompt_cost": {"value": 0.00090144}, "meta_eval_completion_cost": {"value": 0.00115712}}, "created": "2025-12-10T21:52:35.7769099Z"}
{"ref": "radiant-vector", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.94845911887939}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.946379}, "meta_inference_prompt_tokens": {"value": 11292.0}, "meta_inference_completion_tokens": {"value": 769.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022584}, "meta_inference_completion_cost": {"value": 0.0012304}, "meta_eval_time": {"value": 24.924}, "meta_eval_prompt_tokens": {"value": 5932.0}, "meta_eval_completion_tokens": {"value": 2282.0}, "meta_eval_prompt_cost": {"value": 0.00189824}, "meta_eval_completion_cost": {"value": 0.00292096}}, "created": "2025-12-10T21:52:36.5170316Z"}
{"ref": "quiet-steel-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.95}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.4}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.160525}, "meta_inference_prompt_tokens": {"value": 10800.0}, "meta_inference_completion_tokens": {"value": 768.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00216}, "meta_inference_completion_cost": {"value": 0.0012288}, "meta_eval_time": {"value": 23.306}, "meta_eval_prompt_tokens": {"value": 5723.0}, "meta_eval_completion_tokens": {"value": 1947.0}, "meta_eval_prompt_cost": {"value": 0.00183136}, "meta_eval_completion_cost": {"value": 0.00249216}}, "created": "2025-12-10T21:52:36.6793018Z"}
{"ref": "ragged-filet", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.25}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.203645}, "meta_inference_prompt_tokens": {"value": 6880.0}, "meta_inference_completion_tokens": {"value": 855.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001376}, "meta_inference_completion_cost": {"value": 0.001368}, "meta_eval_time": {"value": 12.988}, "meta_eval_prompt_tokens": {"value": 3222.0}, "meta_eval_completion_tokens": {"value": 917.0}, "meta_eval_prompt_cost": {"value": 0.00103104}, "meta_eval_completion_cost": {"value": 0.00117376}}, "created": "2025-12-10T21:52:36.8294715Z"}
{"ref": "random-zipper", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.147598}, "meta_inference_prompt_tokens": {"value": 2252.0}, "meta_inference_completion_tokens": {"value": 569.0}, "meta_inference_prompt_cost": {"value": 0.0004504}, "meta_inference_completion_cost": {"value": 0.0009104}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:36.8639759Z"}
{"ref": "purple-bastion-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.714285714285714}, "retrieval_mrr": {"value": 0.413888888888889}, "retrieval_dcg": {"value": 2.98920142920169}, "generation_faithfulness": {"value": 0.96969696969697}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.555555555555556}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.29226}, "meta_inference_prompt_tokens": {"value": 14510.0}, "meta_inference_completion_tokens": {"value": 1044.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002902}, "meta_inference_completion_cost": {"value": 0.0016704}, "meta_eval_time": {"value": 37.898}, "meta_eval_prompt_tokens": {"value": 9798.0}, "meta_eval_completion_tokens": {"value": 3224.0}, "meta_eval_prompt_cost": {"value": 0.00313536}, "meta_eval_completion_cost": {"value": 0.00412672}}, "created": "2025-12-10T21:52:37.057946Z"}
{"ref": "prompt-poset", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.44639463035719}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.827586206896552}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 30.046892}, "meta_inference_prompt_tokens": {"value": 11045.0}, "meta_inference_completion_tokens": {"value": 1208.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002209}, "meta_inference_completion_cost": {"value": 0.0019328}, "meta_eval_time": {"value": 41.545}, "meta_eval_prompt_tokens": {"value": 7052.0}, "meta_eval_completion_tokens": {"value": 3850.0}, "meta_eval_prompt_cost": {"value": 0.00225664}, "meta_eval_completion_cost": {"value": 0.004928}}, "created": "2025-12-10T21:52:37.4721471Z"}
{"ref": "radiant-vector", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.94845911887939}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.884}, "meta_inference_prompt_tokens": {"value": 11295.0}, "meta_inference_completion_tokens": {"value": 751.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002259}, "meta_inference_completion_cost": {"value": 0.0012016}, "meta_eval_time": {"value": 25.819}, "meta_eval_prompt_tokens": {"value": 6104.0}, "meta_eval_completion_tokens": {"value": 2181.0}, "meta_eval_prompt_cost": {"value": 0.00195328}, "meta_eval_completion_cost": {"value": 0.00279168}}, "created": "2025-12-10T21:52:38.9352218Z"}
{"ref": "prompt-poset", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "meta_inference_time": {"value": 27.565099}, "meta_inference_prompt_tokens": {"value": 11001.0}, "meta_inference_completion_tokens": {"value": 1338.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022002}, "meta_inference_completion_cost": {"value": 0.0021408}, "meta_eval_time": {"value": 41.401}, "meta_eval_prompt_tokens": {"value": 6002.0}, "meta_eval_completion_tokens": {"value": 3140.0}, "meta_eval_prompt_cost": {"value": 0.00192064}, "meta_eval_completion_cost": {"value": 0.0040192}}, "created": "2025-12-10T21:52:39.449588Z"}
{"ref": "quiet-steel-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 0.870967741935484}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.4}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.901785}, "meta_inference_prompt_tokens": {"value": 10522.0}, "meta_inference_completion_tokens": {"value": 1141.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021044}, "meta_inference_completion_cost": {"value": 0.0018256}, "meta_eval_time": {"value": 30.233}, "meta_eval_prompt_tokens": {"value": 6083.0}, "meta_eval_completion_tokens": {"value": 2803.0}, "meta_eval_prompt_cost": {"value": 0.00194656}, "meta_eval_completion_cost": {"value": 0.00358784}}, "created": "2025-12-10T21:52:40.8954334Z"}
{"ref": "radiant-vector", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.94845911887939}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.951492}, "meta_inference_prompt_tokens": {"value": 11600.0}, "meta_inference_completion_tokens": {"value": 550.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00232}, "meta_inference_completion_cost": {"value": 0.00088}, "meta_eval_time": {"value": 28.231}, "meta_eval_prompt_tokens": {"value": 6472.0}, "meta_eval_completion_tokens": {"value": 2754.0}, "meta_eval_prompt_cost": {"value": 0.00207104}, "meta_eval_completion_cost": {"value": 0.00352512}}, "created": "2025-12-10T21:52:40.9584752Z"}
{"ref": "radiant-vector", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.94845911887939}, "generation_faithfulness": {"value": 0.96551724137931}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.279369}, "meta_inference_prompt_tokens": {"value": 11293.0}, "meta_inference_completion_tokens": {"value": 729.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022586}, "meta_inference_completion_cost": {"value": 0.0011664}, "meta_eval_time": {"value": 29.482}, "meta_eval_prompt_tokens": {"value": 6093.0}, "meta_eval_completion_tokens": {"value": 2541.0}, "meta_eval_prompt_cost": {"value": 0.00194976}, "meta_eval_completion_cost": {"value": 0.00325248}}, "created": "2025-12-10T21:52:42.0242873Z"}
{"ref": "purple-bastion-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.714285714285714}, "retrieval_mrr": {"value": 0.413888888888889}, "retrieval_dcg": {"value": 3.20732308124736}, "generation_faithfulness": {"value": 0.966666666666667}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.555555555555556}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.31266}, "meta_inference_prompt_tokens": {"value": 14579.0}, "meta_inference_completion_tokens": {"value": 892.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029158}, "meta_inference_completion_cost": {"value": 0.0014272}, "meta_eval_time": {"value": 34.857}, "meta_eval_prompt_tokens": {"value": 9602.0}, "meta_eval_completion_tokens": {"value": 2689.0}, "meta_eval_prompt_cost": {"value": 0.00307264}, "meta_eval_completion_cost": {"value": 0.00344192}}, "created": "2025-12-10T21:52:42.2019202Z"}
{"ref": "purple-bastion-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.714285714285714}, "retrieval_mrr": {"value": 0.413888888888889}, "retrieval_dcg": {"value": 3.00706988574929}, "generation_faithfulness": {"value": 0.948717948717949}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.555555555555556}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.96784}, "meta_inference_prompt_tokens": {"value": 14205.0}, "meta_inference_completion_tokens": {"value": 1238.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002841}, "meta_inference_completion_cost": {"value": 0.0019808}, "meta_eval_time": {"value": 37.804}, "meta_eval_prompt_tokens": {"value": 9685.0}, "meta_eval_completion_tokens": {"value": 3493.0}, "meta_eval_prompt_cost": {"value": 0.0030992}, "meta_eval_completion_cost": {"value": 0.00447104}}, "created": "2025-12-10T21:52:44.5540034Z"}
{"ref": "rapid-bookcase", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.732433}, "meta_inference_prompt_tokens": {"value": 11613.0}, "meta_inference_completion_tokens": {"value": 978.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023226}, "meta_inference_completion_cost": {"value": 0.0015648}, "meta_eval_time": {"value": 12.073}, "meta_eval_prompt_tokens": {"value": 6134.0}, "meta_eval_completion_tokens": {"value": 1097.0}, "meta_eval_prompt_cost": {"value": 0.00196288}, "meta_eval_completion_cost": {"value": 0.00140416}}, "created": "2025-12-10T21:52:45.4333398Z"}
{"ref": "ragged-filet", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.538461538461538}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.25}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.22588}, "meta_inference_prompt_tokens": {"value": 6874.0}, "meta_inference_completion_tokens": {"value": 821.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0013748}, "meta_inference_completion_cost": {"value": 0.0013136}, "meta_eval_time": {"value": 20.541}, "meta_eval_prompt_tokens": {"value": 3531.0}, "meta_eval_completion_tokens": {"value": 1456.0}, "meta_eval_prompt_cost": {"value": 0.00112992}, "meta_eval_completion_cost": {"value": 0.00186368}}, "created": "2025-12-10T21:52:45.853214Z"}
{"ref": "radiant-vector", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.94845911887939}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.635349}, "meta_inference_prompt_tokens": {"value": 11291.0}, "meta_inference_completion_tokens": {"value": 932.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022582}, "meta_inference_completion_cost": {"value": 0.0014912}, "meta_eval_time": {"value": 32.985}, "meta_eval_prompt_tokens": {"value": 6449.0}, "meta_eval_completion_tokens": {"value": 3305.0}, "meta_eval_prompt_cost": {"value": 0.00206368}, "meta_eval_completion_cost": {"value": 0.0042304}}, "created": "2025-12-10T21:52:46.1554834Z"}
{"ref": "roaring-bay", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.964023}, "meta_inference_prompt_tokens": {"value": 2257.0}, "meta_inference_completion_tokens": {"value": 651.0}, "meta_inference_prompt_cost": {"value": 0.0004514}, "meta_inference_completion_cost": {"value": 0.0010416}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:46.1916293Z"}
{"ref": "rank-dolcetto-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.579710144927536}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 13.411402}, "meta_inference_prompt_tokens": {"value": 11456.0}, "meta_inference_completion_tokens": {"value": 578.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022912}, "meta_inference_completion_cost": {"value": 0.0009248}, "meta_eval_time": {"value": 19.825}, "meta_eval_prompt_tokens": {"value": 6693.0}, "meta_eval_completion_tokens": {"value": 1733.0}, "meta_eval_prompt_cost": {"value": 0.00214176}, "meta_eval_completion_cost": {"value": 0.00221824}}, "created": "2025-12-10T21:52:46.8891439Z"}
{"ref": "roaring-bay", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.04761}, "meta_inference_prompt_tokens": {"value": 2257.0}, "meta_inference_completion_tokens": {"value": 658.0}, "meta_inference_prompt_cost": {"value": 0.0004514}, "meta_inference_completion_cost": {"value": 0.0010528}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:46.9279662Z"}
{"ref": "rancid-insulation", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.265854}, "meta_inference_prompt_tokens": {"value": 16792.0}, "meta_inference_completion_tokens": {"value": 1265.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0033584}, "meta_inference_completion_cost": {"value": 0.002024}, "meta_eval_time": {"value": 27.218}, "meta_eval_prompt_tokens": {"value": 11543.0}, "meta_eval_completion_tokens": {"value": 2803.0}, "meta_eval_prompt_cost": {"value": 0.00369376}, "meta_eval_completion_cost": {"value": 0.00358784}}, "created": "2025-12-10T21:52:47.7326507Z"}
{"ref": "roaring-bay", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.05747}, "meta_inference_prompt_tokens": {"value": 14366.0}, "meta_inference_completion_tokens": {"value": 1776.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028732}, "meta_inference_completion_cost": {"value": 0.0028416}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:47.7675334Z"}
{"ref": "salmon-venison", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.896494}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 521.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0008336}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:47.8038075Z"}
{"ref": "rancid-insulation", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.931034482758621}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.565362}, "meta_inference_prompt_tokens": {"value": 16315.0}, "meta_inference_completion_tokens": {"value": 1326.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003263}, "meta_inference_completion_cost": {"value": 0.0021216}, "meta_eval_time": {"value": 32.158}, "meta_eval_prompt_tokens": {"value": 10940.0}, "meta_eval_completion_tokens": {"value": 3013.0}, "meta_eval_prompt_cost": {"value": 0.0035008}, "meta_eval_completion_cost": {"value": 0.00385664}}, "created": "2025-12-10T21:52:49.903522Z"}
{"ref": "rainy-bogey", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 26.159309}, "meta_inference_prompt_tokens": {"value": 11045.0}, "meta_inference_completion_tokens": {"value": 1588.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002209}, "meta_inference_completion_cost": {"value": 0.0025408}, "meta_eval_time": {"value": 32.41}, "meta_eval_prompt_tokens": {"value": 6750.0}, "meta_eval_completion_tokens": {"value": 2818.0}, "meta_eval_prompt_cost": {"value": 0.00216}, "meta_eval_completion_cost": {"value": 0.00360704}}, "created": "2025-12-10T21:52:50.2895935Z"}
{"ref": "prompt-poset", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.44845911887939}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.865979381443299}, "generation_factuality_precision": {"value": 0.875}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 25.096926}, "meta_inference_prompt_tokens": {"value": 11199.0}, "meta_inference_completion_tokens": {"value": 1333.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022398}, "meta_inference_completion_cost": {"value": 0.0021328}, "meta_eval_time": {"value": 42.452}, "meta_eval_prompt_tokens": {"value": 7908.0}, "meta_eval_completion_tokens": {"value": 4128.0}, "meta_eval_prompt_cost": {"value": 0.00253056}, "meta_eval_completion_cost": {"value": 0.00528384}}, "created": "2025-12-10T21:52:50.81Z"}
{"ref": "roaring-bay", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.564176}, "meta_inference_prompt_tokens": {"value": 2257.0}, "meta_inference_completion_tokens": {"value": 658.0}, "meta_inference_prompt_cost": {"value": 0.0004514}, "meta_inference_completion_cost": {"value": 0.0010528}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:50.8459107Z"}
{"ref": "salmon-venison", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.226377}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 774.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0012384}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:50.8855743Z"}
{"ref": "rancid-insulation", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.863636363636364}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 47.088988}, "meta_inference_prompt_tokens": {"value": 16242.0}, "meta_inference_completion_tokens": {"value": 1000.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032484}, "meta_inference_completion_cost": {"value": 0.0016}, "meta_eval_time": {"value": 26.039}, "meta_eval_prompt_tokens": {"value": 10459.0}, "meta_eval_completion_tokens": {"value": 2402.0}, "meta_eval_prompt_cost": {"value": 0.00334688}, "meta_eval_completion_cost": {"value": 0.00307456}}, "created": "2025-12-10T21:52:50.9634596Z"}
{"ref": "salmon-venison", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.530851}, "meta_inference_prompt_tokens": {"value": 8831.0}, "meta_inference_completion_tokens": {"value": 1263.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0017662}, "meta_inference_completion_cost": {"value": 0.0020208}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:50.9977361Z"}
{"ref": "rank-dolcetto-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.625}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 17.780201}, "meta_inference_prompt_tokens": {"value": 11055.0}, "meta_inference_completion_tokens": {"value": 647.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002211}, "meta_inference_completion_cost": {"value": 0.0010352}, "meta_eval_time": {"value": 19.119}, "meta_eval_prompt_tokens": {"value": 6280.0}, "meta_eval_completion_tokens": {"value": 1715.0}, "meta_eval_prompt_cost": {"value": 0.0020096}, "meta_eval_completion_cost": {"value": 0.0021952}}, "created": "2025-12-10T21:52:51.8664033Z"}
{"ref": "salmon-venison", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.297525}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 595.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.000952}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:51.9026647Z"}
{"ref": "rank-dolcetto-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 20.176323}, "meta_inference_prompt_tokens": {"value": 11086.0}, "meta_inference_completion_tokens": {"value": 1013.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022172}, "meta_inference_completion_cost": {"value": 0.0016208}, "meta_eval_time": {"value": 25.61}, "meta_eval_prompt_tokens": {"value": 6739.0}, "meta_eval_completion_tokens": {"value": 2278.0}, "meta_eval_prompt_cost": {"value": 0.00215648}, "meta_eval_completion_cost": {"value": 0.00291584}}, "created": "2025-12-10T21:52:53.8860094Z"}
{"ref": "rapid-bookcase", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.974758}, "meta_inference_prompt_tokens": {"value": 10962.0}, "meta_inference_completion_tokens": {"value": 943.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021924}, "meta_inference_completion_cost": {"value": 0.0015088}, "meta_eval_time": {"value": 18.321}, "meta_eval_prompt_tokens": {"value": 5807.0}, "meta_eval_completion_tokens": {"value": 1616.0}, "meta_eval_prompt_cost": {"value": 0.00185824}, "meta_eval_completion_cost": {"value": 0.00206848}}, "created": "2025-12-10T21:52:54.8749403Z"}
{"ref": "rapid-bookcase", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.517014}, "meta_inference_prompt_tokens": {"value": 10283.0}, "meta_inference_completion_tokens": {"value": 923.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020566}, "meta_inference_completion_cost": {"value": 0.0014768}, "meta_eval_time": {"value": 21.316}, "meta_eval_prompt_tokens": {"value": 5291.0}, "meta_eval_completion_tokens": {"value": 1931.0}, "meta_eval_prompt_cost": {"value": 0.00169312}, "meta_eval_completion_cost": {"value": 0.00247168}}, "created": "2025-12-10T21:52:55.1996756Z"}
{"ref": "regular-cape", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.874764}, "meta_inference_prompt_tokens": {"value": 10384.0}, "meta_inference_completion_tokens": {"value": 1457.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020768}, "meta_inference_completion_cost": {"value": 0.0023312}, "meta_eval_time": {"value": 23.239}, "meta_eval_prompt_tokens": {"value": 5662.0}, "meta_eval_completion_tokens": {"value": 2076.0}, "meta_eval_prompt_cost": {"value": 0.00181184}, "meta_eval_completion_cost": {"value": 0.00265728}}, "created": "2025-12-10T21:52:55.9396323Z"}
{"ref": "rectilinear-zipper", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 17.998628}, "meta_inference_prompt_tokens": {"value": 9869.0}, "meta_inference_completion_tokens": {"value": 872.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019738}, "meta_inference_completion_cost": {"value": 0.0013952}, "meta_eval_time": {"value": 21.04}, "meta_eval_prompt_tokens": {"value": 4898.0}, "meta_eval_completion_tokens": {"value": 2024.0}, "meta_eval_prompt_cost": {"value": 0.00156736}, "meta_eval_completion_cost": {"value": 0.00259072}}, "created": "2025-12-10T21:52:56.3124857Z"}
{"ref": "rapid-bookcase", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.958333333333334}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.136744}, "meta_inference_prompt_tokens": {"value": 10725.0}, "meta_inference_completion_tokens": {"value": 1138.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002145}, "meta_inference_completion_cost": {"value": 0.0018208}, "meta_eval_time": {"value": 25.853}, "meta_eval_prompt_tokens": {"value": 5952.0}, "meta_eval_completion_tokens": {"value": 2263.0}, "meta_eval_prompt_cost": {"value": 0.00190464}, "meta_eval_completion_cost": {"value": 0.00289664}}, "created": "2025-12-10T21:52:56.3885694Z"}
{"ref": "rank-dolcetto-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 15.254459}, "meta_inference_prompt_tokens": {"value": 11101.0}, "meta_inference_completion_tokens": {"value": 879.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022202}, "meta_inference_completion_cost": {"value": 0.0014064}, "meta_eval_time": {"value": 22.596}, "meta_eval_prompt_tokens": {"value": 6460.0}, "meta_eval_completion_tokens": {"value": 2047.0}, "meta_eval_prompt_cost": {"value": 0.0020672}, "meta_eval_completion_cost": {"value": 0.00262016}}, "created": "2025-12-10T21:52:56.5096802Z"}
{"ref": "rancid-insulation", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.970588235294118}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.727826}, "meta_inference_prompt_tokens": {"value": 16549.0}, "meta_inference_completion_tokens": {"value": 1252.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0033098}, "meta_inference_completion_cost": {"value": 0.0020032}, "meta_eval_time": {"value": 35.126}, "meta_eval_prompt_tokens": {"value": 11078.0}, "meta_eval_completion_tokens": {"value": 3359.0}, "meta_eval_prompt_cost": {"value": 0.00354496}, "meta_eval_completion_cost": {"value": 0.00429952}}, "created": "2025-12-10T21:52:57.7786252Z"}
{"ref": "regular-cape", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.82891}, "meta_inference_prompt_tokens": {"value": 10940.0}, "meta_inference_completion_tokens": {"value": 1468.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002188}, "meta_inference_completion_cost": {"value": 0.0023488}, "meta_eval_time": {"value": 18.957}, "meta_eval_prompt_tokens": {"value": 5883.0}, "meta_eval_completion_tokens": {"value": 1652.0}, "meta_eval_prompt_cost": {"value": 0.00188256}, "meta_eval_completion_cost": {"value": 0.00211456}}, "created": "2025-12-10T21:52:57.9300246Z"}
{"ref": "regular-cape", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.244650542118226}, "generation_faithfulness": {"value": 0.882352941176471}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.05}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 37.122139}, "meta_inference_prompt_tokens": {"value": 23893.0}, "meta_inference_completion_tokens": {"value": 1764.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0047786}, "meta_inference_completion_cost": {"value": 0.0028224}, "meta_eval_time": {"value": 21.672}, "meta_eval_prompt_tokens": {"value": 7844.0}, "meta_eval_completion_tokens": {"value": 1946.0}, "meta_eval_prompt_cost": {"value": 0.00251008}, "meta_eval_completion_cost": {"value": 0.00249088}}, "created": "2025-12-10T21:52:58.568922Z"}
{"ref": "right-formant-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.28906482631789}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.895526}, "meta_inference_prompt_tokens": {"value": 11138.0}, "meta_inference_completion_tokens": {"value": 665.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022276}, "meta_inference_completion_cost": {"value": 0.001064}, "meta_eval_time": {"value": 22.411}, "meta_eval_prompt_tokens": {"value": 6384.0}, "meta_eval_completion_tokens": {"value": 2080.0}, "meta_eval_prompt_cost": {"value": 0.00204288}, "meta_eval_completion_cost": {"value": 0.0026624}}, "created": "2025-12-10T21:52:59.5059347Z"}
{"ref": "salmon-venison", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 7.959573}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 323.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0005168}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:52:59.5428045Z"}
{"ref": "rectilinear-zipper", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.210526315789474}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 20.822305}, "meta_inference_prompt_tokens": {"value": 10808.0}, "meta_inference_completion_tokens": {"value": 1084.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021616}, "meta_inference_completion_cost": {"value": 0.0017344}, "meta_eval_time": {"value": 28.174}, "meta_eval_prompt_tokens": {"value": 6173.0}, "meta_eval_completion_tokens": {"value": 2737.0}, "meta_eval_prompt_cost": {"value": 0.00197536}, "meta_eval_completion_cost": {"value": 0.00350336}}, "created": "2025-12-10T21:53:00.3948458Z"}
{"ref": "right-formant-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.875}, "generation_factuality_precision": {"value": 0.777777777777778}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.533248}, "meta_inference_prompt_tokens": {"value": 10829.0}, "meta_inference_completion_tokens": {"value": 588.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021658}, "meta_inference_completion_cost": {"value": 0.0009408}, "meta_eval_time": {"value": 21.385}, "meta_eval_prompt_tokens": {"value": 5951.0}, "meta_eval_completion_tokens": {"value": 1880.0}, "meta_eval_prompt_cost": {"value": 0.00190432}, "meta_eval_completion_cost": {"value": 0.0024064}}, "created": "2025-12-10T21:53:00.8687682Z"}
{"ref": "rainy-bogey", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.933333333333333}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.875}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.875}, "meta_inference_time": {"value": 31.401118}, "meta_inference_prompt_tokens": {"value": 11444.0}, "meta_inference_completion_tokens": {"value": 1682.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022888}, "meta_inference_completion_cost": {"value": 0.0026912}, "meta_eval_time": {"value": 40.256}, "meta_eval_prompt_tokens": {"value": 7767.0}, "meta_eval_completion_tokens": {"value": 3783.0}, "meta_eval_prompt_cost": {"value": 0.00248544}, "meta_eval_completion_cost": {"value": 0.00484224}}, "created": "2025-12-10T21:53:03.6468037Z"}
{"ref": "right-formant-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.518868}, "meta_inference_prompt_tokens": {"value": 11001.0}, "meta_inference_completion_tokens": {"value": 756.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022002}, "meta_inference_completion_cost": {"value": 0.0012096}, "meta_eval_time": {"value": 19.075}, "meta_eval_prompt_tokens": {"value": 6093.0}, "meta_eval_completion_tokens": {"value": 1921.0}, "meta_eval_prompt_cost": {"value": 0.00194976}, "meta_eval_completion_cost": {"value": 0.00245888}}, "created": "2025-12-10T21:53:03.6684812Z"}
{"ref": "right-formant-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.944444444444444}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.297753}, "meta_inference_prompt_tokens": {"value": 10669.0}, "meta_inference_completion_tokens": {"value": 629.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021338}, "meta_inference_completion_cost": {"value": 0.0010064}, "meta_eval_time": {"value": 21.808}, "meta_eval_prompt_tokens": {"value": 5696.0}, "meta_eval_completion_tokens": {"value": 1890.0}, "meta_eval_prompt_cost": {"value": 0.00182272}, "meta_eval_completion_cost": {"value": 0.0024192}}, "created": "2025-12-10T21:53:03.8686233Z"}
{"ref": "rectilinear-zipper", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.249095}, "meta_inference_prompt_tokens": {"value": 10861.0}, "meta_inference_completion_tokens": {"value": 1154.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021722}, "meta_inference_completion_cost": {"value": 0.0018464}, "meta_eval_time": {"value": 29.453}, "meta_eval_prompt_tokens": {"value": 5997.0}, "meta_eval_completion_tokens": {"value": 2398.0}, "meta_eval_prompt_cost": {"value": 0.00191904}, "meta_eval_completion_cost": {"value": 0.00306944}}, "created": "2025-12-10T21:53:04.2714422Z"}
{"ref": "regular-cape", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 30.604359}, "meta_inference_prompt_tokens": {"value": 11766.0}, "meta_inference_completion_tokens": {"value": 2044.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023532}, "meta_inference_completion_cost": {"value": 0.0032704}, "meta_eval_time": {"value": 27.122}, "meta_eval_prompt_tokens": {"value": 7089.0}, "meta_eval_completion_tokens": {"value": 2317.0}, "meta_eval_prompt_cost": {"value": 0.00226848}, "meta_eval_completion_cost": {"value": 0.00296576}}, "created": "2025-12-10T21:53:04.6310966Z"}
{"ref": "rancid-insulation", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 51.342106}, "meta_inference_prompt_tokens": {"value": 17614.0}, "meta_inference_completion_tokens": {"value": 1443.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0035228}, "meta_inference_completion_cost": {"value": 0.0023088}, "meta_eval_time": {"value": 38.406}, "meta_eval_prompt_tokens": {"value": 12730.0}, "meta_eval_completion_tokens": {"value": 3526.0}, "meta_eval_prompt_cost": {"value": 0.0040736}, "meta_eval_completion_cost": {"value": 0.00451328}}, "created": "2025-12-10T21:53:04.92735Z"}
{"ref": "rainy-bogey", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.938775510204082}, "generation_factuality_f1": {"value": 0.807692307692308}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 0.875}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.875}, "meta_inference_time": {"value": 28.572613}, "meta_inference_prompt_tokens": {"value": 11133.0}, "meta_inference_completion_tokens": {"value": 1550.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022266}, "meta_inference_completion_cost": {"value": 0.00248}, "meta_eval_time": {"value": 44.388}, "meta_eval_prompt_tokens": {"value": 7205.0}, "meta_eval_completion_tokens": {"value": 4077.0}, "meta_eval_prompt_cost": {"value": 0.0023056}, "meta_eval_completion_cost": {"value": 0.00521856}}, "created": "2025-12-10T21:53:06.0865015Z"}
{"ref": "seething-gofer-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.953235}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 797.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0012752}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:06.1236487Z"}
{"ref": "seething-gofer-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.503738}, "meta_inference_prompt_tokens": {"value": 4642.0}, "meta_inference_completion_tokens": {"value": 1060.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009284}, "meta_inference_completion_cost": {"value": 0.001696}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:06.1574172Z"}
{"ref": "seething-gofer-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.072309}, "meta_inference_prompt_tokens": {"value": 5368.0}, "meta_inference_completion_tokens": {"value": 1186.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0010736}, "meta_inference_completion_cost": {"value": 0.0018976}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:06.1947093Z"}
{"ref": "salty-accrual", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.895985}, "meta_inference_prompt_tokens": {"value": 12213.0}, "meta_inference_completion_tokens": {"value": 844.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024426}, "meta_inference_completion_cost": {"value": 0.0013504}, "meta_eval_time": {"value": 8.584}, "meta_eval_prompt_tokens": {"value": 6132.0}, "meta_eval_completion_tokens": {"value": 554.0}, "meta_eval_prompt_cost": {"value": 0.00196224}, "meta_eval_completion_cost": {"value": 0.00070912}}, "created": "2025-12-10T21:53:06.549741Z"}
{"ref": "seething-gofer-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.231197}, "meta_inference_prompt_tokens": {"value": 4634.0}, "meta_inference_completion_tokens": {"value": 1327.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009268}, "meta_inference_completion_cost": {"value": 0.0021232}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:06.5866777Z"}
{"ref": "salty-accrual", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.727272727272727}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.702553}, "meta_inference_prompt_tokens": {"value": 11957.0}, "meta_inference_completion_tokens": {"value": 1308.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023914}, "meta_inference_completion_cost": {"value": 0.0020928}, "meta_eval_time": {"value": 14.843}, "meta_eval_prompt_tokens": {"value": 6535.0}, "meta_eval_completion_tokens": {"value": 1360.0}, "meta_eval_prompt_cost": {"value": 0.0020912}, "meta_eval_completion_cost": {"value": 0.0017408}}, "created": "2025-12-10T21:53:06.7790499Z"}
{"ref": "rapid-bookcase", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.772915}, "meta_inference_prompt_tokens": {"value": 10839.0}, "meta_inference_completion_tokens": {"value": 1261.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021678}, "meta_inference_completion_cost": {"value": 0.0020176}, "meta_eval_time": {"value": 33.899}, "meta_eval_prompt_tokens": {"value": 6545.0}, "meta_eval_completion_tokens": {"value": 3050.0}, "meta_eval_prompt_cost": {"value": 0.0020944}, "meta_eval_completion_cost": {"value": 0.003904}}, "created": "2025-12-10T21:53:06.8092711Z"}
{"ref": "shabby-atlas", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 8.585174}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 386.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0006176}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:06.8140261Z"}
{"ref": "shabby-atlas", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.051617}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 587.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0009392}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:06.8473157Z"}
{"ref": "shabby-atlas", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.617237}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 719.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0011504}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:06.8581714Z"}
{"ref": "shabby-atlas", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.252046}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 435.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.000696}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:06.8865305Z"}
{"ref": "rank-dolcetto-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.540540540540541}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 19.902274}, "meta_inference_prompt_tokens": {"value": 11077.0}, "meta_inference_completion_tokens": {"value": 982.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022154}, "meta_inference_completion_cost": {"value": 0.0015712}, "meta_eval_time": {"value": 32.867}, "meta_eval_prompt_tokens": {"value": 6737.0}, "meta_eval_completion_tokens": {"value": 2727.0}, "meta_eval_prompt_cost": {"value": 0.00215584}, "meta_eval_completion_cost": {"value": 0.00349056}}, "created": "2025-12-10T21:53:07.4618694Z"}
{"ref": "rectilinear-zipper", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.801029995663981}, "generation_faithfulness": {"value": 0.962962962962963}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.613542}, "meta_inference_prompt_tokens": {"value": 10292.0}, "meta_inference_completion_tokens": {"value": 1296.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020584}, "meta_inference_completion_cost": {"value": 0.0020736}, "meta_eval_time": {"value": 32.838}, "meta_eval_prompt_tokens": {"value": 5694.0}, "meta_eval_completion_tokens": {"value": 2902.0}, "meta_eval_prompt_cost": {"value": 0.00182208}, "meta_eval_completion_cost": {"value": 0.00371456}}, "created": "2025-12-10T21:53:07.5954883Z"}
{"ref": "shabby-atlas", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.118522}, "meta_inference_prompt_tokens": {"value": 2251.0}, "meta_inference_completion_tokens": {"value": 508.0}, "meta_inference_prompt_cost": {"value": 0.0004502}, "meta_inference_completion_cost": {"value": 0.0008128}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:07.6357664Z"}
{"ref": "regular-cape", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.967741935483871}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 30.193474}, "meta_inference_prompt_tokens": {"value": 11191.0}, "meta_inference_completion_tokens": {"value": 1724.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022382}, "meta_inference_completion_cost": {"value": 0.0027584}, "meta_eval_time": {"value": 32.543}, "meta_eval_prompt_tokens": {"value": 6951.0}, "meta_eval_completion_tokens": {"value": 3113.0}, "meta_eval_prompt_cost": {"value": 0.00222432}, "meta_eval_completion_cost": {"value": 0.00398464}}, "created": "2025-12-10T21:53:08.3557708Z"}
{"ref": "salty-accrual", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.587971}, "meta_inference_prompt_tokens": {"value": 11078.0}, "meta_inference_completion_tokens": {"value": 916.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022156}, "meta_inference_completion_cost": {"value": 0.0014656}, "meta_eval_time": {"value": 12.46}, "meta_eval_prompt_tokens": {"value": 5382.0}, "meta_eval_completion_tokens": {"value": 1046.0}, "meta_eval_prompt_cost": {"value": 0.00172224}, "meta_eval_completion_cost": {"value": 0.00133888}}, "created": "2025-12-10T21:53:09.0101221Z"}
{"ref": "rectilinear-zipper", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.886852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.820063}, "meta_inference_prompt_tokens": {"value": 11608.0}, "meta_inference_completion_tokens": {"value": 1457.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023216}, "meta_inference_completion_cost": {"value": 0.0023312}, "meta_eval_time": {"value": 32.3}, "meta_eval_prompt_tokens": {"value": 6937.0}, "meta_eval_completion_tokens": {"value": 2744.0}, "meta_eval_prompt_cost": {"value": 0.00221984}, "meta_eval_completion_cost": {"value": 0.00351232}}, "created": "2025-12-10T21:53:09.0219156Z"}
{"ref": "rainy-bogey", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.881889763779528}, "generation_factuality_precision": {"value": 0.888888888888889}, "generation_factuality_recall": {"value": 0.875}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.875}, "meta_inference_time": {"value": 35.667209}, "meta_inference_prompt_tokens": {"value": 11164.0}, "meta_inference_completion_tokens": {"value": 1348.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022328}, "meta_inference_completion_cost": {"value": 0.0021568}, "meta_eval_time": {"value": 48.098}, "meta_eval_prompt_tokens": {"value": 7607.0}, "meta_eval_completion_tokens": {"value": 4387.0}, "meta_eval_prompt_cost": {"value": 0.00243424}, "meta_eval_completion_cost": {"value": 0.00561536}}, "created": "2025-12-10T21:53:10.8748582Z"}
{"ref": "rounded-align", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.956521739130435}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.659572}, "meta_inference_prompt_tokens": {"value": 10266.0}, "meta_inference_completion_tokens": {"value": 1425.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020532}, "meta_inference_completion_cost": {"value": 0.00228}, "meta_eval_time": {"value": 23.131}, "meta_eval_prompt_tokens": {"value": 5399.0}, "meta_eval_completion_tokens": {"value": 2182.0}, "meta_eval_prompt_cost": {"value": 0.00172768}, "meta_eval_completion_cost": {"value": 0.00279296}}, "created": "2025-12-10T21:53:10.9692854Z"}
{"ref": "salty-accrual", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.636363636363636}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.521748}, "meta_inference_prompt_tokens": {"value": 12105.0}, "meta_inference_completion_tokens": {"value": 1397.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002421}, "meta_inference_completion_cost": {"value": 0.0022352}, "meta_eval_time": {"value": 16.164}, "meta_eval_prompt_tokens": {"value": 6451.0}, "meta_eval_completion_tokens": {"value": 1376.0}, "meta_eval_prompt_cost": {"value": 0.00206432}, "meta_eval_completion_cost": {"value": 0.00176128}}, "created": "2025-12-10T21:53:11.0827792Z"}
{"ref": "right-formant-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.328102}, "meta_inference_prompt_tokens": {"value": 10480.0}, "meta_inference_completion_tokens": {"value": 667.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002096}, "meta_inference_completion_cost": {"value": 0.0010672}, "meta_eval_time": {"value": 21.535}, "meta_eval_prompt_tokens": {"value": 5815.0}, "meta_eval_completion_tokens": {"value": 2172.0}, "meta_eval_prompt_cost": {"value": 0.0018608}, "meta_eval_completion_cost": {"value": 0.00278016}}, "created": "2025-12-10T21:53:12.5647946Z"}
{"ref": "rainy-bogey", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.88677}, "meta_inference_prompt_tokens": {"value": 11099.0}, "meta_inference_completion_tokens": {"value": 1616.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022198}, "meta_inference_completion_cost": {"value": 0.0025856}, "meta_eval_time": {"value": 51.987}, "meta_eval_prompt_tokens": {"value": 7550.0}, "meta_eval_completion_tokens": {"value": 3698.0}, "meta_eval_prompt_cost": {"value": 0.002416}, "meta_eval_completion_cost": {"value": 0.00473344}}, "created": "2025-12-10T21:53:12.7067624Z"}
{"ref": "rounded-align", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 0.954545454545454}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.038639}, "meta_inference_prompt_tokens": {"value": 12562.0}, "meta_inference_completion_tokens": {"value": 1442.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025124}, "meta_inference_completion_cost": {"value": 0.0023072}, "meta_eval_time": {"value": 28.574}, "meta_eval_prompt_tokens": {"value": 7720.0}, "meta_eval_completion_tokens": {"value": 2418.0}, "meta_eval_prompt_cost": {"value": 0.0024704}, "meta_eval_completion_cost": {"value": 0.00309504}}, "created": "2025-12-10T21:53:14.4652291Z"}
{"ref": "salty-stew-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.008513}, "meta_inference_prompt_tokens": {"value": 11049.0}, "meta_inference_completion_tokens": {"value": 825.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022098}, "meta_inference_completion_cost": {"value": 0.00132}, "meta_eval_time": {"value": 23.04}, "meta_eval_prompt_tokens": {"value": 6301.0}, "meta_eval_completion_tokens": {"value": 2040.0}, "meta_eval_prompt_cost": {"value": 0.00201632}, "meta_eval_completion_cost": {"value": 0.0026112}}, "created": "2025-12-10T21:53:18.2755086Z"}
{"ref": "salty-stew-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.389599}, "meta_inference_prompt_tokens": {"value": 11049.0}, "meta_inference_completion_tokens": {"value": 880.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022098}, "meta_inference_completion_cost": {"value": 0.001408}, "meta_eval_time": {"value": 24.903}, "meta_eval_prompt_tokens": {"value": 6377.0}, "meta_eval_completion_tokens": {"value": 2244.0}, "meta_eval_prompt_cost": {"value": 0.00204064}, "meta_eval_completion_cost": {"value": 0.00287232}}, "created": "2025-12-10T21:53:18.8287101Z"}
{"ref": "rounded-align", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.88427}, "meta_inference_prompt_tokens": {"value": 13318.0}, "meta_inference_completion_tokens": {"value": 1799.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026636}, "meta_inference_completion_cost": {"value": 0.0028784}, "meta_eval_time": {"value": 28.901}, "meta_eval_prompt_tokens": {"value": 8743.0}, "meta_eval_completion_tokens": {"value": 2608.0}, "meta_eval_prompt_cost": {"value": 0.00279776}, "meta_eval_completion_cost": {"value": 0.00333824}}, "created": "2025-12-10T21:53:18.8437683Z"}
{"ref": "right-gulf", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.44639463035719}, "generation_faithfulness": {"value": 0.903225806451613}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.65951}, "meta_inference_prompt_tokens": {"value": 11266.0}, "meta_inference_completion_tokens": {"value": 1681.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022532}, "meta_inference_completion_cost": {"value": 0.0026896}, "meta_eval_time": {"value": 35.378}, "meta_eval_prompt_tokens": {"value": 7442.0}, "meta_eval_completion_tokens": {"value": 3570.0}, "meta_eval_prompt_cost": {"value": 0.00238144}, "meta_eval_completion_cost": {"value": 0.0045696}}, "created": "2025-12-10T21:53:20.8487183Z"}
{"ref": "sienna-radiator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.166666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.916964}, "meta_inference_prompt_tokens": {"value": 8333.0}, "meta_inference_completion_tokens": {"value": 754.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0016666}, "meta_inference_completion_cost": {"value": 0.0012064}, "meta_eval_time": {"value": 10.278}, "meta_eval_prompt_tokens": {"value": 3983.0}, "meta_eval_completion_tokens": {"value": 885.0}, "meta_eval_prompt_cost": {"value": 0.00127456}, "meta_eval_completion_cost": {"value": 0.0011328}}, "created": "2025-12-10T21:53:21.3985707Z"}
{"ref": "salty-accrual", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.921992}, "meta_inference_prompt_tokens": {"value": 11078.0}, "meta_inference_completion_tokens": {"value": 1052.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022156}, "meta_inference_completion_cost": {"value": 0.0016832}, "meta_eval_time": {"value": 19.302}, "meta_eval_prompt_tokens": {"value": 5656.0}, "meta_eval_completion_tokens": {"value": 1644.0}, "meta_eval_prompt_cost": {"value": 0.00180992}, "meta_eval_completion_cost": {"value": 0.00210432}}, "created": "2025-12-10T21:53:22.9863628Z"}
{"ref": "savage-pot", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.689744}, "meta_inference_prompt_tokens": {"value": 10748.0}, "meta_inference_completion_tokens": {"value": 870.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021496}, "meta_inference_completion_cost": {"value": 0.001392}, "meta_eval_time": {"value": 23.312}, "meta_eval_prompt_tokens": {"value": 5794.0}, "meta_eval_completion_tokens": {"value": 2223.0}, "meta_eval_prompt_cost": {"value": 0.00185408}, "meta_eval_completion_cost": {"value": 0.00284544}}, "created": "2025-12-10T21:53:23.7417423Z"}
{"ref": "right-gulf", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.893083}, "meta_inference_prompt_tokens": {"value": 11771.0}, "meta_inference_completion_tokens": {"value": 1726.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023542}, "meta_inference_completion_cost": {"value": 0.0027616}, "meta_eval_time": {"value": 43.647}, "meta_eval_prompt_tokens": {"value": 8494.0}, "meta_eval_completion_tokens": {"value": 4124.0}, "meta_eval_prompt_cost": {"value": 0.00271808}, "meta_eval_completion_cost": {"value": 0.00527872}}, "created": "2025-12-10T21:53:24.5831604Z"}
{"ref": "saucy-sky", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.764278}, "meta_inference_prompt_tokens": {"value": 11730.0}, "meta_inference_completion_tokens": {"value": 905.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002346}, "meta_inference_completion_cost": {"value": 0.001448}, "meta_eval_time": {"value": 29.102}, "meta_eval_prompt_tokens": {"value": 6627.0}, "meta_eval_completion_tokens": {"value": 2869.0}, "meta_eval_prompt_cost": {"value": 0.00212064}, "meta_eval_completion_cost": {"value": 0.00367232}}, "created": "2025-12-10T21:53:25.0766647Z"}
{"ref": "rounded-align", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.205823}, "meta_inference_prompt_tokens": {"value": 11845.0}, "meta_inference_completion_tokens": {"value": 2356.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002369}, "meta_inference_completion_cost": {"value": 0.0037696}, "meta_eval_time": {"value": 34.985}, "meta_eval_prompt_tokens": {"value": 7705.0}, "meta_eval_completion_tokens": {"value": 3362.0}, "meta_eval_prompt_cost": {"value": 0.0024656}, "meta_eval_completion_cost": {"value": 0.00430336}}, "created": "2025-12-10T21:53:25.3110047Z"}
{"ref": "sizzling-fractal", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.683926}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 507.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0008112}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:25.3740061Z"}
{"ref": "savage-pot", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.58063}, "meta_inference_prompt_tokens": {"value": 14569.0}, "meta_inference_completion_tokens": {"value": 862.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029138}, "meta_inference_completion_cost": {"value": 0.0013792}, "meta_eval_time": {"value": 28.38}, "meta_eval_prompt_tokens": {"value": 9842.0}, "meta_eval_completion_tokens": {"value": 2916.0}, "meta_eval_prompt_cost": {"value": 0.00314944}, "meta_eval_completion_cost": {"value": 0.00373248}}, "created": "2025-12-10T21:53:26.1950496Z"}
{"ref": "sizzling-fractal", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.028396}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 515.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.000824}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:26.2298045Z"}
{"ref": "sizzling-fractal", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.397117}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 443.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0007088}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:26.2656245Z"}
{"ref": "skinny-chain", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.051927}, "meta_inference_prompt_tokens": {"value": 4667.0}, "meta_inference_completion_tokens": {"value": 442.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009334}, "meta_inference_completion_cost": {"value": 0.0007072}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:26.2969799Z"}
{"ref": "sizzling-fractal", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 8.393484}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 262.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0004192}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:26.3356086Z"}
{"ref": "sienna-radiator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.231797}, "meta_inference_prompt_tokens": {"value": 14273.0}, "meta_inference_completion_tokens": {"value": 816.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028546}, "meta_inference_completion_cost": {"value": 0.0013056}, "meta_eval_time": {"value": 15.523}, "meta_eval_prompt_tokens": {"value": 8768.0}, "meta_eval_completion_tokens": {"value": 1411.0}, "meta_eval_prompt_cost": {"value": 0.00280576}, "meta_eval_completion_cost": {"value": 0.00180608}}, "created": "2025-12-10T21:53:28.1470593Z"}
{"ref": "right-gulf", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.98713694067948}, "generation_faithfulness": {"value": 0.818181818181818}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.730892}, "meta_inference_prompt_tokens": {"value": 12888.0}, "meta_inference_completion_tokens": {"value": 2067.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025776}, "meta_inference_completion_cost": {"value": 0.0033072}, "meta_eval_time": {"value": 45.934}, "meta_eval_prompt_tokens": {"value": 9689.0}, "meta_eval_completion_tokens": {"value": 4492.0}, "meta_eval_prompt_cost": {"value": 0.00310048}, "meta_eval_completion_cost": {"value": 0.00574976}}, "created": "2025-12-10T21:53:28.1735864Z"}
{"ref": "skinny-chain", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.6779}, "meta_inference_prompt_tokens": {"value": 4666.0}, "meta_inference_completion_tokens": {"value": 893.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009332}, "meta_inference_completion_cost": {"value": 0.0014288}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:28.181514Z"}
{"ref": "sizzling-fractal", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.083273}, "meta_inference_prompt_tokens": {"value": 4621.0}, "meta_inference_completion_tokens": {"value": 1134.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009242}, "meta_inference_completion_cost": {"value": 0.0018144}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:28.206951Z"}
{"ref": "skinny-chain", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 11.68969}, "meta_inference_prompt_tokens": {"value": 2253.0}, "meta_inference_completion_tokens": {"value": 451.0}, "meta_inference_prompt_cost": {"value": 0.0004506}, "meta_inference_completion_cost": {"value": 0.0007216}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:28.2395604Z"}
{"ref": "sienna-mercury", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.014005}, "meta_inference_prompt_tokens": {"value": 11202.0}, "meta_inference_completion_tokens": {"value": 1090.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022404}, "meta_inference_completion_cost": {"value": 0.001744}, "meta_eval_time": {"value": 22.078}, "meta_eval_prompt_tokens": {"value": 6261.0}, "meta_eval_completion_tokens": {"value": 1962.0}, "meta_eval_prompt_cost": {"value": 0.00200352}, "meta_eval_completion_cost": {"value": 0.00251136}}, "created": "2025-12-10T21:53:28.9691652Z"}
{"ref": "sienna-radiator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.142857142857143}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.486676}, "meta_inference_prompt_tokens": {"value": 10289.0}, "meta_inference_completion_tokens": {"value": 899.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020578}, "meta_inference_completion_cost": {"value": 0.0014384}, "meta_eval_time": {"value": 19.803}, "meta_eval_prompt_tokens": {"value": 6124.0}, "meta_eval_completion_tokens": {"value": 1765.0}, "meta_eval_prompt_cost": {"value": 0.00195968}, "meta_eval_completion_cost": {"value": 0.0022592}}, "created": "2025-12-10T21:53:30.8161926Z"}
{"ref": "skinny-chain", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 15.974174}, "meta_inference_prompt_tokens": {"value": 2253.0}, "meta_inference_completion_tokens": {"value": 948.0}, "meta_inference_prompt_cost": {"value": 0.0004506}, "meta_inference_completion_cost": {"value": 0.0015168}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:30.8734884Z"}
{"ref": "sienna-radiator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.33885}, "meta_inference_prompt_tokens": {"value": 13366.0}, "meta_inference_completion_tokens": {"value": 965.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026732}, "meta_inference_completion_cost": {"value": 0.001544}, "meta_eval_time": {"value": 18.524}, "meta_eval_prompt_tokens": {"value": 8341.0}, "meta_eval_completion_tokens": {"value": 1778.0}, "meta_eval_prompt_cost": {"value": 0.00266912}, "meta_eval_completion_cost": {"value": 0.00227584}}, "created": "2025-12-10T21:53:31.2889854Z"}
{"ref": "right-gulf", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.56160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.369378}, "meta_inference_prompt_tokens": {"value": 11080.0}, "meta_inference_completion_tokens": {"value": 1409.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002216}, "meta_inference_completion_cost": {"value": 0.0022544}, "meta_eval_time": {"value": 40.629}, "meta_eval_prompt_tokens": {"value": 7496.0}, "meta_eval_completion_tokens": {"value": 3973.0}, "meta_eval_prompt_cost": {"value": 0.00239872}, "meta_eval_completion_cost": {"value": 0.00508544}}, "created": "2025-12-10T21:53:31.5489327Z"}
{"ref": "savage-pot", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.742013}, "meta_inference_prompt_tokens": {"value": 10876.0}, "meta_inference_completion_tokens": {"value": 905.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021752}, "meta_inference_completion_cost": {"value": 0.001448}, "meta_eval_time": {"value": 27.529}, "meta_eval_prompt_tokens": {"value": 6270.0}, "meta_eval_completion_tokens": {"value": 2534.0}, "meta_eval_prompt_cost": {"value": 0.0020064}, "meta_eval_completion_cost": {"value": 0.00324352}}, "created": "2025-12-10T21:53:31.8377488Z"}
{"ref": "sienna-mercury", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.993314}, "meta_inference_prompt_tokens": {"value": 11719.0}, "meta_inference_completion_tokens": {"value": 1139.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023438}, "meta_inference_completion_cost": {"value": 0.0018224}, "meta_eval_time": {"value": 23.144}, "meta_eval_prompt_tokens": {"value": 6765.0}, "meta_eval_completion_tokens": {"value": 2110.0}, "meta_eval_prompt_cost": {"value": 0.0021648}, "meta_eval_completion_cost": {"value": 0.0027008}}, "created": "2025-12-10T21:53:32.205402Z"}
{"ref": "rounded-align", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.959183673469388}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.235046}, "meta_inference_prompt_tokens": {"value": 12811.0}, "meta_inference_completion_tokens": {"value": 2076.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025622}, "meta_inference_completion_cost": {"value": 0.0033216}, "meta_eval_time": {"value": 45.361}, "meta_eval_prompt_tokens": {"value": 9399.0}, "meta_eval_completion_tokens": {"value": 4309.0}, "meta_eval_prompt_cost": {"value": 0.00300768}, "meta_eval_completion_cost": {"value": 0.00551552}}, "created": "2025-12-10T21:53:32.4721634Z"}
{"ref": "selfish-asphalt", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.133333333333333}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0714285714285714}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.2}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.368916}, "meta_inference_prompt_tokens": {"value": 12706.0}, "meta_inference_completion_tokens": {"value": 1121.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025412}, "meta_inference_completion_cost": {"value": 0.0017936}, "meta_eval_time": {"value": 25.008}, "meta_eval_prompt_tokens": {"value": 7574.0}, "meta_eval_completion_tokens": {"value": 2121.0}, "meta_eval_prompt_cost": {"value": 0.00242368}, "meta_eval_completion_cost": {"value": 0.00271488}}, "created": "2025-12-10T21:53:32.5053933Z"}
{"ref": "sluggish-weight", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 8.365296}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 320.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.000512}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:32.5397735Z"}
{"ref": "sienna-mercury", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.385282}, "meta_inference_prompt_tokens": {"value": 12580.0}, "meta_inference_completion_tokens": {"value": 1027.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002516}, "meta_inference_completion_cost": {"value": 0.0016432}, "meta_eval_time": {"value": 25.639}, "meta_eval_prompt_tokens": {"value": 7931.0}, "meta_eval_completion_tokens": {"value": 2353.0}, "meta_eval_prompt_cost": {"value": 0.00253792}, "meta_eval_completion_cost": {"value": 0.00301184}}, "created": "2025-12-10T21:53:32.5594764Z"}
{"ref": "skinny-chain", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.773141}, "meta_inference_prompt_tokens": {"value": 4671.0}, "meta_inference_completion_tokens": {"value": 1030.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009342}, "meta_inference_completion_cost": {"value": 0.001648}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:32.5712235Z"}
{"ref": "sluggish-weight", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.04521}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 582.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.0009312}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:32.6190411Z"}
{"ref": "salty-stew-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.947368421052632}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.420362}, "meta_inference_prompt_tokens": {"value": 11052.0}, "meta_inference_completion_tokens": {"value": 967.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022104}, "meta_inference_completion_cost": {"value": 0.0015472}, "meta_eval_time": {"value": 27.831}, "meta_eval_prompt_tokens": {"value": 6474.0}, "meta_eval_completion_tokens": {"value": 2708.0}, "meta_eval_prompt_cost": {"value": 0.00207168}, "meta_eval_completion_cost": {"value": 0.00346624}}, "created": "2025-12-10T21:53:32.7940181Z"}
{"ref": "selfish-asphalt", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.6}, "retrieval_dcg": {"value": 0.720186140567875}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.4}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.533015}, "meta_inference_prompt_tokens": {"value": 12603.0}, "meta_inference_completion_tokens": {"value": 1537.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025206}, "meta_inference_completion_cost": {"value": 0.0024592}, "meta_eval_time": {"value": 26.615}, "meta_eval_prompt_tokens": {"value": 7932.0}, "meta_eval_completion_tokens": {"value": 2750.0}, "meta_eval_prompt_cost": {"value": 0.00253824}, "meta_eval_completion_cost": {"value": 0.00352}}, "created": "2025-12-10T21:53:33.2373667Z"}
{"ref": "sluggish-weight", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.674756}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 385.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.000616}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:33.2802541Z"}
{"ref": "sluggish-weight", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.326332}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 512.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.0008192}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:33.3270903Z"}
{"ref": "sluggish-weight", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 7.070697}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 261.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.0004176}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:33.3615858Z"}
{"ref": "selfish-asphalt", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.566666666666667}, "retrieval_dcg": {"value": 1.48713694067948}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.933333333333333}, "generation_factuality_precision": {"value": 0.875}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.560378}, "meta_inference_prompt_tokens": {"value": 13758.0}, "meta_inference_completion_tokens": {"value": 1032.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027516}, "meta_inference_completion_cost": {"value": 0.0016512}, "meta_eval_time": {"value": 25.727}, "meta_eval_prompt_tokens": {"value": 8693.0}, "meta_eval_completion_tokens": {"value": 2456.0}, "meta_eval_prompt_cost": {"value": 0.00278176}, "meta_eval_completion_cost": {"value": 0.00314368}}, "created": "2025-12-10T21:53:33.3945344Z"}
{"ref": "smart-parallel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 18.535983}, "meta_inference_prompt_tokens": {"value": 10708.0}, "meta_inference_completion_tokens": {"value": 842.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021416}, "meta_inference_completion_cost": {"value": 0.0013472}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:33.4344511Z"}
{"ref": "salty-stew-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.459478}, "meta_inference_prompt_tokens": {"value": 11050.0}, "meta_inference_completion_tokens": {"value": 817.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00221}, "meta_inference_completion_cost": {"value": 0.0013072}, "meta_eval_time": {"value": 34.875}, "meta_eval_prompt_tokens": {"value": 6736.0}, "meta_eval_completion_tokens": {"value": 2739.0}, "meta_eval_prompt_cost": {"value": 0.00215552}, "meta_eval_completion_cost": {"value": 0.00350592}}, "created": "2025-12-10T21:53:33.4865823Z"}
{"ref": "salty-stew-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.887323943661972}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 0.875}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.875}, "meta_inference_time": {"value": 20.08522}, "meta_inference_prompt_tokens": {"value": 10916.0}, "meta_inference_completion_tokens": {"value": 1068.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021832}, "meta_inference_completion_cost": {"value": 0.0017088}, "meta_eval_time": {"value": 37.759}, "meta_eval_prompt_tokens": {"value": 6741.0}, "meta_eval_completion_tokens": {"value": 3624.0}, "meta_eval_prompt_cost": {"value": 0.00215712}, "meta_eval_completion_cost": {"value": 0.00463872}}, "created": "2025-12-10T21:53:34.1126855Z"}
{"ref": "savage-pot", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.938422}, "meta_inference_prompt_tokens": {"value": 11056.0}, "meta_inference_completion_tokens": {"value": 1039.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022112}, "meta_inference_completion_cost": {"value": 0.0016624}, "meta_eval_time": {"value": 33.598}, "meta_eval_prompt_tokens": {"value": 6610.0}, "meta_eval_completion_tokens": {"value": 3146.0}, "meta_eval_prompt_cost": {"value": 0.0021152}, "meta_eval_completion_cost": {"value": 0.00402688}}, "created": "2025-12-10T21:53:34.5060085Z"}
{"ref": "selfish-asphalt", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.4}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.670192}, "meta_inference_prompt_tokens": {"value": 14507.0}, "meta_inference_completion_tokens": {"value": 1236.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029014}, "meta_inference_completion_cost": {"value": 0.0019776}, "meta_eval_time": {"value": 26.548}, "meta_eval_prompt_tokens": {"value": 9396.0}, "meta_eval_completion_tokens": {"value": 2128.0}, "meta_eval_prompt_cost": {"value": 0.00300672}, "meta_eval_completion_cost": {"value": 0.00272384}}, "created": "2025-12-10T21:53:35.5933675Z"}
{"ref": "right-gulf", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.46426308690479}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.875656}, "meta_inference_prompt_tokens": {"value": 12657.0}, "meta_inference_completion_tokens": {"value": 1708.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025314}, "meta_inference_completion_cost": {"value": 0.0027328}, "meta_eval_time": {"value": 55.008}, "meta_eval_prompt_tokens": {"value": 9386.0}, "meta_eval_completion_tokens": {"value": 4618.0}, "meta_eval_prompt_cost": {"value": 0.00300352}, "meta_eval_completion_cost": {"value": 0.00591104}}, "created": "2025-12-10T21:53:36.0631359Z"}
{"ref": "sienna-mercury", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.356207187108022}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 41.498837}, "meta_inference_prompt_tokens": {"value": 12655.0}, "meta_inference_completion_tokens": {"value": 1163.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002531}, "meta_inference_completion_cost": {"value": 0.0018608}, "meta_eval_time": {"value": 25.589}, "meta_eval_prompt_tokens": {"value": 7697.0}, "meta_eval_completion_tokens": {"value": 2229.0}, "meta_eval_prompt_cost": {"value": 0.00246304}, "meta_eval_completion_cost": {"value": 0.00285312}}, "created": "2025-12-10T21:53:36.5054341Z"}
{"ref": "savage-pot", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.725356}, "meta_inference_prompt_tokens": {"value": 11479.0}, "meta_inference_completion_tokens": {"value": 1251.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022958}, "meta_inference_completion_cost": {"value": 0.0020016}, "meta_eval_time": {"value": 32.118}, "meta_eval_prompt_tokens": {"value": 6876.0}, "meta_eval_completion_tokens": {"value": 2834.0}, "meta_eval_prompt_cost": {"value": 0.00220032}, "meta_eval_completion_cost": {"value": 0.00362752}}, "created": "2025-12-10T21:53:36.7838349Z"}
{"ref": "saucy-sky", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.133333333333333}, "generation_factuality_precision": {"value": 0.0714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.507258}, "meta_inference_prompt_tokens": {"value": 12101.0}, "meta_inference_completion_tokens": {"value": 999.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024202}, "meta_inference_completion_cost": {"value": 0.0015984}, "meta_eval_time": {"value": 33.092}, "meta_eval_prompt_tokens": {"value": 7155.0}, "meta_eval_completion_tokens": {"value": 3215.0}, "meta_eval_prompt_cost": {"value": 0.0022896}, "meta_eval_completion_cost": {"value": 0.0041152}}, "created": "2025-12-10T21:53:36.7970439Z"}
{"ref": "saucy-sky", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.307692307692308}, "generation_factuality_precision": {"value": 0.181818181818182}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.991066}, "meta_inference_prompt_tokens": {"value": 12022.0}, "meta_inference_completion_tokens": {"value": 911.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024044}, "meta_inference_completion_cost": {"value": 0.0014576}, "meta_eval_time": {"value": 33.968}, "meta_eval_prompt_tokens": {"value": 6997.0}, "meta_eval_completion_tokens": {"value": 2836.0}, "meta_eval_prompt_cost": {"value": 0.00223904}, "meta_eval_completion_cost": {"value": 0.00363008}}, "created": "2025-12-10T21:53:37.8745648Z"}
{"ref": "selfish-asphalt", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.133333333333333}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0714285714285714}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.2}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.866011}, "meta_inference_prompt_tokens": {"value": 14526.0}, "meta_inference_completion_tokens": {"value": 1198.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029052}, "meta_inference_completion_cost": {"value": 0.0019168}, "meta_eval_time": {"value": 31.95}, "meta_eval_prompt_tokens": {"value": 9736.0}, "meta_eval_completion_tokens": {"value": 2662.0}, "meta_eval_prompt_cost": {"value": 0.00311552}, "meta_eval_completion_cost": {"value": 0.00340736}}, "created": "2025-12-10T21:53:38.1795787Z"}
{"ref": "skinny-height-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 14.797248}, "meta_inference_prompt_tokens": {"value": 9722.0}, "meta_inference_completion_tokens": {"value": 487.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019444}, "meta_inference_completion_cost": {"value": 0.0007792}, "meta_eval_time": {"value": 12.623}, "meta_eval_prompt_tokens": {"value": 4555.0}, "meta_eval_completion_tokens": {"value": 1253.0}, "meta_eval_prompt_cost": {"value": 0.0014576}, "meta_eval_completion_cost": {"value": 0.00160384}}, "created": "2025-12-10T21:53:38.9938252Z"}
{"ref": "skinny-height-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.777777777777778}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 19.519797}, "meta_inference_prompt_tokens": {"value": 9652.0}, "meta_inference_completion_tokens": {"value": 870.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019304}, "meta_inference_completion_cost": {"value": 0.001392}, "meta_eval_time": {"value": 13.677}, "meta_eval_prompt_tokens": {"value": 4492.0}, "meta_eval_completion_tokens": {"value": 1189.0}, "meta_eval_prompt_cost": {"value": 0.00143744}, "meta_eval_completion_cost": {"value": 0.00152192}}, "created": "2025-12-10T21:53:39.0837152Z"}
{"ref": "saucy-sky", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.127177}, "meta_inference_prompt_tokens": {"value": 11274.0}, "meta_inference_completion_tokens": {"value": 1184.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022548}, "meta_inference_completion_cost": {"value": 0.0018944}, "meta_eval_time": {"value": 39.773}, "meta_eval_prompt_tokens": {"value": 6321.0}, "meta_eval_completion_tokens": {"value": 3577.0}, "meta_eval_prompt_cost": {"value": 0.00202272}, "meta_eval_completion_cost": {"value": 0.00457856}}, "created": "2025-12-10T21:53:39.3545992Z"}
{"ref": "skinny-height-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.685714285714286}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 15.227986}, "meta_inference_prompt_tokens": {"value": 9721.0}, "meta_inference_completion_tokens": {"value": 406.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019442}, "meta_inference_completion_cost": {"value": 0.0006496}, "meta_eval_time": {"value": 11.731}, "meta_eval_prompt_tokens": {"value": 4475.0}, "meta_eval_completion_tokens": {"value": 1077.0}, "meta_eval_prompt_cost": {"value": 0.001432}, "meta_eval_completion_cost": {"value": 0.00137856}}, "created": "2025-12-10T21:53:40.0028273Z"}
{"ref": "skinny-height-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.184388}, "meta_inference_prompt_tokens": {"value": 9721.0}, "meta_inference_completion_tokens": {"value": 476.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019442}, "meta_inference_completion_cost": {"value": 0.0007616}, "meta_eval_time": {"value": 11.851}, "meta_eval_prompt_tokens": {"value": 4509.0}, "meta_eval_completion_tokens": {"value": 1107.0}, "meta_eval_prompt_cost": {"value": 0.00144288}, "meta_eval_completion_cost": {"value": 0.00141696}}, "created": "2025-12-10T21:53:40.8541777Z"}
{"ref": "sienna-mercury", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.872236}, "meta_inference_prompt_tokens": {"value": 12180.0}, "meta_inference_completion_tokens": {"value": 1368.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002436}, "meta_inference_completion_cost": {"value": 0.0021888}, "meta_eval_time": {"value": 23.372}, "meta_eval_prompt_tokens": {"value": 7420.0}, "meta_eval_completion_tokens": {"value": 2137.0}, "meta_eval_prompt_cost": {"value": 0.0023744}, "meta_eval_completion_cost": {"value": 0.00273536}}, "created": "2025-12-10T21:53:42.3135647Z"}
{"ref": "seething-gofer-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.481886}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 702.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0011232}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:53:42.3496731Z"}
{"ref": "saucy-sky", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.36097}, "meta_inference_prompt_tokens": {"value": 12100.0}, "meta_inference_completion_tokens": {"value": 1209.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00242}, "meta_inference_completion_cost": {"value": 0.0019344}, "meta_eval_time": {"value": 46.525}, "meta_eval_prompt_tokens": {"value": 7783.0}, "meta_eval_completion_tokens": {"value": 4005.0}, "meta_eval_prompt_cost": {"value": 0.00249056}, "meta_eval_completion_cost": {"value": 0.0051264}}, "created": "2025-12-10T21:53:42.948647Z"}
{"ref": "smart-parallel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.030667}, "meta_inference_prompt_tokens": {"value": 9020.0}, "meta_inference_completion_tokens": {"value": 1367.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001804}, "meta_inference_completion_cost": {"value": 0.0021872}, "meta_eval_time": {"value": 9.74}, "meta_eval_prompt_tokens": {"value": 4062.0}, "meta_eval_completion_tokens": {"value": 764.0}, "meta_eval_prompt_cost": {"value": 0.00129984}, "meta_eval_completion_cost": {"value": 0.00097792}}, "created": "2025-12-10T21:53:43.1386214Z"}
{"ref": "skinny-height-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 15.105227}, "meta_inference_prompt_tokens": {"value": 9714.0}, "meta_inference_completion_tokens": {"value": 534.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019428}, "meta_inference_completion_cost": {"value": 0.0008544}, "meta_eval_time": {"value": 11.278}, "meta_eval_prompt_tokens": {"value": 4475.0}, "meta_eval_completion_tokens": {"value": 975.0}, "meta_eval_prompt_cost": {"value": 0.001432}, "meta_eval_completion_cost": {"value": 0.001248}}, "created": "2025-12-10T21:53:43.9330636Z"}
{"ref": "sluggish-cinema", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.28906482631789}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666666}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 19.651974}, "meta_inference_prompt_tokens": {"value": 11695.0}, "meta_inference_completion_tokens": {"value": 844.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002339}, "meta_inference_completion_cost": {"value": 0.0013504}, "meta_eval_time": {"value": 12.589}, "meta_eval_prompt_tokens": {"value": 6279.0}, "meta_eval_completion_tokens": {"value": 1024.0}, "meta_eval_prompt_cost": {"value": 0.00200928}, "meta_eval_completion_cost": {"value": 0.00131072}}, "created": "2025-12-10T21:53:44.8291024Z"}
{"ref": "smart-parallel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.781983}, "meta_inference_prompt_tokens": {"value": 6111.0}, "meta_inference_completion_tokens": {"value": 1427.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0012222}, "meta_inference_completion_cost": {"value": 0.0022832}, "meta_eval_time": {"value": 11.311}, "meta_eval_prompt_tokens": {"value": 2813.0}, "meta_eval_completion_tokens": {"value": 923.0}, "meta_eval_prompt_cost": {"value": 0.00090016}, "meta_eval_completion_cost": {"value": 0.00118144}}, "created": "2025-12-10T21:53:47.8553229Z"}
{"ref": "simple-audio-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.470588235294118}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.15086269864127}, "generation_faithfulness": {"value": 0.971428571428571}, "generation_factuality_f1": {"value": 0.847058823529412}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.307692307692308}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.571428571428571}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 21.442902}, "meta_inference_prompt_tokens": {"value": 13324.0}, "meta_inference_completion_tokens": {"value": 1222.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026648}, "meta_inference_completion_cost": {"value": 0.0019552}, "meta_eval_time": {"value": 40.406}, "meta_eval_prompt_tokens": {"value": 9968.0}, "meta_eval_completion_tokens": {"value": 3538.0}, "meta_eval_prompt_cost": {"value": 0.00318976}, "meta_eval_completion_cost": {"value": 0.00452864}}, "created": "2025-12-10T21:53:48.8009567Z"}
{"ref": "smart-parallel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.61885672214522}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0625}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 48.109608}, "meta_inference_prompt_tokens": {"value": 23684.0}, "meta_inference_completion_tokens": {"value": 3027.0}, "meta_inference_tool_call_count": {"value": 3.0}, "meta_inference_prompt_cost": {"value": 0.0047368}, "meta_inference_completion_cost": {"value": 0.0048432}, "meta_eval_time": {"value": 14.692}, "meta_eval_prompt_tokens": {"value": 5564.0}, "meta_eval_completion_tokens": {"value": 1365.0}, "meta_eval_prompt_cost": {"value": 0.00178048}, "meta_eval_completion_cost": {"value": 0.0017472}}, "created": "2025-12-10T21:53:48.842305Z"}
{"ref": "sluggish-cinema", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 19.025671}, "meta_inference_prompt_tokens": {"value": 12162.0}, "meta_inference_completion_tokens": {"value": 744.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024324}, "meta_inference_completion_cost": {"value": 0.0011904}, "meta_eval_time": {"value": 16.852}, "meta_eval_prompt_tokens": {"value": 7026.0}, "meta_eval_completion_tokens": {"value": 1620.0}, "meta_eval_prompt_cost": {"value": 0.00224832}, "meta_eval_completion_cost": {"value": 0.0020736}}, "created": "2025-12-10T21:53:49.3609383Z"}
{"ref": "sienna-radiator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.846153846153846}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.166666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.138225}, "meta_inference_prompt_tokens": {"value": 9300.0}, "meta_inference_completion_tokens": {"value": 784.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00186}, "meta_inference_completion_cost": {"value": 0.0012544}, "meta_eval_time": {"value": 24.896}, "meta_eval_prompt_tokens": {"value": 5471.0}, "meta_eval_completion_tokens": {"value": 1863.0}, "meta_eval_prompt_cost": {"value": 0.00175072}, "meta_eval_completion_cost": {"value": 0.00238464}}, "created": "2025-12-10T21:53:49.5170604Z"}
{"ref": "sluggish-cinema", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.705882352941176}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 16.933668}, "meta_inference_prompt_tokens": {"value": 12144.0}, "meta_inference_completion_tokens": {"value": 745.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024288}, "meta_inference_completion_cost": {"value": 0.001192}, "meta_eval_time": {"value": 17.725}, "meta_eval_prompt_tokens": {"value": 6822.0}, "meta_eval_completion_tokens": {"value": 1407.0}, "meta_eval_prompt_cost": {"value": 0.00218304}, "meta_eval_completion_cost": {"value": 0.00180096}}, "created": "2025-12-10T21:53:50.3187342Z"}
{"ref": "sluggish-cinema", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.648648648648649}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 22.258796}, "meta_inference_prompt_tokens": {"value": 12819.0}, "meta_inference_completion_tokens": {"value": 1059.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025638}, "meta_inference_completion_cost": {"value": 0.0016944}, "meta_eval_time": {"value": 19.869}, "meta_eval_prompt_tokens": {"value": 7537.0}, "meta_eval_completion_tokens": {"value": 1500.0}, "meta_eval_prompt_cost": {"value": 0.00241184}, "meta_eval_completion_cost": {"value": 0.00192}}, "created": "2025-12-10T21:53:51.1923186Z"}
{"ref": "sluggish-cinema", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.785714285714286}, "generation_factuality_f1": {"value": 0.521739130434783}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 18.946879}, "meta_inference_prompt_tokens": {"value": 13021.0}, "meta_inference_completion_tokens": {"value": 805.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026042}, "meta_inference_completion_cost": {"value": 0.001288}, "meta_eval_time": {"value": 17.914}, "meta_eval_prompt_tokens": {"value": 7883.0}, "meta_eval_completion_tokens": {"value": 1638.0}, "meta_eval_prompt_cost": {"value": 0.00252256}, "meta_eval_completion_cost": {"value": 0.00209664}}, "created": "2025-12-10T21:53:53.5417422Z"}
{"ref": "simple-audio-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.96969696969697}, "generation_factuality_f1": {"value": 0.579710144927536}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 27.686863}, "meta_inference_prompt_tokens": {"value": 16813.0}, "meta_inference_completion_tokens": {"value": 1410.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0033626}, "meta_inference_completion_cost": {"value": 0.002256}, "meta_eval_time": {"value": 38.931}, "meta_eval_prompt_tokens": {"value": 12489.0}, "meta_eval_completion_tokens": {"value": 3431.0}, "meta_eval_prompt_cost": {"value": 0.00399648}, "meta_eval_completion_cost": {"value": 0.00439168}}, "created": "2025-12-10T21:53:57.2584114Z"}
{"ref": "smart-parallel", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0833333333333333}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.578439}, "meta_inference_prompt_tokens": {"value": 14990.0}, "meta_inference_completion_tokens": {"value": 1650.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.002998}, "meta_inference_completion_cost": {"value": 0.00264}, "meta_eval_time": {"value": 18.158}, "meta_eval_prompt_tokens": {"value": 5612.0}, "meta_eval_completion_tokens": {"value": 1323.0}, "meta_eval_prompt_cost": {"value": 0.00179584}, "meta_eval_completion_cost": {"value": 0.00169344}}, "created": "2025-12-10T21:53:58.1943294Z"}
{"ref": "sleek-horn", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.72}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.677969}, "meta_inference_prompt_tokens": {"value": 10107.0}, "meta_inference_completion_tokens": {"value": 1451.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020214}, "meta_inference_completion_cost": {"value": 0.0023216}, "meta_eval_time": {"value": 27.885}, "meta_eval_prompt_tokens": {"value": 5745.0}, "meta_eval_completion_tokens": {"value": 2731.0}, "meta_eval_prompt_cost": {"value": 0.0018384}, "meta_eval_completion_cost": {"value": 0.00349568}}, "created": "2025-12-10T21:53:59.4690783Z"}
{"ref": "snowy-suitcase-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.817529365307935}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.222222222222222}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.386228}, "meta_inference_prompt_tokens": {"value": 11127.0}, "meta_inference_completion_tokens": {"value": 992.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022254}, "meta_inference_completion_cost": {"value": 0.0015872}, "meta_eval_time": {"value": 19.532}, "meta_eval_prompt_tokens": {"value": 6193.0}, "meta_eval_completion_tokens": {"value": 1730.0}, "meta_eval_prompt_cost": {"value": 0.00198176}, "meta_eval_completion_cost": {"value": 0.0022144}}, "created": "2025-12-10T21:54:02.5208796Z"}
{"ref": "simple-audio-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.561145}, "meta_inference_prompt_tokens": {"value": 16355.0}, "meta_inference_completion_tokens": {"value": 1500.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003271}, "meta_inference_completion_cost": {"value": 0.0024}, "meta_eval_time": {"value": 41.959}, "meta_eval_prompt_tokens": {"value": 12296.0}, "meta_eval_completion_tokens": {"value": 4095.0}, "meta_eval_prompt_cost": {"value": 0.00393472}, "meta_eval_completion_cost": {"value": 0.0052416}}, "created": "2025-12-10T21:54:03.3925992Z"}
{"ref": "snowy-suitcase-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.833333333333333}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.285714285714286}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.324479}, "meta_inference_prompt_tokens": {"value": 9898.0}, "meta_inference_completion_tokens": {"value": 988.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019796}, "meta_inference_completion_cost": {"value": 0.0015808}, "meta_eval_time": {"value": 16.376}, "meta_eval_prompt_tokens": {"value": 5504.0}, "meta_eval_completion_tokens": {"value": 1473.0}, "meta_eval_prompt_cost": {"value": 0.00176128}, "meta_eval_completion_cost": {"value": 0.00188544}}, "created": "2025-12-10T21:54:05.2111881Z"}
{"ref": "roaring-bay", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.246753246753247}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 49.731568}, "meta_inference_prompt_tokens": {"value": 14643.0}, "meta_inference_completion_tokens": {"value": 3619.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029286}, "meta_inference_completion_cost": {"value": 0.0057904}, "meta_eval_time": {"value": 79.218}, "meta_eval_prompt_tokens": {"value": 11035.0}, "meta_eval_completion_tokens": {"value": 6356.0}, "meta_eval_prompt_cost": {"value": 0.0035312}, "meta_eval_completion_cost": {"value": 0.00813568}}, "created": "2025-12-10T21:54:05.4460412Z"}
{"ref": "simple-audio-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.235294117647059}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.133333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.285714285714286}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.172034}, "meta_inference_prompt_tokens": {"value": 12586.0}, "meta_inference_completion_tokens": {"value": 1303.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025172}, "meta_inference_completion_cost": {"value": 0.0020848}, "meta_eval_time": {"value": 42.535}, "meta_eval_prompt_tokens": {"value": 9551.0}, "meta_eval_completion_tokens": {"value": 4060.0}, "meta_eval_prompt_cost": {"value": 0.00305632}, "meta_eval_completion_cost": {"value": 0.0051968}}, "created": "2025-12-10T21:54:05.5655362Z"}
{"ref": "sleek-horn", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.939393939393939}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.613246}, "meta_inference_prompt_tokens": {"value": 11099.0}, "meta_inference_completion_tokens": {"value": 1641.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022198}, "meta_inference_completion_cost": {"value": 0.0026256}, "meta_eval_time": {"value": 34.521}, "meta_eval_prompt_tokens": {"value": 7218.0}, "meta_eval_completion_tokens": {"value": 3340.0}, "meta_eval_prompt_cost": {"value": 0.00230976}, "meta_eval_completion_cost": {"value": 0.0042752}}, "created": "2025-12-10T21:54:06.3970055Z"}
{"ref": "soft-bud", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.48}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 18.118302}, "meta_inference_prompt_tokens": {"value": 13496.0}, "meta_inference_completion_tokens": {"value": 986.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026992}, "meta_inference_completion_cost": {"value": 0.0015776}, "meta_eval_time": {"value": 15.321}, "meta_eval_prompt_tokens": {"value": 7903.0}, "meta_eval_completion_tokens": {"value": 1355.0}, "meta_eval_prompt_cost": {"value": 0.00252896}, "meta_eval_completion_cost": {"value": 0.0017344}}, "created": "2025-12-10T21:54:06.54518Z"}
{"ref": "sleek-horn", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.315464876785729}, "generation_faithfulness": {"value": 0.620689655172414}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.821004}, "meta_inference_prompt_tokens": {"value": 11309.0}, "meta_inference_completion_tokens": {"value": 1404.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022618}, "meta_inference_completion_cost": {"value": 0.0022464}, "meta_eval_time": {"value": 38.843}, "meta_eval_prompt_tokens": {"value": 7059.0}, "meta_eval_completion_tokens": {"value": 3204.0}, "meta_eval_prompt_cost": {"value": 0.00225888}, "meta_eval_completion_cost": {"value": 0.00410112}}, "created": "2025-12-10T21:54:07.0684061Z"}
{"ref": "smoggy-producer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.878787878787879}, "generation_factuality_f1": {"value": 0.307692307692308}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.4}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.4}, "meta_inference_time": {"value": 26.877973}, "meta_inference_prompt_tokens": {"value": 9471.0}, "meta_inference_completion_tokens": {"value": 1359.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018942}, "meta_inference_completion_cost": {"value": 0.0021744}, "meta_eval_time": {"value": 30.107}, "meta_eval_prompt_tokens": {"value": 5270.0}, "meta_eval_completion_tokens": {"value": 3088.0}, "meta_eval_prompt_cost": {"value": 0.0016864}, "meta_eval_completion_cost": {"value": 0.00395264}}, "created": "2025-12-10T21:54:08.0156787Z"}
{"ref": "smoggy-producer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.766666666666667}, "generation_factuality_f1": {"value": 0.470588235294118}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 28.272014}, "meta_inference_prompt_tokens": {"value": 9638.0}, "meta_inference_completion_tokens": {"value": 1718.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019276}, "meta_inference_completion_cost": {"value": 0.0027488}, "meta_eval_time": {"value": 35.347}, "meta_eval_prompt_tokens": {"value": 5774.0}, "meta_eval_completion_tokens": {"value": 3225.0}, "meta_eval_prompt_cost": {"value": 0.00184768}, "meta_eval_completion_cost": {"value": 0.004128}}, "created": "2025-12-10T21:54:08.8706599Z"}
{"ref": "sleek-horn", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.552488}, "meta_inference_prompt_tokens": {"value": 10782.0}, "meta_inference_completion_tokens": {"value": 1863.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021564}, "meta_inference_completion_cost": {"value": 0.0029808}, "meta_eval_time": {"value": 36.995}, "meta_eval_prompt_tokens": {"value": 6745.0}, "meta_eval_completion_tokens": {"value": 3483.0}, "meta_eval_prompt_cost": {"value": 0.0021584}, "meta_eval_completion_cost": {"value": 0.00445824}}, "created": "2025-12-10T21:54:09.8421239Z"}
{"ref": "smoked-edge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.87398974791402}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 38.230455}, "meta_inference_prompt_tokens": {"value": 14668.0}, "meta_inference_completion_tokens": {"value": 1495.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029336}, "meta_inference_completion_cost": {"value": 0.002392}, "meta_eval_time": {"value": 32.812}, "meta_eval_prompt_tokens": {"value": 10431.0}, "meta_eval_completion_tokens": {"value": 3110.0}, "meta_eval_prompt_cost": {"value": 0.00333792}, "meta_eval_completion_cost": {"value": 0.0039808}}, "created": "2025-12-10T21:54:11.0267186Z"}
{"ref": "some-lightship", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.828891}, "meta_inference_prompt_tokens": {"value": 4679.0}, "meta_inference_completion_tokens": {"value": 1035.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009358}, "meta_inference_completion_cost": {"value": 0.001656}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:11.0587583Z"}
{"ref": "snowy-suitcase-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.405089}, "meta_inference_prompt_tokens": {"value": 7176.0}, "meta_inference_completion_tokens": {"value": 1029.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0014352}, "meta_inference_completion_cost": {"value": 0.0016464}, "meta_eval_time": {"value": 17.883}, "meta_eval_prompt_tokens": {"value": 4207.0}, "meta_eval_completion_tokens": {"value": 1716.0}, "meta_eval_prompt_cost": {"value": 0.00134624}, "meta_eval_completion_cost": {"value": 0.00219648}}, "created": "2025-12-10T21:54:11.4579468Z"}
{"ref": "simple-audio-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.333333333333333}, "generation_faithfulness": {"value": 0.979591836734694}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.432961}, "meta_inference_prompt_tokens": {"value": 15483.0}, "meta_inference_completion_tokens": {"value": 1653.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030966}, "meta_inference_completion_cost": {"value": 0.0026448}, "meta_eval_time": {"value": 52.814}, "meta_eval_prompt_tokens": {"value": 11951.0}, "meta_eval_completion_tokens": {"value": 5157.0}, "meta_eval_prompt_cost": {"value": 0.00382432}, "meta_eval_completion_cost": {"value": 0.00660096}}, "created": "2025-12-10T21:54:11.6809625Z"}
{"ref": "soft-bud", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.032965}, "meta_inference_prompt_tokens": {"value": 11427.0}, "meta_inference_completion_tokens": {"value": 1182.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022854}, "meta_inference_completion_cost": {"value": 0.0018912}, "meta_eval_time": {"value": 27.342}, "meta_eval_prompt_tokens": {"value": 6849.0}, "meta_eval_completion_tokens": {"value": 2377.0}, "meta_eval_prompt_cost": {"value": 0.00219168}, "meta_eval_completion_cost": {"value": 0.00304256}}, "created": "2025-12-10T21:54:12.2199964Z"}
{"ref": "smoked-edge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.76529308256877}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.426504}, "meta_inference_prompt_tokens": {"value": 14416.0}, "meta_inference_completion_tokens": {"value": 1342.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028832}, "meta_inference_completion_cost": {"value": 0.0021472}, "meta_eval_time": {"value": 35.596}, "meta_eval_prompt_tokens": {"value": 10204.0}, "meta_eval_completion_tokens": {"value": 3517.0}, "meta_eval_prompt_cost": {"value": 0.00326528}, "meta_eval_completion_cost": {"value": 0.00450176}}, "created": "2025-12-10T21:54:12.4212926Z"}
{"ref": "snowy-suitcase-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.10234862196714}, "generation_faithfulness": {"value": 0.956521739130435}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.209995}, "meta_inference_prompt_tokens": {"value": 12602.0}, "meta_inference_completion_tokens": {"value": 1099.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025204}, "meta_inference_completion_cost": {"value": 0.0017584}, "meta_eval_time": {"value": 24.43}, "meta_eval_prompt_tokens": {"value": 7553.0}, "meta_eval_completion_tokens": {"value": 2424.0}, "meta_eval_prompt_cost": {"value": 0.00241696}, "meta_eval_completion_cost": {"value": 0.00310272}}, "created": "2025-12-10T21:54:13.3055033Z"}
{"ref": "simple-audio-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.82}, "generation_factuality_f1": {"value": 0.436363636363636}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 32.465957}, "meta_inference_prompt_tokens": {"value": 16154.0}, "meta_inference_completion_tokens": {"value": 1775.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032308}, "meta_inference_completion_cost": {"value": 0.00284}, "meta_eval_time": {"value": 50.677}, "meta_eval_prompt_tokens": {"value": 12411.0}, "meta_eval_completion_tokens": {"value": 5004.0}, "meta_eval_prompt_cost": {"value": 0.00397152}, "meta_eval_completion_cost": {"value": 0.00640512}}, "created": "2025-12-10T21:54:15.7909384Z"}
{"ref": "simple-audio-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.754716981132076}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.285714285714286}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 33.249131}, "meta_inference_prompt_tokens": {"value": 14173.0}, "meta_inference_completion_tokens": {"value": 1699.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028346}, "meta_inference_completion_cost": {"value": 0.0027184}, "meta_eval_time": {"value": 61.356}, "meta_eval_prompt_tokens": {"value": 12344.0}, "meta_eval_completion_tokens": {"value": 5773.0}, "meta_eval_prompt_cost": {"value": 0.00395008}, "meta_eval_completion_cost": {"value": 0.00738944}}, "created": "2025-12-10T21:54:15.8574076Z"}
{"ref": "simple-audio-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.963636363636364}, "generation_factuality_f1": {"value": 0.625}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 23.487202}, "meta_inference_prompt_tokens": {"value": 15937.0}, "meta_inference_completion_tokens": {"value": 1362.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031874}, "meta_inference_completion_cost": {"value": 0.0021792}, "meta_eval_time": {"value": 52.471}, "meta_eval_prompt_tokens": {"value": 11805.0}, "meta_eval_completion_tokens": {"value": 4930.0}, "meta_eval_prompt_cost": {"value": 0.0037776}, "meta_eval_completion_cost": {"value": 0.0063104}}, "created": "2025-12-10T21:54:16.2696136Z"}
{"ref": "smoked-edge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.85111589413933}, "generation_faithfulness": {"value": 0.9}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.089797}, "meta_inference_prompt_tokens": {"value": 14651.0}, "meta_inference_completion_tokens": {"value": 2028.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029302}, "meta_inference_completion_cost": {"value": 0.0032448}, "meta_eval_time": {"value": 37.604}, "meta_eval_prompt_tokens": {"value": 10592.0}, "meta_eval_completion_tokens": {"value": 3540.0}, "meta_eval_prompt_cost": {"value": 0.00338944}, "meta_eval_completion_cost": {"value": 0.0045312}}, "created": "2025-12-10T21:54:18.4948259Z"}
{"ref": "snow-clause-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.841629}, "meta_inference_prompt_tokens": {"value": 15147.0}, "meta_inference_completion_tokens": {"value": 1041.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030294}, "meta_inference_completion_cost": {"value": 0.0016656}, "meta_eval_time": {"value": 36.041}, "meta_eval_prompt_tokens": {"value": 11492.0}, "meta_eval_completion_tokens": {"value": 3708.0}, "meta_eval_prompt_cost": {"value": 0.00367744}, "meta_eval_completion_cost": {"value": 0.00474624}}, "created": "2025-12-10T21:54:19.2127222Z"}
{"ref": "simple-audio-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 0.930676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.816326530612245}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.285714285714286}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 87.684358}, "meta_inference_prompt_tokens": {"value": 14617.0}, "meta_inference_completion_tokens": {"value": 1907.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029234}, "meta_inference_completion_cost": {"value": 0.0030512}, "meta_eval_time": {"value": 59.163}, "meta_eval_prompt_tokens": {"value": 11983.0}, "meta_eval_completion_tokens": {"value": 4933.0}, "meta_eval_prompt_cost": {"value": 0.00383456}, "meta_eval_completion_cost": {"value": 0.00631424}}, "created": "2025-12-10T21:54:20.0469608Z"}
{"ref": "soft-bud", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.709677419354839}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.034873}, "meta_inference_prompt_tokens": {"value": 10769.0}, "meta_inference_completion_tokens": {"value": 1462.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021538}, "meta_inference_completion_cost": {"value": 0.0023392}, "meta_eval_time": {"value": 30.891}, "meta_eval_prompt_tokens": {"value": 6493.0}, "meta_eval_completion_tokens": {"value": 3062.0}, "meta_eval_prompt_cost": {"value": 0.00207776}, "meta_eval_completion_cost": {"value": 0.00391936}}, "created": "2025-12-10T21:54:20.444009Z"}
{"ref": "smoked-edge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.77972796369052}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 23.162648}, "meta_inference_prompt_tokens": {"value": 13493.0}, "meta_inference_completion_tokens": {"value": 1447.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026986}, "meta_inference_completion_cost": {"value": 0.0023152}, "meta_eval_time": {"value": 41.852}, "meta_eval_prompt_tokens": {"value": 9686.0}, "meta_eval_completion_tokens": {"value": 3605.0}, "meta_eval_prompt_cost": {"value": 0.00309952}, "meta_eval_completion_cost": {"value": 0.0046144}}, "created": "2025-12-10T21:54:20.8806337Z"}
{"ref": "some-lightship", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.680735}, "meta_inference_prompt_tokens": {"value": 4651.0}, "meta_inference_completion_tokens": {"value": 1073.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009302}, "meta_inference_completion_cost": {"value": 0.0017168}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:20.9131353Z"}
{"ref": "snowy-suitcase-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.07947476819246}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.02317}, "meta_inference_prompt_tokens": {"value": 12262.0}, "meta_inference_completion_tokens": {"value": 1246.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024524}, "meta_inference_completion_cost": {"value": 0.0019936}, "meta_eval_time": {"value": 18.601}, "meta_eval_prompt_tokens": {"value": 7013.0}, "meta_eval_completion_tokens": {"value": 1592.0}, "meta_eval_prompt_cost": {"value": 0.00224416}, "meta_eval_completion_cost": {"value": 0.00203776}}, "created": "2025-12-10T21:54:21.1577396Z"}
{"ref": "some-lightship", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.694785}, "meta_inference_prompt_tokens": {"value": 4653.0}, "meta_inference_completion_tokens": {"value": 1065.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009306}, "meta_inference_completion_cost": {"value": 0.001704}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:21.1952381Z"}
{"ref": "soft-bud", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.740740740740741}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.595844}, "meta_inference_prompt_tokens": {"value": 9841.0}, "meta_inference_completion_tokens": {"value": 1519.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019682}, "meta_inference_completion_cost": {"value": 0.0024304}, "meta_eval_time": {"value": 31.064}, "meta_eval_prompt_tokens": {"value": 5339.0}, "meta_eval_completion_tokens": {"value": 2757.0}, "meta_eval_prompt_cost": {"value": 0.00170848}, "meta_eval_completion_cost": {"value": 0.00352896}}, "created": "2025-12-10T21:54:21.4164033Z"}
{"ref": "some-lightship", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.36073}, "meta_inference_prompt_tokens": {"value": 9512.0}, "meta_inference_completion_tokens": {"value": 1423.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019024}, "meta_inference_completion_cost": {"value": 0.0022768}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:21.4538665Z"}
{"ref": "snow-clause-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.98713694067948}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.875}, "generation_factuality_precision": {"value": 0.777777777777778}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.734744}, "meta_inference_prompt_tokens": {"value": 14446.0}, "meta_inference_completion_tokens": {"value": 1358.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028892}, "meta_inference_completion_cost": {"value": 0.0021728}, "meta_eval_time": {"value": 34.429}, "meta_eval_prompt_tokens": {"value": 10497.0}, "meta_eval_completion_tokens": {"value": 3271.0}, "meta_eval_prompt_cost": {"value": 0.00335904}, "meta_eval_completion_cost": {"value": 0.00418688}}, "created": "2025-12-10T21:54:22.3193071Z"}
{"ref": "smoggy-producer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.96426308690479}, "generation_faithfulness": {"value": 0.765957446808511}, "generation_factuality_f1": {"value": 0.436363636363636}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 33.409301}, "meta_inference_prompt_tokens": {"value": 9456.0}, "meta_inference_completion_tokens": {"value": 1790.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018912}, "meta_inference_completion_cost": {"value": 0.002864}, "meta_eval_time": {"value": 46.55}, "meta_eval_prompt_tokens": {"value": 6042.0}, "meta_eval_completion_tokens": {"value": 4394.0}, "meta_eval_prompt_cost": {"value": 0.00193344}, "meta_eval_completion_cost": {"value": 0.00562432}}, "created": "2025-12-10T21:54:23.3854091Z"}
{"ref": "sleek-horn", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.159658}, "meta_inference_prompt_tokens": {"value": 11400.0}, "meta_inference_completion_tokens": {"value": 1851.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00228}, "meta_inference_completion_cost": {"value": 0.0029616}, "meta_eval_time": {"value": 52.935}, "meta_eval_prompt_tokens": {"value": 8449.0}, "meta_eval_completion_tokens": {"value": 5066.0}, "meta_eval_prompt_cost": {"value": 0.00270368}, "meta_eval_completion_cost": {"value": 0.00648448}}, "created": "2025-12-10T21:54:23.843031Z"}
{"ref": "some-lightship", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.840632}, "meta_inference_prompt_tokens": {"value": 4652.0}, "meta_inference_completion_tokens": {"value": 1194.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009304}, "meta_inference_completion_cost": {"value": 0.0019104}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:23.8755987Z"}
{"ref": "snow-clause-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.188899}, "meta_inference_prompt_tokens": {"value": 14833.0}, "meta_inference_completion_tokens": {"value": 975.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029666}, "meta_inference_completion_cost": {"value": 0.00156}, "meta_eval_time": {"value": 35.785}, "meta_eval_prompt_tokens": {"value": 11145.0}, "meta_eval_completion_tokens": {"value": 3446.0}, "meta_eval_prompt_cost": {"value": 0.0035664}, "meta_eval_completion_cost": {"value": 0.00441088}}, "created": "2025-12-10T21:54:25.1823174Z"}
{"ref": "snow-clause-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.28906482631789}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.946023}, "meta_inference_prompt_tokens": {"value": 14418.0}, "meta_inference_completion_tokens": {"value": 1426.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028836}, "meta_inference_completion_cost": {"value": 0.0022816}, "meta_eval_time": {"value": 53.036}, "meta_eval_prompt_tokens": {"value": 11244.0}, "meta_eval_completion_tokens": {"value": 4914.0}, "meta_eval_prompt_cost": {"value": 0.00359808}, "meta_eval_completion_cost": {"value": 0.00628992}}, "created": "2025-12-10T21:54:29.1646931Z"}
{"ref": "smoked-edge", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.82047027401281}, "generation_faithfulness": {"value": 0.96551724137931}, "generation_factuality_f1": {"value": 0.685714285714286}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 26.657143}, "meta_inference_prompt_tokens": {"value": 13483.0}, "meta_inference_completion_tokens": {"value": 1492.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026966}, "meta_inference_completion_cost": {"value": 0.0023872}, "meta_eval_time": {"value": 50.441}, "meta_eval_prompt_tokens": {"value": 9232.0}, "meta_eval_completion_tokens": {"value": 3382.0}, "meta_eval_prompt_cost": {"value": 0.00295424}, "meta_eval_completion_cost": {"value": 0.00432896}}, "created": "2025-12-10T21:54:29.5603384Z"}
{"ref": "solid-app", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.12481474695503}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.15}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.262155}, "meta_inference_prompt_tokens": {"value": 26894.0}, "meta_inference_completion_tokens": {"value": 2127.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0053788}, "meta_inference_completion_cost": {"value": 0.0034032}, "meta_eval_time": {"value": 24.017}, "meta_eval_prompt_tokens": {"value": 9121.0}, "meta_eval_completion_tokens": {"value": 2057.0}, "meta_eval_prompt_cost": {"value": 0.00291872}, "meta_eval_completion_cost": {"value": 0.00263296}}, "created": "2025-12-10T21:54:29.6158536Z"}
{"ref": "smoggy-producer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.976744186046512}, "generation_factuality_f1": {"value": 0.533333333333333}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 24.610695}, "meta_inference_prompt_tokens": {"value": 9320.0}, "meta_inference_completion_tokens": {"value": 1493.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001864}, "meta_inference_completion_cost": {"value": 0.0023888}, "meta_eval_time": {"value": 56.166}, "meta_eval_prompt_tokens": {"value": 6309.0}, "meta_eval_completion_tokens": {"value": 4498.0}, "meta_eval_prompt_cost": {"value": 0.00201888}, "meta_eval_completion_cost": {"value": 0.00575744}}, "created": "2025-12-10T21:54:29.6674176Z"}
{"ref": "solid-sap", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.37537}, "meta_inference_prompt_tokens": {"value": 11530.0}, "meta_inference_completion_tokens": {"value": 805.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002306}, "meta_inference_completion_cost": {"value": 0.001288}, "meta_eval_time": {"value": 23.508}, "meta_eval_prompt_tokens": {"value": 6505.0}, "meta_eval_completion_tokens": {"value": 2036.0}, "meta_eval_prompt_cost": {"value": 0.0020816}, "meta_eval_completion_cost": {"value": 0.00260608}}, "created": "2025-12-10T21:54:30.6113349Z"}
{"ref": "smoggy-producer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.017782560806}, "generation_faithfulness": {"value": 0.901960784313726}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 38.67972}, "meta_inference_prompt_tokens": {"value": 10868.0}, "meta_inference_completion_tokens": {"value": 2133.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021736}, "meta_inference_completion_cost": {"value": 0.0034128}, "meta_eval_time": {"value": 56.634}, "meta_eval_prompt_tokens": {"value": 7766.0}, "meta_eval_completion_tokens": {"value": 4722.0}, "meta_eval_prompt_cost": {"value": 0.00248512}, "meta_eval_completion_cost": {"value": 0.00604416}}, "created": "2025-12-10T21:54:31.1967517Z"}
{"ref": "spicy-canister", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.34824}, "meta_inference_prompt_tokens": {"value": 2254.0}, "meta_inference_completion_tokens": {"value": 653.0}, "meta_inference_prompt_cost": {"value": 0.0004508}, "meta_inference_completion_cost": {"value": 0.0010448}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:31.2358597Z"}
{"ref": "solid-app", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.687882802898523}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.51063829787234}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 26.365966}, "meta_inference_prompt_tokens": {"value": 11265.0}, "meta_inference_completion_tokens": {"value": 1438.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002253}, "meta_inference_completion_cost": {"value": 0.0023008}, "meta_eval_time": {"value": 25.906}, "meta_eval_prompt_tokens": {"value": 6340.0}, "meta_eval_completion_tokens": {"value": 2584.0}, "meta_eval_prompt_cost": {"value": 0.0020288}, "meta_eval_completion_cost": {"value": 0.00330752}}, "created": "2025-12-10T21:54:34.8300148Z"}
{"ref": "spicy-canister", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.0467}, "meta_inference_prompt_tokens": {"value": 2254.0}, "meta_inference_completion_tokens": {"value": 585.0}, "meta_inference_prompt_cost": {"value": 0.0004508}, "meta_inference_completion_cost": {"value": 0.000936}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:34.8617492Z"}
{"ref": "spicy-canister", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.574577}, "meta_inference_prompt_tokens": {"value": 11277.0}, "meta_inference_completion_tokens": {"value": 1020.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022554}, "meta_inference_completion_cost": {"value": 0.001632}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:34.8944922Z"}
{"ref": "solid-sap", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.511368}, "meta_inference_prompt_tokens": {"value": 13140.0}, "meta_inference_completion_tokens": {"value": 937.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002628}, "meta_inference_completion_cost": {"value": 0.0014992}, "meta_eval_time": {"value": 25.116}, "meta_eval_prompt_tokens": {"value": 8111.0}, "meta_eval_completion_tokens": {"value": 2279.0}, "meta_eval_prompt_cost": {"value": 0.00259552}, "meta_eval_completion_cost": {"value": 0.00291712}}, "created": "2025-12-10T21:54:34.9903247Z"}
{"ref": "spicy-canister", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.377587}, "meta_inference_prompt_tokens": {"value": 2254.0}, "meta_inference_completion_tokens": {"value": 445.0}, "meta_inference_prompt_cost": {"value": 0.0004508}, "meta_inference_completion_cost": {"value": 0.000712}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:35.021724Z"}
{"ref": "soft-bud", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.142857142857143}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0769230769230769}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.905793}, "meta_inference_prompt_tokens": {"value": 12020.0}, "meta_inference_completion_tokens": {"value": 1563.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002404}, "meta_inference_completion_cost": {"value": 0.0025008}, "meta_eval_time": {"value": 37.998}, "meta_eval_prompt_tokens": {"value": 8015.0}, "meta_eval_completion_tokens": {"value": 3807.0}, "meta_eval_prompt_cost": {"value": 0.0025648}, "meta_eval_completion_cost": {"value": 0.00487296}}, "created": "2025-12-10T21:54:35.2905312Z"}
{"ref": "soluble-bourbon", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.908954}, "meta_inference_prompt_tokens": {"value": 17130.0}, "meta_inference_completion_tokens": {"value": 994.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003426}, "meta_inference_completion_cost": {"value": 0.0015904}, "meta_eval_time": {"value": 24.207}, "meta_eval_prompt_tokens": {"value": 11069.0}, "meta_eval_completion_tokens": {"value": 2067.0}, "meta_eval_prompt_cost": {"value": 0.00354208}, "meta_eval_completion_cost": {"value": 0.00264576}}, "created": "2025-12-10T21:54:35.2996384Z"}
{"ref": "spicy-canister", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.959464}, "meta_inference_prompt_tokens": {"value": 2254.0}, "meta_inference_completion_tokens": {"value": 833.0}, "meta_inference_prompt_cost": {"value": 0.0004508}, "meta_inference_completion_cost": {"value": 0.0013328}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:35.376996Z"}
{"ref": "solid-app", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.687882802898523}, "generation_faithfulness": {"value": 0.894736842105263}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.224449}, "meta_inference_prompt_tokens": {"value": 11266.0}, "meta_inference_completion_tokens": {"value": 1042.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022532}, "meta_inference_completion_cost": {"value": 0.0016672}, "meta_eval_time": {"value": 23.994}, "meta_eval_prompt_tokens": {"value": 6044.0}, "meta_eval_completion_tokens": {"value": 2016.0}, "meta_eval_prompt_cost": {"value": 0.00193408}, "meta_eval_completion_cost": {"value": 0.00258048}}, "created": "2025-12-10T21:54:35.485289Z"}
{"ref": "snow-clause-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.25}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.688936}, "meta_inference_prompt_tokens": {"value": 14414.0}, "meta_inference_completion_tokens": {"value": 2019.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028828}, "meta_inference_completion_cost": {"value": 0.0032304}, "meta_eval_time": {"value": 53.21}, "meta_eval_prompt_tokens": {"value": 11483.0}, "meta_eval_completion_tokens": {"value": 4495.0}, "meta_eval_prompt_cost": {"value": 0.00367456}, "meta_eval_completion_cost": {"value": 0.0057536}}, "created": "2025-12-10T21:54:35.5948865Z"}
{"ref": "soluble-bourbon", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.815533980582524}, "generation_factuality_precision": {"value": 0.777777777777778}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 18.942367}, "meta_inference_prompt_tokens": {"value": 14396.0}, "meta_inference_completion_tokens": {"value": 807.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028792}, "meta_inference_completion_cost": {"value": 0.0012912}, "meta_eval_time": {"value": 23.493}, "meta_eval_prompt_tokens": {"value": 8754.0}, "meta_eval_completion_tokens": {"value": 1850.0}, "meta_eval_prompt_cost": {"value": 0.00280128}, "meta_eval_completion_cost": {"value": 0.002368}}, "created": "2025-12-10T21:54:35.7467917Z"}
{"ref": "solid-app", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.657237182772003}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.558139534883721}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 24.801703}, "meta_inference_prompt_tokens": {"value": 10723.0}, "meta_inference_completion_tokens": {"value": 1060.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021446}, "meta_inference_completion_cost": {"value": 0.001696}, "meta_eval_time": {"value": 22.636}, "meta_eval_prompt_tokens": {"value": 5447.0}, "meta_eval_completion_tokens": {"value": 1762.0}, "meta_eval_prompt_cost": {"value": 0.00174304}, "meta_eval_completion_cost": {"value": 0.00225536}}, "created": "2025-12-10T21:54:38.5279519Z"}
{"ref": "soluble-bourbon", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.858446}, "meta_inference_prompt_tokens": {"value": 13354.0}, "meta_inference_completion_tokens": {"value": 1238.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026708}, "meta_inference_completion_cost": {"value": 0.0019808}, "meta_eval_time": {"value": 26.251}, "meta_eval_prompt_tokens": {"value": 8233.0}, "meta_eval_completion_tokens": {"value": 2068.0}, "meta_eval_prompt_cost": {"value": 0.00263456}, "meta_eval_completion_cost": {"value": 0.00264704}}, "created": "2025-12-10T21:54:42.0839614Z"}
{"ref": "soft-value", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 0.862068965517241}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 37.129878}, "meta_inference_prompt_tokens": {"value": 17709.0}, "meta_inference_completion_tokens": {"value": 1025.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0035418}, "meta_inference_completion_cost": {"value": 0.00164}, "meta_eval_time": {"value": 30.945}, "meta_eval_prompt_tokens": {"value": 13181.0}, "meta_eval_completion_tokens": {"value": 2554.0}, "meta_eval_prompt_cost": {"value": 0.00421792}, "meta_eval_completion_cost": {"value": 0.00326912}}, "created": "2025-12-10T21:54:43.3995793Z"}
{"ref": "staff-surface-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.807805}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 974.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0015584}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:43.4394029Z"}
{"ref": "sparse-shares", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.588235294117647}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.492107}, "meta_inference_prompt_tokens": {"value": 11516.0}, "meta_inference_completion_tokens": {"value": 1198.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023032}, "meta_inference_completion_cost": {"value": 0.0019168}, "meta_eval_time": {"value": 18.427}, "meta_eval_prompt_tokens": {"value": 6133.0}, "meta_eval_completion_tokens": {"value": 1731.0}, "meta_eval_prompt_cost": {"value": 0.00196256}, "meta_eval_completion_cost": {"value": 0.00221568}}, "created": "2025-12-10T21:54:43.6448749Z"}
{"ref": "soft-value", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.170518}, "meta_inference_prompt_tokens": {"value": 14845.0}, "meta_inference_completion_tokens": {"value": 1103.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002969}, "meta_inference_completion_cost": {"value": 0.0017648}, "meta_eval_time": {"value": 36.932}, "meta_eval_prompt_tokens": {"value": 10777.0}, "meta_eval_completion_tokens": {"value": 3272.0}, "meta_eval_prompt_cost": {"value": 0.00344864}, "meta_eval_completion_cost": {"value": 0.00418816}}, "created": "2025-12-10T21:54:44.9833447Z"}
{"ref": "soluble-bourbon", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.956521739130435}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.338721}, "meta_inference_prompt_tokens": {"value": 17648.0}, "meta_inference_completion_tokens": {"value": 1155.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0035296}, "meta_inference_completion_cost": {"value": 0.001848}, "meta_eval_time": {"value": 31.987}, "meta_eval_prompt_tokens": {"value": 12105.0}, "meta_eval_completion_tokens": {"value": 2641.0}, "meta_eval_prompt_cost": {"value": 0.0038736}, "meta_eval_completion_cost": {"value": 0.00338048}}, "created": "2025-12-10T21:54:45.3245665Z"}
{"ref": "staff-surface-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.729467}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 785.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.001256}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:45.36557Z"}
{"ref": "solid-sap", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.95}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.442139}, "meta_inference_prompt_tokens": {"value": 12572.0}, "meta_inference_completion_tokens": {"value": 1108.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025144}, "meta_inference_completion_cost": {"value": 0.0017728}, "meta_eval_time": {"value": 26.18}, "meta_eval_prompt_tokens": {"value": 7597.0}, "meta_eval_completion_tokens": {"value": 2267.0}, "meta_eval_prompt_cost": {"value": 0.00243104}, "meta_eval_completion_cost": {"value": 0.00290176}}, "created": "2025-12-10T21:54:45.4267925Z"}
{"ref": "solid-app", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.687882802898523}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.145916}, "meta_inference_prompt_tokens": {"value": 11265.0}, "meta_inference_completion_tokens": {"value": 1258.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002253}, "meta_inference_completion_cost": {"value": 0.0020128}, "meta_eval_time": {"value": 25.005}, "meta_eval_prompt_tokens": {"value": 6242.0}, "meta_eval_completion_tokens": {"value": 2089.0}, "meta_eval_prompt_cost": {"value": 0.00199744}, "meta_eval_completion_cost": {"value": 0.00267392}}, "created": "2025-12-10T21:54:45.4828071Z"}
{"ref": "staff-surface-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.112082}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 652.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0010432}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:45.528401Z"}
{"ref": "solid-sap", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.233946}, "meta_inference_prompt_tokens": {"value": 12652.0}, "meta_inference_completion_tokens": {"value": 1142.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025304}, "meta_inference_completion_cost": {"value": 0.0018272}, "meta_eval_time": {"value": 39.221}, "meta_eval_prompt_tokens": {"value": 8225.0}, "meta_eval_completion_tokens": {"value": 3354.0}, "meta_eval_prompt_cost": {"value": 0.002632}, "meta_eval_completion_cost": {"value": 0.00429312}}, "created": "2025-12-10T21:54:45.6503662Z"}
{"ref": "snow-clause-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.875}, "generation_factuality_precision": {"value": 0.777777777777778}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.778611}, "meta_inference_prompt_tokens": {"value": 14819.0}, "meta_inference_completion_tokens": {"value": 938.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029638}, "meta_inference_completion_cost": {"value": 0.0015008}, "meta_eval_time": {"value": 41.444}, "meta_eval_prompt_tokens": {"value": 10913.0}, "meta_eval_completion_tokens": {"value": 3507.0}, "meta_eval_prompt_cost": {"value": 0.00349216}, "meta_eval_completion_cost": {"value": 0.00448896}}, "created": "2025-12-10T21:54:46.6908477Z"}
{"ref": "staff-surface-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.903384}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 644.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0010304}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:46.7253821Z"}
{"ref": "staff-surface-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 48.543706}, "meta_inference_prompt_tokens": {"value": 4660.0}, "meta_inference_completion_tokens": {"value": 1926.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.000932}, "meta_inference_completion_cost": {"value": 0.0030816}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:46.7584893Z"}
{"ref": "solid-sap", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.904761904761905}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.274795}, "meta_inference_prompt_tokens": {"value": 11537.0}, "meta_inference_completion_tokens": {"value": 1073.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023074}, "meta_inference_completion_cost": {"value": 0.0017168}, "meta_eval_time": {"value": 28.98}, "meta_eval_prompt_tokens": {"value": 6959.0}, "meta_eval_completion_tokens": {"value": 2599.0}, "meta_eval_prompt_cost": {"value": 0.00222688}, "meta_eval_completion_cost": {"value": 0.00332672}}, "created": "2025-12-10T21:54:47.5108094Z"}
{"ref": "sparse-shares", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.625}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.749362}, "meta_inference_prompt_tokens": {"value": 11625.0}, "meta_inference_completion_tokens": {"value": 985.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002325}, "meta_inference_completion_cost": {"value": 0.001576}, "meta_eval_time": {"value": 23.818}, "meta_eval_prompt_tokens": {"value": 6187.0}, "meta_eval_completion_tokens": {"value": 1686.0}, "meta_eval_prompt_cost": {"value": 0.00197984}, "meta_eval_completion_cost": {"value": 0.00215808}}, "created": "2025-12-10T21:54:47.7259392Z"}
{"ref": "snow-clause-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.794879}, "meta_inference_prompt_tokens": {"value": 14839.0}, "meta_inference_completion_tokens": {"value": 1610.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029678}, "meta_inference_completion_cost": {"value": 0.002576}, "meta_eval_time": {"value": 51.157}, "meta_eval_prompt_tokens": {"value": 11599.0}, "meta_eval_completion_tokens": {"value": 4424.0}, "meta_eval_prompt_cost": {"value": 0.00371168}, "meta_eval_completion_cost": {"value": 0.00566272}}, "created": "2025-12-10T21:54:49.3841679Z"}
{"ref": "soft-value", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.32}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 27.621495}, "meta_inference_prompt_tokens": {"value": 14849.0}, "meta_inference_completion_tokens": {"value": 1239.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029698}, "meta_inference_completion_cost": {"value": 0.0019824}, "meta_eval_time": {"value": 43.019}, "meta_eval_prompt_tokens": {"value": 10817.0}, "meta_eval_completion_tokens": {"value": 3518.0}, "meta_eval_prompt_cost": {"value": 0.00346144}, "meta_eval_completion_cost": {"value": 0.00450304}}, "created": "2025-12-10T21:54:49.5967261Z"}
{"ref": "snow-clause-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 1.67373655241596}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.740392}, "meta_inference_prompt_tokens": {"value": 14078.0}, "meta_inference_completion_tokens": {"value": 2110.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028156}, "meta_inference_completion_cost": {"value": 0.003376}, "meta_eval_time": {"value": 70.987}, "meta_eval_prompt_tokens": {"value": 11631.0}, "meta_eval_completion_tokens": {"value": 5707.0}, "meta_eval_prompt_cost": {"value": 0.00372192}, "meta_eval_completion_cost": {"value": 0.00730496}}, "created": "2025-12-10T21:54:50.3762175Z"}
{"ref": "soft-value", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.275269}, "meta_inference_prompt_tokens": {"value": 14848.0}, "meta_inference_completion_tokens": {"value": 1267.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029696}, "meta_inference_completion_cost": {"value": 0.0020272}, "meta_eval_time": {"value": 39.356}, "meta_eval_prompt_tokens": {"value": 10696.0}, "meta_eval_completion_tokens": {"value": 3276.0}, "meta_eval_prompt_cost": {"value": 0.00342272}, "meta_eval_completion_cost": {"value": 0.00419328}}, "created": "2025-12-10T21:54:51.0711653Z"}
{"ref": "sparse-shares", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.689655172413793}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.027324}, "meta_inference_prompt_tokens": {"value": 11196.0}, "meta_inference_completion_tokens": {"value": 1347.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022392}, "meta_inference_completion_cost": {"value": 0.0021552}, "meta_eval_time": {"value": 29.61}, "meta_eval_prompt_tokens": {"value": 6693.0}, "meta_eval_completion_tokens": {"value": 2720.0}, "meta_eval_prompt_cost": {"value": 0.00214176}, "meta_eval_completion_cost": {"value": 0.0034816}}, "created": "2025-12-10T21:54:51.0952648Z"}
{"ref": "stale-slab", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.99588}, "meta_inference_prompt_tokens": {"value": 10503.0}, "meta_inference_completion_tokens": {"value": 711.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021006}, "meta_inference_completion_cost": {"value": 0.0011376}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:51.1390265Z"}
{"ref": "stale-slab", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.928713}, "meta_inference_prompt_tokens": {"value": 23229.0}, "meta_inference_completion_tokens": {"value": 710.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0046458}, "meta_inference_completion_cost": {"value": 0.001136}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:51.1753834Z"}
{"ref": "stale-slab", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.311737}, "meta_inference_prompt_tokens": {"value": 72654.0}, "meta_inference_completion_tokens": {"value": 906.0}, "meta_inference_tool_call_count": {"value": 3.0}, "meta_inference_prompt_cost": {"value": 0.0145308}, "meta_inference_completion_cost": {"value": 0.0014496}, "meta_eval_time": {"value": 0.002}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:51.2169446Z"}
{"ref": "sparse-shares", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.777777777777778}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.410063}, "meta_inference_prompt_tokens": {"value": 11524.0}, "meta_inference_completion_tokens": {"value": 989.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023048}, "meta_inference_completion_cost": {"value": 0.0015824}, "meta_eval_time": {"value": 21.983}, "meta_eval_prompt_tokens": {"value": 6259.0}, "meta_eval_completion_tokens": {"value": 1905.0}, "meta_eval_prompt_cost": {"value": 0.00200288}, "meta_eval_completion_cost": {"value": 0.0024384}}, "created": "2025-12-10T21:54:51.5779754Z"}
{"ref": "steamed-inflection-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.466438}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 785.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.001256}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:51.6199914Z"}
{"ref": "soft-value", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.47291}, "meta_inference_prompt_tokens": {"value": 15633.0}, "meta_inference_completion_tokens": {"value": 1608.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031266}, "meta_inference_completion_cost": {"value": 0.0025728}, "meta_eval_time": {"value": 46.881}, "meta_eval_prompt_tokens": {"value": 11979.0}, "meta_eval_completion_tokens": {"value": 3983.0}, "meta_eval_prompt_cost": {"value": 0.00383328}, "meta_eval_completion_cost": {"value": 0.00509824}}, "created": "2025-12-10T21:54:52.360983Z"}
{"ref": "steamed-inflection-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.114602}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 523.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0008368}, "meta_eval_time": {"value": 0.002}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:52.3988076Z"}
{"ref": "steamed-inflection-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.332183}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 651.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0010416}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:52.4399732Z"}
{"ref": "snow-clause-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.73170655373737}, "generation_faithfulness": {"value": 0.983606557377049}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.600382}, "meta_inference_prompt_tokens": {"value": 14988.0}, "meta_inference_completion_tokens": {"value": 1664.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029976}, "meta_inference_completion_cost": {"value": 0.0026624}, "meta_eval_time": {"value": 68.979}, "meta_eval_prompt_tokens": {"value": 12792.0}, "meta_eval_completion_tokens": {"value": 5867.0}, "meta_eval_prompt_cost": {"value": 0.00409344}, "meta_eval_completion_cost": {"value": 0.00750976}}, "created": "2025-12-10T21:54:52.9492095Z"}
{"ref": "snow-clause-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.11855936097192}, "generation_faithfulness": {"value": 0.981132075471698}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 38.790842}, "meta_inference_prompt_tokens": {"value": 12417.0}, "meta_inference_completion_tokens": {"value": 2523.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024834}, "meta_inference_completion_cost": {"value": 0.0040368}, "meta_eval_time": {"value": 56.343}, "meta_eval_prompt_tokens": {"value": 9690.0}, "meta_eval_completion_tokens": {"value": 5056.0}, "meta_eval_prompt_cost": {"value": 0.0031008}, "meta_eval_completion_cost": {"value": 0.00647168}}, "created": "2025-12-10T21:54:55.848201Z"}
{"ref": "steamed-inflection-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.477971}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 522.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0008352}, "meta_eval_time": {"value": 0.002}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:55.8893635Z"}
{"ref": "stale-slab", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.145133}, "meta_inference_prompt_tokens": {"value": 20961.0}, "meta_inference_completion_tokens": {"value": 666.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0041922}, "meta_inference_completion_cost": {"value": 0.0010656}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:54:55.9552191Z"}
{"ref": "staccato-bungalow", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.125854}, "meta_inference_prompt_tokens": {"value": 10002.0}, "meta_inference_completion_tokens": {"value": 758.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020004}, "meta_inference_completion_cost": {"value": 0.0012128}, "meta_eval_time": {"value": 11.762}, "meta_eval_prompt_tokens": {"value": 4805.0}, "meta_eval_completion_tokens": {"value": 1177.0}, "meta_eval_prompt_cost": {"value": 0.0015376}, "meta_eval_completion_cost": {"value": 0.00150656}}, "created": "2025-12-10T21:54:57.3285114Z"}
{"ref": "soluble-bourbon", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.975609756097561}, "generation_factuality_f1": {"value": 0.705882352941176}, "generation_factuality_precision": {"value": 0.545454545454545}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.026489}, "meta_inference_prompt_tokens": {"value": 15485.0}, "meta_inference_completion_tokens": {"value": 1543.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003097}, "meta_inference_completion_cost": {"value": 0.0024688}, "meta_eval_time": {"value": 40.316}, "meta_eval_prompt_tokens": {"value": 10919.0}, "meta_eval_completion_tokens": {"value": 3824.0}, "meta_eval_prompt_cost": {"value": 0.00349408}, "meta_eval_completion_cost": {"value": 0.00489472}}, "created": "2025-12-10T21:55:00.4096862Z"}
{"ref": "stale-slab", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.903313}, "meta_inference_prompt_tokens": {"value": 10503.0}, "meta_inference_completion_tokens": {"value": 313.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021006}, "meta_inference_completion_cost": {"value": 0.0005008}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:00.6204476Z"}
{"ref": "spry-kapok-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.208641}, "meta_inference_prompt_tokens": {"value": 10670.0}, "meta_inference_completion_tokens": {"value": 637.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002134}, "meta_inference_completion_cost": {"value": 0.0010192}, "meta_eval_time": {"value": 25.701}, "meta_eval_prompt_tokens": {"value": 5812.0}, "meta_eval_completion_tokens": {"value": 2407.0}, "meta_eval_prompt_cost": {"value": 0.00185984}, "meta_eval_completion_cost": {"value": 0.00308096}}, "created": "2025-12-10T21:55:00.6272922Z"}
{"ref": "steamed-inflection-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.392063}, "meta_inference_prompt_tokens": {"value": 5274.0}, "meta_inference_completion_tokens": {"value": 1222.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0010548}, "meta_inference_completion_cost": {"value": 0.0019552}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:00.6635544Z"}
{"ref": "staccato-bungalow", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.625}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.773014}, "meta_inference_prompt_tokens": {"value": 10208.0}, "meta_inference_completion_tokens": {"value": 664.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020416}, "meta_inference_completion_cost": {"value": 0.0010624}, "meta_eval_time": {"value": 25.355}, "meta_eval_prompt_tokens": {"value": 5349.0}, "meta_eval_completion_tokens": {"value": 1960.0}, "meta_eval_prompt_cost": {"value": 0.00171168}, "meta_eval_completion_cost": {"value": 0.0025088}}, "created": "2025-12-10T21:55:00.8883681Z"}
{"ref": "spry-kapok-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.770642201834862}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 16.977543}, "meta_inference_prompt_tokens": {"value": 10673.0}, "meta_inference_completion_tokens": {"value": 752.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021346}, "meta_inference_completion_cost": {"value": 0.0012032}, "meta_eval_time": {"value": 25.842}, "meta_eval_prompt_tokens": {"value": 5696.0}, "meta_eval_completion_tokens": {"value": 2230.0}, "meta_eval_prompt_cost": {"value": 0.00182272}, "meta_eval_completion_cost": {"value": 0.0028544}}, "created": "2025-12-10T21:55:01.1659344Z"}
{"ref": "stale-option", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.692307692307692}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.413877}, "meta_inference_prompt_tokens": {"value": 9970.0}, "meta_inference_completion_tokens": {"value": 860.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001994}, "meta_inference_completion_cost": {"value": 0.001376}, "meta_eval_time": {"value": 13.662}, "meta_eval_prompt_tokens": {"value": 4595.0}, "meta_eval_completion_tokens": {"value": 1256.0}, "meta_eval_prompt_cost": {"value": 0.0014704}, "meta_eval_completion_cost": {"value": 0.00160768}}, "created": "2025-12-10T21:55:01.427652Z"}
{"ref": "stale-option", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.089908}, "meta_inference_prompt_tokens": {"value": 9882.0}, "meta_inference_completion_tokens": {"value": 892.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019764}, "meta_inference_completion_cost": {"value": 0.0014272}, "meta_eval_time": {"value": 11.805}, "meta_eval_prompt_tokens": {"value": 4362.0}, "meta_eval_completion_tokens": {"value": 1062.0}, "meta_eval_prompt_cost": {"value": 0.00139584}, "meta_eval_completion_cost": {"value": 0.00135936}}, "created": "2025-12-10T21:55:01.4413752Z"}
{"ref": "stale-option", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.515591}, "meta_inference_prompt_tokens": {"value": 9785.0}, "meta_inference_completion_tokens": {"value": 877.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001957}, "meta_inference_completion_cost": {"value": 0.0014032}, "meta_eval_time": {"value": 12.05}, "meta_eval_prompt_tokens": {"value": 4239.0}, "meta_eval_completion_tokens": {"value": 1004.0}, "meta_eval_prompt_cost": {"value": 0.00135648}, "meta_eval_completion_cost": {"value": 0.00128512}}, "created": "2025-12-10T21:55:03.7098862Z"}
{"ref": "stale-option", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.204625}, "meta_inference_prompt_tokens": {"value": 9831.0}, "meta_inference_completion_tokens": {"value": 646.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019662}, "meta_inference_completion_cost": {"value": 0.0010336}, "meta_eval_time": {"value": 16.75}, "meta_eval_prompt_tokens": {"value": 4564.0}, "meta_eval_completion_tokens": {"value": 1397.0}, "meta_eval_prompt_cost": {"value": 0.00146048}, "meta_eval_completion_cost": {"value": 0.00178816}}, "created": "2025-12-10T21:55:06.174927Z"}
{"ref": "staccato-bungalow", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.173978}, "meta_inference_prompt_tokens": {"value": 10151.0}, "meta_inference_completion_tokens": {"value": 945.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020302}, "meta_inference_completion_cost": {"value": 0.001512}, "meta_eval_time": {"value": 24.058}, "meta_eval_prompt_tokens": {"value": 5568.0}, "meta_eval_completion_tokens": {"value": 2118.0}, "meta_eval_prompt_cost": {"value": 0.00178176}, "meta_eval_completion_cost": {"value": 0.00271104}}, "created": "2025-12-10T21:55:06.182446Z"}
{"ref": "sour-rectangle", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.2}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.2}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.2}, "meta_inference_time": {"value": 24.810868}, "meta_inference_prompt_tokens": {"value": 12440.0}, "meta_inference_completion_tokens": {"value": 1402.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002488}, "meta_inference_completion_cost": {"value": 0.0022432}, "meta_eval_time": {"value": 46.146}, "meta_eval_prompt_tokens": {"value": 8892.0}, "meta_eval_completion_tokens": {"value": 4026.0}, "meta_eval_prompt_cost": {"value": 0.00284544}, "meta_eval_completion_cost": {"value": 0.00515328}}, "created": "2025-12-10T21:55:07.0964845Z"}
{"ref": "staccato-bungalow", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.525909}, "meta_inference_prompt_tokens": {"value": 10507.0}, "meta_inference_completion_tokens": {"value": 546.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021014}, "meta_inference_completion_cost": {"value": 0.0008736}, "meta_eval_time": {"value": 24.366}, "meta_eval_prompt_tokens": {"value": 5428.0}, "meta_eval_completion_tokens": {"value": 1583.0}, "meta_eval_prompt_cost": {"value": 0.00173696}, "meta_eval_completion_cost": {"value": 0.00202624}}, "created": "2025-12-10T21:55:08.0578859Z"}
{"ref": "stable-factorial", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.222222222222222}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.836233}, "meta_inference_prompt_tokens": {"value": 9541.0}, "meta_inference_completion_tokens": {"value": 1369.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019082}, "meta_inference_completion_cost": {"value": 0.0021904}, "meta_eval_time": {"value": 25.132}, "meta_eval_prompt_tokens": {"value": 5182.0}, "meta_eval_completion_tokens": {"value": 2283.0}, "meta_eval_prompt_cost": {"value": 0.00165824}, "meta_eval_completion_cost": {"value": 0.00292224}}, "created": "2025-12-10T21:55:08.6113697Z"}
{"ref": "staccato-bungalow", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.308294}, "meta_inference_prompt_tokens": {"value": 10425.0}, "meta_inference_completion_tokens": {"value": 856.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002085}, "meta_inference_completion_cost": {"value": 0.0013696}, "meta_eval_time": {"value": 23.716}, "meta_eval_prompt_tokens": {"value": 5734.0}, "meta_eval_completion_tokens": {"value": 2315.0}, "meta_eval_prompt_cost": {"value": 0.00183488}, "meta_eval_completion_cost": {"value": 0.0029632}}, "created": "2025-12-10T21:55:08.7603957Z"}
{"ref": "sparse-shares", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.821428571428571}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.771317}, "meta_inference_prompt_tokens": {"value": 11634.0}, "meta_inference_completion_tokens": {"value": 1226.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023268}, "meta_inference_completion_cost": {"value": 0.0019616}, "meta_eval_time": {"value": 37.884}, "meta_eval_prompt_tokens": {"value": 6567.0}, "meta_eval_completion_tokens": {"value": 2591.0}, "meta_eval_prompt_cost": {"value": 0.00210144}, "meta_eval_completion_cost": {"value": 0.00331648}}, "created": "2025-12-10T21:55:09.152441Z"}
{"ref": "spry-kapok-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 1.93067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.878048780487805}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 17.710516}, "meta_inference_prompt_tokens": {"value": 11795.0}, "meta_inference_completion_tokens": {"value": 839.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002359}, "meta_inference_completion_cost": {"value": 0.0013424}, "meta_eval_time": {"value": 35.883}, "meta_eval_prompt_tokens": {"value": 6845.0}, "meta_eval_completion_tokens": {"value": 2951.0}, "meta_eval_prompt_cost": {"value": 0.0021904}, "meta_eval_completion_cost": {"value": 0.00377728}}, "created": "2025-12-10T21:55:10.9374925Z"}
{"ref": "stale-option", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.944444444444444}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.155133}, "meta_inference_prompt_tokens": {"value": 9793.0}, "meta_inference_completion_tokens": {"value": 678.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019586}, "meta_inference_completion_cost": {"value": 0.0010848}, "meta_eval_time": {"value": 18.799}, "meta_eval_prompt_tokens": {"value": 4520.0}, "meta_eval_completion_tokens": {"value": 1631.0}, "meta_eval_prompt_cost": {"value": 0.0014464}, "meta_eval_completion_cost": {"value": 0.00208768}}, "created": "2025-12-10T21:55:11.2748346Z"}
{"ref": "sour-rectangle", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.979166666666666}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.111111111111111}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 35.547112}, "meta_inference_prompt_tokens": {"value": 12267.0}, "meta_inference_completion_tokens": {"value": 1867.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024534}, "meta_inference_completion_cost": {"value": 0.0029872}, "meta_eval_time": {"value": 47.896}, "meta_eval_prompt_tokens": {"value": 9441.0}, "meta_eval_completion_tokens": {"value": 4814.0}, "meta_eval_prompt_cost": {"value": 0.00302112}, "meta_eval_completion_cost": {"value": 0.00616192}}, "created": "2025-12-10T21:55:11.3184926Z"}
{"ref": "stable-factorial", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 1.017782560806}, "generation_faithfulness": {"value": 0.727272727272727}, "generation_factuality_f1": {"value": 0.413793103448276}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.222222222222222}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 19.111687}, "meta_inference_prompt_tokens": {"value": 8989.0}, "meta_inference_completion_tokens": {"value": 1332.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0017978}, "meta_inference_completion_cost": {"value": 0.0021312}, "meta_eval_time": {"value": 35.948}, "meta_eval_prompt_tokens": {"value": 5251.0}, "meta_eval_completion_tokens": {"value": 3326.0}, "meta_eval_prompt_cost": {"value": 0.00168032}, "meta_eval_completion_cost": {"value": 0.00425728}}, "created": "2025-12-10T21:55:11.7293946Z"}
{"ref": "spry-kapok-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 2.017782560806}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.872727272727273}, "generation_factuality_precision": {"value": 0.888888888888889}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 19.186242}, "meta_inference_prompt_tokens": {"value": 11578.0}, "meta_inference_completion_tokens": {"value": 796.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023156}, "meta_inference_completion_cost": {"value": 0.0012736}, "meta_eval_time": {"value": 26.738}, "meta_eval_prompt_tokens": {"value": 6634.0}, "meta_eval_completion_tokens": {"value": 2434.0}, "meta_eval_prompt_cost": {"value": 0.00212288}, "meta_eval_completion_cost": {"value": 0.00311552}}, "created": "2025-12-10T21:55:12.1451278Z"}
{"ref": "simple-audio-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.352941176470588}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.81546487678573}, "generation_faithfulness": {"value": 0.968253968253968}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.214285714285714}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.428571428571429}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 34.584844}, "meta_inference_prompt_tokens": {"value": 14652.0}, "meta_inference_completion_tokens": {"value": 2044.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029304}, "meta_inference_completion_cost": {"value": 0.0032704}, "meta_eval_time": {"value": 68.969}, "meta_eval_prompt_tokens": {"value": 13075.0}, "meta_eval_completion_tokens": {"value": 6239.0}, "meta_eval_prompt_cost": {"value": 0.004184}, "meta_eval_completion_cost": {"value": 0.00798592}}, "created": "2025-12-10T21:55:12.3954184Z"}
{"ref": "steel-precision", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.118452}, "meta_inference_prompt_tokens": {"value": 10540.0}, "meta_inference_completion_tokens": {"value": 1071.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002108}, "meta_inference_completion_cost": {"value": 0.0017136}, "meta_eval_time": {"value": 9.624}, "meta_eval_prompt_tokens": {"value": 4960.0}, "meta_eval_completion_tokens": {"value": 798.0}, "meta_eval_prompt_cost": {"value": 0.0015872}, "meta_eval_completion_cost": {"value": 0.00102144}}, "created": "2025-12-10T21:55:15.86578Z"}
{"ref": "steel-precision", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.96426308690479}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.732285}, "meta_inference_prompt_tokens": {"value": 10284.0}, "meta_inference_completion_tokens": {"value": 869.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020568}, "meta_inference_completion_cost": {"value": 0.0013904}, "meta_eval_time": {"value": 8.946}, "meta_eval_prompt_tokens": {"value": 4573.0}, "meta_eval_completion_tokens": {"value": 709.0}, "meta_eval_prompt_cost": {"value": 0.00146336}, "meta_eval_completion_cost": {"value": 0.00090752}}, "created": "2025-12-10T21:55:16.088669Z"}
{"ref": "steel-precision", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 0.777777777777778}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.607308}, "meta_inference_prompt_tokens": {"value": 11603.0}, "meta_inference_completion_tokens": {"value": 865.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023206}, "meta_inference_completion_cost": {"value": 0.001384}, "meta_eval_time": {"value": 11.382}, "meta_eval_prompt_tokens": {"value": 5703.0}, "meta_eval_completion_tokens": {"value": 987.0}, "meta_eval_prompt_cost": {"value": 0.00182496}, "meta_eval_completion_cost": {"value": 0.00126336}}, "created": "2025-12-10T21:55:17.5990662Z"}
{"ref": "sour-rectangle", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 30.889661}, "meta_inference_prompt_tokens": {"value": 14072.0}, "meta_inference_completion_tokens": {"value": 1557.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028144}, "meta_inference_completion_cost": {"value": 0.0024912}, "meta_eval_time": {"value": 57.398}, "meta_eval_prompt_tokens": {"value": 11231.0}, "meta_eval_completion_tokens": {"value": 5370.0}, "meta_eval_prompt_cost": {"value": 0.00359392}, "meta_eval_completion_cost": {"value": 0.0068736}}, "created": "2025-12-10T21:55:18.6237183Z"}
{"ref": "sour-rectangle", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.333333333333333}, "generation_faithfulness": {"value": 0.87719298245614}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 29.634966}, "meta_inference_prompt_tokens": {"value": 12995.0}, "meta_inference_completion_tokens": {"value": 1722.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002599}, "meta_inference_completion_cost": {"value": 0.0027552}, "meta_eval_time": {"value": 62.497}, "meta_eval_prompt_tokens": {"value": 9774.0}, "meta_eval_completion_tokens": {"value": 5490.0}, "meta_eval_prompt_cost": {"value": 0.00312768}, "meta_eval_completion_cost": {"value": 0.0070272}}, "created": "2025-12-10T21:55:18.8025248Z"}
{"ref": "steel-precision", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.444444444444444}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.285714285714286}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.1634}, "meta_inference_prompt_tokens": {"value": 8462.0}, "meta_inference_completion_tokens": {"value": 726.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0016924}, "meta_inference_completion_cost": {"value": 0.0011616}, "meta_eval_time": {"value": 10.44}, "meta_eval_prompt_tokens": {"value": 3964.0}, "meta_eval_completion_tokens": {"value": 793.0}, "meta_eval_prompt_cost": {"value": 0.00126848}, "meta_eval_completion_cost": {"value": 0.00101504}}, "created": "2025-12-10T21:55:19.0927983Z"}
{"ref": "stubborn-datum-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.73772}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 524.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0008384}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:19.1309394Z"}
{"ref": "sparse-smooth", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.31546487678573}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 43.924494}, "meta_inference_prompt_tokens": {"value": 13557.0}, "meta_inference_completion_tokens": {"value": 2491.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027114}, "meta_inference_completion_cost": {"value": 0.0039856}, "meta_eval_time": {"value": 50.123}, "meta_eval_prompt_tokens": {"value": 10656.0}, "meta_eval_completion_tokens": {"value": 4640.0}, "meta_eval_prompt_cost": {"value": 0.00340992}, "meta_eval_completion_cost": {"value": 0.0059392}}, "created": "2025-12-10T21:55:19.3247731Z"}
{"ref": "strong-plank", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.31303}, "meta_inference_prompt_tokens": {"value": 8450.0}, "meta_inference_completion_tokens": {"value": 635.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.00169}, "meta_inference_completion_cost": {"value": 0.001016}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:19.3629551Z"}
{"ref": "sour-rectangle", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.96875}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 33.489555}, "meta_inference_prompt_tokens": {"value": 12294.0}, "meta_inference_completion_tokens": {"value": 1432.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024588}, "meta_inference_completion_cost": {"value": 0.0022912}, "meta_eval_time": {"value": 57.375}, "meta_eval_prompt_tokens": {"value": 9285.0}, "meta_eval_completion_tokens": {"value": 5474.0}, "meta_eval_prompt_cost": {"value": 0.0029712}, "meta_eval_completion_cost": {"value": 0.00700672}}, "created": "2025-12-10T21:55:19.7309266Z"}
{"ref": "stubborn-datum-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.212769}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 981.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0015696}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:19.7670691Z"}
{"ref": "strong-plank", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.737287}, "meta_inference_prompt_tokens": {"value": 8435.0}, "meta_inference_completion_tokens": {"value": 843.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.001687}, "meta_inference_completion_cost": {"value": 0.0013488}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:19.8017036Z"}
{"ref": "strong-plank", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.875988}, "meta_inference_prompt_tokens": {"value": 25533.0}, "meta_inference_completion_tokens": {"value": 909.0}, "meta_inference_tool_call_count": {"value": 4.0}, "meta_inference_prompt_cost": {"value": 0.0051066}, "meta_inference_completion_cost": {"value": 0.0014544}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:19.8366301Z"}
{"ref": "stubborn-datum-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.290487}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 443.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0007088}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:19.8717234Z"}
{"ref": "spry-kapok-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.43195974923544}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.479124}, "meta_inference_prompt_tokens": {"value": 11706.0}, "meta_inference_completion_tokens": {"value": 773.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023412}, "meta_inference_completion_cost": {"value": 0.0012368}, "meta_eval_time": {"value": 34.851}, "meta_eval_prompt_tokens": {"value": 6949.0}, "meta_eval_completion_tokens": {"value": 3134.0}, "meta_eval_prompt_cost": {"value": 0.00222368}, "meta_eval_completion_cost": {"value": 0.00401152}}, "created": "2025-12-10T21:55:20.541129Z"}
{"ref": "stubborn-datum-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.851144}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 856.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0013696}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:20.5787314Z"}
{"ref": "strong-plank", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.516811}, "meta_inference_prompt_tokens": {"value": 11763.0}, "meta_inference_completion_tokens": {"value": 562.0}, "meta_inference_tool_call_count": {"value": 3.0}, "meta_inference_prompt_cost": {"value": 0.0023526}, "meta_inference_completion_cost": {"value": 0.0008992}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:20.6179936Z"}
{"ref": "sparse-smooth", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.315789473684211}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 31.370432}, "meta_inference_prompt_tokens": {"value": 13305.0}, "meta_inference_completion_tokens": {"value": 2019.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002661}, "meta_inference_completion_cost": {"value": 0.0032304}, "meta_eval_time": {"value": 52.401}, "meta_eval_prompt_tokens": {"value": 10388.0}, "meta_eval_completion_tokens": {"value": 5321.0}, "meta_eval_prompt_cost": {"value": 0.00332416}, "meta_eval_completion_cost": {"value": 0.00681088}}, "created": "2025-12-10T21:55:22.1013007Z"}
{"ref": "stubborn-datum-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.816798}, "meta_inference_prompt_tokens": {"value": 4684.0}, "meta_inference_completion_tokens": {"value": 1552.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009368}, "meta_inference_completion_cost": {"value": 0.0024832}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:22.1463052Z"}
{"ref": "steel-precision", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.98933}, "meta_inference_prompt_tokens": {"value": 10363.0}, "meta_inference_completion_tokens": {"value": 909.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020726}, "meta_inference_completion_cost": {"value": 0.0014544}, "meta_eval_time": {"value": 14.721}, "meta_eval_prompt_tokens": {"value": 5103.0}, "meta_eval_completion_tokens": {"value": 1406.0}, "meta_eval_prompt_cost": {"value": 0.00163296}, "meta_eval_completion_cost": {"value": 0.00179968}}, "created": "2025-12-10T21:55:22.8266571Z"}
{"ref": "strong-plank", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.068864}, "meta_inference_prompt_tokens": {"value": 4661.0}, "meta_inference_completion_tokens": {"value": 333.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009322}, "meta_inference_completion_cost": {"value": 0.0005328}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:22.8660609Z"}
{"ref": "stale-dragster", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.387096774193548}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 20.350324}, "meta_inference_prompt_tokens": {"value": 11783.0}, "meta_inference_completion_tokens": {"value": 961.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023566}, "meta_inference_completion_cost": {"value": 0.0015376}, "meta_eval_time": {"value": 32.637}, "meta_eval_prompt_tokens": {"value": 7205.0}, "meta_eval_completion_tokens": {"value": 2821.0}, "meta_eval_prompt_cost": {"value": 0.0023056}, "meta_eval_completion_cost": {"value": 0.00361088}}, "created": "2025-12-10T21:55:23.8914971Z"}
{"ref": "sparse-smooth", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.315789473684211}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 40.725751}, "meta_inference_prompt_tokens": {"value": 14291.0}, "meta_inference_completion_tokens": {"value": 3139.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028582}, "meta_inference_completion_cost": {"value": 0.0050224}, "meta_eval_time": {"value": 50.108}, "meta_eval_prompt_tokens": {"value": 11330.0}, "meta_eval_completion_tokens": {"value": 4963.0}, "meta_eval_prompt_cost": {"value": 0.0036256}, "meta_eval_completion_cost": {"value": 0.00635264}}, "created": "2025-12-10T21:55:25.7392013Z"}
{"ref": "stable-factorial", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 0.333333333333333}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.954545454545454}, "generation_factuality_f1": {"value": 0.315789473684211}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 34.824946}, "meta_inference_prompt_tokens": {"value": 11177.0}, "meta_inference_completion_tokens": {"value": 1803.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022354}, "meta_inference_completion_cost": {"value": 0.0028848}, "meta_eval_time": {"value": 48.246}, "meta_eval_prompt_tokens": {"value": 8084.0}, "meta_eval_completion_tokens": {"value": 4388.0}, "meta_eval_prompt_cost": {"value": 0.00258688}, "meta_eval_completion_cost": {"value": 0.00561664}}, "created": "2025-12-10T21:55:26.8173209Z"}
{"ref": "stale-dragster", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.215943}, "meta_inference_prompt_tokens": {"value": 12549.0}, "meta_inference_completion_tokens": {"value": 1403.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025098}, "meta_inference_completion_cost": {"value": 0.0022448}, "meta_eval_time": {"value": 40.473}, "meta_eval_prompt_tokens": {"value": 7994.0}, "meta_eval_completion_tokens": {"value": 3570.0}, "meta_eval_prompt_cost": {"value": 0.00255808}, "meta_eval_completion_cost": {"value": 0.0045696}}, "created": "2025-12-10T21:55:28.0360215Z"}
{"ref": "sparse-smooth", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 47.433029}, "meta_inference_prompt_tokens": {"value": 14369.0}, "meta_inference_completion_tokens": {"value": 2877.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028738}, "meta_inference_completion_cost": {"value": 0.0046032}, "meta_eval_time": {"value": 58.675}, "meta_eval_prompt_tokens": {"value": 11865.0}, "meta_eval_completion_tokens": {"value": 5008.0}, "meta_eval_prompt_cost": {"value": 0.0037968}, "meta_eval_completion_cost": {"value": 0.00641024}}, "created": "2025-12-10T21:55:29.3228414Z"}
{"ref": "stern-thumbnail", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 0.818181818181818}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.369092}, "meta_inference_prompt_tokens": {"value": 12268.0}, "meta_inference_completion_tokens": {"value": 1447.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024536}, "meta_inference_completion_cost": {"value": 0.0023152}, "meta_eval_time": {"value": 18.378}, "meta_eval_prompt_tokens": {"value": 7078.0}, "meta_eval_completion_tokens": {"value": 1670.0}, "meta_eval_prompt_cost": {"value": 0.00226496}, "meta_eval_completion_cost": {"value": 0.0021376}}, "created": "2025-12-10T21:55:30.5614115Z"}
{"ref": "stable-factorial", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.856207187108022}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.245058}, "meta_inference_prompt_tokens": {"value": 12540.0}, "meta_inference_completion_tokens": {"value": 1942.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002508}, "meta_inference_completion_cost": {"value": 0.0031072}, "meta_eval_time": {"value": 55.159}, "meta_eval_prompt_tokens": {"value": 9844.0}, "meta_eval_completion_tokens": {"value": 5238.0}, "meta_eval_prompt_cost": {"value": 0.00315008}, "meta_eval_completion_cost": {"value": 0.00670464}}, "created": "2025-12-10T21:55:30.6358177Z"}
{"ref": "stable-factorial", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 0.767441860465116}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.567189}, "meta_inference_prompt_tokens": {"value": 8895.0}, "meta_inference_completion_tokens": {"value": 1521.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001779}, "meta_inference_completion_cost": {"value": 0.0024336}, "meta_eval_time": {"value": 45.582}, "meta_eval_prompt_tokens": {"value": 6603.0}, "meta_eval_completion_tokens": {"value": 4202.0}, "meta_eval_prompt_cost": {"value": 0.00211296}, "meta_eval_completion_cost": {"value": 0.00537856}}, "created": "2025-12-10T21:55:31.0474843Z"}
{"ref": "strong-deposition", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 1.63436332899731}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 15.364864}, "meta_inference_prompt_tokens": {"value": 12519.0}, "meta_inference_completion_tokens": {"value": 643.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025038}, "meta_inference_completion_cost": {"value": 0.0010288}, "meta_eval_time": {"value": 20.311}, "meta_eval_prompt_tokens": {"value": 7017.0}, "meta_eval_completion_tokens": {"value": 1810.0}, "meta_eval_prompt_cost": {"value": 0.00224544}, "meta_eval_completion_cost": {"value": 0.0023168}}, "created": "2025-12-10T21:55:32.0824778Z"}
{"ref": "sparse-smooth", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.428571428571428}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 43.494219}, "meta_inference_prompt_tokens": {"value": 13197.0}, "meta_inference_completion_tokens": {"value": 2752.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026394}, "meta_inference_completion_cost": {"value": 0.0044032}, "meta_eval_time": {"value": 63.953}, "meta_eval_prompt_tokens": {"value": 11481.0}, "meta_eval_completion_tokens": {"value": 5820.0}, "meta_eval_prompt_cost": {"value": 0.00367392}, "meta_eval_completion_cost": {"value": 0.0074496}}, "created": "2025-12-10T21:55:33.6022017Z"}
{"ref": "steel-banner-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.56160631164485}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.291096}, "meta_inference_prompt_tokens": {"value": 14227.0}, "meta_inference_completion_tokens": {"value": 1259.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028454}, "meta_inference_completion_cost": {"value": 0.0020144}, "meta_eval_time": {"value": 33.161}, "meta_eval_prompt_tokens": {"value": 10686.0}, "meta_eval_completion_tokens": {"value": 3451.0}, "meta_eval_prompt_cost": {"value": 0.00341952}, "meta_eval_completion_cost": {"value": 0.00441728}}, "created": "2025-12-10T21:55:34.627835Z"}
{"ref": "steel-banner-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 0.970588235294118}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.885379}, "meta_inference_prompt_tokens": {"value": 13473.0}, "meta_inference_completion_tokens": {"value": 1344.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026946}, "meta_inference_completion_cost": {"value": 0.0021504}, "meta_eval_time": {"value": 39.067}, "meta_eval_prompt_tokens": {"value": 9968.0}, "meta_eval_completion_tokens": {"value": 3675.0}, "meta_eval_prompt_cost": {"value": 0.00318976}, "meta_eval_completion_cost": {"value": 0.004704}}, "created": "2025-12-10T21:55:35.0603073Z"}
{"ref": "stale-dragster", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.98713694067948}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.636368}, "meta_inference_prompt_tokens": {"value": 14444.0}, "meta_inference_completion_tokens": {"value": 1394.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028888}, "meta_inference_completion_cost": {"value": 0.0022304}, "meta_eval_time": {"value": 44.23}, "meta_eval_prompt_tokens": {"value": 10169.0}, "meta_eval_completion_tokens": {"value": 3954.0}, "meta_eval_prompt_cost": {"value": 0.00325408}, "meta_eval_completion_cost": {"value": 0.00506112}}, "created": "2025-12-10T21:55:35.3474102Z"}
{"ref": "steel-banner-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 0.967741935483871}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.464427}, "meta_inference_prompt_tokens": {"value": 15147.0}, "meta_inference_completion_tokens": {"value": 1304.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030294}, "meta_inference_completion_cost": {"value": 0.0020864}, "meta_eval_time": {"value": 34.334}, "meta_eval_prompt_tokens": {"value": 11450.0}, "meta_eval_completion_tokens": {"value": 3317.0}, "meta_eval_prompt_cost": {"value": 0.003664}, "meta_eval_completion_cost": {"value": 0.00424576}}, "created": "2025-12-10T21:55:35.5329316Z"}
{"ref": "stern-kicker", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.212878}, "meta_inference_prompt_tokens": {"value": 9259.0}, "meta_inference_completion_tokens": {"value": 1122.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018518}, "meta_inference_completion_cost": {"value": 0.0017952}, "meta_eval_time": {"value": 27.194}, "meta_eval_prompt_tokens": {"value": 4408.0}, "meta_eval_completion_tokens": {"value": 1848.0}, "meta_eval_prompt_cost": {"value": 0.00141056}, "meta_eval_completion_cost": {"value": 0.00236544}}, "created": "2025-12-10T21:55:36.3844188Z"}
{"ref": "stale-dragster", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.91304347826087}, "generation_factuality_f1": {"value": 0.533333333333333}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 26.073533}, "meta_inference_prompt_tokens": {"value": 11686.0}, "meta_inference_completion_tokens": {"value": 1384.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023372}, "meta_inference_completion_cost": {"value": 0.0022144}, "meta_eval_time": {"value": 49.702}, "meta_eval_prompt_tokens": {"value": 7685.0}, "meta_eval_completion_tokens": {"value": 4128.0}, "meta_eval_prompt_cost": {"value": 0.0024592}, "meta_eval_completion_cost": {"value": 0.00528384}}, "created": "2025-12-10T21:55:36.4967989Z"}
{"ref": "stern-thumbnail", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 1.74614143485912}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.829263}, "meta_inference_prompt_tokens": {"value": 11628.0}, "meta_inference_completion_tokens": {"value": 1323.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023256}, "meta_inference_completion_cost": {"value": 0.0021168}, "meta_eval_time": {"value": 20.942}, "meta_eval_prompt_tokens": {"value": 6521.0}, "meta_eval_completion_tokens": {"value": 1947.0}, "meta_eval_prompt_cost": {"value": 0.00208672}, "meta_eval_completion_cost": {"value": 0.00249216}}, "created": "2025-12-10T21:55:37.0795194Z"}
{"ref": "stern-thumbnail", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 1.74614143485912}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.093676}, "meta_inference_prompt_tokens": {"value": 11196.0}, "meta_inference_completion_tokens": {"value": 1257.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022392}, "meta_inference_completion_cost": {"value": 0.0020112}, "meta_eval_time": {"value": 26.21}, "meta_eval_prompt_tokens": {"value": 6105.0}, "meta_eval_completion_tokens": {"value": 2028.0}, "meta_eval_prompt_cost": {"value": 0.0019536}, "meta_eval_completion_cost": {"value": 0.00259584}}, "created": "2025-12-10T21:55:37.190086Z"}
{"ref": "steel-banner-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.017782560806}, "generation_faithfulness": {"value": 0.96969696969697}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.957884}, "meta_inference_prompt_tokens": {"value": 14309.0}, "meta_inference_completion_tokens": {"value": 1269.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028618}, "meta_inference_completion_cost": {"value": 0.0020304}, "meta_eval_time": {"value": 36.137}, "meta_eval_prompt_tokens": {"value": 10523.0}, "meta_eval_completion_tokens": {"value": 3306.0}, "meta_eval_prompt_cost": {"value": 0.00336736}, "meta_eval_completion_cost": {"value": 0.00423168}}, "created": "2025-12-10T21:55:37.6172581Z"}
{"ref": "stern-kicker", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.730769230769231}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.144619}, "meta_inference_prompt_tokens": {"value": 9474.0}, "meta_inference_completion_tokens": {"value": 1192.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018948}, "meta_inference_completion_cost": {"value": 0.0019072}, "meta_eval_time": {"value": 29.33}, "meta_eval_prompt_tokens": {"value": 5074.0}, "meta_eval_completion_tokens": {"value": 2792.0}, "meta_eval_prompt_cost": {"value": 0.00162368}, "meta_eval_completion_cost": {"value": 0.00357376}}, "created": "2025-12-10T21:55:38.1305811Z"}
{"ref": "stern-thumbnail", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 1.657237182772}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.763799}, "meta_inference_prompt_tokens": {"value": 12574.0}, "meta_inference_completion_tokens": {"value": 1100.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025148}, "meta_inference_completion_cost": {"value": 0.00176}, "meta_eval_time": {"value": 27.002}, "meta_eval_prompt_tokens": {"value": 7865.0}, "meta_eval_completion_tokens": {"value": 2276.0}, "meta_eval_prompt_cost": {"value": 0.0025168}, "meta_eval_completion_cost": {"value": 0.00291328}}, "created": "2025-12-10T21:55:39.4361579Z"}
{"ref": "sunny-pointer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.041803}, "meta_inference_prompt_tokens": {"value": 11651.0}, "meta_inference_completion_tokens": {"value": 430.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023302}, "meta_inference_completion_cost": {"value": 0.000688}, "meta_eval_time": {"value": 9.123}, "meta_eval_prompt_tokens": {"value": 5774.0}, "meta_eval_completion_tokens": {"value": 695.0}, "meta_eval_prompt_cost": {"value": 0.00184768}, "meta_eval_completion_cost": {"value": 0.0008896}}, "created": "2025-12-10T21:55:39.7997655Z"}
{"ref": "stern-thumbnail", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.428571428571428}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 0.818181818181818}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.272727272727273}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.698909}, "meta_inference_prompt_tokens": {"value": 12758.0}, "meta_inference_completion_tokens": {"value": 933.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025516}, "meta_inference_completion_cost": {"value": 0.0014928}, "meta_eval_time": {"value": 21.321}, "meta_eval_prompt_tokens": {"value": 7314.0}, "meta_eval_completion_tokens": {"value": 1572.0}, "meta_eval_prompt_cost": {"value": 0.00234048}, "meta_eval_completion_cost": {"value": 0.00201216}}, "created": "2025-12-10T21:55:39.9830172Z"}
{"ref": "sunny-pointer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.576862}, "meta_inference_prompt_tokens": {"value": 11652.0}, "meta_inference_completion_tokens": {"value": 424.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023304}, "meta_inference_completion_cost": {"value": 0.0006784}, "meta_eval_time": {"value": 8.11}, "meta_eval_prompt_tokens": {"value": 5756.0}, "meta_eval_completion_tokens": {"value": 667.0}, "meta_eval_prompt_cost": {"value": 0.00184192}, "meta_eval_completion_cost": {"value": 0.00085376}}, "created": "2025-12-10T21:55:40.2522586Z"}
{"ref": "strong-deposition", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.291666666666667}, "retrieval_dcg": {"value": 0.833333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.585365853658536}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.6}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.4}, "generation_correctness": {"value": 0.6}, "meta_inference_time": {"value": 17.842621}, "meta_inference_prompt_tokens": {"value": 12423.0}, "meta_inference_completion_tokens": {"value": 772.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024846}, "meta_inference_completion_cost": {"value": 0.0012352}, "meta_eval_time": {"value": 21.338}, "meta_eval_prompt_tokens": {"value": 7164.0}, "meta_eval_completion_tokens": {"value": 2112.0}, "meta_eval_prompt_cost": {"value": 0.00229248}, "meta_eval_completion_cost": {"value": 0.00270336}}, "created": "2025-12-10T21:55:40.5124309Z"}
{"ref": "strong-deposition", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.291666666666667}, "retrieval_dcg": {"value": 0.833333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.4}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 17.791703}, "meta_inference_prompt_tokens": {"value": 12426.0}, "meta_inference_completion_tokens": {"value": 964.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024852}, "meta_inference_completion_cost": {"value": 0.0015424}, "meta_eval_time": {"value": 25.678}, "meta_eval_prompt_tokens": {"value": 7129.0}, "meta_eval_completion_tokens": {"value": 2127.0}, "meta_eval_prompt_cost": {"value": 0.00228128}, "meta_eval_completion_cost": {"value": 0.00272256}}, "created": "2025-12-10T21:55:41.5963753Z"}
{"ref": "stern-kicker", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.635334}, "meta_inference_prompt_tokens": {"value": 9646.0}, "meta_inference_completion_tokens": {"value": 1271.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019292}, "meta_inference_completion_cost": {"value": 0.0020336}, "meta_eval_time": {"value": 31.164}, "meta_eval_prompt_tokens": {"value": 5115.0}, "meta_eval_completion_tokens": {"value": 2794.0}, "meta_eval_prompt_cost": {"value": 0.0016368}, "meta_eval_completion_cost": {"value": 0.00357632}}, "created": "2025-12-10T21:55:42.5290502Z"}
{"ref": "stern-kicker", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.96969696969697}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.696018}, "meta_inference_prompt_tokens": {"value": 9838.0}, "meta_inference_completion_tokens": {"value": 1188.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019676}, "meta_inference_completion_cost": {"value": 0.0019008}, "meta_eval_time": {"value": 31.562}, "meta_eval_prompt_tokens": {"value": 5450.0}, "meta_eval_completion_tokens": {"value": 3270.0}, "meta_eval_prompt_cost": {"value": 0.001744}, "meta_eval_completion_cost": {"value": 0.0041856}}, "created": "2025-12-10T21:55:42.8771259Z"}
{"ref": "sunny-pointer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.940553}, "meta_inference_prompt_tokens": {"value": 11650.0}, "meta_inference_completion_tokens": {"value": 370.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00233}, "meta_inference_completion_cost": {"value": 0.000592}, "meta_eval_time": {"value": 8.553}, "meta_eval_prompt_tokens": {"value": 5780.0}, "meta_eval_completion_tokens": {"value": 713.0}, "meta_eval_prompt_cost": {"value": 0.0018496}, "meta_eval_completion_cost": {"value": 0.00091264}}, "created": "2025-12-10T21:55:43.935499Z"}
{"ref": "stern-kicker", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.625}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.387434}, "meta_inference_prompt_tokens": {"value": 9622.0}, "meta_inference_completion_tokens": {"value": 1000.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019244}, "meta_inference_completion_cost": {"value": 0.0016}, "meta_eval_time": {"value": 26.021}, "meta_eval_prompt_tokens": {"value": 4651.0}, "meta_eval_completion_tokens": {"value": 1834.0}, "meta_eval_prompt_cost": {"value": 0.00148832}, "meta_eval_completion_cost": {"value": 0.00234752}}, "created": "2025-12-10T21:55:44.8638578Z"}
{"ref": "sunny-pointer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.012875}, "meta_inference_prompt_tokens": {"value": 11651.0}, "meta_inference_completion_tokens": {"value": 435.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023302}, "meta_inference_completion_cost": {"value": 0.000696}, "meta_eval_time": {"value": 10.551}, "meta_eval_prompt_tokens": {"value": 5792.0}, "meta_eval_completion_tokens": {"value": 812.0}, "meta_eval_prompt_cost": {"value": 0.00185344}, "meta_eval_completion_cost": {"value": 0.00103936}}, "created": "2025-12-10T21:55:45.2184805Z"}
{"ref": "sunny-bar", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.842105263157895}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.056459}, "meta_inference_prompt_tokens": {"value": 11757.0}, "meta_inference_completion_tokens": {"value": 912.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023514}, "meta_inference_completion_cost": {"value": 0.0014592}, "meta_eval_time": {"value": 25.437}, "meta_eval_prompt_tokens": {"value": 6882.0}, "meta_eval_completion_tokens": {"value": 2101.0}, "meta_eval_prompt_cost": {"value": 0.00220224}, "meta_eval_completion_cost": {"value": 0.00268928}}, "created": "2025-12-10T21:55:46.0910782Z"}
{"ref": "stale-dragster", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.946394630357186}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.226032}, "meta_inference_prompt_tokens": {"value": 12697.0}, "meta_inference_completion_tokens": {"value": 1890.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025394}, "meta_inference_completion_cost": {"value": 0.003024}, "meta_eval_time": {"value": 57.085}, "meta_eval_prompt_tokens": {"value": 9246.0}, "meta_eval_completion_tokens": {"value": 4886.0}, "meta_eval_prompt_cost": {"value": 0.00295872}, "meta_eval_completion_cost": {"value": 0.00625408}}, "created": "2025-12-10T21:55:47.5081001Z"}
{"ref": "sunny-bar", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.791666666666666}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.223335}, "meta_inference_prompt_tokens": {"value": 11972.0}, "meta_inference_completion_tokens": {"value": 1195.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023944}, "meta_inference_completion_cost": {"value": 0.001912}, "meta_eval_time": {"value": 27.074}, "meta_eval_prompt_tokens": {"value": 7356.0}, "meta_eval_completion_tokens": {"value": 2661.0}, "meta_eval_prompt_cost": {"value": 0.00235392}, "meta_eval_completion_cost": {"value": 0.00340608}}, "created": "2025-12-10T21:55:51.0114471Z"}
{"ref": "sunny-bar", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.566447}, "meta_inference_prompt_tokens": {"value": 11430.0}, "meta_inference_completion_tokens": {"value": 1146.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002286}, "meta_inference_completion_cost": {"value": 0.0018336}, "meta_eval_time": {"value": 32.025}, "meta_eval_prompt_tokens": {"value": 7439.0}, "meta_eval_completion_tokens": {"value": 3102.0}, "meta_eval_prompt_cost": {"value": 0.00238048}, "meta_eval_completion_cost": {"value": 0.00397056}}, "created": "2025-12-10T21:55:51.9317015Z"}
{"ref": "steel-banner-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 1.28906482631789}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.541503}, "meta_inference_prompt_tokens": {"value": 13171.0}, "meta_inference_completion_tokens": {"value": 1967.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026342}, "meta_inference_completion_cost": {"value": 0.0031472}, "meta_eval_time": {"value": 51.313}, "meta_eval_prompt_tokens": {"value": 10450.0}, "meta_eval_completion_tokens": {"value": 4875.0}, "meta_eval_prompt_cost": {"value": 0.003344}, "meta_eval_completion_cost": {"value": 0.00624}}, "created": "2025-12-10T21:55:52.0332323Z"}
{"ref": "sunny-bar", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.142368}, "meta_inference_prompt_tokens": {"value": 11754.0}, "meta_inference_completion_tokens": {"value": 1125.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023508}, "meta_inference_completion_cost": {"value": 0.0018}, "meta_eval_time": {"value": 27.362}, "meta_eval_prompt_tokens": {"value": 7281.0}, "meta_eval_completion_tokens": {"value": 2438.0}, "meta_eval_prompt_cost": {"value": 0.00232992}, "meta_eval_completion_cost": {"value": 0.00312064}}, "created": "2025-12-10T21:55:53.1390263Z"}
{"ref": "steel-banner-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 0.886852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.026342}, "meta_inference_prompt_tokens": {"value": 13213.0}, "meta_inference_completion_tokens": {"value": 1671.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026426}, "meta_inference_completion_cost": {"value": 0.0026736}, "meta_eval_time": {"value": 49.612}, "meta_eval_prompt_tokens": {"value": 10304.0}, "meta_eval_completion_tokens": {"value": 4871.0}, "meta_eval_prompt_cost": {"value": 0.00329728}, "meta_eval_completion_cost": {"value": 0.00623488}}, "created": "2025-12-10T21:55:54.1417777Z"}
{"ref": "steel-banner-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.571428571428572}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 1.80466630598741}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.4}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.549467}, "meta_inference_prompt_tokens": {"value": 15345.0}, "meta_inference_completion_tokens": {"value": 1875.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003069}, "meta_inference_completion_cost": {"value": 0.003}, "meta_eval_time": {"value": 53.201}, "meta_eval_prompt_tokens": {"value": 12654.0}, "meta_eval_completion_tokens": {"value": 4796.0}, "meta_eval_prompt_cost": {"value": 0.00404928}, "meta_eval_completion_cost": {"value": 0.00613888}}, "created": "2025-12-10T21:55:54.1420321Z"}
{"ref": "syrupy-azimuth", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 2.80468925342755}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 0.0}, "retrieval_precision": {"value": 0.0384615384615385}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 67.181079}, "meta_inference_prompt_tokens": {"value": 114743.0}, "meta_inference_completion_tokens": {"value": 1982.0}, "meta_inference_tool_call_count": {"value": 8.0}, "meta_inference_prompt_cost": {"value": 0.0229486}, "meta_inference_completion_cost": {"value": 0.0031712}, "meta_eval_time": {"value": 0.004}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:54.1714797Z"}
{"ref": "strong-deposition", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 1.35067113796274}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 20.714427}, "meta_inference_prompt_tokens": {"value": 13347.0}, "meta_inference_completion_tokens": {"value": 945.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026694}, "meta_inference_completion_cost": {"value": 0.001512}, "meta_eval_time": {"value": 37.618}, "meta_eval_prompt_tokens": {"value": 8425.0}, "meta_eval_completion_tokens": {"value": 3266.0}, "meta_eval_prompt_cost": {"value": 0.002696}, "meta_eval_completion_cost": {"value": 0.00418048}}, "created": "2025-12-10T21:55:55.2581655Z"}
{"ref": "steel-banner-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.85620718710802}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.533846}, "meta_inference_prompt_tokens": {"value": 14640.0}, "meta_inference_completion_tokens": {"value": 2037.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002928}, "meta_inference_completion_cost": {"value": 0.0032592}, "meta_eval_time": {"value": 57.902}, "meta_eval_prompt_tokens": {"value": 11914.0}, "meta_eval_completion_tokens": {"value": 4319.0}, "meta_eval_prompt_cost": {"value": 0.00381248}, "meta_eval_completion_cost": {"value": 0.00552832}}, "created": "2025-12-10T21:55:55.2787708Z"}
{"ref": "synchronic-fontina", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.8}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 26.195468}, "meta_inference_prompt_tokens": {"value": 6746.0}, "meta_inference_completion_tokens": {"value": 1344.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0013492}, "meta_inference_completion_cost": {"value": 0.0021504}, "meta_eval_time": {"value": 15.238}, "meta_eval_prompt_tokens": {"value": 2913.0}, "meta_eval_completion_tokens": {"value": 1711.0}, "meta_eval_prompt_cost": {"value": 0.00093216}, "meta_eval_completion_cost": {"value": 0.00219008}}, "created": "2025-12-10T21:55:55.528118Z"}
{"ref": "steel-banner-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.625}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.242473}, "meta_inference_prompt_tokens": {"value": 14389.0}, "meta_inference_completion_tokens": {"value": 1499.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028778}, "meta_inference_completion_cost": {"value": 0.0023984}, "meta_eval_time": {"value": 54.923}, "meta_eval_prompt_tokens": {"value": 11834.0}, "meta_eval_completion_tokens": {"value": 5280.0}, "meta_eval_prompt_cost": {"value": 0.00378688}, "meta_eval_completion_cost": {"value": 0.0067584}}, "created": "2025-12-10T21:55:55.5801127Z"}
{"ref": "sunny-pointer", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.630596}, "meta_inference_prompt_tokens": {"value": 11656.0}, "meta_inference_completion_tokens": {"value": 504.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023312}, "meta_inference_completion_cost": {"value": 0.0008064}, "meta_eval_time": {"value": 9.565}, "meta_eval_prompt_tokens": {"value": 5801.0}, "meta_eval_completion_tokens": {"value": 747.0}, "meta_eval_prompt_cost": {"value": 0.00185632}, "meta_eval_completion_cost": {"value": 0.00095616}}, "created": "2025-12-10T21:55:57.1170389Z"}
{"ref": "sunny-bar", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.837837837837838}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.042932}, "meta_inference_prompt_tokens": {"value": 11467.0}, "meta_inference_completion_tokens": {"value": 1243.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022934}, "meta_inference_completion_cost": {"value": 0.0019888}, "meta_eval_time": {"value": 38.944}, "meta_eval_prompt_tokens": {"value": 7559.0}, "meta_eval_completion_tokens": {"value": 3741.0}, "meta_eval_prompt_cost": {"value": 0.00241888}, "meta_eval_completion_cost": {"value": 0.00478848}}, "created": "2025-12-10T21:55:58.3465671Z"}
{"ref": "tan-cello-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.051979}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 644.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0010304}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:58.380408Z"}
{"ref": "sunny-pear", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.011398}, "meta_inference_prompt_tokens": {"value": 13109.0}, "meta_inference_completion_tokens": {"value": 981.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026218}, "meta_inference_completion_cost": {"value": 0.0015696}, "meta_eval_time": {"value": 36.462}, "meta_eval_prompt_tokens": {"value": 8808.0}, "meta_eval_completion_tokens": {"value": 3272.0}, "meta_eval_prompt_cost": {"value": 0.00281856}, "meta_eval_completion_cost": {"value": 0.00418816}}, "created": "2025-12-10T21:55:58.6511721Z"}
{"ref": "tan-cello-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.369671}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 976.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0015616}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:58.6843641Z"}
{"ref": "steel-banner-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.78688374518142}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.75}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 35.933453}, "meta_inference_prompt_tokens": {"value": 14983.0}, "meta_inference_completion_tokens": {"value": 1787.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029966}, "meta_inference_completion_cost": {"value": 0.0028592}, "meta_eval_time": {"value": 65.85}, "meta_eval_prompt_tokens": {"value": 13020.0}, "meta_eval_completion_tokens": {"value": 6524.0}, "meta_eval_prompt_cost": {"value": 0.0041664}, "meta_eval_completion_cost": {"value": 0.00835072}}, "created": "2025-12-10T21:55:58.8370315Z"}
{"ref": "sunny-sample", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.904761904761905}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.724004}, "meta_inference_prompt_tokens": {"value": 10009.0}, "meta_inference_completion_tokens": {"value": 910.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020018}, "meta_inference_completion_cost": {"value": 0.001456}, "meta_eval_time": {"value": 28.37}, "meta_eval_prompt_tokens": {"value": 5788.0}, "meta_eval_completion_tokens": {"value": 2683.0}, "meta_eval_prompt_cost": {"value": 0.00185216}, "meta_eval_completion_cost": {"value": 0.00343424}}, "created": "2025-12-10T21:55:59.8470859Z"}
{"ref": "sunny-sample", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.095773}, "meta_inference_prompt_tokens": {"value": 9597.0}, "meta_inference_completion_tokens": {"value": 955.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019194}, "meta_inference_completion_cost": {"value": 0.001528}, "meta_eval_time": {"value": 29.188}, "meta_eval_prompt_tokens": {"value": 5330.0}, "meta_eval_completion_tokens": {"value": 2888.0}, "meta_eval_prompt_cost": {"value": 0.0017056}, "meta_eval_completion_cost": {"value": 0.00369664}}, "created": "2025-12-10T21:55:59.8475221Z"}
{"ref": "tan-cello-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.778455}, "meta_inference_prompt_tokens": {"value": 2248.0}, "meta_inference_completion_tokens": {"value": 701.0}, "meta_inference_prompt_cost": {"value": 0.0004496}, "meta_inference_completion_cost": {"value": 0.0011216}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:55:59.916771Z"}
{"ref": "sunny-sample", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.956521739130435}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.037919}, "meta_inference_prompt_tokens": {"value": 9867.0}, "meta_inference_completion_tokens": {"value": 1046.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019734}, "meta_inference_completion_cost": {"value": 0.0016736}, "meta_eval_time": {"value": 25.229}, "meta_eval_prompt_tokens": {"value": 5669.0}, "meta_eval_completion_tokens": {"value": 2702.0}, "meta_eval_prompt_cost": {"value": 0.00181408}, "meta_eval_completion_cost": {"value": 0.00345856}}, "created": "2025-12-10T21:56:00.7960244Z"}
{"ref": "swarm-round", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.695652173913044}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.321561}, "meta_inference_prompt_tokens": {"value": 10435.0}, "meta_inference_completion_tokens": {"value": 1144.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002087}, "meta_inference_completion_cost": {"value": 0.0018304}, "meta_eval_time": {"value": 24.441}, "meta_eval_prompt_tokens": {"value": 5609.0}, "meta_eval_completion_tokens": {"value": 2302.0}, "meta_eval_prompt_cost": {"value": 0.00179488}, "meta_eval_completion_cost": {"value": 0.00294656}}, "created": "2025-12-10T21:56:01.6676419Z"}
{"ref": "strong-deposition", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.527777777777778}, "retrieval_dcg": {"value": 1.93067655807339}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.188181}, "meta_inference_prompt_tokens": {"value": 12634.0}, "meta_inference_completion_tokens": {"value": 919.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025268}, "meta_inference_completion_cost": {"value": 0.0014704}, "meta_eval_time": {"value": 38.791}, "meta_eval_prompt_tokens": {"value": 8254.0}, "meta_eval_completion_tokens": {"value": 3124.0}, "meta_eval_prompt_cost": {"value": 0.00264128}, "meta_eval_completion_cost": {"value": 0.00399872}}, "created": "2025-12-10T21:56:01.6958234Z"}
{"ref": "synchronic-novella", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.865621}, "meta_inference_prompt_tokens": {"value": 9662.0}, "meta_inference_completion_tokens": {"value": 791.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019324}, "meta_inference_completion_cost": {"value": 0.0012656}, "meta_eval_time": {"value": 16.997}, "meta_eval_prompt_tokens": {"value": 4279.0}, "meta_eval_completion_tokens": {"value": 1364.0}, "meta_eval_prompt_cost": {"value": 0.00136928}, "meta_eval_completion_cost": {"value": 0.00174592}}, "created": "2025-12-10T21:56:01.9024376Z"}
{"ref": "sunny-pear", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.638647}, "meta_inference_prompt_tokens": {"value": 13333.0}, "meta_inference_completion_tokens": {"value": 1114.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026666}, "meta_inference_completion_cost": {"value": 0.0017824}, "meta_eval_time": {"value": 35.202}, "meta_eval_prompt_tokens": {"value": 8806.0}, "meta_eval_completion_tokens": {"value": 3094.0}, "meta_eval_prompt_cost": {"value": 0.00281792}, "meta_eval_completion_cost": {"value": 0.00396032}}, "created": "2025-12-10T21:56:02.0843152Z"}
{"ref": "swarm-round", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.431836}, "meta_inference_prompt_tokens": {"value": 10370.0}, "meta_inference_completion_tokens": {"value": 1091.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002074}, "meta_inference_completion_cost": {"value": 0.0017456}, "meta_eval_time": {"value": 27.284}, "meta_eval_prompt_tokens": {"value": 5775.0}, "meta_eval_completion_tokens": {"value": 2756.0}, "meta_eval_prompt_cost": {"value": 0.001848}, "meta_eval_completion_cost": {"value": 0.00352768}}, "created": "2025-12-10T21:56:03.8307505Z"}
{"ref": "sunny-pear", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.543327}, "meta_inference_prompt_tokens": {"value": 15341.0}, "meta_inference_completion_tokens": {"value": 1286.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030682}, "meta_inference_completion_cost": {"value": 0.0020576}, "meta_eval_time": {"value": 36.064}, "meta_eval_prompt_tokens": {"value": 10936.0}, "meta_eval_completion_tokens": {"value": 3499.0}, "meta_eval_prompt_cost": {"value": 0.00349952}, "meta_eval_completion_cost": {"value": 0.00447872}}, "created": "2025-12-10T21:56:04.1422803Z"}
{"ref": "sunny-sample", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.875}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.438913}, "meta_inference_prompt_tokens": {"value": 10637.0}, "meta_inference_completion_tokens": {"value": 841.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021274}, "meta_inference_completion_cost": {"value": 0.0013456}, "meta_eval_time": {"value": 30.842}, "meta_eval_prompt_tokens": {"value": 6189.0}, "meta_eval_completion_tokens": {"value": 2638.0}, "meta_eval_prompt_cost": {"value": 0.00198048}, "meta_eval_completion_cost": {"value": 0.00337664}}, "created": "2025-12-10T21:56:04.4872789Z"}
{"ref": "sunny-pear", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.00878}, "meta_inference_prompt_tokens": {"value": 14043.0}, "meta_inference_completion_tokens": {"value": 1091.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028086}, "meta_inference_completion_cost": {"value": 0.0017456}, "meta_eval_time": {"value": 35.132}, "meta_eval_prompt_tokens": {"value": 9592.0}, "meta_eval_completion_tokens": {"value": 3400.0}, "meta_eval_prompt_cost": {"value": 0.00306944}, "meta_eval_completion_cost": {"value": 0.004352}}, "created": "2025-12-10T21:56:04.4999226Z"}
{"ref": "swarm-round", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.967741935483871}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.279145}, "meta_inference_prompt_tokens": {"value": 10192.0}, "meta_inference_completion_tokens": {"value": 1134.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020384}, "meta_inference_completion_cost": {"value": 0.0018144}, "meta_eval_time": {"value": 28.068}, "meta_eval_prompt_tokens": {"value": 5376.0}, "meta_eval_completion_tokens": {"value": 2608.0}, "meta_eval_prompt_cost": {"value": 0.00172032}, "meta_eval_completion_cost": {"value": 0.00333824}}, "created": "2025-12-10T21:56:05.1895092Z"}
{"ref": "synchronic-novella", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.862518}, "meta_inference_prompt_tokens": {"value": 10359.0}, "meta_inference_completion_tokens": {"value": 948.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020718}, "meta_inference_completion_cost": {"value": 0.0015168}, "meta_eval_time": {"value": 24.394}, "meta_eval_prompt_tokens": {"value": 5282.0}, "meta_eval_completion_tokens": {"value": 2009.0}, "meta_eval_prompt_cost": {"value": 0.00169024}, "meta_eval_completion_cost": {"value": 0.00257152}}, "created": "2025-12-10T21:56:06.0268158Z"}
{"ref": "swarm-round", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.870967741935484}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 18.491749}, "meta_inference_prompt_tokens": {"value": 11648.0}, "meta_inference_completion_tokens": {"value": 849.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023296}, "meta_inference_completion_cost": {"value": 0.0013584}, "meta_eval_time": {"value": 28.027}, "meta_eval_prompt_tokens": {"value": 6659.0}, "meta_eval_completion_tokens": {"value": 2544.0}, "meta_eval_prompt_cost": {"value": 0.00213088}, "meta_eval_completion_cost": {"value": 0.00325632}}, "created": "2025-12-10T21:56:07.51129Z"}
{"ref": "syrupy-azimuth", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 2.0106494993885}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0833333333333333}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 33.443543}, "meta_inference_prompt_tokens": {"value": 41927.0}, "meta_inference_completion_tokens": {"value": 1072.0}, "meta_inference_tool_call_count": {"value": 4.0}, "meta_inference_prompt_cost": {"value": 0.0083854}, "meta_inference_completion_cost": {"value": 0.0017152}, "meta_eval_time": {"value": 12.475}, "meta_eval_prompt_tokens": {"value": 7927.0}, "meta_eval_completion_tokens": {"value": 1043.0}, "meta_eval_prompt_cost": {"value": 0.00253664}, "meta_eval_completion_cost": {"value": 0.00133504}}, "created": "2025-12-10T21:56:07.7936054Z"}
{"ref": "syrupy-azimuth", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 2.70223137713196}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.05}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 47.705933}, "meta_inference_prompt_tokens": {"value": 86705.0}, "meta_inference_completion_tokens": {"value": 1434.0}, "meta_inference_tool_call_count": {"value": 7.0}, "meta_inference_prompt_cost": {"value": 0.017341}, "meta_inference_completion_cost": {"value": 0.0022944}, "meta_eval_time": {"value": 12.778}, "meta_eval_prompt_tokens": {"value": 9586.0}, "meta_eval_completion_tokens": {"value": 1097.0}, "meta_eval_prompt_cost": {"value": 0.00306752}, "meta_eval_completion_cost": {"value": 0.00140416}}, "created": "2025-12-10T21:56:08.0842033Z"}
{"ref": "synchronic-novella", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.965613}, "meta_inference_prompt_tokens": {"value": 10359.0}, "meta_inference_completion_tokens": {"value": 730.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020718}, "meta_inference_completion_cost": {"value": 0.001168}, "meta_eval_time": {"value": 17.422}, "meta_eval_prompt_tokens": {"value": 5007.0}, "meta_eval_completion_tokens": {"value": 1658.0}, "meta_eval_prompt_cost": {"value": 0.00160224}, "meta_eval_completion_cost": {"value": 0.00212224}}, "created": "2025-12-10T21:56:08.4825958Z"}
{"ref": "syrupy-azimuth", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 1.72018614056788}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 29.534799}, "meta_inference_prompt_tokens": {"value": 25177.0}, "meta_inference_completion_tokens": {"value": 1004.0}, "meta_inference_tool_call_count": {"value": 3.0}, "meta_inference_prompt_cost": {"value": 0.0050354}, "meta_inference_completion_cost": {"value": 0.0016064}, "meta_eval_time": {"value": 11.45}, "meta_eval_prompt_tokens": {"value": 5588.0}, "meta_eval_completion_tokens": {"value": 900.0}, "meta_eval_prompt_cost": {"value": 0.00178816}, "meta_eval_completion_cost": {"value": 0.001152}}, "created": "2025-12-10T21:56:08.6048718Z"}
{"ref": "sunny-sample", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.109547}, "meta_inference_prompt_tokens": {"value": 10133.0}, "meta_inference_completion_tokens": {"value": 1079.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020266}, "meta_inference_completion_cost": {"value": 0.0017264}, "meta_eval_time": {"value": 33.56}, "meta_eval_prompt_tokens": {"value": 6123.0}, "meta_eval_completion_tokens": {"value": 3143.0}, "meta_eval_prompt_cost": {"value": 0.00195936}, "meta_eval_completion_cost": {"value": 0.00402304}}, "created": "2025-12-10T21:56:08.663001Z"}
{"ref": "synchronic-novella", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.400882}, "meta_inference_prompt_tokens": {"value": 9706.0}, "meta_inference_completion_tokens": {"value": 704.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019412}, "meta_inference_completion_cost": {"value": 0.0011264}, "meta_eval_time": {"value": 17.599}, "meta_eval_prompt_tokens": {"value": 4486.0}, "meta_eval_completion_tokens": {"value": 1672.0}, "meta_eval_prompt_cost": {"value": 0.00143552}, "meta_eval_completion_cost": {"value": 0.00214016}}, "created": "2025-12-10T21:56:09.67227Z"}
{"ref": "syrupy-azimuth", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.266666666666667}, "retrieval_mrr": {"value": 0.571428571428571}, "retrieval_dcg": {"value": 2.79955812019478}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.3}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.2}, "retrieval_accuracy": {"value": 0.153846153846154}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.2}, "meta_inference_time": {"value": 50.727154}, "meta_inference_prompt_tokens": {"value": 57131.0}, "meta_inference_completion_tokens": {"value": 2309.0}, "meta_inference_tool_call_count": {"value": 6.0}, "meta_inference_prompt_cost": {"value": 0.0114262}, "meta_inference_completion_cost": {"value": 0.0036944}, "meta_eval_time": {"value": 18.253}, "meta_eval_prompt_tokens": {"value": 8258.0}, "meta_eval_completion_tokens": {"value": 1594.0}, "meta_eval_prompt_cost": {"value": 0.00264256}, "meta_eval_completion_cost": {"value": 0.00204032}}, "created": "2025-12-10T21:56:10.2244936Z"}
{"ref": "synchronic-fontina", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.9375}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 26.477702}, "meta_inference_prompt_tokens": {"value": 15389.0}, "meta_inference_completion_tokens": {"value": 1650.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030778}, "meta_inference_completion_cost": {"value": 0.00264}, "meta_eval_time": {"value": 27.779}, "meta_eval_prompt_tokens": {"value": 10230.0}, "meta_eval_completion_tokens": {"value": 2727.0}, "meta_eval_prompt_cost": {"value": 0.0032736}, "meta_eval_completion_cost": {"value": 0.00349056}}, "created": "2025-12-10T21:56:10.6940159Z"}
{"ref": "syrupy-locus", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.24863}, "meta_inference_prompt_tokens": {"value": 12997.0}, "meta_inference_completion_tokens": {"value": 733.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025994}, "meta_inference_completion_cost": {"value": 0.0011728}, "meta_eval_time": {"value": 15.965}, "meta_eval_prompt_tokens": {"value": 7596.0}, "meta_eval_completion_tokens": {"value": 1576.0}, "meta_eval_prompt_cost": {"value": 0.00243072}, "meta_eval_completion_cost": {"value": 0.00201728}}, "created": "2025-12-10T21:56:11.5789123Z"}
{"ref": "synchronic-fontina", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 1.0}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 27.127074}, "meta_inference_prompt_tokens": {"value": 10029.0}, "meta_inference_completion_tokens": {"value": 1609.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020058}, "meta_inference_completion_cost": {"value": 0.0025744}, "meta_eval_time": {"value": 28.182}, "meta_eval_prompt_tokens": {"value": 5766.0}, "meta_eval_completion_tokens": {"value": 2693.0}, "meta_eval_prompt_cost": {"value": 0.00184512}, "meta_eval_completion_cost": {"value": 0.00344704}}, "created": "2025-12-10T21:56:12.1542095Z"}
{"ref": "swarm-round", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.696969696969697}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 20.722978}, "meta_inference_prompt_tokens": {"value": 10077.0}, "meta_inference_completion_tokens": {"value": 929.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020154}, "meta_inference_completion_cost": {"value": 0.0014864}, "meta_eval_time": {"value": 32.195}, "meta_eval_prompt_tokens": {"value": 5476.0}, "meta_eval_completion_tokens": {"value": 2861.0}, "meta_eval_prompt_cost": {"value": 0.00175232}, "meta_eval_completion_cost": {"value": 0.00366208}}, "created": "2025-12-10T21:56:12.3090412Z"}
{"ref": "sunny-pear", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.860166}, "meta_inference_prompt_tokens": {"value": 15245.0}, "meta_inference_completion_tokens": {"value": 1003.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003049}, "meta_inference_completion_cost": {"value": 0.0016048}, "meta_eval_time": {"value": 36.229}, "meta_eval_prompt_tokens": {"value": 10564.0}, "meta_eval_completion_tokens": {"value": 3442.0}, "meta_eval_prompt_cost": {"value": 0.00338048}, "meta_eval_completion_cost": {"value": 0.00440576}}, "created": "2025-12-10T21:56:12.6626223Z"}
{"ref": "terminal-cockatoo", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.263597}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 893.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0014288}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:56:12.6988076Z"}
{"ref": "terminal-cockatoo", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.09552}, "meta_inference_prompt_tokens": {"value": 7983.0}, "meta_inference_completion_tokens": {"value": 1803.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0015966}, "meta_inference_completion_cost": {"value": 0.0028848}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:56:12.7311075Z"}
{"ref": "tan-cello-A", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.764705882352941}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 37.15668}, "meta_inference_prompt_tokens": {"value": 10941.0}, "meta_inference_completion_tokens": {"value": 2161.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021882}, "meta_inference_completion_cost": {"value": 0.0034576}, "meta_eval_time": {"value": 14.544}, "meta_eval_prompt_tokens": {"value": 4940.0}, "meta_eval_completion_tokens": {"value": 1401.0}, "meta_eval_prompt_cost": {"value": 0.0015808}, "meta_eval_completion_cost": {"value": 0.00179328}}, "created": "2025-12-10T21:56:12.9564476Z"}
{"ref": "terminal-cockatoo", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.164412}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 574.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0009184}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:56:12.9891104Z"}
{"ref": "sweet-bowl", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.970588235294118}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 23.446866}, "meta_inference_prompt_tokens": {"value": 10631.0}, "meta_inference_completion_tokens": {"value": 1272.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021262}, "meta_inference_completion_cost": {"value": 0.0020352}, "meta_eval_time": {"value": 35.699}, "meta_eval_prompt_tokens": {"value": 7157.0}, "meta_eval_completion_tokens": {"value": 3966.0}, "meta_eval_prompt_cost": {"value": 0.00229024}, "meta_eval_completion_cost": {"value": 0.00507648}}, "created": "2025-12-10T21:56:13.3540191Z"}
{"ref": "terminal-cockatoo", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.56997}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 696.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0011136}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:56:13.388984Z"}
{"ref": "syrupy-locus", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.673022}, "meta_inference_prompt_tokens": {"value": 13095.0}, "meta_inference_completion_tokens": {"value": 931.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002619}, "meta_inference_completion_cost": {"value": 0.0014896}, "meta_eval_time": {"value": 20.064}, "meta_eval_prompt_tokens": {"value": 7879.0}, "meta_eval_completion_tokens": {"value": 1877.0}, "meta_eval_prompt_cost": {"value": 0.00252128}, "meta_eval_completion_cost": {"value": 0.00240256}}, "created": "2025-12-10T21:56:14.256808Z"}
{"ref": "terminal-cockatoo", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.96}, "meta_inference_prompt_tokens": {"value": 5711.0}, "meta_inference_completion_tokens": {"value": 1769.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0011422}, "meta_inference_completion_cost": {"value": 0.0028304}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:56:14.2897506Z"}
{"ref": "tempered-macaw", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.5}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.369075}, "meta_inference_prompt_tokens": {"value": 10000.0}, "meta_inference_completion_tokens": {"value": 731.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002}, "meta_inference_completion_cost": {"value": 0.0011696}, "meta_eval_time": {"value": 9.117}, "meta_eval_prompt_tokens": {"value": 4425.0}, "meta_eval_completion_tokens": {"value": 806.0}, "meta_eval_prompt_cost": {"value": 0.001416}, "meta_eval_completion_cost": {"value": 0.00103168}}, "created": "2025-12-10T21:56:14.3397077Z"}
{"ref": "synchronic-fontina", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.885714285714286}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 26.885858}, "meta_inference_prompt_tokens": {"value": 16643.0}, "meta_inference_completion_tokens": {"value": 1655.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0033286}, "meta_inference_completion_cost": {"value": 0.002648}, "meta_eval_time": {"value": 32.864}, "meta_eval_prompt_tokens": {"value": 11684.0}, "meta_eval_completion_tokens": {"value": 3233.0}, "meta_eval_prompt_cost": {"value": 0.00373888}, "meta_eval_completion_cost": {"value": 0.00413824}}, "created": "2025-12-10T21:56:15.4347077Z"}
{"ref": "syrupy-locus", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.340592}, "meta_inference_prompt_tokens": {"value": 9389.0}, "meta_inference_completion_tokens": {"value": 812.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0018778}, "meta_inference_completion_cost": {"value": 0.0012992}, "meta_eval_time": {"value": 21.504}, "meta_eval_prompt_tokens": {"value": 5458.0}, "meta_eval_completion_tokens": {"value": 1760.0}, "meta_eval_prompt_cost": {"value": 0.00174656}, "meta_eval_completion_cost": {"value": 0.0022528}}, "created": "2025-12-10T21:56:15.7134848Z"}
{"ref": "sweet-bowl", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.76}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.371102}, "meta_inference_prompt_tokens": {"value": 11176.0}, "meta_inference_completion_tokens": {"value": 1449.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022352}, "meta_inference_completion_cost": {"value": 0.0023184}, "meta_eval_time": {"value": 29.629}, "meta_eval_prompt_tokens": {"value": 6511.0}, "meta_eval_completion_tokens": {"value": 2588.0}, "meta_eval_prompt_cost": {"value": 0.00208352}, "meta_eval_completion_cost": {"value": 0.00331264}}, "created": "2025-12-10T21:56:15.7581414Z"}
{"ref": "sweet-bowl", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.868421052631579}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 33.259537}, "meta_inference_prompt_tokens": {"value": 11328.0}, "meta_inference_completion_tokens": {"value": 1711.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022656}, "meta_inference_completion_cost": {"value": 0.0027376}, "meta_eval_time": {"value": 37.731}, "meta_eval_prompt_tokens": {"value": 7572.0}, "meta_eval_completion_tokens": {"value": 3641.0}, "meta_eval_prompt_cost": {"value": 0.00242304}, "meta_eval_completion_cost": {"value": 0.00466048}}, "created": "2025-12-10T21:56:15.8998087Z"}
{"ref": "tomato-bus", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.163617}, "meta_inference_prompt_tokens": {"value": 13129.0}, "meta_inference_completion_tokens": {"value": 1479.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026258}, "meta_inference_completion_cost": {"value": 0.0023664}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:56:15.9322686Z"}
{"ref": "tomato-bus", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.327184}, "meta_inference_prompt_tokens": {"value": 4703.0}, "meta_inference_completion_tokens": {"value": 1025.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009406}, "meta_inference_completion_cost": {"value": 0.00164}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:56:15.9662446Z"}
{"ref": "tomato-bus", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.433446}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 719.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.0011504}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:56:15.9967686Z"}
{"ref": "synchronic-fontina", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.84375}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 36.348606}, "meta_inference_prompt_tokens": {"value": 16491.0}, "meta_inference_completion_tokens": {"value": 2263.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032982}, "meta_inference_completion_cost": {"value": 0.0036208}, "meta_eval_time": {"value": 35.449}, "meta_eval_prompt_tokens": {"value": 11150.0}, "meta_eval_completion_tokens": {"value": 2914.0}, "meta_eval_prompt_cost": {"value": 0.003568}, "meta_eval_completion_cost": {"value": 0.00372992}}, "created": "2025-12-10T21:56:16.0029294Z"}
{"ref": "tomato-bus", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.922202}, "meta_inference_prompt_tokens": {"value": 2258.0}, "meta_inference_completion_tokens": {"value": 708.0}, "meta_inference_prompt_cost": {"value": 0.0004516}, "meta_inference_completion_cost": {"value": 0.0011328}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:56:16.0435133Z"}
{"ref": "syrupy-locus", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.07755}, "meta_inference_prompt_tokens": {"value": 12543.0}, "meta_inference_completion_tokens": {"value": 762.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025086}, "meta_inference_completion_cost": {"value": 0.0012192}, "meta_eval_time": {"value": 21.207}, "meta_eval_prompt_tokens": {"value": 7379.0}, "meta_eval_completion_tokens": {"value": 1930.0}, "meta_eval_prompt_cost": {"value": 0.00236128}, "meta_eval_completion_cost": {"value": 0.0024704}}, "created": "2025-12-10T21:56:16.7697543Z"}
{"ref": "synchronic-novella", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.839401}, "meta_inference_prompt_tokens": {"value": 9705.0}, "meta_inference_completion_tokens": {"value": 659.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001941}, "meta_inference_completion_cost": {"value": 0.0010544}, "meta_eval_time": {"value": 15.806}, "meta_eval_prompt_tokens": {"value": 4299.0}, "meta_eval_completion_tokens": {"value": 1308.0}, "meta_eval_prompt_cost": {"value": 0.00137568}, "meta_eval_completion_cost": {"value": 0.00167424}}, "created": "2025-12-10T21:56:17.9405354Z"}
{"ref": "tomato-bus", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.277119}, "meta_inference_prompt_tokens": {"value": 4730.0}, "meta_inference_completion_tokens": {"value": 1284.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.000946}, "meta_inference_completion_cost": {"value": 0.0020544}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:56:17.984462Z"}
{"ref": "tempered-macaw", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.942414}, "meta_inference_prompt_tokens": {"value": 10828.0}, "meta_inference_completion_tokens": {"value": 663.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021656}, "meta_inference_completion_cost": {"value": 0.0010608}, "meta_eval_time": {"value": 11.217}, "meta_eval_prompt_tokens": {"value": 5220.0}, "meta_eval_completion_tokens": {"value": 837.0}, "meta_eval_prompt_cost": {"value": 0.0016704}, "meta_eval_completion_cost": {"value": 0.00107136}}, "created": "2025-12-10T21:56:19.3412271Z"}
{"ref": "syrupy-locus", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.952380952380952}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.222222222222222}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.838572}, "meta_inference_prompt_tokens": {"value": 12603.0}, "meta_inference_completion_tokens": {"value": 974.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025206}, "meta_inference_completion_cost": {"value": 0.0015584}, "meta_eval_time": {"value": 27.669}, "meta_eval_prompt_tokens": {"value": 7862.0}, "meta_eval_completion_tokens": {"value": 2270.0}, "meta_eval_prompt_cost": {"value": 0.00251584}, "meta_eval_completion_cost": {"value": 0.0029056}}, "created": "2025-12-10T21:56:21.8529852Z"}
{"ref": "tempered-macaw", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.62386}, "meta_inference_prompt_tokens": {"value": 10447.0}, "meta_inference_completion_tokens": {"value": 728.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020894}, "meta_inference_completion_cost": {"value": 0.0011648}, "meta_eval_time": {"value": 18.026}, "meta_eval_prompt_tokens": {"value": 5251.0}, "meta_eval_completion_tokens": {"value": 1454.0}, "meta_eval_prompt_cost": {"value": 0.00168032}, "meta_eval_completion_cost": {"value": 0.00186112}}, "created": "2025-12-10T21:56:21.9013457Z"}
{"ref": "sweet-bowl", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.945945945945946}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 23.425894}, "meta_inference_prompt_tokens": {"value": 10933.0}, "meta_inference_completion_tokens": {"value": 1235.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021866}, "meta_inference_completion_cost": {"value": 0.001976}, "meta_eval_time": {"value": 37.419}, "meta_eval_prompt_tokens": {"value": 6929.0}, "meta_eval_completion_tokens": {"value": 3328.0}, "meta_eval_prompt_cost": {"value": 0.00221728}, "meta_eval_completion_cost": {"value": 0.00425984}}, "created": "2025-12-10T21:56:22.6768707Z"}
{"ref": "tempered-store", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.456006}, "meta_inference_prompt_tokens": {"value": 9703.0}, "meta_inference_completion_tokens": {"value": 1216.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019406}, "meta_inference_completion_cost": {"value": 0.0019456}, "meta_eval_time": {"value": 14.459}, "meta_eval_prompt_tokens": {"value": 4545.0}, "meta_eval_completion_tokens": {"value": 1506.0}, "meta_eval_prompt_cost": {"value": 0.0014544}, "meta_eval_completion_cost": {"value": 0.00192768}}, "created": "2025-12-10T21:56:24.717306Z"}
{"ref": "tempered-store", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.742964}, "meta_inference_prompt_tokens": {"value": 9529.0}, "meta_inference_completion_tokens": {"value": 1166.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019058}, "meta_inference_completion_cost": {"value": 0.0018656}, "meta_eval_time": {"value": 14.442}, "meta_eval_prompt_tokens": {"value": 4294.0}, "meta_eval_completion_tokens": {"value": 1366.0}, "meta_eval_prompt_cost": {"value": 0.00137408}, "meta_eval_completion_cost": {"value": 0.00174848}}, "created": "2025-12-10T21:56:26.788627Z"}
{"ref": "tempered-macaw", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.6}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.021891}, "meta_inference_prompt_tokens": {"value": 10806.0}, "meta_inference_completion_tokens": {"value": 1067.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021612}, "meta_inference_completion_cost": {"value": 0.0017072}, "meta_eval_time": {"value": 17.6}, "meta_eval_prompt_tokens": {"value": 5515.0}, "meta_eval_completion_tokens": {"value": 1304.0}, "meta_eval_prompt_cost": {"value": 0.0017648}, "meta_eval_completion_cost": {"value": 0.00166912}}, "created": "2025-12-10T21:56:27.305571Z"}
{"ref": "sweet-bowl", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.826086956521739}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.298488}, "meta_inference_prompt_tokens": {"value": 10247.0}, "meta_inference_completion_tokens": {"value": 1377.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020494}, "meta_inference_completion_cost": {"value": 0.0022032}, "meta_eval_time": {"value": 49.015}, "meta_eval_prompt_tokens": {"value": 6852.0}, "meta_eval_completion_tokens": {"value": 4461.0}, "meta_eval_prompt_cost": {"value": 0.00219264}, "meta_eval_completion_cost": {"value": 0.00571008}}, "created": "2025-12-10T21:56:28.8542915Z"}
{"ref": "timid-turbine", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.779357}, "meta_inference_prompt_tokens": {"value": 11103.0}, "meta_inference_completion_tokens": {"value": 651.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022206}, "meta_inference_completion_cost": {"value": 0.0010416}, "meta_eval_time": {"value": 13.966}, "meta_eval_prompt_tokens": {"value": 5627.0}, "meta_eval_completion_tokens": {"value": 1271.0}, "meta_eval_prompt_cost": {"value": 0.00180064}, "meta_eval_completion_cost": {"value": 0.00162688}}, "created": "2025-12-10T21:56:29.7139436Z"}
{"ref": "timid-turbine", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.992897}, "meta_inference_prompt_tokens": {"value": 10971.0}, "meta_inference_completion_tokens": {"value": 378.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021942}, "meta_inference_completion_cost": {"value": 0.0006048}, "meta_eval_time": {"value": 14.363}, "meta_eval_prompt_tokens": {"value": 5453.0}, "meta_eval_completion_tokens": {"value": 1088.0}, "meta_eval_prompt_cost": {"value": 0.00174496}, "meta_eval_completion_cost": {"value": 0.00139264}}, "created": "2025-12-10T21:56:29.8290573Z"}
{"ref": "tempered-store", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.882352941176471}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.169569}, "meta_inference_prompt_tokens": {"value": 9686.0}, "meta_inference_completion_tokens": {"value": 839.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019372}, "meta_inference_completion_cost": {"value": 0.0013424}, "meta_eval_time": {"value": 19.561}, "meta_eval_prompt_tokens": {"value": 4575.0}, "meta_eval_completion_tokens": {"value": 1695.0}, "meta_eval_prompt_cost": {"value": 0.001464}, "meta_eval_completion_cost": {"value": 0.0021696}}, "created": "2025-12-10T21:56:30.286672Z"}
{"ref": "timid-turbine", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.971183}, "meta_inference_prompt_tokens": {"value": 11594.0}, "meta_inference_completion_tokens": {"value": 357.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023188}, "meta_inference_completion_cost": {"value": 0.0005712}, "meta_eval_time": {"value": 14.576}, "meta_eval_prompt_tokens": {"value": 6029.0}, "meta_eval_completion_tokens": {"value": 1161.0}, "meta_eval_prompt_cost": {"value": 0.00192928}, "meta_eval_completion_cost": {"value": 0.00148608}}, "created": "2025-12-10T21:56:30.6579611Z"}
{"ref": "tangy-queue", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.165047}, "meta_inference_prompt_tokens": {"value": 12265.0}, "meta_inference_completion_tokens": {"value": 1295.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002453}, "meta_inference_completion_cost": {"value": 0.002072}, "meta_eval_time": {"value": 32.172}, "meta_eval_prompt_tokens": {"value": 8420.0}, "meta_eval_completion_tokens": {"value": 3060.0}, "meta_eval_prompt_cost": {"value": 0.0026944}, "meta_eval_completion_cost": {"value": 0.0039168}}, "created": "2025-12-10T21:56:30.8900927Z"}
{"ref": "tempered-macaw", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.236951}, "meta_inference_prompt_tokens": {"value": 10830.0}, "meta_inference_completion_tokens": {"value": 892.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002166}, "meta_inference_completion_cost": {"value": 0.0014272}, "meta_eval_time": {"value": 22.732}, "meta_eval_prompt_tokens": {"value": 5728.0}, "meta_eval_completion_tokens": {"value": 1583.0}, "meta_eval_prompt_cost": {"value": 0.00183296}, "meta_eval_completion_cost": {"value": 0.00202624}}, "created": "2025-12-10T21:56:31.2467896Z"}
{"ref": "timid-turbine", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.363636363636364}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.222222222222222}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.015245}, "meta_inference_prompt_tokens": {"value": 12210.0}, "meta_inference_completion_tokens": {"value": 458.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002442}, "meta_inference_completion_cost": {"value": 0.0007328}, "meta_eval_time": {"value": 16.638}, "meta_eval_prompt_tokens": {"value": 6596.0}, "meta_eval_completion_tokens": {"value": 1492.0}, "meta_eval_prompt_cost": {"value": 0.00211072}, "meta_eval_completion_cost": {"value": 0.00190976}}, "created": "2025-12-10T21:56:32.4284505Z"}
{"ref": "tan-cello-A", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.695652173913044}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 28.935405}, "meta_inference_prompt_tokens": {"value": 11846.0}, "meta_inference_completion_tokens": {"value": 1716.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023692}, "meta_inference_completion_cost": {"value": 0.0027456}, "meta_eval_time": {"value": 24.147}, "meta_eval_prompt_tokens": {"value": 6044.0}, "meta_eval_completion_tokens": {"value": 1988.0}, "meta_eval_prompt_cost": {"value": 0.00193408}, "meta_eval_completion_cost": {"value": 0.00254464}}, "created": "2025-12-10T21:56:32.8406604Z"}
{"ref": "tempered-store", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.644313}, "meta_inference_prompt_tokens": {"value": 11077.0}, "meta_inference_completion_tokens": {"value": 1219.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022154}, "meta_inference_completion_cost": {"value": 0.0019504}, "meta_eval_time": {"value": 20.068}, "meta_eval_prompt_tokens": {"value": 5833.0}, "meta_eval_completion_tokens": {"value": 1735.0}, "meta_eval_prompt_cost": {"value": 0.00186656}, "meta_eval_completion_cost": {"value": 0.0022208}}, "created": "2025-12-10T21:56:34.3929389Z"}
{"ref": "tempered-store", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.444887}, "meta_inference_prompt_tokens": {"value": 10132.0}, "meta_inference_completion_tokens": {"value": 996.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020264}, "meta_inference_completion_cost": {"value": 0.0015936}, "meta_eval_time": {"value": 21.171}, "meta_eval_prompt_tokens": {"value": 4934.0}, "meta_eval_completion_tokens": {"value": 1757.0}, "meta_eval_prompt_cost": {"value": 0.00157888}, "meta_eval_completion_cost": {"value": 0.00224896}}, "created": "2025-12-10T21:56:34.5912916Z"}
{"ref": "teal-generator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.256303}, "meta_inference_prompt_tokens": {"value": 9839.0}, "meta_inference_completion_tokens": {"value": 1268.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0019678}, "meta_inference_completion_cost": {"value": 0.0020288}, "meta_eval_time": {"value": 32.8}, "meta_eval_prompt_tokens": {"value": 5625.0}, "meta_eval_completion_tokens": {"value": 2846.0}, "meta_eval_prompt_cost": {"value": 0.0018}, "meta_eval_completion_cost": {"value": 0.00364288}}, "created": "2025-12-10T21:56:34.7399606Z"}
{"ref": "teal-tequila", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 29.397902}, "meta_inference_prompt_tokens": {"value": 10465.0}, "meta_inference_completion_tokens": {"value": 1657.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002093}, "meta_inference_completion_cost": {"value": 0.0026512}, "meta_eval_time": {"value": 30.252}, "meta_eval_prompt_tokens": {"value": 6324.0}, "meta_eval_completion_tokens": {"value": 3011.0}, "meta_eval_prompt_cost": {"value": 0.00202368}, "meta_eval_completion_cost": {"value": 0.00385408}}, "created": "2025-12-10T21:56:34.8135889Z"}
{"ref": "teal-tequila", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.931034482758621}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 24.515082}, "meta_inference_prompt_tokens": {"value": 11189.0}, "meta_inference_completion_tokens": {"value": 1465.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022378}, "meta_inference_completion_cost": {"value": 0.002344}, "meta_eval_time": {"value": 33.211}, "meta_eval_prompt_tokens": {"value": 6859.0}, "meta_eval_completion_tokens": {"value": 2806.0}, "meta_eval_prompt_cost": {"value": 0.00219488}, "meta_eval_completion_cost": {"value": 0.00359168}}, "created": "2025-12-10T21:56:34.9467493Z"}
{"ref": "teal-generator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.90625}, "generation_factuality_f1": {"value": 0.615384615384615}, "generation_factuality_precision": {"value": 0.444444444444444}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.298813}, "meta_inference_prompt_tokens": {"value": 10864.0}, "meta_inference_completion_tokens": {"value": 1534.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021728}, "meta_inference_completion_cost": {"value": 0.0024544}, "meta_eval_time": {"value": 33.439}, "meta_eval_prompt_tokens": {"value": 6470.0}, "meta_eval_completion_tokens": {"value": 3162.0}, "meta_eval_prompt_cost": {"value": 0.0020704}, "meta_eval_completion_cost": {"value": 0.00404736}}, "created": "2025-12-10T21:56:35.1460882Z"}
{"ref": "tense-build", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.521739130434783}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 24.980016}, "meta_inference_prompt_tokens": {"value": 11573.0}, "meta_inference_completion_tokens": {"value": 1503.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023146}, "meta_inference_completion_cost": {"value": 0.0024048}, "meta_eval_time": {"value": 22.318}, "meta_eval_prompt_tokens": {"value": 6237.0}, "meta_eval_completion_tokens": {"value": 1856.0}, "meta_eval_prompt_cost": {"value": 0.00199584}, "meta_eval_completion_cost": {"value": 0.00237568}}, "created": "2025-12-10T21:56:35.3376216Z"}
{"ref": "tangy-queue", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 0.96875}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.492261}, "meta_inference_prompt_tokens": {"value": 12644.0}, "meta_inference_completion_tokens": {"value": 1572.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025288}, "meta_inference_completion_cost": {"value": 0.0025152}, "meta_eval_time": {"value": 38.881}, "meta_eval_prompt_tokens": {"value": 9022.0}, "meta_eval_completion_tokens": {"value": 3470.0}, "meta_eval_prompt_cost": {"value": 0.00288704}, "meta_eval_completion_cost": {"value": 0.0044416}}, "created": "2025-12-10T21:56:37.754058Z"}
{"ref": "tangy-queue", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.261911}, "meta_inference_prompt_tokens": {"value": 12910.0}, "meta_inference_completion_tokens": {"value": 1294.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002582}, "meta_inference_completion_cost": {"value": 0.0020704}, "meta_eval_time": {"value": 39.232}, "meta_eval_prompt_tokens": {"value": 9070.0}, "meta_eval_completion_tokens": {"value": 3324.0}, "meta_eval_prompt_cost": {"value": 0.0029024}, "meta_eval_completion_cost": {"value": 0.00425472}}, "created": "2025-12-10T21:56:39.1160604Z"}
{"ref": "teal-generator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.657237182772}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.550085}, "meta_inference_prompt_tokens": {"value": 10453.0}, "meta_inference_completion_tokens": {"value": 1332.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020906}, "meta_inference_completion_cost": {"value": 0.0021312}, "meta_eval_time": {"value": 32.002}, "meta_eval_prompt_tokens": {"value": 6313.0}, "meta_eval_completion_tokens": {"value": 2776.0}, "meta_eval_prompt_cost": {"value": 0.00202016}, "meta_eval_completion_cost": {"value": 0.00355328}}, "created": "2025-12-10T21:56:39.5498012Z"}
{"ref": "tangy-queue", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.967741935483871}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.90614}, "meta_inference_prompt_tokens": {"value": 12023.0}, "meta_inference_completion_tokens": {"value": 1066.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024046}, "meta_inference_completion_cost": {"value": 0.0017056}, "meta_eval_time": {"value": 39.099}, "meta_eval_prompt_tokens": {"value": 8356.0}, "meta_eval_completion_tokens": {"value": 3415.0}, "meta_eval_prompt_cost": {"value": 0.00267392}, "meta_eval_completion_cost": {"value": 0.0043712}}, "created": "2025-12-10T21:56:39.9324966Z"}
{"ref": "timid-turbine", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.23238}, "meta_inference_prompt_tokens": {"value": 12630.0}, "meta_inference_completion_tokens": {"value": 756.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002526}, "meta_inference_completion_cost": {"value": 0.0012096}, "meta_eval_time": {"value": 18.349}, "meta_eval_prompt_tokens": {"value": 7005.0}, "meta_eval_completion_tokens": {"value": 1429.0}, "meta_eval_prompt_cost": {"value": 0.0022416}, "meta_eval_completion_cost": {"value": 0.00182912}}, "created": "2025-12-10T21:56:40.2432648Z"}
{"ref": "tense-build", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.416666666666667}, "retrieval_dcg": {"value": 0.946394630357186}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.222222222222222}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 30.788755}, "meta_inference_prompt_tokens": {"value": 10139.0}, "meta_inference_completion_tokens": {"value": 1587.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020278}, "meta_inference_completion_cost": {"value": 0.0025392}, "meta_eval_time": {"value": 29.303}, "meta_eval_prompt_tokens": {"value": 5465.0}, "meta_eval_completion_tokens": {"value": 2390.0}, "meta_eval_prompt_cost": {"value": 0.0017488}, "meta_eval_completion_cost": {"value": 0.0030592}}, "created": "2025-12-10T21:56:41.4931435Z"}
{"ref": "tense-build", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.125}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.85}, "generation_factuality_f1": {"value": 0.648648648648649}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.0666666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.166666666666667}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 24.738}, "meta_inference_prompt_tokens": {"value": 10260.0}, "meta_inference_completion_tokens": {"value": 1377.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002052}, "meta_inference_completion_cost": {"value": 0.0022032}, "meta_eval_time": {"value": 31.046}, "meta_eval_prompt_tokens": {"value": 5583.0}, "meta_eval_completion_tokens": {"value": 2390.0}, "meta_eval_prompt_cost": {"value": 0.00178656}, "meta_eval_completion_cost": {"value": 0.0030592}}, "created": "2025-12-10T21:56:43.8078395Z"}
{"ref": "tense-build", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.30102999566398}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.097499}, "meta_inference_prompt_tokens": {"value": 10184.0}, "meta_inference_completion_tokens": {"value": 1354.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020368}, "meta_inference_completion_cost": {"value": 0.0021664}, "meta_eval_time": {"value": 29.776}, "meta_eval_prompt_tokens": {"value": 5515.0}, "meta_eval_completion_tokens": {"value": 2429.0}, "meta_eval_prompt_cost": {"value": 0.0017648}, "meta_eval_completion_cost": {"value": 0.00310912}}, "created": "2025-12-10T21:56:44.1502101Z"}
{"ref": "teal-generator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.35620718710802}, "generation_faithfulness": {"value": 0.897435897435898}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.521218}, "meta_inference_prompt_tokens": {"value": 11287.0}, "meta_inference_completion_tokens": {"value": 1329.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022574}, "meta_inference_completion_cost": {"value": 0.0021264}, "meta_eval_time": {"value": 42.115}, "meta_eval_prompt_tokens": {"value": 7241.0}, "meta_eval_completion_tokens": {"value": 3666.0}, "meta_eval_prompt_cost": {"value": 0.00231712}, "meta_eval_completion_cost": {"value": 0.00469248}}, "created": "2025-12-10T21:56:46.3011872Z"}
{"ref": "teal-tequila", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 0.5}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 0.976744186046512}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.1}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 30.604487}, "meta_inference_prompt_tokens": {"value": 11557.0}, "meta_inference_completion_tokens": {"value": 1850.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023114}, "meta_inference_completion_cost": {"value": 0.00296}, "meta_eval_time": {"value": 46.372}, "meta_eval_prompt_tokens": {"value": 8256.0}, "meta_eval_completion_tokens": {"value": 4348.0}, "meta_eval_prompt_cost": {"value": 0.00264192}, "meta_eval_completion_cost": {"value": 0.00556544}}, "created": "2025-12-10T21:56:46.3280654Z"}
{"ref": "teal-tequila", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.852941176470588}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 27.004477}, "meta_inference_prompt_tokens": {"value": 10735.0}, "meta_inference_completion_tokens": {"value": 1935.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002147}, "meta_inference_completion_cost": {"value": 0.003096}, "meta_eval_time": {"value": 38.193}, "meta_eval_prompt_tokens": {"value": 6781.0}, "meta_eval_completion_tokens": {"value": 3504.0}, "meta_eval_prompt_cost": {"value": 0.00216992}, "meta_eval_completion_cost": {"value": 0.00448512}}, "created": "2025-12-10T21:56:46.8307373Z"}
{"ref": "teal-tequila", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 33.272737}, "meta_inference_prompt_tokens": {"value": 10837.0}, "meta_inference_completion_tokens": {"value": 1982.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021674}, "meta_inference_completion_cost": {"value": 0.0031712}, "meta_eval_time": {"value": 43.294}, "meta_eval_prompt_tokens": {"value": 7020.0}, "meta_eval_completion_tokens": {"value": 3629.0}, "meta_eval_prompt_cost": {"value": 0.0022464}, "meta_eval_completion_cost": {"value": 0.00464512}}, "created": "2025-12-10T21:56:47.8494317Z"}
{"ref": "tense-build", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.731706553737374}, "generation_faithfulness": {"value": 0.931034482758621}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 22.296575}, "meta_inference_prompt_tokens": {"value": 10884.0}, "meta_inference_completion_tokens": {"value": 1359.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021768}, "meta_inference_completion_cost": {"value": 0.0021744}, "meta_eval_time": {"value": 36.62}, "meta_eval_prompt_tokens": {"value": 6460.0}, "meta_eval_completion_tokens": {"value": 3007.0}, "meta_eval_prompt_cost": {"value": 0.0020672}, "meta_eval_completion_cost": {"value": 0.00384896}}, "created": "2025-12-10T21:56:48.2319903Z"}
{"ref": "topped-bright-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.68032}, "meta_inference_prompt_tokens": {"value": 11700.0}, "meta_inference_completion_tokens": {"value": 1365.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00234}, "meta_inference_completion_cost": {"value": 0.002184}, "meta_eval_time": {"value": 30.891}, "meta_eval_prompt_tokens": {"value": 7864.0}, "meta_eval_completion_tokens": {"value": 3372.0}, "meta_eval_prompt_cost": {"value": 0.00251648}, "meta_eval_completion_cost": {"value": 0.00431616}}, "created": "2025-12-10T21:56:48.9114799Z"}
{"ref": "topped-bright-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 0.935483870967742}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.666527}, "meta_inference_prompt_tokens": {"value": 11707.0}, "meta_inference_completion_tokens": {"value": 1152.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023414}, "meta_inference_completion_cost": {"value": 0.0018432}, "meta_eval_time": {"value": 36.397}, "meta_eval_prompt_tokens": {"value": 7649.0}, "meta_eval_completion_tokens": {"value": 2843.0}, "meta_eval_prompt_cost": {"value": 0.00244768}, "meta_eval_completion_cost": {"value": 0.00363904}}, "created": "2025-12-10T21:56:52.4265067Z"}
{"ref": "topped-bright-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 28.08064}, "meta_inference_prompt_tokens": {"value": 11665.0}, "meta_inference_completion_tokens": {"value": 1354.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002333}, "meta_inference_completion_cost": {"value": 0.0021664}, "meta_eval_time": {"value": 27.577}, "meta_eval_prompt_tokens": {"value": 7323.0}, "meta_eval_completion_tokens": {"value": 2285.0}, "meta_eval_prompt_cost": {"value": 0.00234336}, "meta_eval_completion_cost": {"value": 0.0029248}}, "created": "2025-12-10T21:56:54.9235765Z"}
{"ref": "topped-bright-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.956521739130435}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 28.596471}, "meta_inference_prompt_tokens": {"value": 12944.0}, "meta_inference_completion_tokens": {"value": 1126.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025888}, "meta_inference_completion_cost": {"value": 0.0018016}, "meta_eval_time": {"value": 25.091}, "meta_eval_prompt_tokens": {"value": 8723.0}, "meta_eval_completion_tokens": {"value": 2342.0}, "meta_eval_prompt_cost": {"value": 0.00279136}, "meta_eval_completion_cost": {"value": 0.00299776}}, "created": "2025-12-10T21:56:54.9571669Z"}
{"ref": "topped-bright-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 35.786271}, "meta_inference_prompt_tokens": {"value": 12737.0}, "meta_inference_completion_tokens": {"value": 1672.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025474}, "meta_inference_completion_cost": {"value": 0.0026752}, "meta_eval_time": {"value": 32.658}, "meta_eval_prompt_tokens": {"value": 8916.0}, "meta_eval_completion_tokens": {"value": 2736.0}, "meta_eval_prompt_cost": {"value": 0.00285312}, "meta_eval_completion_cost": {"value": 0.00350208}}, "created": "2025-12-10T21:56:55.3748762Z"}
{"ref": "topped-bright-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.301029995663981}, "generation_faithfulness": {"value": 0.921052631578947}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.822455}, "meta_inference_prompt_tokens": {"value": 11704.0}, "meta_inference_completion_tokens": {"value": 1176.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023408}, "meta_inference_completion_cost": {"value": 0.0018816}, "meta_eval_time": {"value": 39.083}, "meta_eval_prompt_tokens": {"value": 7893.0}, "meta_eval_completion_tokens": {"value": 3739.0}, "meta_eval_prompt_cost": {"value": 0.00252576}, "meta_eval_completion_cost": {"value": 0.00478592}}, "created": "2025-12-10T21:56:55.896966Z"}
{"ref": "tranquil-grade", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.736842105263158}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.491404}, "meta_inference_prompt_tokens": {"value": 10955.0}, "meta_inference_completion_tokens": {"value": 879.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002191}, "meta_inference_completion_cost": {"value": 0.0014064}, "meta_eval_time": {"value": 21.563}, "meta_eval_prompt_tokens": {"value": 5984.0}, "meta_eval_completion_tokens": {"value": 1872.0}, "meta_eval_prompt_cost": {"value": 0.00191488}, "meta_eval_completion_cost": {"value": 0.00239616}}, "created": "2025-12-10T21:56:56.7478257Z"}
{"ref": "topped-bright-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.386852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 23.897338}, "meta_inference_prompt_tokens": {"value": 11665.0}, "meta_inference_completion_tokens": {"value": 1112.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002333}, "meta_inference_completion_cost": {"value": 0.0017792}, "meta_eval_time": {"value": 30.078}, "meta_eval_prompt_tokens": {"value": 7449.0}, "meta_eval_completion_tokens": {"value": 2764.0}, "meta_eval_prompt_cost": {"value": 0.00238368}, "meta_eval_completion_cost": {"value": 0.00353792}}, "created": "2025-12-10T21:56:56.9080326Z"}
{"ref": "tranquil-grade", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.110934}, "meta_inference_prompt_tokens": {"value": 11548.0}, "meta_inference_completion_tokens": {"value": 653.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023096}, "meta_inference_completion_cost": {"value": 0.0010448}, "meta_eval_time": {"value": 19.559}, "meta_eval_prompt_tokens": {"value": 6320.0}, "meta_eval_completion_tokens": {"value": 1560.0}, "meta_eval_prompt_cost": {"value": 0.0020224}, "meta_eval_completion_cost": {"value": 0.0019968}}, "created": "2025-12-10T21:56:59.1477523Z"}
{"ref": "tossed-degree", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.517782560806}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.497671}, "meta_inference_prompt_tokens": {"value": 11692.0}, "meta_inference_completion_tokens": {"value": 633.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023384}, "meta_inference_completion_cost": {"value": 0.0010128}, "meta_eval_time": {"value": 23.809}, "meta_eval_prompt_tokens": {"value": 6699.0}, "meta_eval_completion_tokens": {"value": 1974.0}, "meta_eval_prompt_cost": {"value": 0.00214368}, "meta_eval_completion_cost": {"value": 0.00252672}}, "created": "2025-12-10T21:56:59.1955922Z"}
{"ref": "tangy-queue", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.329926}, "meta_inference_prompt_tokens": {"value": 12041.0}, "meta_inference_completion_tokens": {"value": 1875.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024082}, "meta_inference_completion_cost": {"value": 0.003}, "meta_eval_time": {"value": 51.488}, "meta_eval_prompt_tokens": {"value": 8340.0}, "meta_eval_completion_tokens": {"value": 3924.0}, "meta_eval_prompt_cost": {"value": 0.0026688}, "meta_eval_completion_cost": {"value": 0.00502272}}, "created": "2025-12-10T21:56:59.3151277Z"}
{"ref": "tossed-degree", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.37707118843058}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.938138}, "meta_inference_prompt_tokens": {"value": 11950.0}, "meta_inference_completion_tokens": {"value": 1324.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00239}, "meta_inference_completion_cost": {"value": 0.0021184}, "meta_eval_time": {"value": 28.42}, "meta_eval_prompt_tokens": {"value": 7417.0}, "meta_eval_completion_tokens": {"value": 2859.0}, "meta_eval_prompt_cost": {"value": 0.00237344}, "meta_eval_completion_cost": {"value": 0.00365952}}, "created": "2025-12-10T21:57:02.8502078Z"}
{"ref": "topped-bright-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.848484848484848}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 28.768267}, "meta_inference_prompt_tokens": {"value": 11503.0}, "meta_inference_completion_tokens": {"value": 1476.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023006}, "meta_inference_completion_cost": {"value": 0.0023616}, "meta_eval_time": {"value": 38.158}, "meta_eval_prompt_tokens": {"value": 7760.0}, "meta_eval_completion_tokens": {"value": 3197.0}, "meta_eval_prompt_cost": {"value": 0.0024832}, "meta_eval_completion_cost": {"value": 0.00409216}}, "created": "2025-12-10T21:57:02.9301916Z"}
{"ref": "tranquil-grade", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.8}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.909274}, "meta_inference_prompt_tokens": {"value": 10726.0}, "meta_inference_completion_tokens": {"value": 615.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021452}, "meta_inference_completion_cost": {"value": 0.000984}, "meta_eval_time": {"value": 19.175}, "meta_eval_prompt_tokens": {"value": 5581.0}, "meta_eval_completion_tokens": {"value": 1639.0}, "meta_eval_prompt_cost": {"value": 0.00178592}, "meta_eval_completion_cost": {"value": 0.00209792}}, "created": "2025-12-10T21:57:03.0224924Z"}
{"ref": "tranquil-grade", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.705882352941176}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.225831}, "meta_inference_prompt_tokens": {"value": 10787.0}, "meta_inference_completion_tokens": {"value": 651.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021574}, "meta_inference_completion_cost": {"value": 0.0010416}, "meta_eval_time": {"value": 24.504}, "meta_eval_prompt_tokens": {"value": 5954.0}, "meta_eval_completion_tokens": {"value": 2014.0}, "meta_eval_prompt_cost": {"value": 0.00190528}, "meta_eval_completion_cost": {"value": 0.00257792}}, "created": "2025-12-10T21:57:03.6626715Z"}
{"ref": "tranquil-grade", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.80952380952381}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.770209}, "meta_inference_prompt_tokens": {"value": 10966.0}, "meta_inference_completion_tokens": {"value": 676.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021932}, "meta_inference_completion_cost": {"value": 0.0010816}, "meta_eval_time": {"value": 26.861}, "meta_eval_prompt_tokens": {"value": 6023.0}, "meta_eval_completion_tokens": {"value": 2098.0}, "meta_eval_prompt_cost": {"value": 0.00192736}, "meta_eval_completion_cost": {"value": 0.00268544}}, "created": "2025-12-10T21:57:04.6543904Z"}
{"ref": "unsolvable-lamp", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.879883}, "meta_inference_prompt_tokens": {"value": 13137.0}, "meta_inference_completion_tokens": {"value": 1120.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026274}, "meta_inference_completion_cost": {"value": 0.001792}, "meta_eval_time": {"value": 23.542}, "meta_eval_prompt_tokens": {"value": 7634.0}, "meta_eval_completion_tokens": {"value": 2100.0}, "meta_eval_prompt_cost": {"value": 0.00244288}, "meta_eval_completion_cost": {"value": 0.002688}}, "created": "2025-12-10T21:57:05.0736908Z"}
{"ref": "tossed-degree", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 2.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.229611}, "meta_inference_prompt_tokens": {"value": 12397.0}, "meta_inference_completion_tokens": {"value": 1261.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024794}, "meta_inference_completion_cost": {"value": 0.0020176}, "meta_eval_time": {"value": 31.286}, "meta_eval_prompt_tokens": {"value": 7644.0}, "meta_eval_completion_tokens": {"value": 2845.0}, "meta_eval_prompt_cost": {"value": 0.00244608}, "meta_eval_completion_cost": {"value": 0.0036416}}, "created": "2025-12-10T21:57:06.1777553Z"}
{"ref": "topped-noodle", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.971428571428571}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.668237}, "meta_inference_prompt_tokens": {"value": 11636.0}, "meta_inference_completion_tokens": {"value": 1480.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023272}, "meta_inference_completion_cost": {"value": 0.002368}, "meta_eval_time": {"value": 39.774}, "meta_eval_prompt_tokens": {"value": 8303.0}, "meta_eval_completion_tokens": {"value": 3735.0}, "meta_eval_prompt_cost": {"value": 0.00265696}, "meta_eval_completion_cost": {"value": 0.0047808}}, "created": "2025-12-10T21:57:09.5296953Z"}
{"ref": "topped-noodle", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.043193}, "meta_inference_prompt_tokens": {"value": 11212.0}, "meta_inference_completion_tokens": {"value": 1967.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022424}, "meta_inference_completion_cost": {"value": 0.0031472}, "meta_eval_time": {"value": 40.917}, "meta_eval_prompt_tokens": {"value": 8030.0}, "meta_eval_completion_tokens": {"value": 3735.0}, "meta_eval_prompt_cost": {"value": 0.0025696}, "meta_eval_completion_cost": {"value": 0.0047808}}, "created": "2025-12-10T21:57:11.2448189Z"}
{"ref": "topped-bright-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.777243}, "meta_inference_prompt_tokens": {"value": 12234.0}, "meta_inference_completion_tokens": {"value": 1401.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024468}, "meta_inference_completion_cost": {"value": 0.0022416}, "meta_eval_time": {"value": 50.232}, "meta_eval_prompt_tokens": {"value": 9028.0}, "meta_eval_completion_tokens": {"value": 4535.0}, "meta_eval_prompt_cost": {"value": 0.00288896}, "meta_eval_completion_cost": {"value": 0.0058048}}, "created": "2025-12-10T21:57:12.1719706Z"}
{"ref": "topped-noodle", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.266666666666667}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 27.488025}, "meta_inference_prompt_tokens": {"value": 11250.0}, "meta_inference_completion_tokens": {"value": 1629.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00225}, "meta_inference_completion_cost": {"value": 0.0026064}, "meta_eval_time": {"value": 43.449}, "meta_eval_prompt_tokens": {"value": 8179.0}, "meta_eval_completion_tokens": {"value": 3809.0}, "meta_eval_prompt_cost": {"value": 0.00261728}, "meta_eval_completion_cost": {"value": 0.00487552}}, "created": "2025-12-10T21:57:12.3422101Z"}
{"ref": "upbeat-mamba", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.947368421052632}, "generation_factuality_f1": {"value": 0.315789473684211}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 27.221439}, "meta_inference_prompt_tokens": {"value": 12642.0}, "meta_inference_completion_tokens": {"value": 1464.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025284}, "meta_inference_completion_cost": {"value": 0.0023424}, "meta_eval_time": {"value": 23.694}, "meta_eval_prompt_tokens": {"value": 7140.0}, "meta_eval_completion_tokens": {"value": 2082.0}, "meta_eval_prompt_cost": {"value": 0.0022848}, "meta_eval_completion_cost": {"value": 0.00266496}}, "created": "2025-12-10T21:57:12.6462115Z"}
{"ref": "teal-generator", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.33333333333333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.363636363636364}, "generation_factuality_precision": {"value": 0.222222222222222}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.567065}, "meta_inference_prompt_tokens": {"value": 14148.0}, "meta_inference_completion_tokens": {"value": 1778.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028296}, "meta_inference_completion_cost": {"value": 0.0028448}, "meta_eval_time": {"value": 66.713}, "meta_eval_prompt_tokens": {"value": 19951.0}, "meta_eval_completion_tokens": {"value": 5573.0}, "meta_eval_prompt_cost": {"value": 0.00638432}, "meta_eval_completion_cost": {"value": 0.00713344}}, "created": "2025-12-10T21:57:12.7748542Z"}
{"ref": "topped-bright-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.765348}, "meta_inference_prompt_tokens": {"value": 12769.0}, "meta_inference_completion_tokens": {"value": 1798.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025538}, "meta_inference_completion_cost": {"value": 0.0028768}, "meta_eval_time": {"value": 54.173}, "meta_eval_prompt_tokens": {"value": 9878.0}, "meta_eval_completion_tokens": {"value": 4596.0}, "meta_eval_prompt_cost": {"value": 0.00316096}, "meta_eval_completion_cost": {"value": 0.00588288}}, "created": "2025-12-10T21:57:13.5533335Z"}
{"ref": "unsolvable-lamp", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.468817}, "meta_inference_prompt_tokens": {"value": 12123.0}, "meta_inference_completion_tokens": {"value": 1289.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024246}, "meta_inference_completion_cost": {"value": 0.0020624}, "meta_eval_time": {"value": 27.078}, "meta_eval_prompt_tokens": {"value": 7040.0}, "meta_eval_completion_tokens": {"value": 2205.0}, "meta_eval_prompt_cost": {"value": 0.0022528}, "meta_eval_completion_cost": {"value": 0.0028224}}, "created": "2025-12-10T21:57:13.9452994Z"}
{"ref": "unsolvable-lamp", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.76}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.118725}, "meta_inference_prompt_tokens": {"value": 14094.0}, "meta_inference_completion_tokens": {"value": 1482.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028188}, "meta_inference_completion_cost": {"value": 0.0023712}, "meta_eval_time": {"value": 30.055}, "meta_eval_prompt_tokens": {"value": 8861.0}, "meta_eval_completion_tokens": {"value": 2586.0}, "meta_eval_prompt_cost": {"value": 0.00283552}, "meta_eval_completion_cost": {"value": 0.00331008}}, "created": "2025-12-10T21:57:14.2450513Z"}
{"ref": "topped-noodle", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.948717948717949}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.94608}, "meta_inference_prompt_tokens": {"value": 11213.0}, "meta_inference_completion_tokens": {"value": 1383.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022426}, "meta_inference_completion_cost": {"value": 0.0022128}, "meta_eval_time": {"value": 44.452}, "meta_eval_prompt_tokens": {"value": 7931.0}, "meta_eval_completion_tokens": {"value": 4171.0}, "meta_eval_prompt_cost": {"value": 0.00253792}, "meta_eval_completion_cost": {"value": 0.00533888}}, "created": "2025-12-10T21:57:15.3781109Z"}
{"ref": "topped-pique", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.195964}, "meta_inference_prompt_tokens": {"value": 10039.0}, "meta_inference_completion_tokens": {"value": 1399.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020078}, "meta_inference_completion_cost": {"value": 0.0022384}, "meta_eval_time": {"value": 44.182}, "meta_eval_prompt_tokens": {"value": 6301.0}, "meta_eval_completion_tokens": {"value": 3713.0}, "meta_eval_prompt_cost": {"value": 0.00201632}, "meta_eval_completion_cost": {"value": 0.00475264}}, "created": "2025-12-10T21:57:15.4989974Z"}
{"ref": "tossed-degree", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.96426308690479}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.714285714285714}, "generation_factuality_precision": {"value": 0.555555555555556}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.300897}, "meta_inference_prompt_tokens": {"value": 12554.0}, "meta_inference_completion_tokens": {"value": 1028.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025108}, "meta_inference_completion_cost": {"value": 0.0016448}, "meta_eval_time": {"value": 41.269}, "meta_eval_prompt_tokens": {"value": 8157.0}, "meta_eval_completion_tokens": {"value": 3401.0}, "meta_eval_prompt_cost": {"value": 0.00261024}, "meta_eval_completion_cost": {"value": 0.00435328}}, "created": "2025-12-10T21:57:16.2520005Z"}
{"ref": "uniform-abscissa", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.966666666666667}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.082541}, "meta_inference_prompt_tokens": {"value": 13006.0}, "meta_inference_completion_tokens": {"value": 1376.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026012}, "meta_inference_completion_cost": {"value": 0.0022016}, "meta_eval_time": {"value": 36.757}, "meta_eval_prompt_tokens": {"value": 8778.0}, "meta_eval_completion_tokens": {"value": 3143.0}, "meta_eval_prompt_cost": {"value": 0.00280896}, "meta_eval_completion_cost": {"value": 0.00402304}}, "created": "2025-12-10T21:57:16.7256461Z"}
{"ref": "uniform-abscissa", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.089967}, "meta_inference_prompt_tokens": {"value": 12943.0}, "meta_inference_completion_tokens": {"value": 1091.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025886}, "meta_inference_completion_cost": {"value": 0.0017456}, "meta_eval_time": {"value": 30.722}, "meta_eval_prompt_tokens": {"value": 8220.0}, "meta_eval_completion_tokens": {"value": 2490.0}, "meta_eval_prompt_cost": {"value": 0.0026304}, "meta_eval_completion_cost": {"value": 0.0031872}}, "created": "2025-12-10T21:57:17.0630826Z"}
{"ref": "unsolvable-lamp", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.533333333333333}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 0.8}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 0.8}, "meta_inference_time": {"value": 25.215241}, "meta_inference_prompt_tokens": {"value": 13124.0}, "meta_inference_completion_tokens": {"value": 1410.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026248}, "meta_inference_completion_cost": {"value": 0.002256}, "meta_eval_time": {"value": 29.284}, "meta_eval_prompt_tokens": {"value": 7806.0}, "meta_eval_completion_tokens": {"value": 2545.0}, "meta_eval_prompt_cost": {"value": 0.00249792}, "meta_eval_completion_cost": {"value": 0.0032576}}, "created": "2025-12-10T21:57:17.5551262Z"}
{"ref": "topped-pique", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.954545454545454}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.348867}, "meta_inference_prompt_tokens": {"value": 11578.0}, "meta_inference_completion_tokens": {"value": 1721.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023156}, "meta_inference_completion_cost": {"value": 0.0027536}, "meta_eval_time": {"value": 42.836}, "meta_eval_prompt_tokens": {"value": 8005.0}, "meta_eval_completion_tokens": {"value": 4010.0}, "meta_eval_prompt_cost": {"value": 0.0025616}, "meta_eval_completion_cost": {"value": 0.0051328}}, "created": "2025-12-10T21:57:17.6141205Z"}
{"ref": "uniform-abscissa", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.956521739130435}, "generation_factuality_f1": {"value": 0.545454545454545}, "generation_factuality_precision": {"value": 0.375}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.946238}, "meta_inference_prompt_tokens": {"value": 12165.0}, "meta_inference_completion_tokens": {"value": 1044.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002433}, "meta_inference_completion_cost": {"value": 0.0016704}, "meta_eval_time": {"value": 31.248}, "meta_eval_prompt_tokens": {"value": 7521.0}, "meta_eval_completion_tokens": {"value": 2625.0}, "meta_eval_prompt_cost": {"value": 0.00240672}, "meta_eval_completion_cost": {"value": 0.00336}}, "created": "2025-12-10T21:57:19.1389111Z"}
{"ref": "topped-pique", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.18517}, "meta_inference_prompt_tokens": {"value": 10884.0}, "meta_inference_completion_tokens": {"value": 1977.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021768}, "meta_inference_completion_cost": {"value": 0.0031632}, "meta_eval_time": {"value": 47.739}, "meta_eval_prompt_tokens": {"value": 7165.0}, "meta_eval_completion_tokens": {"value": 3583.0}, "meta_eval_prompt_cost": {"value": 0.0022928}, "meta_eval_completion_cost": {"value": 0.00458624}}, "created": "2025-12-10T21:57:20.2051602Z"}
{"ref": "uniform-abscissa", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.037119}, "meta_inference_prompt_tokens": {"value": 13580.0}, "meta_inference_completion_tokens": {"value": 1240.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002716}, "meta_inference_completion_cost": {"value": 0.001984}, "meta_eval_time": {"value": 36.312}, "meta_eval_prompt_tokens": {"value": 9200.0}, "meta_eval_completion_tokens": {"value": 3084.0}, "meta_eval_prompt_cost": {"value": 0.002944}, "meta_eval_completion_cost": {"value": 0.00394752}}, "created": "2025-12-10T21:57:22.6846188Z"}
{"ref": "unsolvable-lamp", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.195233}, "meta_inference_prompt_tokens": {"value": 12848.0}, "meta_inference_completion_tokens": {"value": 951.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025696}, "meta_inference_completion_cost": {"value": 0.0015216}, "meta_eval_time": {"value": 30.842}, "meta_eval_prompt_tokens": {"value": 7752.0}, "meta_eval_completion_tokens": {"value": 2657.0}, "meta_eval_prompt_cost": {"value": 0.00248064}, "meta_eval_completion_cost": {"value": 0.00340096}}, "created": "2025-12-10T21:57:23.3419649Z"}
{"ref": "upbeat-mamba", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.8125}, "generation_factuality_f1": {"value": 0.2}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 0.25}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.25}, "meta_inference_time": {"value": 26.663163}, "meta_inference_prompt_tokens": {"value": 11710.0}, "meta_inference_completion_tokens": {"value": 1683.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002342}, "meta_inference_completion_cost": {"value": 0.0026928}, "meta_eval_time": {"value": 24.692}, "meta_eval_prompt_tokens": {"value": 6616.0}, "meta_eval_completion_tokens": {"value": 1814.0}, "meta_eval_prompt_cost": {"value": 0.00211712}, "meta_eval_completion_cost": {"value": 0.00232192}}, "created": "2025-12-10T21:57:24.0423529Z"}
{"ref": "uniform-abscissa", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.178509}, "meta_inference_prompt_tokens": {"value": 13071.0}, "meta_inference_completion_tokens": {"value": 1285.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026142}, "meta_inference_completion_cost": {"value": 0.002056}, "meta_eval_time": {"value": 44.29}, "meta_eval_prompt_tokens": {"value": 8756.0}, "meta_eval_completion_tokens": {"value": 3039.0}, "meta_eval_prompt_cost": {"value": 0.00280192}, "meta_eval_completion_cost": {"value": 0.00388992}}, "created": "2025-12-10T21:57:24.5692193Z"}
{"ref": "upbeat-mamba", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.1}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0526315789473684}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.05}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 45.229867}, "meta_inference_prompt_tokens": {"value": 28939.0}, "meta_inference_completion_tokens": {"value": 2729.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0057878}, "meta_inference_completion_cost": {"value": 0.0043664}, "meta_eval_time": {"value": 27.765}, "meta_eval_prompt_tokens": {"value": 11261.0}, "meta_eval_completion_tokens": {"value": 2075.0}, "meta_eval_prompt_cost": {"value": 0.00360352}, "meta_eval_completion_cost": {"value": 0.002656}}, "created": "2025-12-10T21:57:26.9513178Z"}
{"ref": "vertical-weight", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.6}, "generation_factuality_precision": {"value": 0.428571428571429}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.30269}, "meta_inference_prompt_tokens": {"value": 10837.0}, "meta_inference_completion_tokens": {"value": 880.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021674}, "meta_inference_completion_cost": {"value": 0.001408}, "meta_eval_time": {"value": 23.312}, "meta_eval_prompt_tokens": {"value": 5744.0}, "meta_eval_completion_tokens": {"value": 1859.0}, "meta_eval_prompt_cost": {"value": 0.00183808}, "meta_eval_completion_cost": {"value": 0.00237952}}, "created": "2025-12-10T21:57:27.0114146Z"}
{"ref": "urbane-whippet-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.894736842105263}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.802648}, "meta_inference_prompt_tokens": {"value": 15740.0}, "meta_inference_completion_tokens": {"value": 859.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003148}, "meta_inference_completion_cost": {"value": 0.0013744}, "meta_eval_time": {"value": 24.697}, "meta_eval_prompt_tokens": {"value": 11285.0}, "meta_eval_completion_tokens": {"value": 2198.0}, "meta_eval_prompt_cost": {"value": 0.0036112}, "meta_eval_completion_cost": {"value": 0.00281344}}, "created": "2025-12-10T21:57:27.7540826Z"}
{"ref": "violent-mustard", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.714285714285714}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.276847}, "meta_inference_prompt_tokens": {"value": 11423.0}, "meta_inference_completion_tokens": {"value": 975.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022846}, "meta_inference_completion_cost": {"value": 0.00156}, "meta_eval_time": {"value": 14.17}, "meta_eval_prompt_tokens": {"value": 5694.0}, "meta_eval_completion_tokens": {"value": 1113.0}, "meta_eval_prompt_cost": {"value": 0.00182208}, "meta_eval_completion_cost": {"value": 0.00142464}}, "created": "2025-12-10T21:57:27.7884538Z"}
{"ref": "vertical-weight", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.666666666666667}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.899345}, "meta_inference_prompt_tokens": {"value": 10799.0}, "meta_inference_completion_tokens": {"value": 1357.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021598}, "meta_inference_completion_cost": {"value": 0.0021712}, "meta_eval_time": {"value": 21.977}, "meta_eval_prompt_tokens": {"value": 5867.0}, "meta_eval_completion_tokens": {"value": 1935.0}, "meta_eval_prompt_cost": {"value": 0.00187744}, "meta_eval_completion_cost": {"value": 0.0024768}}, "created": "2025-12-10T21:57:28.1928863Z"}
{"ref": "topped-pique", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.98}, "generation_factuality_f1": {"value": 0.181818181818182}, "generation_factuality_precision": {"value": 0.125}, "generation_factuality_recall": {"value": 0.333333333333333}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.333333333333333}, "meta_inference_time": {"value": 31.0682}, "meta_inference_prompt_tokens": {"value": 10943.0}, "meta_inference_completion_tokens": {"value": 1783.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021886}, "meta_inference_completion_cost": {"value": 0.0028528}, "meta_eval_time": {"value": 54.475}, "meta_eval_prompt_tokens": {"value": 7605.0}, "meta_eval_completion_tokens": {"value": 4702.0}, "meta_eval_prompt_cost": {"value": 0.0024336}, "meta_eval_completion_cost": {"value": 0.00601856}}, "created": "2025-12-10T21:57:29.1032115Z"}
{"ref": "upbeat-mamba", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.962962962962963}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 0.5}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.5}, "meta_inference_time": {"value": 31.039499}, "meta_inference_prompt_tokens": {"value": 14176.0}, "meta_inference_completion_tokens": {"value": 2157.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028352}, "meta_inference_completion_cost": {"value": 0.0034512}, "meta_eval_time": {"value": 34.518}, "meta_eval_prompt_tokens": {"value": 9082.0}, "meta_eval_completion_tokens": {"value": 2613.0}, "meta_eval_prompt_cost": {"value": 0.00290624}, "meta_eval_completion_cost": {"value": 0.00334464}}, "created": "2025-12-10T21:57:29.5219898Z"}
{"ref": "warm-beaujolais-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.28356}, "meta_inference_prompt_tokens": {"value": 10839.0}, "meta_inference_completion_tokens": {"value": 1317.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021678}, "meta_inference_completion_cost": {"value": 0.0021072}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:57:29.5694833Z"}
{"ref": "warm-beaujolais-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 12.728281}, "meta_inference_prompt_tokens": {"value": 2261.0}, "meta_inference_completion_tokens": {"value": 763.0}, "meta_inference_prompt_cost": {"value": 0.0004522}, "meta_inference_completion_cost": {"value": 0.0012208}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:57:29.6159582Z"}
{"ref": "vertical-weight", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.777777777777778}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.489176}, "meta_inference_prompt_tokens": {"value": 11472.0}, "meta_inference_completion_tokens": {"value": 1018.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022944}, "meta_inference_completion_cost": {"value": 0.0016288}, "meta_eval_time": {"value": 17.698}, "meta_eval_prompt_tokens": {"value": 6087.0}, "meta_eval_completion_tokens": {"value": 1427.0}, "meta_eval_prompt_cost": {"value": 0.00194784}, "meta_eval_completion_cost": {"value": 0.00182656}}, "created": "2025-12-10T21:57:29.9093518Z"}
{"ref": "warm-beaujolais-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.946655}, "meta_inference_prompt_tokens": {"value": 2261.0}, "meta_inference_completion_tokens": {"value": 569.0}, "meta_inference_prompt_cost": {"value": 0.0004522}, "meta_inference_completion_cost": {"value": 0.0009104}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:57:29.9487703Z"}
{"ref": "wary-rocket", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.64702}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 515.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.000824}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:57:29.987397Z"}
{"ref": "urbane-whippet-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.904761904761905}, "generation_factuality_f1": {"value": 0.947368421052632}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.75684}, "meta_inference_prompt_tokens": {"value": 14911.0}, "meta_inference_completion_tokens": {"value": 899.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029822}, "meta_inference_completion_cost": {"value": 0.0014384}, "meta_eval_time": {"value": 27.394}, "meta_eval_prompt_tokens": {"value": 10627.0}, "meta_eval_completion_tokens": {"value": 2390.0}, "meta_eval_prompt_cost": {"value": 0.00340064}, "meta_eval_completion_cost": {"value": 0.0030592}}, "created": "2025-12-10T21:57:30.3842359Z"}
{"ref": "wary-rocket", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.560148}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 318.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0005088}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:57:30.4225181Z"}
{"ref": "violent-mustard", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.242956}, "meta_inference_prompt_tokens": {"value": 13015.0}, "meta_inference_completion_tokens": {"value": 1166.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002603}, "meta_inference_completion_cost": {"value": 0.0018656}, "meta_eval_time": {"value": 15.017}, "meta_eval_prompt_tokens": {"value": 7265.0}, "meta_eval_completion_tokens": {"value": 1087.0}, "meta_eval_prompt_cost": {"value": 0.0023248}, "meta_eval_completion_cost": {"value": 0.00139136}}, "created": "2025-12-10T21:57:30.4370394Z"}
{"ref": "warm-beaujolais-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.444614}, "meta_inference_prompt_tokens": {"value": 2261.0}, "meta_inference_completion_tokens": {"value": 584.0}, "meta_inference_prompt_cost": {"value": 0.0004522}, "meta_inference_completion_cost": {"value": 0.0009344}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:57:30.4590503Z"}
{"ref": "warm-beaujolais-A", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 13.912511}, "meta_inference_prompt_tokens": {"value": 2261.0}, "meta_inference_completion_tokens": {"value": 639.0}, "meta_inference_prompt_cost": {"value": 0.0004522}, "meta_inference_completion_cost": {"value": 0.0010224}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:57:30.5461992Z"}
{"ref": "wary-rocket", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 10.314826}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 517.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0008272}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:57:30.5853116Z"}
{"ref": "vertical-weight", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.75}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.42883}, "meta_inference_prompt_tokens": {"value": 11156.0}, "meta_inference_completion_tokens": {"value": 1229.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022312}, "meta_inference_completion_cost": {"value": 0.0019664}, "meta_eval_time": {"value": 15.067}, "meta_eval_prompt_tokens": {"value": 5887.0}, "meta_eval_completion_tokens": {"value": 1242.0}, "meta_eval_prompt_cost": {"value": 0.00188384}, "meta_eval_completion_cost": {"value": 0.00158976}}, "created": "2025-12-10T21:57:30.6085287Z"}
{"ref": "upbeat-mamba", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.1}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.884615384615384}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0526315789473684}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.05}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 41.075522}, "meta_inference_prompt_tokens": {"value": 30979.0}, "meta_inference_completion_tokens": {"value": 2195.0}, "meta_inference_tool_call_count": {"value": 2.0}, "meta_inference_prompt_cost": {"value": 0.0061958}, "meta_inference_completion_cost": {"value": 0.003512}, "meta_eval_time": {"value": 35.376}, "meta_eval_prompt_tokens": {"value": 12534.0}, "meta_eval_completion_tokens": {"value": 3042.0}, "meta_eval_prompt_cost": {"value": 0.00401088}, "meta_eval_completion_cost": {"value": 0.00389376}}, "created": "2025-12-10T21:57:30.7897028Z"}
{"ref": "wary-rocket", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.293302}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 702.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0011232}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:57:30.8365694Z"}
{"ref": "urbane-whippet-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.947368421052632}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.026954}, "meta_inference_prompt_tokens": {"value": 13710.0}, "meta_inference_completion_tokens": {"value": 690.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002742}, "meta_inference_completion_cost": {"value": 0.001104}, "meta_eval_time": {"value": 28.826}, "meta_eval_prompt_tokens": {"value": 9218.0}, "meta_eval_completion_tokens": {"value": 2182.0}, "meta_eval_prompt_cost": {"value": 0.00294976}, "meta_eval_completion_cost": {"value": 0.00279296}}, "created": "2025-12-10T21:57:31.7159757Z"}
{"ref": "vertical-weight", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.692307692307692}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.723567}, "meta_inference_prompt_tokens": {"value": 11393.0}, "meta_inference_completion_tokens": {"value": 1171.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022786}, "meta_inference_completion_cost": {"value": 0.0018736}, "meta_eval_time": {"value": 18.227}, "meta_eval_prompt_tokens": {"value": 6145.0}, "meta_eval_completion_tokens": {"value": 1720.0}, "meta_eval_prompt_cost": {"value": 0.0019664}, "meta_eval_completion_cost": {"value": 0.0022016}}, "created": "2025-12-10T21:57:32.208151Z"}
{"ref": "urbane-whippet-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.93195974923544}, "generation_faithfulness": {"value": 0.933333333333333}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 42.830405}, "meta_inference_prompt_tokens": {"value": 11710.0}, "meta_inference_completion_tokens": {"value": 1517.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002342}, "meta_inference_completion_cost": {"value": 0.0024272}, "meta_eval_time": {"value": 37.725}, "meta_eval_prompt_tokens": {"value": 7475.0}, "meta_eval_completion_tokens": {"value": 2970.0}, "meta_eval_prompt_cost": {"value": 0.002392}, "meta_eval_completion_cost": {"value": 0.0038016}}, "created": "2025-12-10T21:57:33.6659837Z"}
{"ref": "wary-rocket", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 9.360589}, "meta_inference_prompt_tokens": {"value": 2255.0}, "meta_inference_completion_tokens": {"value": 451.0}, "meta_inference_prompt_cost": {"value": 0.000451}, "meta_inference_completion_cost": {"value": 0.0007216}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:57:33.713969Z"}
{"ref": "topped-noodle", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 29.881869}, "meta_inference_prompt_tokens": {"value": 11212.0}, "meta_inference_completion_tokens": {"value": 1957.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022424}, "meta_inference_completion_cost": {"value": 0.0031312}, "meta_eval_time": {"value": 63.195}, "meta_eval_prompt_tokens": {"value": 8479.0}, "meta_eval_completion_tokens": {"value": 4493.0}, "meta_eval_prompt_cost": {"value": 0.00271328}, "meta_eval_completion_cost": {"value": 0.00575104}}, "created": "2025-12-10T21:57:33.8982552Z"}
{"ref": "violent-mustard", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.142857142857143}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.173916}, "meta_inference_prompt_tokens": {"value": 10729.0}, "meta_inference_completion_tokens": {"value": 1127.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021458}, "meta_inference_completion_cost": {"value": 0.0018032}, "meta_eval_time": {"value": 18.712}, "meta_eval_prompt_tokens": {"value": 5832.0}, "meta_eval_completion_tokens": {"value": 1519.0}, "meta_eval_prompt_cost": {"value": 0.00186624}, "meta_eval_completion_cost": {"value": 0.00194432}}, "created": "2025-12-10T21:57:35.8224385Z"}
{"ref": "urbane-whippet-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.461538461538462}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 1.93195974923544}, "generation_faithfulness": {"value": 0.916666666666666}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.3}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.576561}, "meta_inference_prompt_tokens": {"value": 11706.0}, "meta_inference_completion_tokens": {"value": 1291.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023412}, "meta_inference_completion_cost": {"value": 0.0020656}, "meta_eval_time": {"value": 39.055}, "meta_eval_prompt_tokens": {"value": 7811.0}, "meta_eval_completion_tokens": {"value": 3456.0}, "meta_eval_prompt_cost": {"value": 0.00249952}, "meta_eval_completion_cost": {"value": 0.00442368}}, "created": "2025-12-10T21:57:36.0014922Z"}
{"ref": "white-coopetition", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 10.568368}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 414.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0006624}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:57:36.0652614Z"}
{"ref": "white-coopetition", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 18.093089}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 929.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0014864}, "meta_eval_time": {"value": 0.001}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:57:36.1035845Z"}
{"ref": "violent-mustard", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.964267}, "meta_inference_prompt_tokens": {"value": 11536.0}, "meta_inference_completion_tokens": {"value": 1138.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023072}, "meta_inference_completion_cost": {"value": 0.0018208}, "meta_eval_time": {"value": 19.588}, "meta_eval_prompt_tokens": {"value": 6180.0}, "meta_eval_completion_tokens": {"value": 1752.0}, "meta_eval_prompt_cost": {"value": 0.0019776}, "meta_eval_completion_cost": {"value": 0.00224256}}, "created": "2025-12-10T21:57:37.2403373Z"}
{"ref": "white-coopetition", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 14.2528}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 679.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0010864}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:57:37.3049491Z"}
{"ref": "violent-mustard", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.909090909090909}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.453997}, "meta_inference_prompt_tokens": {"value": 14507.0}, "meta_inference_completion_tokens": {"value": 1149.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029014}, "meta_inference_completion_cost": {"value": 0.0018384}, "meta_eval_time": {"value": 20.569}, "meta_eval_prompt_tokens": {"value": 8630.0}, "meta_eval_completion_tokens": {"value": 1605.0}, "meta_eval_prompt_cost": {"value": 0.0027616}, "meta_eval_completion_cost": {"value": 0.0020544}}, "created": "2025-12-10T21:57:37.3368567Z"}
{"ref": "white-coopetition", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 8.386984}, "meta_inference_prompt_tokens": {"value": 2250.0}, "meta_inference_completion_tokens": {"value": 286.0}, "meta_inference_prompt_cost": {"value": 0.00045}, "meta_inference_completion_cost": {"value": 0.0004576}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:57:37.3570867Z"}
{"ref": "white-coopetition", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.488917}, "meta_inference_prompt_tokens": {"value": 4664.0}, "meta_inference_completion_tokens": {"value": 1033.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0009328}, "meta_inference_completion_cost": {"value": 0.0016528}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:57:37.3989825Z"}
{"ref": "topped-pique", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 28.900549}, "meta_inference_prompt_tokens": {"value": 10875.0}, "meta_inference_completion_tokens": {"value": 1833.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002175}, "meta_inference_completion_cost": {"value": 0.0029328}, "meta_eval_time": {"value": 65.119}, "meta_eval_prompt_tokens": {"value": 8134.0}, "meta_eval_completion_tokens": {"value": 5348.0}, "meta_eval_prompt_cost": {"value": 0.00260288}, "meta_eval_completion_cost": {"value": 0.00684544}}, "created": "2025-12-10T21:57:38.002599Z"}
{"ref": "urbane-whippet-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.91304347826087}, "generation_factuality_f1": {"value": 0.875}, "generation_factuality_precision": {"value": 0.777777777777778}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.673415}, "meta_inference_prompt_tokens": {"value": 16552.0}, "meta_inference_completion_tokens": {"value": 963.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0033104}, "meta_inference_completion_cost": {"value": 0.0015408}, "meta_eval_time": {"value": 26.812}, "meta_eval_prompt_tokens": {"value": 12107.0}, "meta_eval_completion_tokens": {"value": 2296.0}, "meta_eval_prompt_cost": {"value": 0.00387424}, "meta_eval_completion_cost": {"value": 0.00293888}}, "created": "2025-12-10T21:57:38.1058121Z"}
{"ref": "vintage-store-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.73752394519728}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.227272727272727}, "generation_factuality_recall": {"value": 0.625}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.625}, "meta_inference_time": {"value": 23.226629}, "meta_inference_prompt_tokens": {"value": 18342.0}, "meta_inference_completion_tokens": {"value": 1150.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0036684}, "meta_inference_completion_cost": {"value": 0.00184}, "meta_eval_time": {"value": 30.706}, "meta_eval_prompt_tokens": {"value": 13712.0}, "meta_eval_completion_tokens": {"value": 2565.0}, "meta_eval_prompt_cost": {"value": 0.00438784}, "meta_eval_completion_cost": {"value": 0.0032832}}, "created": "2025-12-10T21:57:43.5354929Z"}
{"ref": "urbane-whippet-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.630929753571458}, "generation_faithfulness": {"value": 0.96551724137931}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.181505}, "meta_inference_prompt_tokens": {"value": 13456.0}, "meta_inference_completion_tokens": {"value": 1141.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026912}, "meta_inference_completion_cost": {"value": 0.0018256}, "meta_eval_time": {"value": 31.21}, "meta_eval_prompt_tokens": {"value": 9335.0}, "meta_eval_completion_tokens": {"value": 2836.0}, "meta_eval_prompt_cost": {"value": 0.0029872}, "meta_eval_completion_cost": {"value": 0.00363008}}, "created": "2025-12-10T21:57:43.8949407Z"}
{"ref": "urbane-whippet-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 0.851063829787234}, "generation_factuality_f1": {"value": 0.285714285714286}, "generation_factuality_precision": {"value": 0.166666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.672971}, "meta_inference_prompt_tokens": {"value": 11343.0}, "meta_inference_completion_tokens": {"value": 1444.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022686}, "meta_inference_completion_cost": {"value": 0.0023104}, "meta_eval_time": {"value": 48.468}, "meta_eval_prompt_tokens": {"value": 7973.0}, "meta_eval_completion_tokens": {"value": 4357.0}, "meta_eval_prompt_cost": {"value": 0.00255136}, "meta_eval_completion_cost": {"value": 0.00557696}}, "created": "2025-12-10T21:57:45.2569114Z"}
{"ref": "vintage-store-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.07947476819246}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.387096774193548}, "generation_factuality_precision": {"value": 0.260869565217391}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 22.338781}, "meta_inference_prompt_tokens": {"value": 17285.0}, "meta_inference_completion_tokens": {"value": 993.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003457}, "meta_inference_completion_cost": {"value": 0.0015888}, "meta_eval_time": {"value": 33.575}, "meta_eval_prompt_tokens": {"value": 12972.0}, "meta_eval_completion_tokens": {"value": 3119.0}, "meta_eval_prompt_cost": {"value": 0.00415104}, "meta_eval_completion_cost": {"value": 0.00399232}}, "created": "2025-12-10T21:57:45.9545785Z"}
{"ref": "vintage-store-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.73752394519728}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.428571428571428}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 24.61259}, "meta_inference_prompt_tokens": {"value": 18345.0}, "meta_inference_completion_tokens": {"value": 926.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003669}, "meta_inference_completion_cost": {"value": 0.0014816}, "meta_eval_time": {"value": 44.602}, "meta_eval_prompt_tokens": {"value": 14280.0}, "meta_eval_completion_tokens": {"value": 3787.0}, "meta_eval_prompt_cost": {"value": 0.0045696}, "meta_eval_completion_cost": {"value": 0.00484736}}, "created": "2025-12-10T21:57:49.2955364Z"}
{"ref": "urbane-whippet-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.886852807234542}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.094399}, "meta_inference_prompt_tokens": {"value": 12633.0}, "meta_inference_completion_tokens": {"value": 1478.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025266}, "meta_inference_completion_cost": {"value": 0.0023648}, "meta_eval_time": {"value": 55.06}, "meta_eval_prompt_tokens": {"value": 9535.0}, "meta_eval_completion_tokens": {"value": 4709.0}, "meta_eval_prompt_cost": {"value": 0.0030512}, "meta_eval_completion_cost": {"value": 0.00602752}}, "created": "2025-12-10T21:57:50.0229709Z"}
{"ref": "vintage-store-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 1.73752394519728}, "generation_faithfulness": {"value": 0.972972972972973}, "generation_factuality_f1": {"value": 0.27027027027027}, "generation_factuality_precision": {"value": 0.172413793103448}, "generation_factuality_recall": {"value": 0.625}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.625}, "meta_inference_time": {"value": 25.388531}, "meta_inference_prompt_tokens": {"value": 18345.0}, "meta_inference_completion_tokens": {"value": 1270.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.003669}, "meta_inference_completion_cost": {"value": 0.002032}, "meta_eval_time": {"value": 40.541}, "meta_eval_prompt_tokens": {"value": 14189.0}, "meta_eval_completion_tokens": {"value": 3806.0}, "meta_eval_prompt_cost": {"value": 0.00454048}, "meta_eval_completion_cost": {"value": 0.00487168}}, "created": "2025-12-10T21:57:50.1109034Z"}
{"ref": "tossed-degree", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 2.017782560806}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.732411}, "meta_inference_prompt_tokens": {"value": 14400.0}, "meta_inference_completion_tokens": {"value": 1155.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00288}, "meta_inference_completion_cost": {"value": 0.001848}, "meta_eval_time": {"value": 29.265}, "meta_eval_prompt_tokens": {"value": 9389.0}, "meta_eval_completion_tokens": {"value": 2437.0}, "meta_eval_prompt_cost": {"value": 0.00300448}, "meta_eval_completion_cost": {"value": 0.00311936}}, "created": "2025-12-10T21:57:51.9917394Z"}
{"ref": "violent-pedestal-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.588235294117647}, "retrieval_mrr": {"value": 0.423333333333333}, "retrieval_dcg": {"value": 2.80466630598741}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.941176470588235}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 0.888888888888889}, "retrieval_accuracy": {"value": 0.416666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 0.714285714285714}, "generation_correctness": {"value": 0.888888888888889}, "meta_inference_time": {"value": 20.733671}, "meta_inference_prompt_tokens": {"value": 14251.0}, "meta_inference_completion_tokens": {"value": 1103.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028502}, "meta_inference_completion_cost": {"value": 0.0017648}, "meta_eval_time": {"value": 39.631}, "meta_eval_prompt_tokens": {"value": 9868.0}, "meta_eval_completion_tokens": {"value": 3299.0}, "meta_eval_prompt_cost": {"value": 0.00315776}, "meta_eval_completion_cost": {"value": 0.00422272}}, "created": "2025-12-10T21:57:57.2284475Z"}
{"ref": "volumetric-embedding", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.863636363636364}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 22.60346}, "meta_inference_prompt_tokens": {"value": 9790.0}, "meta_inference_completion_tokens": {"value": 1386.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.001958}, "meta_inference_completion_cost": {"value": 0.0022176}, "meta_eval_time": {"value": 27.889}, "meta_eval_prompt_tokens": {"value": 5278.0}, "meta_eval_completion_tokens": {"value": 2772.0}, "meta_eval_prompt_cost": {"value": 0.00168896}, "meta_eval_completion_cost": {"value": 0.00354816}}, "created": "2025-12-10T21:57:57.5436505Z"}
{"ref": "urbane-whippet-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.13092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.628393}, "meta_inference_prompt_tokens": {"value": 12425.0}, "meta_inference_completion_tokens": {"value": 1508.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002485}, "meta_inference_completion_cost": {"value": 0.0024128}, "meta_eval_time": {"value": 58.953}, "meta_eval_prompt_tokens": {"value": 9452.0}, "meta_eval_completion_tokens": {"value": 5268.0}, "meta_eval_prompt_cost": {"value": 0.00302464}, "meta_eval_completion_cost": {"value": 0.00674304}}, "created": "2025-12-10T21:57:58.1832897Z"}
{"ref": "vintage-store-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 0.583333333333333}, "retrieval_dcg": {"value": 2.18788280289852}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.631578947368421}, "generation_factuality_precision": {"value": 0.545454545454545}, "generation_factuality_recall": {"value": 0.75}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.75}, "meta_inference_time": {"value": 26.97647}, "meta_inference_prompt_tokens": {"value": 16907.0}, "meta_inference_completion_tokens": {"value": 1420.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0033814}, "meta_inference_completion_cost": {"value": 0.002272}, "meta_eval_time": {"value": 39.874}, "meta_eval_prompt_tokens": {"value": 13047.0}, "meta_eval_completion_tokens": {"value": 3594.0}, "meta_eval_prompt_cost": {"value": 0.00417504}, "meta_eval_completion_cost": {"value": 0.00460032}}, "created": "2025-12-10T21:57:59.0538115Z"}
{"ref": "violent-pedestal-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.588235294117647}, "retrieval_mrr": {"value": 0.423333333333333}, "retrieval_dcg": {"value": 2.07085727853061}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.72289156626506}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.416666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 0.714285714285714}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 27.565907}, "meta_inference_prompt_tokens": {"value": 14175.0}, "meta_inference_completion_tokens": {"value": 1423.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002835}, "meta_inference_completion_cost": {"value": 0.0022768}, "meta_eval_time": {"value": 45.15}, "meta_eval_prompt_tokens": {"value": 10299.0}, "meta_eval_completion_tokens": {"value": 3995.0}, "meta_eval_prompt_cost": {"value": 0.00329568}, "meta_eval_completion_cost": {"value": 0.0051136}}, "created": "2025-12-10T21:57:59.4357849Z"}
{"ref": "weathered-deque", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.5}, "generation_factuality_precision": {"value": 0.333333333333333}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.85956}, "meta_inference_prompt_tokens": {"value": 12058.0}, "meta_inference_completion_tokens": {"value": 999.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024116}, "meta_inference_completion_cost": {"value": 0.0015984}, "meta_eval_time": {"value": 23.801}, "meta_eval_prompt_tokens": {"value": 7018.0}, "meta_eval_completion_tokens": {"value": 2335.0}, "meta_eval_prompt_cost": {"value": 0.00224576}, "meta_eval_completion_cost": {"value": 0.0029888}}, "created": "2025-12-10T21:57:59.6643284Z"}
{"ref": "weathered-deque", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.222222222222222}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.533333333333333}, "generation_factuality_precision": {"value": 0.363636363636364}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.125}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.125}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 16.868037}, "meta_inference_prompt_tokens": {"value": 11630.0}, "meta_inference_completion_tokens": {"value": 903.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002326}, "meta_inference_completion_cost": {"value": 0.0014448}, "meta_eval_time": {"value": 25.842}, "meta_eval_prompt_tokens": {"value": 7125.0}, "meta_eval_completion_tokens": {"value": 2364.0}, "meta_eval_prompt_cost": {"value": 0.00228}, "meta_eval_completion_cost": {"value": 0.00302592}}, "created": "2025-12-10T21:57:59.7808032Z"}
{"ref": "weathered-deque", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.928571428571429}, "generation_factuality_f1": {"value": 0.333333333333333}, "generation_factuality_precision": {"value": 0.2}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.166666666666667}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.443179}, "meta_inference_prompt_tokens": {"value": 8879.0}, "meta_inference_completion_tokens": {"value": 1022.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0017758}, "meta_inference_completion_cost": {"value": 0.0016352}, "meta_eval_time": {"value": 28.781}, "meta_eval_prompt_tokens": {"value": 5647.0}, "meta_eval_completion_tokens": {"value": 2860.0}, "meta_eval_prompt_cost": {"value": 0.00180704}, "meta_eval_completion_cost": {"value": 0.0036608}}, "created": "2025-12-10T21:58:01.0290249Z"}
{"ref": "volumetric-embedding", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 29.296541}, "meta_inference_prompt_tokens": {"value": 11811.0}, "meta_inference_completion_tokens": {"value": 1453.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023622}, "meta_inference_completion_cost": {"value": 0.0023248}, "meta_eval_time": {"value": 33.781}, "meta_eval_prompt_tokens": {"value": 7732.0}, "meta_eval_completion_tokens": {"value": 3327.0}, "meta_eval_prompt_cost": {"value": 0.00247424}, "meta_eval_completion_cost": {"value": 0.00425856}}, "created": "2025-12-10T21:58:01.5765625Z"}
{"ref": "warped-chickadee", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.430676558073393}, "generation_faithfulness": {"value": 0.92}, "generation_factuality_f1": {"value": 0.631578947368421}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 0.666666666666667}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.666666666666667}, "meta_inference_time": {"value": 29.166626}, "meta_inference_prompt_tokens": {"value": 13348.0}, "meta_inference_completion_tokens": {"value": 1635.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026696}, "meta_inference_completion_cost": {"value": 0.002616}, "meta_eval_time": {"value": 31.031}, "meta_eval_prompt_tokens": {"value": 9101.0}, "meta_eval_completion_tokens": {"value": 2723.0}, "meta_eval_prompt_cost": {"value": 0.00291232}, "meta_eval_completion_cost": {"value": 0.00348544}}, "created": "2025-12-10T21:58:01.9130632Z"}
{"ref": "warped-chickadee", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.961538461538462}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 0.833333333333334}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 0.833333333333334}, "meta_inference_time": {"value": 28.313556}, "meta_inference_prompt_tokens": {"value": 12386.0}, "meta_inference_completion_tokens": {"value": 1812.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024772}, "meta_inference_completion_cost": {"value": 0.0028992}, "meta_eval_time": {"value": 32.624}, "meta_eval_prompt_tokens": {"value": 8420.0}, "meta_eval_completion_tokens": {"value": 3159.0}, "meta_eval_prompt_cost": {"value": 0.0026944}, "meta_eval_completion_cost": {"value": 0.00404352}}, "created": "2025-12-10T21:58:03.2763647Z"}
{"ref": "wide-lens", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 29.111935}, "meta_inference_prompt_tokens": {"value": 15624.0}, "meta_inference_completion_tokens": {"value": 1653.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031248}, "meta_inference_completion_cost": {"value": 0.0026448}, "meta_eval_time": {"value": 26.067}, "meta_eval_prompt_tokens": {"value": 10191.0}, "meta_eval_completion_tokens": {"value": 2470.0}, "meta_eval_prompt_cost": {"value": 0.00326112}, "meta_eval_completion_cost": {"value": 0.0031616}}, "created": "2025-12-10T21:58:04.111796Z"}
{"ref": "weathered-deque", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.5}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.833333333333334}, "generation_factuality_f1": {"value": 0.4}, "generation_factuality_precision": {"value": 0.25}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.333333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.333333333333333}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.399651}, "meta_inference_prompt_tokens": {"value": 6878.0}, "meta_inference_completion_tokens": {"value": 1134.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0013756}, "meta_inference_completion_cost": {"value": 0.0018144}, "meta_eval_time": {"value": 34.28}, "meta_eval_prompt_tokens": {"value": 4948.0}, "meta_eval_completion_tokens": {"value": 2994.0}, "meta_eval_prompt_cost": {"value": 0.00158336}, "meta_eval_completion_cost": {"value": 0.00383232}}, "created": "2025-12-10T21:58:04.7605717Z"}
{"ref": "weathered-deque", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.25}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.142857142857143}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.142857142857143}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.012639}, "meta_inference_prompt_tokens": {"value": 10571.0}, "meta_inference_completion_tokens": {"value": 987.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0021142}, "meta_inference_completion_cost": {"value": 0.0015792}, "meta_eval_time": {"value": 33.175}, "meta_eval_prompt_tokens": {"value": 6746.0}, "meta_eval_completion_tokens": {"value": 2782.0}, "meta_eval_prompt_cost": {"value": 0.00215872}, "meta_eval_completion_cost": {"value": 0.00356096}}, "created": "2025-12-10T21:58:04.9351432Z"}
{"ref": "violent-pedestal-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.588235294117647}, "retrieval_mrr": {"value": 0.423333333333333}, "retrieval_dcg": {"value": 2.5471714305231}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.878048780487805}, "generation_factuality_precision": {"value": 0.9}, "generation_factuality_recall": {"value": 0.857142857142857}, "retrieval_accuracy": {"value": 0.416666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 0.714285714285714}, "generation_correctness": {"value": 0.857142857142857}, "meta_inference_time": {"value": 30.146903}, "meta_inference_prompt_tokens": {"value": 14861.0}, "meta_inference_completion_tokens": {"value": 1746.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029722}, "meta_inference_completion_cost": {"value": 0.0027936}, "meta_eval_time": {"value": 44.792}, "meta_eval_prompt_tokens": {"value": 11498.0}, "meta_eval_completion_tokens": {"value": 4293.0}, "meta_eval_prompt_cost": {"value": 0.00367936}, "meta_eval_completion_cost": {"value": 0.00549504}}, "created": "2025-12-10T21:58:05.0617859Z"}
{"ref": "young-cheeseburger", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 9.153199}, "meta_inference_prompt_tokens": {"value": 2254.0}, "meta_inference_completion_tokens": {"value": 283.0}, "meta_inference_prompt_cost": {"value": 0.0004508}, "meta_inference_completion_cost": {"value": 0.0004528}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:58:05.0998851Z"}
{"ref": "young-cheeseburger", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 11.35702}, "meta_inference_prompt_tokens": {"value": 2254.0}, "meta_inference_completion_tokens": {"value": 474.0}, "meta_inference_prompt_cost": {"value": 0.0004508}, "meta_inference_completion_cost": {"value": 0.0007584}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:58:05.1582977Z"}
{"ref": "violent-pedestal-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.470588235294118}, "retrieval_mrr": {"value": 0.404166666666667}, "retrieval_dcg": {"value": 2.39493964497818}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.307692307692308}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.571428571428571}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.430701}, "meta_inference_prompt_tokens": {"value": 15666.0}, "meta_inference_completion_tokens": {"value": 1724.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0031332}, "meta_inference_completion_cost": {"value": 0.0027584}, "meta_eval_time": {"value": 48.945}, "meta_eval_prompt_tokens": {"value": 12640.0}, "meta_eval_completion_tokens": {"value": 4626.0}, "meta_eval_prompt_cost": {"value": 0.0040448}, "meta_eval_completion_cost": {"value": 0.00592128}}, "created": "2025-12-10T21:58:05.2396969Z"}
{"ref": "volumetric-embedding", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.964285714285714}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 22.156965}, "meta_inference_prompt_tokens": {"value": 10481.0}, "meta_inference_completion_tokens": {"value": 1414.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020962}, "meta_inference_completion_cost": {"value": 0.0022624}, "meta_eval_time": {"value": 38.314}, "meta_eval_prompt_tokens": {"value": 6296.0}, "meta_eval_completion_tokens": {"value": 3332.0}, "meta_eval_prompt_cost": {"value": 0.00201472}, "meta_eval_completion_cost": {"value": 0.00426496}}, "created": "2025-12-10T21:58:05.3684961Z"}
{"ref": "warped-chickadee", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.181818181818182}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.870967741935484}, "generation_factuality_f1": {"value": 0.933333333333333}, "generation_factuality_precision": {"value": 0.875}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.1}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 31.331841}, "meta_inference_prompt_tokens": {"value": 12356.0}, "meta_inference_completion_tokens": {"value": 1861.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024712}, "meta_inference_completion_cost": {"value": 0.0029776}, "meta_eval_time": {"value": 35.59}, "meta_eval_prompt_tokens": {"value": 8534.0}, "meta_eval_completion_tokens": {"value": 3464.0}, "meta_eval_prompt_cost": {"value": 0.00273088}, "meta_eval_completion_cost": {"value": 0.00443392}}, "created": "2025-12-10T21:58:06.2307973Z"}
{"ref": "young-cheeseburger", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 8.564647}, "meta_inference_prompt_tokens": {"value": 2254.0}, "meta_inference_completion_tokens": {"value": 350.0}, "meta_inference_prompt_cost": {"value": 0.0004508}, "meta_inference_completion_cost": {"value": 0.00056}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:58:06.2785052Z"}
{"ref": "violent-pedestal-A", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.588235294117647}, "retrieval_mrr": {"value": 0.423333333333333}, "retrieval_dcg": {"value": 2.52077138005526}, "generation_faithfulness": {"value": 0.979591836734694}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.416666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 0.714285714285714}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.436596}, "meta_inference_prompt_tokens": {"value": 14869.0}, "meta_inference_completion_tokens": {"value": 1374.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029738}, "meta_inference_completion_cost": {"value": 0.0021984}, "meta_eval_time": {"value": 61.443}, "meta_eval_prompt_tokens": {"value": 11271.0}, "meta_eval_completion_tokens": {"value": 4584.0}, "meta_eval_prompt_cost": {"value": 0.00360672}, "meta_eval_completion_cost": {"value": 0.00586752}}, "created": "2025-12-10T21:58:06.5551569Z"}
{"ref": "warped-chickadee", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.911764705882353}, "generation_factuality_f1": {"value": 0.909090909090909}, "generation_factuality_precision": {"value": 0.833333333333334}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 34.946144}, "meta_inference_prompt_tokens": {"value": 12117.0}, "meta_inference_completion_tokens": {"value": 1672.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024234}, "meta_inference_completion_cost": {"value": 0.0026752}, "meta_eval_time": {"value": 38.327}, "meta_eval_prompt_tokens": {"value": 8430.0}, "meta_eval_completion_tokens": {"value": 3443.0}, "meta_eval_prompt_cost": {"value": 0.0026976}, "meta_eval_completion_cost": {"value": 0.00440704}}, "created": "2025-12-10T21:58:08.3664395Z"}
{"ref": "wide-penny", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 30.747587}, "meta_inference_prompt_tokens": {"value": 11793.0}, "meta_inference_completion_tokens": {"value": 1425.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023586}, "meta_inference_completion_cost": {"value": 0.00228}, "meta_eval_time": {"value": 30.267}, "meta_eval_prompt_tokens": {"value": 7129.0}, "meta_eval_completion_tokens": {"value": 2508.0}, "meta_eval_prompt_cost": {"value": 0.00228128}, "meta_eval_completion_cost": {"value": 0.00321024}}, "created": "2025-12-10T21:58:08.4139098Z"}
{"ref": "warped-chickadee", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.931034482758621}, "generation_factuality_f1": {"value": 0.857142857142857}, "generation_factuality_precision": {"value": 0.75}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.600303}, "meta_inference_prompt_tokens": {"value": 12242.0}, "meta_inference_completion_tokens": {"value": 1830.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024484}, "meta_inference_completion_cost": {"value": 0.002928}, "meta_eval_time": {"value": 34.973}, "meta_eval_prompt_tokens": {"value": 8307.0}, "meta_eval_completion_tokens": {"value": 3141.0}, "meta_eval_prompt_cost": {"value": 0.00265824}, "meta_eval_completion_cost": {"value": 0.00402048}}, "created": "2025-12-10T21:58:08.7274645Z"}
{"ref": "volumetric-embedding", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 24.036402}, "meta_inference_prompt_tokens": {"value": 11998.0}, "meta_inference_completion_tokens": {"value": 1310.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023996}, "meta_inference_completion_cost": {"value": 0.002096}, "meta_eval_time": {"value": 41.916}, "meta_eval_prompt_tokens": {"value": 8229.0}, "meta_eval_completion_tokens": {"value": 4202.0}, "meta_eval_prompt_cost": {"value": 0.00263328}, "meta_eval_completion_cost": {"value": 0.00537856}}, "created": "2025-12-10T21:58:09.7468512Z"}
{"ref": "wide-lens", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 24.207019}, "meta_inference_prompt_tokens": {"value": 14208.0}, "meta_inference_completion_tokens": {"value": 1474.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028416}, "meta_inference_completion_cost": {"value": 0.0023584}, "meta_eval_time": {"value": 25.288}, "meta_eval_prompt_tokens": {"value": 8746.0}, "meta_eval_completion_tokens": {"value": 2542.0}, "meta_eval_prompt_cost": {"value": 0.00279872}, "meta_eval_completion_cost": {"value": 0.00325376}}, "created": "2025-12-10T21:58:11.2893469Z"}
{"ref": "young-cheeseburger", "set": "20251210152915", "metrics": {"generation_should_not_answer_accuracy": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 11.730669}, "meta_inference_prompt_tokens": {"value": 2254.0}, "meta_inference_completion_tokens": {"value": 711.0}, "meta_inference_prompt_cost": {"value": 0.0004508}, "meta_inference_completion_cost": {"value": 0.0011376}, "meta_eval_time": {"value": 0.0}, "meta_eval_prompt_tokens": {"value": 0.0}, "meta_eval_completion_tokens": {"value": 0.0}}, "created": "2025-12-10T21:58:11.3267748Z"}
{"ref": "volumetric-embedding", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 29.376555}, "meta_inference_prompt_tokens": {"value": 11561.0}, "meta_inference_completion_tokens": {"value": 1586.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0023122}, "meta_inference_completion_cost": {"value": 0.0025376}, "meta_eval_time": {"value": 46.881}, "meta_eval_prompt_tokens": {"value": 7736.0}, "meta_eval_completion_tokens": {"value": 3857.0}, "meta_eval_prompt_cost": {"value": 0.00247552}, "meta_eval_completion_cost": {"value": 0.00493696}}, "created": "2025-12-10T21:58:13.878023Z"}
{"ref": "white-lumen", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.648798210119062}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.279508}, "meta_inference_prompt_tokens": {"value": 13480.0}, "meta_inference_completion_tokens": {"value": 1452.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002696}, "meta_inference_completion_cost": {"value": 0.0023232}, "meta_eval_time": {"value": 41.06}, "meta_eval_prompt_tokens": {"value": 9791.0}, "meta_eval_completion_tokens": {"value": 4114.0}, "meta_eval_prompt_cost": {"value": 0.00313312}, "meta_eval_completion_cost": {"value": 0.00526592}}, "created": "2025-12-10T21:58:17.2053322Z"}
{"ref": "wood-polytope", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.727272727272727}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 14.434514}, "meta_inference_prompt_tokens": {"value": 10179.0}, "meta_inference_completion_tokens": {"value": 706.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020358}, "meta_inference_completion_cost": {"value": 0.0011296}, "meta_eval_time": {"value": 16.75}, "meta_eval_prompt_tokens": {"value": 4955.0}, "meta_eval_completion_tokens": {"value": 1418.0}, "meta_eval_prompt_cost": {"value": 0.0015856}, "meta_eval_completion_cost": {"value": 0.00181504}}, "created": "2025-12-10T21:58:18.7148459Z"}
{"ref": "witty-type", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.003777}, "meta_inference_prompt_tokens": {"value": 11318.0}, "meta_inference_completion_tokens": {"value": 1221.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022636}, "meta_inference_completion_cost": {"value": 0.0019536}, "meta_eval_time": {"value": 17.175}, "meta_eval_prompt_tokens": {"value": 6003.0}, "meta_eval_completion_tokens": {"value": 1622.0}, "meta_eval_prompt_cost": {"value": 0.00192096}, "meta_eval_completion_cost": {"value": 0.00207616}}, "created": "2025-12-10T21:58:18.7928438Z"}
{"ref": "young-cheeseburger", "set": "20251210152915", "metrics": {"generation_faithfulness": {"value": 0.666666666666667}, "generation_should_not_answer_accuracy": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 20.930225}, "meta_inference_prompt_tokens": {"value": 6851.0}, "meta_inference_completion_tokens": {"value": 966.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0013702}, "meta_inference_completion_cost": {"value": 0.0015456}, "meta_eval_time": {"value": 10.635}, "meta_eval_prompt_tokens": {"value": 3031.0}, "meta_eval_completion_tokens": {"value": 974.0}, "meta_eval_prompt_cost": {"value": 0.00096992}, "meta_eval_completion_cost": {"value": 0.00124672}}, "created": "2025-12-10T21:58:19.0894442Z"}
{"ref": "wide-lens", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.25}, "generation_factuality_precision": {"value": 0.142857142857143}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.68154}, "meta_inference_prompt_tokens": {"value": 16008.0}, "meta_inference_completion_tokens": {"value": 1725.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0032016}, "meta_inference_completion_cost": {"value": 0.00276}, "meta_eval_time": {"value": 35.705}, "meta_eval_prompt_tokens": {"value": 10740.0}, "meta_eval_completion_tokens": {"value": 3522.0}, "meta_eval_prompt_cost": {"value": 0.0034368}, "meta_eval_completion_cost": {"value": 0.00450816}}, "created": "2025-12-10T21:58:19.280062Z"}
{"ref": "violent-pedestal-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.48713694067948}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 36.675951}, "meta_inference_prompt_tokens": {"value": 15318.0}, "meta_inference_completion_tokens": {"value": 1877.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030636}, "meta_inference_completion_cost": {"value": 0.0030032}, "meta_eval_time": {"value": 56.737}, "meta_eval_prompt_tokens": {"value": 11458.0}, "meta_eval_completion_tokens": {"value": 5214.0}, "meta_eval_prompt_cost": {"value": 0.00366656}, "meta_eval_completion_cost": {"value": 0.00667392}}, "created": "2025-12-10T21:58:21.3432962Z"}
{"ref": "wide-penny", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 25.283991}, "meta_inference_prompt_tokens": {"value": 13046.0}, "meta_inference_completion_tokens": {"value": 1388.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026092}, "meta_inference_completion_cost": {"value": 0.0022208}, "meta_eval_time": {"value": 31.631}, "meta_eval_prompt_tokens": {"value": 8324.0}, "meta_eval_completion_tokens": {"value": 2973.0}, "meta_eval_prompt_cost": {"value": 0.00266368}, "meta_eval_completion_cost": {"value": 0.00380544}}, "created": "2025-12-10T21:58:21.7847725Z"}
{"ref": "wood-polytope", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.846153846153846}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.920743}, "meta_inference_prompt_tokens": {"value": 11224.0}, "meta_inference_completion_tokens": {"value": 584.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022448}, "meta_inference_completion_cost": {"value": 0.0009344}, "meta_eval_time": {"value": 18.082}, "meta_eval_prompt_tokens": {"value": 6054.0}, "meta_eval_completion_tokens": {"value": 1369.0}, "meta_eval_prompt_cost": {"value": 0.00193728}, "meta_eval_completion_cost": {"value": 0.00175232}}, "created": "2025-12-10T21:58:22.2511718Z"}
{"ref": "witty-type", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.517188}, "meta_inference_prompt_tokens": {"value": 12764.0}, "meta_inference_completion_tokens": {"value": 1189.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025528}, "meta_inference_completion_cost": {"value": 0.0019024}, "meta_eval_time": {"value": 22.968}, "meta_eval_prompt_tokens": {"value": 7424.0}, "meta_eval_completion_tokens": {"value": 2141.0}, "meta_eval_prompt_cost": {"value": 0.00237568}, "meta_eval_completion_cost": {"value": 0.00274048}}, "created": "2025-12-10T21:58:22.4443543Z"}
{"ref": "witty-type", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.923076923076923}, "generation_factuality_precision": {"value": 0.857142857142857}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.459653}, "meta_inference_prompt_tokens": {"value": 11555.0}, "meta_inference_completion_tokens": {"value": 1293.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002311}, "meta_inference_completion_cost": {"value": 0.0020688}, "meta_eval_time": {"value": 21.38}, "meta_eval_prompt_tokens": {"value": 6155.0}, "meta_eval_completion_tokens": {"value": 1746.0}, "meta_eval_prompt_cost": {"value": 0.0019696}, "meta_eval_completion_cost": {"value": 0.00223488}}, "created": "2025-12-10T21:58:22.4493256Z"}
{"ref": "wood-polytope", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.166666666666667}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.857142857142857}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0909090909090909}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.768497}, "meta_inference_prompt_tokens": {"value": 10062.0}, "meta_inference_completion_tokens": {"value": 692.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020124}, "meta_inference_completion_cost": {"value": 0.0011072}, "meta_eval_time": {"value": 17.114}, "meta_eval_prompt_tokens": {"value": 4881.0}, "meta_eval_completion_tokens": {"value": 1534.0}, "meta_eval_prompt_cost": {"value": 0.00156192}, "meta_eval_completion_cost": {"value": 0.00196352}}, "created": "2025-12-10T21:58:22.5207455Z"}
{"ref": "wood-polytope", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.285714285714286}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.866666666666667}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.166666666666667}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 15.175385}, "meta_inference_prompt_tokens": {"value": 7914.0}, "meta_inference_completion_tokens": {"value": 581.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0015828}, "meta_inference_completion_cost": {"value": 0.0009296}, "meta_eval_time": {"value": 17.359}, "meta_eval_prompt_tokens": {"value": 4229.0}, "meta_eval_completion_tokens": {"value": 1588.0}, "meta_eval_prompt_cost": {"value": 0.00135328}, "meta_eval_completion_cost": {"value": 0.00203264}}, "created": "2025-12-10T21:58:22.5508307Z"}
{"ref": "wood-polytope", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.846153846153846}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.25}, "retrieval_recall": {"value": 0.5}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 17.031029}, "meta_inference_prompt_tokens": {"value": 6924.0}, "meta_inference_completion_tokens": {"value": 678.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0013848}, "meta_inference_completion_cost": {"value": 0.0010848}, "meta_eval_time": {"value": 18.342}, "meta_eval_prompt_tokens": {"value": 3461.0}, "meta_eval_completion_tokens": {"value": 1390.0}, "meta_eval_prompt_cost": {"value": 0.00110752}, "meta_eval_completion_cost": {"value": 0.0017792}}, "created": "2025-12-10T21:58:23.1408754Z"}
{"ref": "wide-tempo", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.956521739130435}, "generation_factuality_f1": {"value": 0.769230769230769}, "generation_factuality_precision": {"value": 0.625}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 22.378605}, "meta_inference_prompt_tokens": {"value": 13125.0}, "meta_inference_completion_tokens": {"value": 1178.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002625}, "meta_inference_completion_cost": {"value": 0.0018848}, "meta_eval_time": {"value": 33.958}, "meta_eval_prompt_tokens": {"value": 8657.0}, "meta_eval_completion_tokens": {"value": 3044.0}, "meta_eval_prompt_cost": {"value": 0.00277024}, "meta_eval_completion_cost": {"value": 0.00389632}}, "created": "2025-12-10T21:58:23.2965197Z"}
{"ref": "witty-type", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.923076923076923}, "generation_factuality_f1": {"value": 0.727272727272727}, "generation_factuality_precision": {"value": 0.571428571428571}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 23.12431}, "meta_inference_prompt_tokens": {"value": 11469.0}, "meta_inference_completion_tokens": {"value": 1281.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022938}, "meta_inference_completion_cost": {"value": 0.0020496}, "meta_eval_time": {"value": 18.354}, "meta_eval_prompt_tokens": {"value": 6313.0}, "meta_eval_completion_tokens": {"value": 1632.0}, "meta_eval_prompt_cost": {"value": 0.00202016}, "meta_eval_completion_cost": {"value": 0.00208896}}, "created": "2025-12-10T21:58:23.3380526Z"}
{"ref": "wide-lens", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 28.468031}, "meta_inference_prompt_tokens": {"value": 14248.0}, "meta_inference_completion_tokens": {"value": 1649.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0028496}, "meta_inference_completion_cost": {"value": 0.0026384}, "meta_eval_time": {"value": 31.838}, "meta_eval_prompt_tokens": {"value": 8957.0}, "meta_eval_completion_tokens": {"value": 2821.0}, "meta_eval_prompt_cost": {"value": 0.00286624}, "meta_eval_completion_cost": {"value": 0.00361088}}, "created": "2025-12-10T21:58:23.8687438Z"}
{"ref": "white-lumen", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.789064826317888}, "generation_faithfulness": {"value": 0.942857142857143}, "generation_factuality_f1": {"value": 0.888888888888889}, "generation_factuality_precision": {"value": 0.8}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 20.948129}, "meta_inference_prompt_tokens": {"value": 13574.0}, "meta_inference_completion_tokens": {"value": 1729.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027148}, "meta_inference_completion_cost": {"value": 0.0027664}, "meta_eval_time": {"value": 43.755}, "meta_eval_prompt_tokens": {"value": 10090.0}, "meta_eval_completion_tokens": {"value": 3899.0}, "meta_eval_prompt_cost": {"value": 0.0032288}, "meta_eval_completion_cost": {"value": 0.00499072}}, "created": "2025-12-10T21:58:27.6916794Z"}
{"ref": "wide-tempo", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.826086956521739}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.331802}, "meta_inference_prompt_tokens": {"value": 13307.0}, "meta_inference_completion_tokens": {"value": 1360.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026614}, "meta_inference_completion_cost": {"value": 0.002176}, "meta_eval_time": {"value": 31.85}, "meta_eval_prompt_tokens": {"value": 8960.0}, "meta_eval_completion_tokens": {"value": 3109.0}, "meta_eval_prompt_cost": {"value": 0.0028672}, "meta_eval_completion_cost": {"value": 0.00397952}}, "created": "2025-12-10T21:58:29.1186883Z"}
{"ref": "witty-type", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.666666666666667}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.941176470588235}, "generation_factuality_f1": {"value": 0.833333333333333}, "generation_factuality_precision": {"value": 0.714285714285714}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 19.67815}, "meta_inference_prompt_tokens": {"value": 12168.0}, "meta_inference_completion_tokens": {"value": 968.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0024336}, "meta_inference_completion_cost": {"value": 0.0015488}, "meta_eval_time": {"value": 26.16}, "meta_eval_prompt_tokens": {"value": 6740.0}, "meta_eval_completion_tokens": {"value": 1875.0}, "meta_eval_prompt_cost": {"value": 0.0021568}, "meta_eval_completion_cost": {"value": 0.0024}}, "created": "2025-12-10T21:58:29.482571Z"}
{"ref": "wide-penny", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.894736842105263}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 30.118854}, "meta_inference_prompt_tokens": {"value": 12777.0}, "meta_inference_completion_tokens": {"value": 1660.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0025554}, "meta_inference_completion_cost": {"value": 0.002656}, "meta_eval_time": {"value": 39.897}, "meta_eval_prompt_tokens": {"value": 8302.0}, "meta_eval_completion_tokens": {"value": 3540.0}, "meta_eval_prompt_cost": {"value": 0.00265664}, "meta_eval_completion_cost": {"value": 0.0045312}}, "created": "2025-12-10T21:58:29.9579597Z"}
{"ref": "wide-tempo", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 0.869565217391304}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.602302}, "meta_inference_prompt_tokens": {"value": 13874.0}, "meta_inference_completion_tokens": {"value": 1152.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027748}, "meta_inference_completion_cost": {"value": 0.0018432}, "meta_eval_time": {"value": 32.736}, "meta_eval_prompt_tokens": {"value": 9678.0}, "meta_eval_completion_tokens": {"value": 3124.0}, "meta_eval_prompt_cost": {"value": 0.00309696}, "meta_eval_completion_cost": {"value": 0.00399872}}, "created": "2025-12-10T21:58:30.3448561Z"}
{"ref": "wide-tempo", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.63092975357146}, "generation_faithfulness": {"value": 0.84}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 18.423018}, "meta_inference_prompt_tokens": {"value": 13900.0}, "meta_inference_completion_tokens": {"value": 1134.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.00278}, "meta_inference_completion_cost": {"value": 0.0018144}, "meta_eval_time": {"value": 32.304}, "meta_eval_prompt_tokens": {"value": 9551.0}, "meta_eval_completion_tokens": {"value": 3162.0}, "meta_eval_prompt_cost": {"value": 0.00305632}, "meta_eval_completion_cost": {"value": 0.00404736}}, "created": "2025-12-10T21:58:32.0128485Z"}
{"ref": "wide-penny", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 22.630432}, "meta_inference_prompt_tokens": {"value": 11248.0}, "meta_inference_completion_tokens": {"value": 1321.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0022496}, "meta_inference_completion_cost": {"value": 0.0021136}, "meta_eval_time": {"value": 32.263}, "meta_eval_prompt_tokens": {"value": 6477.0}, "meta_eval_completion_tokens": {"value": 2853.0}, "meta_eval_prompt_cost": {"value": 0.00207264}, "meta_eval_completion_cost": {"value": 0.00365184}}, "created": "2025-12-10T21:58:32.0826669Z"}
{"ref": "wide-penny", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.0}, "retrieval_mrr": {"value": 0.0}, "retrieval_dcg": {"value": 0.0}, "generation_faithfulness": {"value": 0.9375}, "generation_factuality_f1": {"value": 0.0}, "generation_factuality_precision": {"value": 0.0}, "generation_factuality_recall": {"value": 0.0}, "retrieval_accuracy": {"value": 0.0}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.0}, "retrieval_recall": {"value": 0.0}, "generation_correctness": {"value": 0.0}, "meta_inference_time": {"value": 21.867969}, "meta_inference_prompt_tokens": {"value": 13298.0}, "meta_inference_completion_tokens": {"value": 1307.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026596}, "meta_inference_completion_cost": {"value": 0.0020912}, "meta_eval_time": {"value": 35.517}, "meta_eval_prompt_tokens": {"value": 8811.0}, "meta_eval_completion_tokens": {"value": 3265.0}, "meta_eval_prompt_cost": {"value": 0.00281952}, "meta_eval_completion_cost": {"value": 0.0041792}}, "created": "2025-12-10T21:58:34.6084949Z"}
{"ref": "white-lumen", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.64527201342591}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.666666666666667}, "generation_factuality_precision": {"value": 0.5}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 30.582693}, "meta_inference_prompt_tokens": {"value": 13533.0}, "meta_inference_completion_tokens": {"value": 1726.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027066}, "meta_inference_completion_cost": {"value": 0.0027616}, "meta_eval_time": {"value": 49.82}, "meta_eval_prompt_tokens": {"value": 10156.0}, "meta_eval_completion_tokens": {"value": 4502.0}, "meta_eval_prompt_cost": {"value": 0.00324992}, "meta_eval_completion_cost": {"value": 0.00576256}}, "created": "2025-12-10T21:58:35.1169651Z"}
{"ref": "violent-pedestal-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.4}, "retrieval_mrr": {"value": 0.611111111111111}, "retrieval_dcg": {"value": 2.06160631164485}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.875}, "generation_factuality_precision": {"value": 0.777777777777778}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.25}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.3}, "retrieval_recall": {"value": 0.6}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 33.973419}, "meta_inference_prompt_tokens": {"value": 14528.0}, "meta_inference_completion_tokens": {"value": 1659.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0029056}, "meta_inference_completion_cost": {"value": 0.0026544}, "meta_eval_time": {"value": 67.353}, "meta_eval_prompt_tokens": {"value": 11223.0}, "meta_eval_completion_tokens": {"value": 6159.0}, "meta_eval_prompt_cost": {"value": 0.00359136}, "meta_eval_completion_cost": {"value": 0.00788352}}, "created": "2025-12-10T21:58:36.4990861Z"}
{"ref": "violent-pedestal-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.666666666666667}, "retrieval_mrr": {"value": 0.456666666666667}, "retrieval_dcg": {"value": 2.72102457555333}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.580645161290323}, "generation_factuality_precision": {"value": 0.409090909090909}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.5}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.5}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 26.223643}, "meta_inference_prompt_tokens": {"value": 15222.0}, "meta_inference_completion_tokens": {"value": 1724.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030444}, "meta_inference_completion_cost": {"value": 0.0027584}, "meta_eval_time": {"value": 73.073}, "meta_eval_prompt_tokens": {"value": 11651.0}, "meta_eval_completion_tokens": {"value": 6139.0}, "meta_eval_prompt_cost": {"value": 0.00372832}, "meta_eval_completion_cost": {"value": 0.00785792}}, "created": "2025-12-10T21:58:37.1609406Z"}
{"ref": "wide-tempo", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.307692307692308}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.5}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.181818181818182}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 0.666666666666667}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 24.424729}, "meta_inference_prompt_tokens": {"value": 13877.0}, "meta_inference_completion_tokens": {"value": 1317.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027754}, "meta_inference_completion_cost": {"value": 0.0021072}, "meta_eval_time": {"value": 40.791}, "meta_eval_prompt_tokens": {"value": 9651.0}, "meta_eval_completion_tokens": {"value": 3228.0}, "meta_eval_prompt_cost": {"value": 0.00308832}, "meta_eval_completion_cost": {"value": 0.00413184}}, "created": "2025-12-10T21:58:39.0134818Z"}
{"ref": "white-lumen", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.657237182772003}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.823529411764706}, "generation_factuality_precision": {"value": 0.7}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.988948}, "meta_inference_prompt_tokens": {"value": 13483.0}, "meta_inference_completion_tokens": {"value": 1731.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0026966}, "meta_inference_completion_cost": {"value": 0.0027696}, "meta_eval_time": {"value": 63.356}, "meta_eval_prompt_tokens": {"value": 10688.0}, "meta_eval_completion_tokens": {"value": 4973.0}, "meta_eval_prompt_cost": {"value": 0.00342016}, "meta_eval_completion_cost": {"value": 0.00636544}}, "created": "2025-12-10T21:58:40.7329926Z"}
{"ref": "white-lumen", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.2}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 0.604529703103617}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.111111111111111}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.170165}, "meta_inference_prompt_tokens": {"value": 13571.0}, "meta_inference_completion_tokens": {"value": 1832.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027142}, "meta_inference_completion_cost": {"value": 0.0029312}, "meta_eval_time": {"value": 64.949}, "meta_eval_prompt_tokens": {"value": 10594.0}, "meta_eval_completion_tokens": {"value": 5477.0}, "meta_eval_prompt_cost": {"value": 0.00339008}, "meta_eval_completion_cost": {"value": 0.00701056}}, "created": "2025-12-10T21:58:42.3849516Z"}
{"ref": "wide-lens", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.153846153846154}, "retrieval_mrr": {"value": 1.0}, "retrieval_dcg": {"value": 1.0}, "generation_faithfulness": {"value": 0.96551724137931}, "generation_factuality_f1": {"value": 0.444444444444444}, "generation_factuality_precision": {"value": 0.285714285714286}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.0833333333333333}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.1}, "retrieval_recall": {"value": 0.333333333333333}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.73086}, "meta_inference_prompt_tokens": {"value": 14625.0}, "meta_inference_completion_tokens": {"value": 1502.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002925}, "meta_inference_completion_cost": {"value": 0.0024032}, "meta_eval_time": {"value": 32.708}, "meta_eval_prompt_tokens": {"value": 9222.0}, "meta_eval_completion_tokens": {"value": 2876.0}, "meta_eval_prompt_cost": {"value": 0.00295104}, "meta_eval_completion_cost": {"value": 0.00368128}}, "created": "2025-12-10T21:58:42.5014792Z"}
{"ref": "violent-pedestal-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.508333333333333}, "retrieval_dcg": {"value": 2.517782560806}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.086858}, "meta_inference_prompt_tokens": {"value": 13799.0}, "meta_inference_completion_tokens": {"value": 1928.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0027598}, "meta_inference_completion_cost": {"value": 0.0030848}, "meta_eval_time": {"value": 75.337}, "meta_eval_prompt_tokens": {"value": 11012.0}, "meta_eval_completion_tokens": {"value": 6861.0}, "meta_eval_prompt_cost": {"value": 0.00352384}, "meta_eval_completion_cost": {"value": 0.00878208}}, "created": "2025-12-10T21:58:43.5696481Z"}
{"ref": "yummy-torus", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.43067655807339}, "generation_faithfulness": {"value": 0.951219512195122}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 27.665732}, "meta_inference_prompt_tokens": {"value": 10255.0}, "meta_inference_completion_tokens": {"value": 1451.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002051}, "meta_inference_completion_cost": {"value": 0.0023216}, "meta_eval_time": {"value": 40.002}, "meta_eval_prompt_tokens": {"value": 7281.0}, "meta_eval_completion_tokens": {"value": 4444.0}, "meta_eval_prompt_cost": {"value": 0.00232992}, "meta_eval_completion_cost": {"value": 0.00568832}}, "created": "2025-12-10T21:58:46.598184Z"}
{"ref": "violent-pedestal-B", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.533333333333333}, "retrieval_mrr": {"value": 0.520833333333333}, "retrieval_dcg": {"value": 2.37707118843058}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 1.0}, "generation_factuality_precision": {"value": 1.0}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.363636363636364}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.4}, "retrieval_recall": {"value": 0.8}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.967331}, "meta_inference_prompt_tokens": {"value": 15119.0}, "meta_inference_completion_tokens": {"value": 2229.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0030238}, "meta_inference_completion_cost": {"value": 0.0035664}, "meta_eval_time": {"value": 90.189}, "meta_eval_prompt_tokens": {"value": 11865.0}, "meta_eval_completion_tokens": {"value": 6480.0}, "meta_eval_prompt_cost": {"value": 0.0037968}, "meta_eval_completion_cost": {"value": 0.0082944}}, "created": "2025-12-10T21:58:53.5960455Z"}
{"ref": "yummy-torus", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 1.38685280723454}, "generation_faithfulness": {"value": 0.977777777777778}, "generation_factuality_f1": {"value": 0.8}, "generation_factuality_precision": {"value": 0.666666666666667}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 25.042804}, "meta_inference_prompt_tokens": {"value": 10271.0}, "meta_inference_completion_tokens": {"value": 1333.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020542}, "meta_inference_completion_cost": {"value": 0.0021328}, "meta_eval_time": {"value": 48.943}, "meta_eval_prompt_tokens": {"value": 6953.0}, "meta_eval_completion_tokens": {"value": 4326.0}, "meta_eval_prompt_cost": {"value": 0.00222496}, "meta_eval_completion_cost": {"value": 0.00553728}}, "created": "2025-12-10T21:58:54.2224631Z"}
{"ref": "yummy-torus", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.786883745181415}, "generation_faithfulness": {"value": 0.851063829787234}, "generation_factuality_f1": {"value": 0.75}, "generation_factuality_precision": {"value": 0.6}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 28.512342}, "meta_inference_prompt_tokens": {"value": 10261.0}, "meta_inference_completion_tokens": {"value": 1533.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020522}, "meta_inference_completion_cost": {"value": 0.0024528}, "meta_eval_time": {"value": 49.809}, "meta_eval_prompt_tokens": {"value": 7323.0}, "meta_eval_completion_tokens": {"value": 4700.0}, "meta_eval_prompt_cost": {"value": 0.00234336}, "meta_eval_completion_cost": {"value": 0.006016}}, "created": "2025-12-10T21:58:56.1294321Z"}
{"ref": "yummy-torus", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.856207187108022}, "generation_faithfulness": {"value": 1.0}, "generation_factuality_f1": {"value": 0.571428571428572}, "generation_factuality_precision": {"value": 0.4}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 32.503989}, "meta_inference_prompt_tokens": {"value": 10206.0}, "meta_inference_completion_tokens": {"value": 1784.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.0020412}, "meta_inference_completion_cost": {"value": 0.0028544}, "meta_eval_time": {"value": 52.968}, "meta_eval_prompt_tokens": {"value": 7585.0}, "meta_eval_completion_tokens": {"value": 4787.0}, "meta_eval_prompt_cost": {"value": 0.0024272}, "meta_eval_completion_cost": {"value": 0.00612736}}, "created": "2025-12-10T21:59:01.3720303Z"}
{"ref": "yummy-torus", "set": "20251210152915", "metrics": {"retrieval_f1": {"value": 0.333333333333333}, "retrieval_mrr": {"value": 0.75}, "retrieval_dcg": {"value": 0.930676558073393}, "generation_faithfulness": {"value": 0.888888888888889}, "generation_factuality_f1": {"value": 0.461538461538462}, "generation_factuality_precision": {"value": 0.3}, "generation_factuality_recall": {"value": 1.0}, "retrieval_accuracy": {"value": 0.2}, "generation_should_answer_accuracy": {"value": 1.0}, "retrieval_precision": {"value": 0.2}, "retrieval_recall": {"value": 1.0}, "generation_correctness": {"value": 1.0}, "meta_inference_time": {"value": 21.570493}, "meta_inference_prompt_tokens": {"value": 10195.0}, "meta_inference_completion_tokens": {"value": 1348.0}, "meta_inference_tool_call_count": {"value": 1.0}, "meta_inference_prompt_cost": {"value": 0.002039}, "meta_inference_completion_cost": {"value": 0.0021568}, "meta_eval_time": {"value": 61.824}, "meta_eval_prompt_tokens": {"value": 6608.0}, "meta_eval_completion_tokens": {"value": 3924.0}, "meta_eval_prompt_cost": {"value": 0.00211456}, "meta_eval_completion_cost": {"value": 0.00502272}}, "created": "2025-12-10T21:59:10.588091Z"}
